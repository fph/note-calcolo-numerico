\documentclass[a4paper]{report}

\usepackage{amsmath,amsthm,amssymb,mathtools}

\usepackage{tikz}
\usepackage{pgfplots}

\usepackage{listings}
\lstset{basicstyle=\ttfamily}

\usepackage{algorithm2e}
\usepackage{booktabs}
\usepackage[italian]{babel}


\usepackage{hyperref}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollario}
\theoremstyle{definiton}
\newtheorem{definition}[theorem]{Definizione}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Osservazione}
\newtheorem{esercizio}[theorem]{Esercizio}

\newcommand{\x}{\mathbf{x}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\f}{\mathbf{f}}
\renewcommand{\b}{\mathbf{b}}
\renewcommand{\v}{\mathbf{v}}

\pgfplotsset{compat=1.17}

%\newcommand{\doteq}{\mathrel{\stackrel{\dot}{=}}}

\title{Note --- Calcolo Numerico}
\author{\texttt{federico.poloni@unipi.it}}
\date{}

\begin{document}
\maketitle

Queste note sono pensate per fare da `scaletta' della lezione per il corso per me mentre tengo le lezioni, e non necessariamente per essere usate come dispense o documento a sé stante.

Scelta degli argomenti, dimostrazioni ed esempi sono in parte presi dalle dispense di Luca Gemignani, Paolo Ghelardoni, Cecilia Magherini.


\chapter{Motivazione}

Vedremo algoritmi per risolvere al computer alcuni problemi che avete visto nei corsi di analisi e algebra lineare. 

\paragraph{Problemi senza soluzione esatta} Alcuni problemi non hanno una soluzione esatta data da una formula, per esempio $\int_0^1 e^{x^2} \mathrm{d}x$, ma si riescono a calcolare approssimazioni di queste soluzioni, per esempio approssimare un integrale tramite somme di Riemann. Vista la quantità di conti, meglio farlo fare a un computer.

\paragraph{Algoritmi lenti} Non sempre gli algoritmi che si vedono in un corso `teorico' funzionano bene su un computer. Ad esempio, consideriamo il calcolo del determinante di una matrice $A \in \mathbb{R}^{n\times n}$ tramite la formula di Laplace lungo la prima riga:
\[
    \det A = \sum_{j=1}^n (-1)^{j+1} a_{1j} A^{(1,j)}
\]
Qui $A^{1,j}$ il determinante della sottomatrice $(n-1)\times (n-1)$ che si ottiene eliminando da $A$ la riga 1 e la colonna $j$. Notiamo che per calcolare il determinante di una matrice $11\times 11$ bisogna calcolare $11$ determinanti di matrici $10\times 10$, che a loro volta richiedono ognuno il calcolo di $10$ determinanti di matrici $9\times 9$, e così via.

A meno che non ci siano proprietà particolari nella matrice $A$, come moltissime entrate uguali a zero, il calcolo di un determinante con questa formula è molto lento, non solo per un umano ma anche per un computer. Sul mio computer, i tempi crescono in questo modo in funzione della dimensione $n$:
\begin{center}
\begin{tikzpicture}
    \begin{axis}[ymode = log, xlabel={$n$}, ylabel={tempo / secondi}]
        \addplot[
    color=blue,
    mark=square,
    ]
    coordinates {
   (1.0000e+00,3.3700e-04)
   (2.0000e+00,8.9820e-04)
   (3.0000e+00,1.1920e-03)
   (4.0000e+00,2.5600e-03)
   (5.0000e+00,4.1300e-03)
   (6.0000e+00,1.3605e-02)
   (7.0000e+00,5.7616e-02)
   (8.0000e+00,3.0071e-01)
   (9.0000e+00,1.4279e+00)
   (1.0000e+01,1.4244e+01)
   (1.1000e+01,1.7992e+02)
   };    
    \end{axis}
\end{tikzpicture}
\end{center}
Per calcolare il determinante di una matrice $11\times 11$ ci vogliono più di 100 secondi! Un algoritmo così lento è poco utile in pratica.

\paragraph{Algoritmi inaccurati} Un altro fattore è \emph{come} il computer implementa certe operazioni. Numeri come $1/3$ o $\sqrt{2}$ hanno infinite cifre; non possiamo fare le operazioni ``in colonna''. Ci sono diversi modi di gestire i calcoli, ma per la maggior parte delle applicazioni l'esperienza ha insegnato che la strategia migliore è tenere (essenzialmente) solo un certo numero di cifre significative. Questo significa che certe operazioni sono approssimate; per esempio $\frac13 + \frac13 + \frac13 \approx 0.33333 + 0.33333 + 0.33333 = 0.99999 \neq 1$. Alcuni algoritmi vanno implementati con attenzione per evitare che queste approssimazioni che sembrano innocue abbiano un grosso impatto sul risultato. Per esempio: l'eliminazione di Gauss, o anche formule semplici come quella per risolvere un'equazione di secondo grado.

\paragraph{Importanza} Risolvere problemi computazionali al computer è diventato sempre più importante negli ultimi anni. Pensate per esempio a chi deve progettare un aereo. Quanto spessa deve essere la parete di metallo da usare nelle ali? Se è troppo spessa, il nostro aereo consuma più carburante del necessario. Se è troppo sottile, l'ala potrebbe rompersi. Una volta c'era un solo modo di scoprirlo: costruisci un prototipo di aereo, e vedi se cade o no. Oggi, la maggior parte di questi esperimenti possono essere rimpiazzati da simulazioni al computer. Va trovato il modo più efficiente di farle (un aereo è un oggetto molto complesso), ed è fondamentale capire se i risultati sono affidabili e se questi errori diventano così grandi da compromettere il risultato. Anche voi volete simulare reazioni e processi chimici.

\paragraph{Programmazione} L'altro scopo importante di questo corso è come \emph{programmare} un computer, cioè scrivere delle istruzioni per far eseguire sequenze specifiche di operazioni: non vogliamo calcolare noi le somme di Riemann di $\int_0^1 e^{x^2} \mathrm{d}x$, o il determinante di una matrice $11\times 11$, ma vogliamo imparare a fare in modo che il computer esegua questo calcolo per noi. Non vogliamo affidarci a un'app o un sito già fatto per ogni singolo problema, ma imparare come \emph{programmare} il computer in modo da saper risolvere da soli qualunque nuovo problema ci capiti davanti.

\chapter{Equazioni non lineari (zeri di funzione)}

\paragraph{Un esempio pratico} In termodinamica, esistono diverse formule che modificano l'equazione di stato dei gas perfetti e forniscono leggi che legano temperatura, pressione e volume. Una delle più famose è la \emph{formula di van der Waals}
\[
    P = \frac{RT}{V-B} - \frac{A}{V^2}.
\]
Qui $P$ è la pressione, $T$ è la temperatura, $V$ è il cosiddetto ``volume molare'', cioè il volume occupato da una mole del gas, e $R,A,B$ sono costanti (con $A,B$ che dipendono dal gas in questione). Supponiamo di sapere la pressione $P$ e la temperatura $T$, e voler calcolare il volume occupato da un gas. Questo è equivalente a trovare il valore $x$ che risolve
\[
    \frac{RT}{x-B} - \frac{A}{x^2} - P = 0.
\]
Lavorando con problemi ingegneristici è normale incontrare problemi come questi; in qualche caso siamo in grado di espandere i calcoli e risolvere esattamente l'equazione (per esempio perché si riconduce a trovare uno zero di un polinomio di grado $2$); ma in generale sarebbe utile avere a disposizione un metodo per calcolare approssimatamente la soluzione di equazioni anhce più complicate.

\paragraph{Il problema} Data una funzione $f: [a,b] \to \mathbb{R}$, vogliamo calcolare uno \emph{zero della funzione}, cioè un punto $\alpha$ tale che $f(\alpha) = 0$. Un altro esempio semplice è il calcolo di radici $n$-esime: calcolare $\sqrt[n]{a}$ è equivalente a trovare uno zero della funzione $f(x) = x^n - a$.

Ci potrebbero essere più soluzioni in un dato intervallo (a priori anche infinite!). Un modo conveniente di dimostrare che esiste \emph{almeno} una soluzione in un dato intervallo $[a,b]$ è mostrare che è un \emph{intervallo di separazione}, cioè $f(a)$ e $f(b)$ hanno segni opposti: $f(a)>0,f(b)<0$ oppure $f(a)>0,f(b)<0$. Un modo semplice di scrivere questa condizione è $f(a)f(b) < 0$. Difatti, ricordiamo questo teorema che avete visto ad analisi.
\begin{theorem}[Teorema degli zeri]
Sia $f \in \mathcal{C}^0([a,b])$. Se $f(a)$ e $f(b)$ hanno segno opposto (uno positivo e uno negativo), allora esiste almeno un reale $\alpha \in (a,b)$ tale che $f(\alpha) = 0$.
\end{theorem}
Detto in altro modo, se $f$ è una funzione continua e $[a,b]$ è un intervallo di separazione, allora esso contiene uno zero della funzione.

Questo risultato non ci assicura che lo zero sia unico. Se riusciamo a mostrare che $f$ è (strettamente) crescente o decrescente in $[a,b]$ (per esempio, per una $f\in\mathcal{C}^1$ mostrando che $f'(x) > 0$ per ogni $x\in (a,b)$ o $f'(x) < 0$ per ogni $x\in (a,b)$).

Esempio: per ogni $n>2, a > 0$, consideriamo la funzione $f(x) = x^n - a$. Si ha $f(0) = -a < 0$, mentre per $x$ sufficientemente grande si ha $f(x) > 0$ (difatti $x \to \infty$). Per esempio, $f(a) = a^n - a > 0$. Quindi $[0,a]$ è un intervallo di separazione, ed esiste una soluzione nell'intervallo. La soluzione è unica? La funzione $f$ ha derivata $f'(x) = nx^{n-1}$; quindi $f'(x) > 0$ per ogni $x > 0$, e $f'(0) = 0$. Questo permette di concludere che la soluzione è una sola. Come dimostrarlo formalmente? Un modo è tramite il teorema di Rolle, che avete sicuramente visto ad analisi. Lo enunciamo qui, con delle ipotesi forse un pochino più restrittive di quelle che avete visto ad analisi.

\begin{theorem}[Teorema di Rolle]
Sia $f:[a,b] \to \mathbb{R}$ una funzione di classe $\mathcal{C}^1$. Se $f(a) = f(b)$, allora esiste almeno un punto $c\in (a,b)$ in cui $f'(c) = 0$.
\end{theorem}

Se per assurdo esistessero due punti $a,b \in [0,\infty)$ tali che $f(a) = f(b) = 0$ (supponiamo per semplicità di avere scelto i nomi in modo che $a<b$), allora esisterebbe un punto $c \in (a,b) \subset (0,\infty)$ tale che $f'(c) = 0$, ma questo è impossibile perché abbiamo detto che $f'(x) > 0$ per $x>0$.

\section{Metodo di bisezione}

È un metodo che funziona con poche ipotesi sulla $f$: serve solo che $f \in \mathcal{C}^0([a,b])$, e che $[a,b]$ sia un intervallo di separazione.

\paragraph{Descrizione del metodo} L'idea del metodo è la seguente: voglio costruire una sequenza di intervalli di separazione $[a_k,b_k]$ sempre più piccoli. Parto ponendo $a_1 = a, b_1 = b$. A questo punto, calcolo $c_1 = \frac{a_1+b_1}{2}$, il punto medio tra $a_1$ e $b_1$. Se $f(c_1) = 0$, allora ho trovato uno zero e posso terminare. Altrimenti, uno dei due intervalli $[a_1,c_1]$ e $[c_1,b_1]$ è un intervallo di separazione, come si può vedere facilmente considerando i casi possibili per i segni. Quindi pongo $[a_2,b_2] = [a_1,c_1]$ oppure $[c_1,b_1]$. A questo punto posso ripetere la procedura a partire da $[a_2,b_2]$ e continuare.

\begin{algorithm}
$a_1=a,b_1=b$\;
\For{$k=1,2,\dots$}{
    $c_k = \frac{a_k + b_k}{2}$\;
    \uIf{$f(c_k) = 0$}{
        $\alpha = c_k$\;
        \textbf{break}\;
    }
    \uElseIf{$f(a_k)f(c_k) < 0$}{
        $a_{k+1} = a_k$, $b_{k+1} = c_k$\;
    }
    \uElse{
        $a_{k+1} = c_k$, $b_{k+1} = b_k$\;
    }
}
\caption{Il metodo di bisezione}
\end{algorithm}

\paragraph{Esempio} Prendiamo $f(x) = x^2 - 2$. L'intervallo $[a,b] = [0,2]$ è un intervallo di separazione, quindi contiene (almeno) uno zero $\alpha$ di $f$. Sappiamo già in realtà che ne contiene esattamente uno, $\alpha=\sqrt{2}$.

\begin{center}
    \begin{tabular}{cccccccc}
        \toprule
        $k$ & $a_k$ & $c_k$ & $b_k$ & $f(a_k)$ & $f(c_k)$ & $f(b_k)$\\
        \midrule
        1 & 0 & 1 & 2 & -2 & -1 & 2\\
        2 & 1 & 1.5 & 2 & -1 & 0.25 & 2\\
        3 & 1 & 1.25 & 1.5 & -1 & -0.4375 & 0.25\\
        $\vdots$\\
        \bottomrule
    \end{tabular}
\end{center}

\paragraph{Costo computazionale} Come vedremo, una delle domande importanti quando abbiamo un metodo numerico per calcolare qualcosa è: quanto tempo ci mette? In particolare, il tempo impiegato da un computer per eseguire un calcolo dipende dal numero di operazioni che lo compongono. Per esempio, calcolare la somma $1+2+3+\dots+10$ richiede $9$ somme; calcolare $1+2+3+\dots+20$ richiede $19$ somme, cioè circa il doppio, e ci aspettiamo che ci metta il doppio del tempo.

Nel caso del metodo di bisezione, la difficoltà maggiore nel calcolare il tempo è che non sappiamo quante operazioni sono necessarie per calcolare la $f$. Spesso il metodo viene usato con funzioni $f$ date da formule molto complicate, per cui anche solo calcolare la $f$ in un punto è dispendioso. Per questo ha senso chiedersi quante volte viene va calcolato il valore della funzione $f$ in ogni passo. Nei passi del metodo sono necessarie anche poche altre operazioni, quelle per calcolare $\frac{a_k+b_k}{2}$, ma il loro costo è tipicamente trascurabile rispetto a quello del calcolo della $f$, quindi possiamo ignorarle.

Guardando la tabella più sopra, possiamo vedere che, a parte il passo iniziale in cui abbiamo calcolato la $f$ tre volte, in $a_1,b_1,c_1$, in ogni passo successivo abbiamo calcolato il valore in \emph{un} solo nuovo punto, cioè $c_k$. Difatti, i valori di $f(a_k)$ e $f(b_k)$ sono già noti dal passo precedente, e ci è bastato ricopiarli dalla riga precedente della tabella.

Per questo diciamo che il costo per passo del metodo di bisezione è di una valutazione della funzione.

\paragraph{Criterio di arresto} Si può dimostrare formalmente (noi non lo faremo) che le successioni $a_k,b_k,c_k$ convergono a un valore $\alpha$ che è uno zero di $f$. A noi però interessa poco cosa succede al limite, perché possiamo fare solo un numero finito di passi.

%%
% enunciare un teorema?
%%

Supponiamo di voler determinare il valore $\alpha$ a meno di una tolleranza $\varepsilon$; in questo paragrafo vediamo come è possibile scegliere quanti passi fare in base a questo requisito.

È semplice vedere che ad ogni passo la lunghezza dell'intervallo si dimezza:
\[
b_{k+1} - a_{k+1} = \frac{b_{k} - a_{k}}{2} = \frac{b_{k-1} - a_{k-1}}{4} = \dots = \frac{b_{1} - a_{1}}{2^k}
\]
Quindi se ci fermiamo dopo $n$ iterazioni del metodo abbiamo un intervallo di ampiezza $\frac{b_1-a_1}{2^{n-1}}$ che contiene \emph{uno} zero $\alpha$ della funzione. Se vogliamo restituire \emph{un} valore che sia la migliore approssimazione possibile (con le informazioni a disposizione) di $\alpha$, la cosa migliore da fare è restituire il punto medio $c_n = \frac{a_n + b_n}{2}$. Difatti se $\alpha$ è un punto di cui sappiamo solo che sta nell'intervallo $(a_n,b_n)$, di ampiezza $\ell = \frac{b_1-a_1}{2^{n-1}}$, la distanza tra $\alpha$ e il punto medio dell'intervallo è al massimo $\ell/2$. Se restituissi $a_n$ o $b_n$ invece nel caso peggiore l'errore è $\ell$.
\begin{center}
    \begin{tikzpicture}[scale=0.5]
        \draw [->] (0,0) -- (10,0);
        \draw (2,0) node[below] {$a$} circle (2pt);
        \draw (8,0) node[below] {$b$} circle (2pt);
        \draw (5,0) node[below] {$c$} circle (2pt);
        \draw (2.5,0) node[below] {$\alpha$} circle (2pt);
        \end{tikzpicture}\\
        \begin{tikzpicture}[scale=0.5]
            \draw [->] (0,0) -- (10,0);
            \draw (2,0) node[below] {$a$} circle (2pt);
            \draw (8,0) node[below] {$b$} circle (2pt);
            \draw (5,0) node[below] {$c$} circle (2pt);
            \draw (7.5,0) node[below] {$\alpha$} circle (2pt);
            \end{tikzpicture}
\end{center}

Quindi, dato il valore $c_n$ restituito dopo $n$ passi del metodo di bisezione, sappiamo che esiste uno zero $\alpha$ di $f$ tale che 
\[
\abs{c_n - \alpha} \leq \frac{b_1-a_1}{2^{n}}.
\]
Dato un valore $\varepsilon > 0$ possiamo calcolare quante iterazioni sono necessarie perché il termine di destra di questa uguaglianza sia minore di $\varepsilon$. Questo succede per il primo intero $n$ tale che
\[
\frac{b_1 - a_1}{2^n} \leq \varepsilon \iff 2^n \geq \frac{b_1 - a_1}{\varepsilon} \iff n \geq \log_2 \frac{b_1 - a_1}{\varepsilon}.
\]

\paragraph{Criterio di arresto euristico} Un'altra idea naturale è fermarsi quando $f(c_k)$ è ``sufficientemente piccolo''. Abbiamo già accennato al fatto che su un computer i calcoli non vengono effettuati esattamente, ma solo con un certo numero di cifre significative. In particolare, la condizione di arresto $f(c_k) = 0$ potrebbe non essere mai verificata esattamente, ma quando $f(c_k)$ è molto piccolo potremmo decidere di essere soddisfatti e fermare il calcolo. È però vero che se abbiamo trovato un valore $c$ per cui $f(c)$ è piccolo, allora siamo vicini a uno zero $\alpha$? È facile costruire funzioni per cui questo non succede: basta prendere una funzione positiva che diminuisce fino ad arrivare molto vicino a zero e poi risale. Però possiamo introdurre un \emph{criterio euristico}, cioè un criterio non rigoroso (e di cui non è garantito il successo). 

Supponiamo di avere calcolato la funzione in un punto $c_k$, ottenendo $f(c_k)$. Una delle idee fondamentali dell'analisi è che se ``zoomiamo il grafico'' e ne guardiamo una sezione sufficientemente piccola, una funzione $f$ che sia \emph{differenziabile} si avvicina molto alla sua retta tangente. Pertanto, se $f$ è differenziabile in $c_k$,
\[
    f(x) \approx y = f(c_k) + f'(c_k)(x-c_k),
\]
dove a destra dell'uguale abbiamo l'equazione della retta tangente in $c_k$. Un modo di trasformare questa relazione in un'uguaglianza esatta è tramite lo sviluppo di Taylor: $f$ è una funzione di classe $\mathcal{C}^2$, allora per $x-c_k$ sufficientemente piccolo vale
\[
    f(x) = f(c_k) + f'(c_k)(x-c_k) + \frac{1}{2}f''(\xi) (x-c_k)^2,
\]
dove $\xi$ è un punto compreso nell'intervallo tra $c_k$ e $x$ (in qualunque ordine essi siano). Ci aspettiamo che l'ultimo termine sia piccolo, se stiamo guardando in una sezione abbastanza piccola del grafico: se $x-c_k$ è piccolo, $(x-c_k)^2$ lo è molto di più.

Supponiamo che ci sia uno zero $x = \alpha$ vicino a $c_k$; siamo in grado di valutare la distanza $\abs{\alpha - c_k}$ usando le formule sopra? Possiamo ricavare dalla prima formula
\[
\abs{c_k-\alpha} \approx \frac{\abs{f(c_k)}}{\abs{f'(c_k)}}.
\]
Rovesciando il ragionamento, se $\frac{\abs{f(c_k)}}{\abs{f'(c_k)}} \leq \varepsilon$ ci possiamo aspettare (ma non è garantito!) che $c_k$ disti al più $\varepsilon$ da uno zero $\alpha$ della funzione. Questo procedimento non è rigoroso però; può essere che la funzione $f$ vari più di quanto ci aspettiamo; questo succede per esempio quando $f''(\xi)$ è grande, o la funzione non è $\mathcal{C}^2$.

Notiamo il fatto interessante che non importa che $f$ sia piccolo in assoluto in $c_k$, ma che sia piccolo \emph{rispetto alla sua derivata}. Valore piccolo e derivata piccola vuol dire semplicemente che la nostra funzione è molto ``piatta'', non per forza che siamo vicini a uno zero.
\begin{center}
    \begin{tikzpicture}
        \draw[->] (-2,0) -- (5,0) node[right] {$x$};
        \draw[->] (0,-1) -- (0,2) node[above] {$y$};
        \draw (4.5,0) node[below] {$c_k$} circle (1pt);
        \draw (2,0) node[below] {$\alpha$} circle (1pt);
        
        \draw[domain=-1.5:4.5,smooth,variable=\x,blue] plot ({\x},{0.05*(\x-2)});      
    \end{tikzpicture}
\end{center}
È utile cercare di avere un criterio di arresto che non dipenda dal valore della funzione, perché questi possono variare molto a seconda delle applicazioni: se la funzione di cui cerchiamo uno zero ha a che vedere con le distanze tra gli atomi di una molecola, per esempio, la scala sull'asse delle $y$ sarà di circa $f(x) \approx 10^{-10}$ già di suo.

Ci manca ancora un ingrediente per completare questo criterio di arresto. Il valore di $f(c_k)$ viene calcolato lungo l'algoritmo, ma $f'(c_k)$ no, e calcolarlo può essere molto più complicato. Possiamo però rimpiazzarlo con un'altra approssimazione: se $c_k \in [a_k, b_k]$, allora
\[
f'(c_k) \approx \frac{f(b_k) - f(a_k)}{b_k - a_k}.
\]
Difatti questo è un rapporto incrementale fatto tra due punti sufficientemente vicini a $c_k$ (IMMAGINE). Ricordiamo anche un altro teorema di analisi, il teorema di Lagrange:
\begin{theorem}
    Se $f: [a,b] \to \mathbb{R}$ è una funzione di classe $\mathcal{C}^1$, allora esiste un punto $\xi \in (a,b)$ tale che
    \[
        f'(\xi) = \frac{f(b)-f(a)}{b-a}.
    \]
\end{theorem}
(Enunciamo questa versione per semplicità, in realtà forse nel corso di analisi avete visto il teorema con delle ipotesi leggermente diverse e meno restrittive). Questo dice che la quantità che stiamo calcolando è la derivata di $f$ in un punto $\xi$, diverso da $c_k$ (e dallo $\xi$ del teorema precedente!), ma non troppo lontano da esso.

Quindi un possibile criterio di arresto è: se vogliamo calcolare $\alpha$ con un errore (circa) $\varepsilon$, possiamo fermare il metodo quando vale la disuguaglianza 
\[
\abs{f(c_k)} \leq \abs*{\frac{f(b_k) - f(a_k)}{b_k-a_k}} \varepsilon
\]
(\emph{criterio di arresto sul residuo}).

\paragraph{Vantaggi e svantaggi del metodo di bisezione}

Vantaggi:

\begin{itemize}
    \item Si applica a molte funzioni: richiede solo la continuità di $f$.
    \item Funziona \emph{sicuramente} se partiamo da un intervallo di separazione, restituendo un intervallo piccolo a piacere che contiene uno zero della funzione: come vedremo, non tutti i metodi offrono una garanzia di convergenza.
\end{itemize}

Svantaggi:

\begin{itemize}
    \item Serve avere a disposizione un intervallo di separazione da cui iniziare.
    \item La convergenza è lenta rispetto ad altri metodi (vedremo più avanti come misurarla).
\end{itemize}


\section{Metodo del punto fisso}

Un altro algoritmo che ci permette di cercare zeri di funzioni è il \emph{metodo del punto fisso}, o di \emph{iterazione funzionale}. Per usare questo metodo, è necessario fare delle manipolazioni algebriche per riscrivere l'equazione dalla forma $f(x) = 0$ alla forma $x = \Phi(x)$, per un'opportuna funzione $\Phi$. Per esempio, se stiamo cercando uno zero della funzione $f(x) = x^3 - 2$, possiamo riscrivere l'equazione $f(x)$ in vari modi; per esempio: 
\begin{itemize}
    \item $x = x^3 - 2 + x$;
    \item $x = x - \frac16 (x^3-2)$;
    \item $x = \frac{2}{x^2}$.
\end{itemize}
Ognuno di queste scritture porta a una definizione diversa di $\Phi(x)$, la funzione che sta a destra dell'uguale. In tutti questi casi, uno zero $\alpha$ di $f(\alpha)=0$ è anche un \emph{punto fisso} di $\Phi$, cioè soddisfa $\alpha = \Phi(\alpha)$. Tutte queste possibilità portano a scelte diverse di $\Phi(x)$, e quindi a metodi che hanno (potenzialmente) comportamenti molto diversi. Alcuni di questi metodi potrebbero generare successioni che convergono a $\alpha$ ed altri no. Studiamo in generale questi metodi.

Il metodo del punto fisso funziona in questo modo: fissata una certa $\Phi:[a,b] \to \mathbb{R}$ e scelto $x_0 \in [a,b]$, costruiamo la successione
\begin{equation} \label{puntofisso}
    x_{n+1} = \Phi(x_n), \quad n=0,1,2,\dots    
\end{equation}

% \paragraph{Comportamento al limite (*)} Possiamo cercare di capire (non formalmente) come si comporta il metodo facendo uno sviluppo di Taylor in $\alpha$:
% \[
% x_{n+1} - \alpha = \Phi(x_n) - \alpha = \underbrace{\Phi(\alpha)}_{=\alpha} + \Phi'(\alpha)(x_n - \alpha) + \mathcal{O}((x_n-\alpha)^2) - \alpha \approx \Phi'(\alpha)(x_n - \alpha).
% \]
% Quindi ad ogni passo la distanza $x_n - \alpha$ è moltiplicata (approssimativamente) per $\Phi'(\alpha)$. Possiamo distinguere diversi casi:
% \begin{itemize}
%     \item Se $\Phi'(\alpha) \in (0,1)$, allora ci aspettiamo che le iterate si avvicinino ad $\alpha$, comportandosi come una progressione geometrica.
%     \item Se $\Phi'(\alpha) \in (-1,0)$, allora succede qualcosa di simile, ma le differenze $x_n-\alpha$ hanno segno che cambia ad ogni passo, quindi le iterate $x_n$ stanno una a sinistra e una a destra di $\alpha$, alternativamente.
%     \item Se $\abs{\Phi'(\alpha)} > 1$, la distanza delle iterate da $\alpha$ aumenta, anziché diminuire, quindi il metodo non converge.
%     \item Se $\Phi'(\alpha) = 0$, il metodo sembra convergere in un passo. In realtà questo vuol dire che la nostra scelta di trascurare $\mathcal{O}((x_n-\alpha)^2)$ non funziona bene, e dovremmo tener conto di quel termine.
%     \item  Se $\Phi'(\alpha) = 1$, similmente, la distanza $x_n - \alpha$ resta invariata nella nostra approssimazione, e ci tocca considerare anche il termine che abbiamo trascurato per capire se effettivamente le iterate si avvicinano o si allontanano da $\alpha$.
% \end{itemize}

% Tutte queste osservazioni però non sono rigorose visto che abbiamo trascurato un termine $\mathcal{O}((x_n-\alpha)^2)$. 

\paragraph{Teorema del punto fisso} Possiamo dimostrare questo risultato di convergenza:
\begin{theorem}[Convergenza locale del metodo del punto fisso] \label{thm:puntofisso}
Sia $\Phi \in \mathcal{C}^1([a,b])$, e $\alpha \in (a,b)$ un suo \emph{punto fisso}, cioè un punto tale che $\Phi(\alpha) = \alpha$. Supponiamo che esista un intervallo chiuso $I = [\alpha-\rho, \alpha+\rho] \subseteq [a,b]$ tale che $\abs{\Phi'(x)} < 1$ per ogni $x \in I$. Allora, il metodo~\eqref{puntofisso} è tale che per ogni $x_0 \in I$ si ha
\begin{itemize}
    \item $x_n \in I$ per ogni $n \geq 0$ (e quindi la successione è ben definita);
    \item $\lim_{n\to\infty} x_n = \alpha$.
\end{itemize}
\end{theorem}

%%
% Aggiungere qui un terzo punto su |x_{k+1}-\alpha| / |x_k-\alpha| \to |f'(\alpha)| ?
%%

\begin{proof}
Sia $L = \max_{x\in I} \abs{\Phi'(x)}$. Questo massimo esiste per il teorema di Weierstrass: $\abs{\Phi'(x)}$ è una funzione continua (in quanto composizione di $\abs{\cdot}$ e della funzione $\Phi'(x)$ che è continua in quanto $\Phi \in \mathcal{C}^1$) e l'intervallo $I$ è chiuso e limitato. Inoltre $L<1$.

Vogliamo dimostrare per induzione che 
\begin{equation} \label{fpindu}
    \abs{x_n - \alpha} \leq L^n \rho \quad \text{ per ogni $n \geq 0$}.    
\end{equation}
Per $n=0$, la~\eqref{fpindu} diventa $\abs{x_0 - \alpha} \leq \rho$, che è vera perché $x_0 \in I$. Supponiamo la~\eqref{fpindu} vera per un certo $n$, e dimostriamola per $n+1$:
\begin{equation} \label{fpindu2}
    \abs{x_{n+1} - \alpha} = \abs{\Phi(x_n) - \Phi(\alpha)} = \abs{\Phi'(\xi_n)} \abs{x_n - \alpha} \leq L L^n r = L^{n+1}\rho,    
\end{equation}
dove abbiamo usato il teorema di Lagrange, che dice che esiste un punto $\xi_k$ nell'intervallo aperto di estremi $x_n$ e $\alpha$ (in qualunque ordine essi siano) tale che $\Phi'(\xi_n) = \frac{\Phi(x_n) - \Phi(\alpha)}{x_n - \alpha}$. Visto che $x_n$ e $\alpha$ stanno entrambi in $I$, anche $\xi_n \in I$ e quindi $\abs{\Phi'(\xi_n)} \leq L$. 

Questo completa la dimostrazione della~\eqref{fpindu}. Da questa relazione si ha che $x_n \in I$, visto che $\abs{x_n - \alpha} \leq L^n \rho \leq \rho$. Inoltre
\[
0 \leq \abs{x_n - \alpha} \leq L^n \rho
\]
da cui per il teorema dei carabinieri segue che $\lim_{k\to \infty} x_n = \alpha$.
\end{proof}

\paragraph{Esempio} Consideriamo la funzione $\Phi(x) = x - \frac16 (x^3-2)$. Questa ha come punto fisso $\alpha =\sqrt[3]{2} \approx 1.26$. La sua derivata è $\Phi'(x) = 1 - \frac{1}{6}3x^2 = 1 - \frac{1}{2}x^2$. Si ha allora $\abs{\Phi'(x)}<1$ per $x \in (-2,0) \cup (0,2)$. Se prendiamo $\rho = 0.5$, abbiamo che su tutto l'intervallo
\[
    [\alpha-\rho,\alpha+\rho] \approx [1.26-0.5,1.26+0.5]
\]
si ha $\abs{\Phi'(x)}<1$. Possiamo quindi applicare il teorema, e concludere che il metodo converge per ogni scelta di $x_0$ in questo intervallo. Al posto di $0.5$, possiamo scegliere qualunque ampiezza $\rho < 2 - \sqrt[3]{2} \approx 0.74$ e la soluzione è analoga.

Consideriamo invece la funzione $\Phi(x) = \frac{2}{x^2}$, che ha sempre come punto fisso $x=\sqrt[3]{2}$. Questa volta si ha $\Phi'(x) = -\frac{4}{x^3}$, quindi $\Phi'(\alpha) = -2$. Non riusciremo mai a trovare un intervallo in cui applicare il teorema, perché già nel centro dell'intervallo non abbiamo $\abs{\Phi'(x)}< 1$. Si può difatti vedere che il metodo di punto fisso con questa funzione non converge ad $\alpha$, anzi, anche se partiamo da un $x_0$ molto vicino ad $\alpha$ (ma diverso da esso) le iterate si allontanano sempre di più.

\begin{remark} \label{oss:corpuntofisso}
    Se $\Phi(x) \in \mathcal{C}^1([a,b])$ e $\abs{\Phi'(\alpha)} < 1$ per un certo punto fisso $\alpha$, allora per continuità possiamo prendere un $\rho$ sufficientemente piccolo da avere $\abs{\Phi'(x)} < 1$ per ogni $x \in I = [\alpha - \rho, \alpha + \rho]$. Quindi le ipotesi del teorema di convergenza locale~\ref{thm:puntofisso} sono verificate per questo $\rho$. Non è semplice stabilire a priori quanto dev'essere piccolo $\rho$.
\end{remark}
    
\paragraph{Esempio}

Esercizio: consideriamo l'equazione di punto fisso $x = \cos x$ (con $x$ in radianti). Quante soluzioni positive ha? Sappiamo individuare esplicitamente un intervallo $I$ in cui si applica il teorema del punto fisso?

%%
% un po' palloso
%%

Svolgimento: una soluzione corrisponde a uno zero di $f(x) = x - \cos x$. Questa funzione è tale che $f(0) = -1$, $f(\pi/2) = \pi/2$, quindi esiste almeno uno zero in $(0,\pi/2)$. La derivata di questa funzione è $f'(x) = 1 + \sin(x) \geq 0$, che si annulla solo in punti isolati, quindi la funzione è strettamente crescente. Pertanto c'è \emph{solo} uno zero in $(0,\pi/2)$. Inoltre, non ci sono altri zeri in $[\pi/2, \infty)$ perché la funzione è strettamente positiva, $f(x) \geq x - 1 > 0$. La derivata $f'(x)$ è \emph{strettamente} minore di $1$ (in valore assoluto) al di fuori dei punti $-\pi/2, \pi/2$, e in generale tutti i punti della forma $\frac12 \pi + k\pi$, per $k\in\mathbb{Z}$. Quindi dobbiamo prendere un intervallo centrato in $\alpha \approx 0.7391$ che non contenga $-\pi/2 \approx -1.5708$ né $\pi/2 \approx 1.5708$.

\begin{esercizio}
    Consideriamo il metodo del punto fisso applicato a una funzione lineare $\Phi(x) = mx + q$. Sotto quali condizioni su $m$ e $q$ il metodo converge?
\end{esercizio}
\begin{esercizio}
    Applichiamo il metodo del punto fisso all'equazione $x = \Phi(x) = \frac13 + \frac23 x^2$. Quali sono gli zeri della funzione? Per quali valori di $x_0$ possiamo assicurare che il metodo converge usando il teorema visto?
\end{esercizio}

\section{Convergenza lineare di un metodo iterativo}

In questa sezione vediamo un modo di definire quanto velocemente converge un metodo numerico come quelli che abbiamo visto; 
questo è importante in modo da poter confrontare metodi diversi. Abbiamo una successione di approssimazioni $x_n$ di una certa soluzione esatta $\alpha$, ognuna calcolata da quella precedente. La successione si dice \emph{convergente} se l'errore $e_n := \abs{x_n - \alpha}$ tende a $0$. Partiamo con un esempio che mostra cosa succede in un caso reale; in Figura~\ref{fig:iterativi} abbiamo considerato diversi metodi iterativi per risolvere l'equazione $x^3-2 = 0$, e abbiamo tracciato per ognuno di essi un grafico dell'errore $e_n$ rispetto a $n$.
\begin{figure}
\begin{center}
    \begin{tikzpicture}
        \begin{axis}[width=0.7\textwidth, xlabel={iterazione}, ylabel={errore (in scala lineare)}]

            \addplot+[x=it, y=e] table{
                it e
           1.0000e+00   2.5992e-01
           2.0000e+00   4.9008e-01
           3.0000e+00   2.3298e-01
           4.0000e+00   3.0730e-02
           5.0000e+00   2.8083e-02
           6.0000e+00   2.0157e-02
           7.0000e+00   1.7687e-02
           8.0000e+00   1.3288e-02
           9.0000e+00   1.1349e-02
           1.0000e+01   8.7614e-03
           1.1000e+01   7.3487e-03
           1.2000e+01   5.7697e-03
           1.3000e+01   4.7814e-03
           1.4000e+01   3.7945e-03
           1.5000e+01   3.1195e-03
           1.6000e+01   2.4928e-03
           1.7000e+01   2.0385e-03
           1.8000e+01   1.6362e-03
           1.9000e+01   1.3334e-03
           2.0000e+01   1.0734e-03
           2.1000e+01   8.7269e-04
           2.2000e+01   7.0387e-04
           2.3000e+01   5.7139e-04
           2.4000e+01   4.6143e-04
           2.5000e+01   3.7421e-04
           2.6000e+01   3.0244e-04
           2.7000e+01   2.4511e-04
           2.8000e+01   1.9821e-04
           2.9000e+01   1.6057e-04
           3.0000e+01   1.2989e-04
           3.1000e+01   1.0519e-04
           3.2000e+01   8.5111e-05
           3.3000e+01   6.8917e-05
           3.4000e+01   5.5769e-05
           3.5000e+01   4.5153e-05
           3.6000e+01   3.6542e-05
           3.7000e+01   2.9583e-05
           3.8000e+01   2.3943e-05
           3.9000e+01   1.9383e-05
           4.0000e+01   1.5688e-05
           4.1000e+01   1.2700e-05
           4.2000e+01   1.0279e-05
           4.3000e+01   8.3208e-06
           4.4000e+01   6.7350e-06
           4.5000e+01   5.4518e-06
           4.6000e+01   4.4129e-06
            };
    
            \addplot+[x=it, y=e] table{
                it e
                   1.0000e+00   2.5992e-01
           2.0000e+00   2.4008e-01
           3.0000e+00   9.9210e-03
           4.0000e+00   1.1508e-01
           5.0000e+00   5.2579e-02
           6.0000e+00   2.1329e-02
           7.0000e+00   5.7040e-03
           8.0000e+00   2.1085e-03
           9.0000e+00   1.7977e-03
           1.0000e+01   1.5542e-04
           1.1000e+01   8.2114e-04
           1.2000e+01   3.3286e-04
           1.3000e+01   8.8716e-05
           1.4000e+01   3.3355e-05
           1.5000e+01   2.7681e-05
           1.6000e+01   2.8370e-06
           1.7000e+01   1.2422e-05
           1.8000e+01   4.7924e-06
           1.9000e+01   9.7769e-07
           2.0000e+01   9.2966e-07
           2.1000e+01   2.4019e-08
           2.2000e+01   4.5282e-07
           2.3000e+01   2.1440e-07
           2.4000e+01   9.5191e-08
           2.5000e+01   3.5586e-08
           2.6000e+01   5.7836e-09
           2.7000e+01   9.1175e-09
           2.8000e+01   1.6670e-09
           2.9000e+01   2.0583e-09
           3.0000e+01   1.9569e-10
           3.1000e+01   7.3564e-10
           3.2000e+01   2.6998e-10
           3.3000e+01   3.7145e-11
           3.4000e+01   7.9271e-11
           3.5000e+01   2.1063e-11
           3.6000e+01   8.0409e-12
           3.7000e+01   6.5110e-12
           3.8000e+01   7.6494e-13
           3.9000e+01   2.8730e-12
           4.0000e+01   1.0540e-12
           4.1000e+01   1.4455e-13
           4.2000e+01   3.1020e-13
            };
        
            \addplot+[x=it, y=e] table{
                it e
           1.0000e+00   7.4008e-01
           2.0000e+00   7.5992e-01
           3.0000e+00   2.9117e-01
           4.0000e+00   1.8458e-02
           5.0000e+00   3.1969e-03
           6.0000e+00   6.1883e-04
           7.0000e+00   1.1756e-04
           8.0000e+00   2.2414e-05
           9.0000e+00   4.2705e-06
           1.0000e+01   8.1376e-07
           1.1000e+01   1.5506e-07
           1.2000e+01   2.9547e-08
           1.3000e+01   5.6302e-09
           1.4000e+01   1.0728e-09
           1.5000e+01   2.0443e-10
           1.6000e+01   3.8955e-11
           1.7000e+01   7.4227e-12  
           1.8000e+01   1.4144e-12
           1.9000e+01   2.6956e-13
           2.0000e+01   5.1292e-14
            };
            
            \addplot+[x=it, y=e] table{
                it e
           1.0000e+00   7.4008e-01
           2.0000e+00   2.4008e-01
           3.0000e+00   3.6375e-02
           4.0000e+00   1.0112e-03
           5.0000e+00   8.1067e-07
           6.0000e+00   5.2158e-13
           7.0000e+00            0
            };
        \end{axis}
    \end{tikzpicture}
    
    \begin{tikzpicture}
    \begin{axis}[width=0.7\textwidth, ymode = log, xlabel={iterazione}, ylabel={errore (in scala logaritmica)}, legend style={at={(0.5,-0.15)},anchor=north}]

        \addplot+[x=it, y=e] table{
            it e
       1.0000e+00   2.5992e-01
       2.0000e+00   4.9008e-01
       3.0000e+00   2.3298e-01
       4.0000e+00   3.0730e-02
       5.0000e+00   2.8083e-02
       6.0000e+00   2.0157e-02
       7.0000e+00   1.7687e-02
       8.0000e+00   1.3288e-02
       9.0000e+00   1.1349e-02
       1.0000e+01   8.7614e-03
       1.1000e+01   7.3487e-03
       1.2000e+01   5.7697e-03
       1.3000e+01   4.7814e-03
       1.4000e+01   3.7945e-03
       1.5000e+01   3.1195e-03
       1.6000e+01   2.4928e-03
       1.7000e+01   2.0385e-03
       1.8000e+01   1.6362e-03
       1.9000e+01   1.3334e-03
       2.0000e+01   1.0734e-03
       2.1000e+01   8.7269e-04
       2.2000e+01   7.0387e-04
       2.3000e+01   5.7139e-04
       2.4000e+01   4.6143e-04
       2.5000e+01   3.7421e-04
       2.6000e+01   3.0244e-04
       2.7000e+01   2.4511e-04
       2.8000e+01   1.9821e-04
       2.9000e+01   1.6057e-04
       3.0000e+01   1.2989e-04
       3.1000e+01   1.0519e-04
       3.2000e+01   8.5111e-05
       3.3000e+01   6.8917e-05
       3.4000e+01   5.5769e-05
       3.5000e+01   4.5153e-05
       3.6000e+01   3.6542e-05
       3.7000e+01   2.9583e-05
       3.8000e+01   2.3943e-05
       3.9000e+01   1.9383e-05
       4.0000e+01   1.5688e-05
       4.1000e+01   1.2700e-05
       4.2000e+01   1.0279e-05
       4.3000e+01   8.3208e-06
       4.4000e+01   6.7350e-06
       4.5000e+01   5.4518e-06
       4.6000e+01   4.4129e-06
        }; \addlegendentry{Punto fisso su $\Phi(x) = 2/x^2 + (x^3-2)/4$};

        \addplot+[x=it, y=e] table{
            it e
               1.0000e+00   2.5992e-01
       2.0000e+00   2.4008e-01
       3.0000e+00   9.9210e-03
       4.0000e+00   1.1508e-01
       5.0000e+00   5.2579e-02
       6.0000e+00   2.1329e-02
       7.0000e+00   5.7040e-03
       8.0000e+00   2.1085e-03
       9.0000e+00   1.7977e-03
       1.0000e+01   1.5542e-04
       1.1000e+01   8.2114e-04
       1.2000e+01   3.3286e-04
       1.3000e+01   8.8716e-05
       1.4000e+01   3.3355e-05
       1.5000e+01   2.7681e-05
       1.6000e+01   2.8370e-06
       1.7000e+01   1.2422e-05
       1.8000e+01   4.7924e-06
       1.9000e+01   9.7769e-07
       2.0000e+01   9.2966e-07
       2.1000e+01   2.4019e-08
       2.2000e+01   4.5282e-07
       2.3000e+01   2.1440e-07
       2.4000e+01   9.5191e-08
       2.5000e+01   3.5586e-08
       2.6000e+01   5.7836e-09
       2.7000e+01   9.1175e-09
       2.8000e+01   1.6670e-09
       2.9000e+01   2.0583e-09
       3.0000e+01   1.9569e-10
       3.1000e+01   7.3564e-10
       3.2000e+01   2.6998e-10
       3.3000e+01   3.7145e-11
       3.4000e+01   7.9271e-11
       3.5000e+01   2.1063e-11
       3.6000e+01   8.0409e-12
       3.7000e+01   6.5110e-12
       3.8000e+01   7.6494e-13
       3.9000e+01   2.8730e-12
       4.0000e+01   1.0540e-12
       4.1000e+01   1.4455e-13
       4.2000e+01   3.1020e-13
        }; \addlegendentry{Bisezione su $f(x) = x^3-2$}
    
        \addplot+[x=it, y=e] table{
            it e
       1.0000e+00   7.4008e-01
       2.0000e+00   7.5992e-01
       3.0000e+00   2.9117e-01
       4.0000e+00   1.8458e-02
       5.0000e+00   3.1969e-03
       6.0000e+00   6.1883e-04
       7.0000e+00   1.1756e-04
       8.0000e+00   2.2414e-05
       9.0000e+00   4.2705e-06
       1.0000e+01   8.1376e-07
       1.1000e+01   1.5506e-07
       1.2000e+01   2.9547e-08
       1.3000e+01   5.6302e-09
       1.4000e+01   1.0728e-09
       1.5000e+01   2.0443e-10
       1.6000e+01   3.8955e-11
       1.7000e+01   7.4227e-12
       1.8000e+01   1.4144e-12
       1.9000e+01   2.6956e-13
       2.0000e+01   5.1292e-14
        }; \addlegendentry{Punto fisso su $\Phi(x) = x - (x^3-2)/4$};
        
        \addplot+[x=it, y=e] table{
            it e
       1.0000e+00   7.4008e-01
       2.0000e+00   2.4008e-01
       3.0000e+00   3.6375e-02
       4.0000e+00   1.0112e-03
       5.0000e+00   8.1067e-07
       6.0000e+00   5.2158e-13
       7.0000e+00            0
        }; \addlegendentry{Newton (punto fisso su $\Phi(x) = x-(x^3-2)/(3x^2)$)};
    
    \end{axis}
    \end{tikzpicture}
    \end{center}
\caption{Convergenza di diversi metodi iterativi per trovare uno zero di $f(x) = x^3-2$.} \label{fig:iterativi}
\end{figure}
La prima osservazione importante è che è utile usare una \emph{scala logaritmica} sull'asse delle $y$, come nel grafico in basso: con una scala lineare, non si riesce a valutare la velocità di convergenza dei metodi se non nelle primissime iterazioni, perché poi è tutto schiacciato sullo zero.

La seconda osservazione che possiamo fare è che nel secondo grafico i punti sono approssimativamente allineati secondo una retta. Vediamo perché questo succede.

\paragraph{Convergenza lineare} L'esempio più semplice che possiamo fare è quello in cui $e_n$ è una successione geometrica:
\[
e_0 = a,\, e_1 = ar,\, e_2 = ar^2,\, e_3 = ar^3, \dots
\]
Ad ogni passo, l'errore precedente viene moltiplicato per $r$. Ovviamente dobbiamo chiedere che $r < 1$, altrimenti $e_n$ non converge a $0$. In un grafico con scala logaritmica sulle $y$ (come quello della Figura~\ref{fig:iterativi}), la successione $e_k$ corrisponde a punti allineati lungo una retta di coefficiente angolare $\log r$ (che è negativo se $r<1$): difatti la differenza tra le ordinate di due punti successivi è il valore costante $\log e_{n+1} - \log e_n = \log r < 0$.

Molti metodi hanno un comportamento simile a questo al limite, quindi introduciamo una definizione che formalizza questo comportamento. Diciamo che un metodo iterativo \emph{converge linearmente} (o ha \emph{ordine di convergenza $1$}) quando
\begin{equation} \label{tassoconv}
    \lim_{n \to \infty }\frac{e_{n+1}}{e_n} = r \in (0,1).    
\end{equation}
Questo vuol dire che per $n$ sufficientemente grande (c'è un limite!) la successione degli errori si comporta come una successione geometrica. Questo corrisponde al comportamento che vediamo nel grafico per alcune delle successioni nella figura~\ref{fig:iterativi}: a parte i primissimi, i punti tendono ad essere allineati.

La convergenza è più veloce quanto più piccolo è $r$, che si chiama \emph{tasso di convergenza} (in inglese \emph{convergence rate}), o più informalmente spesso si usa \emph{velocità di convergenza}; difatti più piccolo è $r$, più ripida è la retta di coefficiente angolare $\log r$.

\paragraph{Tasso di convergenza del metodo di punto fisso} Riprendendo il calcolo fatto nell'equazione~\eqref{fpindu2}, abbiamo
\[
\lim_{n \to \infty} \frac{\abs{x_{n+1} - \alpha}}{\abs{x_n - \alpha}} = \lim_{n\to\infty} \abs{\Phi'(\xi_n)} = \abs{\Phi'(\alpha)} \in [0,1).
\]
L'ultima uguaglianza vale perché abbiamo $0 \leq \abs{\xi_n - \alpha} \leq \abs{x_n - \alpha}$, e quindi $\xi_n \to \alpha$ per il teorema dei carabinieri. Inoltre abbiamo usato di nuovo il fatto che $x \mapsto \abs{\Phi'(x)}$ è una funzione continua, per calcolare il limite.

Quindi il metodo del punto fisso ha convergenza \emph{almeno lineare}. Perché ``almeno''? Perché può succedere che $\abs{\Phi'(\alpha)} = 0$, allora punti successivi tendono ad essere allineati in verticale, e la successione va a zero più velocemente di qualunque retta sul grafico in scala logaritmica. Questo tipo di convergenza si chiama \emph{superlineare}. Per esempio, i punti potrebbero formare una parabola con la concavità verso il basso. Questo fenomeno succede per la quarta successione in Figura~\ref{fig:iterativi}, che converge più velocemente degli altri metodi. Studieremo questo metodo nel dettaglio più avanti.

\begin{esercizio}
    Consideriamo il metodo del punto fisso applicato a una funzione lineare $\Phi(x) = mx + q$. Quanto vale il tasso di convergenza $r$?
\end{esercizio}
\begin{esercizio}
    Quanto vale $r$ per i diversi metodi del punto fisso studiati più sopra per $f(x) = x^3 - 2$?
\end{esercizio}
\begin{esercizio}
    Supponiamo di avere una funzione con uno zero $\alpha = 1$, e di avere un metodo numerico che produce una successione $x_k$ che converge invece a $\lim x_k = 2$ (per esempio, per un errore di programmazione). Quanto vale il limite $r$ in~\eqref{tassoconv}?
\end{esercizio}
Dall'esercizio precedente, ricaviamo che $r \geq 1$ può essere un'indicazione che il metodo non sta convergendo, o sta convergendo alla soluzione sbagliata!

\paragraph{Tasso di convergenza del metodo di bisezione}

Nel caso del metodo di bisezione, non riusciamo a dimostrare una convergenza secondo questa definizione. Difatti può anche succedere che l'errore $e_k$ cresca da un passo all'altro: è facile costruire una situazione in cui lo zero $\alpha$ è più vicino a $c_k$ che a $c_{k+1}$. Ne abbiamo visto un esempio proprio quando abbiamo visto il nostro primo esempio per calcolare $\alpha=\sqrt{2}$: applicando il metodo di bisezione a quel problema, $\alpha=\sqrt{2}$ è più vicino a $c_2=1.5$ che a $c_3=1.25$. Il comportamento non monotono si vede chiaramente anche nella Figura~\ref{fig:iterativi}.

Riusciamo però a dimostrare che $e_n \leq \varepsilon_n$, dove $\varepsilon_n$ è una successione che converge linearmente: difatti abbiamo visto che
\[
e_n \leq \underbrace{\frac{b_1 - a_1}{2^n}}_{=\varepsilon_n},
\]
e naturalmente
\[
\lim \frac{\varepsilon_{n+1}}{\varepsilon_n} = \frac{1}{2}.
\]
Diciamo allora che il metodo di bisezione ha \emph{convergenza pressoché lineare}. Su un grafico in scala logaritmica, gli errori $e_n$ stanno al di sotto della retta data dai punti $\varepsilon_n$, e solitamente non se ne discostano troppo. Questo è confermato anche dalla nostra figura.

\paragraph{Criteri di arresto per il metodo del punto fisso}

Per un metodo come quello del punto fisso, il criterio di arresto più usato è quello di arrestarsi quando due iterate successive sono vicine, cioè $\abs{x_{n} - x_{n-1}} < \varepsilon$. È importante però osservare che questo non garantisce che $\abs{x_n - \alpha} < \varepsilon$. Difatti, supponiamo per semplicità che le iterate si comportino esattamente come una successione geometrica, cioè $e_n = \abs{x_n-\alpha} = ar^n$ (almeno da un certo punto in poi). Supponiamo anche, per fissare le idee, che le iterate stiano convergendo ad $\alpha$ dal basso, cioè $x_{n-1} < x_{n} < \alpha$. Allora, $x_{n} - x_{n-1} = e_{n-1} - e_n = ar^{n-1} - ar^n = ar^{n-1}(1-r) = e_n \frac{1-r}{r}$. Se $r$ è molto vicino a $1$, $\frac{1-r}{r}$ è molto vicino a $0$. Quindi possiamo avere una situazione in cui $\abs{x_{n-1}-x_n} = e_n \frac{1-r}{r}$ è al di sotto di una certa soglia $\varepsilon$, ma l'errore vero $e_n$ è molto più grande.

Quindi, quando $r$ è molto vicino a $1$, non solo il metodo converge lentamente, ma dobbiamo stare attenti a non arrestare il metodo troppo presto.

\paragraph{Vantaggi e svantaggi del metodo di punto fisso}

Svantaggi:
\begin{itemize}
    \item Convergenza non garantita se non in un intorno della soluzione. È difficile calcolare quanto è grande questo intorno: i teoremi non ci danno una formula facile da calcolare.
    \item Il criterio di arresto non garantisce un errore $\leq \varepsilon$.
\end{itemize}
Vantaggi del metodo:
\begin{itemize}
    \item A seconda della scelta della $\Phi$ (e quindi del valore di $r$), questo metodo può essere anche molto più veloce del metodo di bisezione.
    \item La convergenza è più regolare del metodo di bisezione, nel senso che la distanza da $\alpha$ scende sempre da un certo punto in poi. 
\end{itemize}


\section{Metodo di Newton}

Il metodo di Newton è un metodo per la ricerca di zeri che offre convergenza più veloce, ma richiede di essere in grado di calcolare non solo $f \in \mathcal{C}^1([a,b])$, ma anche la sua derivata $f'$.

L'idea è la seguente. Ad ogni passo, data un'approssimazione $x_n$ di una soluzione, calcoliamo $x_{n+1}$ calcolando uno zero della \emph{retta tangente} al grafico di $f(x)$ in $x_n$. L'equazione di questa retta è
\[
y(x) = f(x_n) + f'(x_n) (x- x_n),
\]
quindi $x_{n+1}$ è il punto tale che
\[
0 = y(x_{n+1}) = f(x_n) + f'(x_n) (x_{n+1}- x_n),
\]
ossia, risolvendo,
\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}.
\]

Il metodo di Newton è un metodo di punto fisso con funzione $\Phi(x) = x - \frac{f(x)}{f'(x)}$. Notiamo che questa funzione può non essere ben definita se $f'(x) = 0$: quando incontriamo un'iterata $x_n$ per cui si ha $f'(x_n) = 0$, il metodo di Newton fallisce e non riusciamo a calcolare l'iterata successiva.

Sotto l'ipotesi aggiuntiva $f'(\alpha) \neq 0$, riusciamo a dimostrare la convergenza locale del metodo di Newton.

\begin{theorem}
Sia $f \in \mathcal{C}^2([a,b])$, e sia $\alpha \in (a,b)$ tale che $f(\alpha) = 0$ e $f'(\alpha) \neq 0$. Allora, il metodo di Newton converge localmente: cioè, esiste un intervallo $I = [\alpha - \rho,\alpha + \rho]$ tale che per ogni successione generata dal metodo con $x_0 \in I$ si ha
\begin{itemize}
    \item $x_n \in I$ per ogni $n\geq 0$;
    \item $\lim_{n\to \infty } x_n = \alpha$.
\end{itemize}
\end{theorem}
\begin{proof}
Poiché $f'(\alpha) \neq 0$ e la funzione derivata $f'(x)$ è continua, in un intorno sufficientemente piccolo di $\alpha$ si ha $f'(x) \neq 0$. Inoltre, possiamo calcolare
\begin{equation} \label{Phiprime}
    \Phi'(x) = 1 - \frac{f'(x)f'(x) - f(x)f''(x)}{(f'(x))^2} = \frac{f(x)f''(x)}{(f'(x))^2};
\end{equation}
pertanto se $f'(\alpha) \neq 0$ abbiamo $\Phi'(\alpha) = 0$. Come nell'Osservazione~\ref{oss:corpuntofisso}, possiamo affermare che in un intorno sufficientemente piccolo di $\alpha$ avremo $\abs{\Phi'(x)} < 1$. Esiste quindi un intervallo $I$ centrato in $\alpha$ in cui la $\Phi(x)$ esiste (il denominatore non si annulla) e $\abs{\Phi'(x)} < 1$ per ogni $x\in I$. In questo intervallo possiamo applicare il teorema del punto fisso e quindi ottenere la tesi.
\end{proof}

\paragraph{Vantaggi e svantaggi del metodo di Newton}
Svantaggi:
\begin{itemize}
    \item Richiede di saper calcolare non solo $f$ ma anche $f'$: con Matlab, tipicamente dovremo passare due funzioni anziché una.
    \item Costo computazionale maggiore: ad ogni passo, dobbiamo valutare $f$ e $f'$ una volta.
    \item Convergenza non garantita.
\end{itemize}
Vantaggi:
\begin{itemize}
    \item Nella maggior parte dei casi, converge molto più velocemente degli altri metodi.
\end{itemize}

Il comportamento che si osserva tipicamente con il metodo di Newton è un certo numero di iterazioni iniziali in cui l'errore non scende per nulla o quasi, e poi una convergenza molto veloce; appena $x_n$ si avvicina a $\alpha$ e l'errore $e_n$ va sotto una certa soglia, esso comincia ad andare a zero molto velocemente.

\paragraph{Ordine di convergenza di un metodo iterativo}

Abbiamo visto che il metodo di Newton ha convergenza superlineare, cioè, il limite $\lim_{n \to \infty }\frac{e_{n+1}}{e_n}$ è uguale a zero: questo vuol dire che la successione degli errori $e_n$ va a zero più velocemente di una serie geometrica, qualunque sia la sua ragione $r$. In un grafico in scala logaritmica, la differenza di ordinata tra due punti successivi $\log e_{n+1} - \log e_n$ tende a $-\infty$. Fissato un qualunque $r>0$, abbiamo che da un certo punto in poi $\lim_{n \to \infty }\frac{e_{n+1}}{e_n} < r$, e  questo vuol dire che la successione degli errori $e_n$ sta al di sotto di una retta con coefficiente angolare $\log r$. In altre parole, un metodo con convergenza superlineare converge sempre (al limite) più velocemente di un metodo lineare.

Per valutare la velocità di convergenza di metodi superlineari in modo più preciso, introduciamo un'altra definizione: dato un $p > 1$, diciamo che un metodo iterativo ha \emph{ordine di convergenza $p$} se vale
\[
\lim_{n \to \infty }\frac{e_{n+1}}{e_n^p} = s \in (0,\infty).
\]
Notare che non stiamo chiedendo che $s<1$, a differenza della convergenza lineare: basta che $s$ sia un limite finito, per ottenere un metodo con convergenza superlineare. Difatti, se un metodo ha ordine di convergenza $p>1$ allora per qualunque $s<\infty$ vale
\begin{equation} \label{almeno}
\lim_{n \to \infty }\frac{e_{n+1}}{e_n} = \lim_{n \to \infty }\frac{e_{n+1}}{e_n^p} \cdot \lim_{n \to \infty } e_n^{p-1} = s \cdot 0 = 0.
\end{equation}

\paragraph{Esempio} La successione $x_n = 3\cdot 10^{-2^n}$ converge a $0$ con ordine di convergenza $2$: difatti si ha
\[
\frac{e_{n+1}}{e_n^2} = \frac{3\cdot 10^{-2^{n+1}}-0}{(3\cdot 10^{-2^n} - 0)^2} = \frac{3\cdot 10^{-2^{n+1}}}{9\cdot 10^{-2^{n+1}}} = \frac13.
\]
I primi elementi della successione sono $x_0 = 3\cdot 10^{-1}$, $x_1 = 3\cdot 10^{-2}$, $x_2 = 3\cdot 10^{-4}$, $x_3 = 3\cdot 10^{-8}$, $x_4 = 3\cdot 10^{-16}$, cioè $x_n = 0,00\dots03$, dove prima del $3$ ci sono $2^n$ zeri in totale (incluso quello prima della virgola). Il numero di zeri raddoppia ad ogni passo, e questo fa sì che la successione converga molto più velocemente che non una successione che converge linearmente. In un grafico in scala logaritmica, gli errori tendono a scendere come un'esponenziale, e la distanza (in verticale) tra due punti successivi $\log e_{n+1} - \log e_n$ raddoppia ad ogni passo.

Diciamo che un metodo numerico converge con ordine \emph{almeno $p$} se vale
\[
\lim_{n \to \infty }\frac{e_{n+1}}{e_n^p} = s \in [0,\infty).
\]
Questa volta abbiamo incluso lo zero tra i possibili valori ammessi per $s$. Notare che questo concetto di ``convergenza di ordine almeno $k$'' si comporta come ci aspettiamo dalle parole che abbiamo usato: se un metodo converge con ordine $k$, allora converge anche di ordine almeno $h$ per ogni $h\leq k$. (La dimostrazione di questo fatto, che non vediamo, è analoga alla~\eqref{almeno}.)

\paragraph{Convergenza quadratica} \begin{theorem}[Convergenza almeno quadratica del metodo di Newton] \label{thm:convnewton}
Supponiamo $f \in \mathcal{C}^2([a,b])$. Se il metodo di Newton converge a $\alpha \in (a,b)$ e se $f'(\alpha) \neq 0$ (cioè se $\alpha$ è uno \emph{zero semplice}), allora l'errore $e_n = \abs{x_n - \alpha}$ soddisfa
\[
\lim_{n\to \infty} \frac{e_{n+1}}{e_n^2} = s \in [0,\infty).
\]
(cioè questo limite esiste ed è finito.)
\end{theorem}

\begin{proof}
Usiamo uno sviluppo di Taylor (con resto di Lagrange) in $x_n$ per scrivere l'uguaglianza
\[
0 = f(\alpha) = f(x_n) + f'(x_n)(\alpha-x_n) + \frac{f''(\xi_n)}{2}(\alpha-x_n)^2
\]
che vale per uno $\xi_n$ compreso tra $\alpha$ e $x_n$.

Dividiamo per $f'(x_n)$ per ottenere
\[
\frac{f''(\xi_n)}{2f'(x_n)}(\alpha-x_n)^2 = - \frac{f(x_n)}{f'(x_n)} - \alpha + x_n   =  x_{n+1} - \alpha.
\]
Allora
\[
\frac{x_{n+1} - \alpha}{(x_n-\alpha)^2} = \frac{f''(\xi_n)}{2f'(x_n)}.
\]
Vogliamo ora passare al limite per $n \to \infty$. Sappiamo che $0 \leq \abs{\xi_n - \alpha} \leq \abs{x_n - \alpha}$, da cui per il teorema dei carabinieri concludiamo che $\abs{\xi_n - \alpha} \to 0$ e quindi $\xi_n \to \alpha$. Allora, di nuovo per continuità di queste funzioni, $f''(\xi_n) \to f''(\alpha)$ e $f'(x_n) \to f'(\alpha)$ (che è diverso da zero); quindi
\[
\lim_{n\to\infty} \frac{x_{n+1} - \alpha}{(x_n-\alpha)^2} = \lim \frac{f''(\xi_n)}{2f'(x_n)} = \frac{f''(\alpha)}{2f'(\alpha)} = s \in [0,\infty).
\]
\end{proof}

\paragraph{Criterio di arresto per il metodo di Newton} Come per il metodo di bisezione, un criterio di arresto euristico è: fermiamoci quando $\abs*{\frac{f(x_n)}{f'(x_n)}} \leq \varepsilon$; ci aspettiamo (senza garanzie!) che questo avvenga quando $\abs{x_n - \alpha} \leq \varepsilon$. Per come è definito il metodo, questo equivale a $\abs{x_n - x_{n+1}} \leq \varepsilon$, cioè, ci fermiamo quando due iterate successive sono abbastanza vicine.

\paragraph{Zeri di molteplicità superiore a 1} Cosa succede al metodo di Newton se la funzione a cui lo applichiamo ha $f'(\alpha) = 0$? Introduciamo innanzitutto una definizione: data una funzione $f\in\mathcal{C}^m$, diciamo che \emph{$f$ ha uno zero di molteplicità $m$ in $\alpha$} se vale
\[
f(\alpha) = f'(\alpha) = f''(\alpha) = \dots = f^{(m-1)}(\alpha) = 0, \quad \text{ ma } f^{(m)}(\alpha) \neq 0.
\]
Esempio: la funzione $f(x) = \sin(2x) - 2\sin(x)$ ha uno zero di molteplicità $3$ in $x=2\pi$. Difatti,
\begin{align*}
    f(\alpha) &= \sin(2\alpha) - 2\sin(\alpha) = 0 - 0 = 0,\\
    f'(\alpha) &= 2\cos(2\alpha) - 2\cos(\alpha) = 2 - 2 = 0,\\
    f''(\alpha) &= -4\sin(2\alpha) +2\sin(\alpha) = -0 + 0 = 0,\\
    f'''(\alpha) &= -8\cos(2\alpha) +2\cos(\alpha) = -8 + 2 \neq 0.
\end{align*}

È possibile dimostrare che questa definizione di molteplicità restituisce lo stesso risultato di quella che già conoscete per i polinomi: se un polinomio si fattorizza come
\[
    p(x) = (x-\alpha)^m g(x),
\]
dove $g(x)$ è il prodotto di tutti gli altri fattori di grado $1$ diversi da $(x-\alpha)$, allora $\alpha$ è uno zero di molteplicità $m$. Però la nostra definizione è più generale, in quanto si applica anche a funzioni che non sono polinomi.

È possibile anche dimostrare questo risultato, analogo a quello che si ha per i polinomi.
\begin{lemma}
Se $f\in\mathcal{C}^m([a,b])$ ha uno zero di molteplicità $m$ in $\alpha \in (a,b)$, allora si ha $f(x) = (x-\alpha)^m g(x)$, dove $g(x)$ è una funzione continua in $[a,b]$ con $g(\alpha) \neq 0$.
\end{lemma}
\begin{proof}
Definiamo $g(x) = \frac{f(x)}{(x-\alpha)^m}$. Questa funzione è definita su tutto $[a,b]$ tranne che in $x=\alpha$, dove si annulla il denominatore. Possiamo però estenderla per continuità. Per farlo, dobbiamo mostrare che esiste ed è finito il limite
\[
\lim_{x\to \alpha} \frac{f(x)}{(x-\alpha)^m}.
\]
Per calcolare questo limite, utilizziamo $m$ volte il teorema di De l'Hopital: 
\begin{align} \label{hop1}
\lim_{x\to \alpha} \frac{f(x)}{(x-\alpha)^m} &= \lim_{x\to \alpha} \frac{f'(x)}{m(x-\alpha)^{m-1}} = \lim_{x\to \alpha} \frac{f''(x)}{m(m-1)(x-\alpha)^{m-2}} = \dots \\
&= \lim_{x\to \alpha} \frac{f^{(m)}(x)}{m!\cdot 1} = \frac{f^{(m)}(\alpha)}{m!} = C\neq 0.
\end{align}
(Tutti i limiti tranne l'ultimo sono della forma $\frac{0}{0}$.)
Quindi possiamo definire
\[
    g(x) = \begin{cases}
        \frac{f(x)}{(x-\alpha)^m} & x\neq \alpha,\\
        C & x=\alpha.
    \end{cases}
\]
In questo modo la funzione $g(x)$ è continua su tutto $[a,b]$, ha $g(\alpha)\neq 0$, e soddisfa $f(x) = (x-\alpha)^m g(x)$, come richiesto.
\end{proof}
Dalla dimostrazione precedente ricaviamo anche un'altra conseguenza: si ha
\begin{equation}
    f(x) \sim C (x-\alpha)^m,
\end{equation}
dove stiamo usando una notazione dell'analisi: $a(x) \sim b(x)$ significa che $\lim a(x) / b(x) = 1$, in questo caso quando $x\to \alpha$. Allo stesso modo, abbiamo anche
\begin{equation} \label{lhopder}
    f'(x) \sim Cm (x-\alpha)^{m-1}, \quad \quad f''(x) \sim Cm(m-1)(x-\alpha)^{m-2}
\end{equation}
grazie alla~\eqref{hop1}.

Con questi risultati, possiamo dimostrare che se $\alpha$ è uno zero di molteplicità $m>1$, la convergenza del metodo di Newton è più lenta.
\begin{theorem}
    Sia $f(x) \in \mathcal{C}^2([a,b])$ una funzione con uno zero $\alpha \in (a,b)$ di molteplicità $m>1$.
    Allora, il metodo di Newton converge localmente ad $\alpha$, e la sua velocità di convergenza è lineare.
\end{theorem}
\begin{proof}
Vogliamo applicare di nuovo i risultati di convergenza locale del metodo di punto fisso; questa volta però ci scontriamo con il problema che la funzione $\Phi(x) = x - \frac{f(x)}{f'(x)}$ non è definita in $x=\alpha$, perché il denominatore si annulla.

Possiamo però estendere anche questa funzione per continuità. Poiché
\[
    \frac{f(x)}{f'(x)} \sim \frac{C(x-\alpha)^m}{Cm(x-\alpha)^{m-1}} \sim \frac{1}{m}(x-\alpha) \to 0,
\]
abbiamo
\begin{align*}
    \lim_{x\to\alpha} \Phi(x) &= \lim_{x\to\alpha} x - \frac{f(x)}{f'(x)} = \alpha - 0 = \alpha.
\end{align*}

Usando la~\eqref{Phiprime} e la~\eqref{lhopder}, abbiamo che
\begin{align*}
    \Phi'(x) = \frac{f(x)f''(x)}{(f'(x))^2} \sim \frac{C(x-\alpha)^m Cm(m-1)(x-\alpha)^{(m-2)}}{(Cm(x-\alpha)^{m-1})^2} = 
    \frac{m(m-1)}{m^2} = \frac{m-1}{m}.
\end{align*}
Ricordando la definizione di $\sim$, questo significa
\[
    \lim_{x\to\alpha} \Phi'(x) = \frac{m-1}{m}.
\]
Quindi è possibile\footnote{Per essere completamente rigorosi, dovremmo anche dimostrare che $\Phi'(\alpha)$ esiste ed è effettivamente uguale al suo limite; qui non lo vediamo.} estendere $\Phi(x)$ a una funzione di classe $\mathcal{C}^1$ con $\Phi(\alpha)=\alpha$ e $\Phi'(\alpha) = \frac{m-1}{m} < 1$. Quindi, per il teorema del punto fisso, il metodo di Newton converge (localmente) linearmente con tasso $\frac{m-1}{m}$.
\end{proof}

\paragraph{Metodo di Newton modificato} Data una funzione $f$ che ha uno zero di molteplicità $m$ in $\alpha$, abbiamo visto che la funzione
\[
    \Phi(x) = x - \frac{f(x)}{f'(x)},
\]
una volta estesa per continuità, soddisfa
\[
    \Phi'(\alpha) = 1 - \frac{1}{m}.
\]
%%%
% definire in generale un metodo di Newton con un parametro in più, e dire che se è uguale alla molteplicità viene superlineare?
%%%
Questo suggerisce di fare una modifica al metodo: se definiamo
\[
    \Phi_m(x) = x - m \frac{f(x)}{f'(x)}
\]
allora possiamo ripetere tutti i passaggi precedenti con un coefficiente $m$ davanti, e otteniamo
\[
    \Phi_m'(\alpha) = 1 - m\frac{1}{m} = 0.
\]

Quindi se il valore della molteplicità $m$ è noto a priori possiamo utilizzare il seguente (\emph{metodo di Newton modificato}):
\begin{equation} \label{newtonmod}
    x_{n+1} = \underbrace{x_n - m\frac{f(x_n)}{f'(x_n)}}_{:=\Phi_m(x_n)} \quad n = 0,1,2,\dots    
\end{equation}
Si può dimostrare, con passaggi simili a quelli precedenti, che questo metodo converge (localmente) con ordine almeno 2, quando viene applicato a una funzione che ha uno zero di molteplicità $m$.

\paragraph{Esercizi}

Esempio: metodo di Newton su una funzione lineare $f(x) = a x + b$ $\rightarrow$ convergenza in un passo.

Esempio: metodo di Newton su $f(x) = x^2-a$ $\rightarrow$ buono come metodo anche per calcolare radici quadrate a mano. Esempio: calcolando $\sqrt{17}$ con $x_0 = 4$, già $x_2$ ha 5 cifre significative esatte.

Esempio: metodo di Newton su $f(x) = x^2$ $\rightarrow$ la convergenza diventa lineare con ragione $\frac12$.

Esempio: metodo di Newton modificato su $f(x) = x^2$ per recuperare convergenza quadratica (converge di nuovo in un passo).

\paragraph{Varianti del metodo di Newton} Non sempre si ha a disposizione (in modo facile da calcolare) la derivata di una funzione $f$ di cui vogliamo trovare gli zeri. Per questo esistono alcune varianti che cercano di ``imitare'' il metodo di Newton ma senza dover calcolare derivate.
\begin{description}
    \item[Metodo delle corde] È l'iterazione $x_{n+1} = x_n - \frac{f(x_n)}{c}$, dove $c$ è un valore costante fissato. Per esempio, si può prendere $c = f'(x_0)$, se lo si conosce; questo richiede di calcolare la $f'$ una volta sola anziché una volta per passo come nel metodo di Newton. Geometricamente, questo metodo corrisponde a rimpiazzare le rette tangenti che si usano nel metodo di Newton con rette che hanno coefficiente angolare costante $c$. Un esempio di questo metodo è l'iterazione di punto fisso che abbiamo già studiato $x_{k+1} = x_{k} - \frac14 (x_k^3-2)$, dove la $c$ vale $\frac14$. Visto che questo è un metodo di punto fisso, possiamo studiarne la convergenza come per un normale metodo di punto fisso; in particolare, per applicare i teoremi di convergenza è necessario scegliere $c$ in modo che $\abs{f'(\alpha)} < 1$.
    \item[Metodo delle secanti] È l'iterazione che si ottiene rimpiazzando, nel metodo di Newton, $f'(x_n)$ con il rapporto incrementale calcolato sugli ultimi due punti,
    \[
    \frac{f(x_n) - f(x_{n-1})}{x_n - x_{n-1}}.
    \]
    In questo modo si rimpiazza la derivata con una sua approssimazione più economica da calcolare: abbiamo già calcolato $f(x_n)$ e $f(x_{n-1})$ nei passi precedenti del metodo, quindi dobbiamo fare solo due sottrazioni e una divisione (che in realtà diventa una moltiplicazione, quando si va a scrivere il metodo per esteso). Anche questo metodo converge localmente, e il suo di convergenza è $p = \frac{1+\sqrt{5}}{2} \approx 1.618$ (non lo dimostriamo, è più complesso: difatti non è un metodo del tipo $x_{n+1} = \Phi(x_n)$, perché ogni valore dipende dalle \emph{due} iterate precedenti). Per applicarlo, serve partire da \emph{due} punti iniziali $x_0$ e $x_1$.
\end{description}

% [Note per lezione Matlab:
% \begin{itemize}
%     \item Descrizione sintassi vettori e matrici: \lstinline{A = [1 2;3 4]}
%     \item Accesso elementi con \lstinline{A(1,2)}. Accesso elementi oltre i limiti.
%     \item \lstinline{size(), length()} 
%     \item Plot: esempio con plot della funzione quadrato.
%     \item Remark che esiste \lstinline{1:n} già fatto.
%     \item Funzioni già pronte per bisezione, punto fisso, Newton. Provarle su $f(x) = x^2 - 2$.
%     \item Calcolo dell'errore come \lstinline{abs(xs - sqrt(2))}.
%     \item Grafici in scala logaritmica.
% \end{itemize}
% ]

% \section{Condizionamento del problema della ricerca di zeri}

% Studiare il condizionamento di questo problema ci richiede di cambiare un po' le nostre definizioni, perché il suo ``input'' non è un numero ma una funzione $f$. Supponiamo qui che invece di ricevere in ``ingresso'' $f$ riceviamo una funzione $g$ che soddisfa $\max |g-f| \leq \delta$ (disegno). Può darsi che una piccola perturbazione sia sufficiente a trasformare un problema risolubile in uno non risolubile; per esempio se $f(x) = x^2$ e $g(x) = x^2 + \varepsilon$.

% Sia $\alpha$ uno zero di $f$. Supponiamo che $f$ sia derivabile con $f'(\alpha) \neq 0$, quindi ``taglia'' l'asse delle ascisse trasversalmente (ed è invertibile in un intorno di $\alpha$).

% Uno zero $\tilde{x}$ di $g$ (se c'è) deve stare per forza tra $f^{-1}(-\delta)$ e $f^{-1}(\delta)$. Sviluppando al primo ordine (e ricordando la derivata della funzione inversa),
% \[
% f^{-1}(\alpha + \delta) = f^{-1}(\alpha) + \delta\frac{1}{f'(\alpha)} + \mathcal{O}(\delta^2)
% \]
% Quindi $f^{-1}(\delta) - \alpha \doteq \frac{1}{f'(\alpha)}\delta$. Rifacendo lo stesso ragionamento su $-\delta$, si ha $f^{-1}(-\delta) - \alpha \doteq -\frac{1}{f'(\alpha)}\delta$, quindi
% \[
% \abs{\tilde{x} - \alpha} \stackrel{.}{\leq} \frac{1}{\abs{f'(\alpha)}} \delta.
% \]

% Per parlare di ``numero di condizionamento'' nello stesso senso usato sopra, ci serve parlare di errori \emph{relativi} sia sulla $\alpha$ che sulla $f$. Un modo di farlo è questo: scriviamo $M = \max_{[a,b]} |f|$, consideriamo una perturbazione $g$ tale che $\abs{f-g} \leq \varepsilon M$ (il nostro input), e chiamiamo $\tilde{x}$ uno zero della $f$ (il nostro output). Allora,
% \[
% \abs*{\frac{\tilde{x} - \alpha}{\alpha}}  \stackrel{.}{\leq} \frac{M}{\abs{\alpha f'(\alpha)}}.
% \]

\chapter{Aritmetica di macchina}

Se provate a implementare i metodi precedenti su un computer con Matlab, noterete in molti casi un comportamento abbastanza particolare: i metodi spesso smettono di convergere attorno a $10^{-15}$ o $10^{-16}$, come accade nella Figura~\ref{fig:iterativi2}. Per comprendere cosa sta succedendo, dobbiamo studiare come i numeri reali vengono rappresentati in un computer.

\begin{figure}
    \begin{center}
        \begin{tikzpicture}
        \begin{axis}[width=\textwidth, ymode = log, xlabel={iterazione}, ylabel={errore (in scala logaritmica)}, legend style={at={(0.5,-0.15)},anchor=north}]
            \addplot+[x=it, y=e] table{
                it e

                1.0000e+00   2.5992e-01
                2.0000e+00   4.9008e-01
                3.0000e+00   2.3298e-01
                4.0000e+00   3.0730e-02
                5.0000e+00   2.8083e-02
                6.0000e+00   2.0157e-02
                7.0000e+00   1.7687e-02
                8.0000e+00   1.3288e-02
                9.0000e+00   1.1349e-02
                1.0000e+01   8.7614e-03
                1.1000e+01   7.3487e-03
                1.2000e+01   5.7697e-03
                1.3000e+01   4.7814e-03
                1.4000e+01   3.7945e-03
                1.5000e+01   3.1195e-03
                1.6000e+01   2.4928e-03
                1.7000e+01   2.0385e-03
                1.8000e+01   1.6362e-03
                1.9000e+01   1.3334e-03
                2.0000e+01   1.0734e-03
                2.1000e+01   8.7269e-04
                2.2000e+01   7.0387e-04
                2.3000e+01   5.7139e-04
                2.4000e+01   4.6143e-04
                2.5000e+01   3.7421e-04
                2.6000e+01   3.0244e-04
                2.7000e+01   2.4511e-04
                2.8000e+01   1.9821e-04
                2.9000e+01   1.6057e-04
                3.0000e+01   1.2989e-04
                3.1000e+01   1.0519e-04
                3.2000e+01   8.5111e-05
                3.3000e+01   6.8917e-05
                3.4000e+01   5.5769e-05
                3.5000e+01   4.5153e-05
                3.6000e+01   3.6542e-05
                3.7000e+01   2.9583e-05
                3.8000e+01   2.3943e-05
                3.9000e+01   1.9383e-05
                4.0000e+01   1.5688e-05
                4.1000e+01   1.2700e-05
                4.2000e+01   1.0279e-05
                4.3000e+01   8.3208e-06
                4.4000e+01   6.7350e-06
                4.5000e+01   5.4518e-06
                4.6000e+01   4.4129e-06
                4.7000e+01   3.5721e-06
                4.8000e+01   2.8914e-06
                4.9000e+01   2.3404e-06
                5.0000e+01   1.8944e-06
                5.1000e+01   1.5335e-06
                5.2000e+01   1.2413e-06
                5.3000e+01   1.0047e-06
                5.4000e+01   8.1328e-07
                5.5000e+01   6.5831e-07
                5.6000e+01   5.3287e-07
                5.7000e+01   4.3133e-07
                5.8000e+01   3.4914e-07
                5.9000e+01   2.8261e-07
                6.0000e+01   2.2876e-07
                6.1000e+01   1.8517e-07
                6.2000e+01   1.4989e-07
                6.3000e+01   1.2132e-07
                6.4000e+01   9.8206e-08
                6.5000e+01   7.9493e-08
                6.6000e+01   6.4345e-08
                6.7000e+01   5.2084e-08
                6.8000e+01   4.2160e-08
                6.9000e+01   3.4126e-08
                7.0000e+01   2.7623e-08
                7.1000e+01   2.2360e-08
                7.2000e+01   1.8099e-08
                7.3000e+01   1.4650e-08
                7.4000e+01   1.1859e-08
                7.5000e+01   9.5990e-09
                7.6000e+01   7.7699e-09
                7.7000e+01   6.2893e-09
                7.8000e+01   5.0909e-09
                7.9000e+01   4.1208e-09
                8.0000e+01   3.3356e-09
                8.1000e+01   2.7000e-09
                8.2000e+01   2.1855e-09
                8.3000e+01   1.7691e-09
                8.4000e+01   1.4320e-09
                8.5000e+01   1.1591e-09
                8.6000e+01   9.3823e-10
                8.7000e+01   7.5945e-10
                8.8000e+01   6.1474e-10
                8.9000e+01   4.9760e-10
                9.0000e+01   4.0278e-10
                9.1000e+01   3.2603e-10
                9.2000e+01   2.6390e-10
                9.3000e+01   2.1362e-10
                9.4000e+01   1.7291e-10
                9.5000e+01   1.3996e-10
                9.6000e+01   1.1329e-10
                9.7000e+01   9.1706e-11
                9.8000e+01   7.4231e-11
                9.9000e+01   6.0086e-11
                1.0000e+02   4.8637e-11
                1.0100e+02   3.9369e-11
                1.0200e+02   3.1867e-11
                1.0300e+02   2.5795e-11
                1.0400e+02   2.0880e-11
                1.0500e+02   1.6901e-11
                1.0600e+02   1.3681e-11
                1.0700e+02   1.1074e-11
                1.0800e+02   8.9637e-12
                1.0900e+02   7.2558e-12
                1.1000e+02   5.8733e-12
                1.1100e+02   4.7542e-12
                1.1200e+02   3.8483e-12
                1.1300e+02   3.1151e-12
                1.1400e+02   2.5218e-12
                1.1500e+02   2.0413e-12
                1.1600e+02   1.6525e-12
                1.1700e+02   1.3376e-12
                1.1800e+02   1.0827e-12
                1.1900e+02   8.7641e-13
                1.2000e+02   7.0965e-13
                1.2100e+02   5.7443e-13
                1.2200e+02   4.6518e-13
                1.2300e+02   3.7637e-13
                1.2400e+02   3.0465e-13
                1.2500e+02   2.4647e-13
                1.2600e+02   1.9962e-13
                1.2700e+02   1.6165e-13
                1.2800e+02   1.3078e-13
                1.2900e+02   1.0569e-13
                1.3000e+02   8.5487e-14
                1.3100e+02   6.9056e-14
                1.3200e+02   5.5733e-14
                1.3300e+02   4.5075e-14
                1.3400e+02   3.6415e-14
                1.3500e+02   2.9310e-14
                1.3600e+02   2.3759e-14
                1.3700e+02   1.9318e-14
                1.3800e+02   1.5765e-14
                1.3900e+02   1.2657e-14
                1.4000e+02   1.0214e-14
                1.4100e+02   8.2157e-15
                1.4200e+02   6.6613e-15
                1.4300e+02   5.5511e-15
                1.4400e+02   4.6629e-15
                1.4500e+02   3.7748e-15
                1.4600e+02   3.3307e-15
                1.4700e+02   2.6645e-15
                1.4800e+02   1.9984e-15
                1.4900e+02   1.5543e-15
                1.5000e+02   1.1102e-15
                1.5100e+02   8.8818e-16
                1.5200e+02   6.6613e-16
                1.5300e+02   6.6613e-16
                1.5400e+02   6.6613e-16
                1.5500e+02   6.6613e-16
                1.5600e+02   6.6613e-16
                1.5700e+02   6.6613e-16
                1.5800e+02   6.6613e-16
                1.5900e+02   6.6613e-16
                1.6000e+02   6.6613e-16
                1.6100e+02   6.6613e-16
                1.6200e+02   6.6613e-16
                1.6300e+02   6.6613e-16
                1.6400e+02   6.6613e-16
                1.6500e+02   6.6613e-16
                1.6600e+02   6.6613e-16
                1.6700e+02   6.6613e-16
                1.6800e+02   6.6613e-16
                1.6900e+02   6.6613e-16
                1.7000e+02   6.6613e-16
                1.7100e+02   6.6613e-16
                1.7200e+02   6.6613e-16
                1.7300e+02   6.6613e-16
                1.7400e+02   6.6613e-16
                1.7500e+02   6.6613e-16
                1.7600e+02   6.6613e-16
                1.7700e+02   6.6613e-16
                1.7800e+02   6.6613e-16
                1.7900e+02   6.6613e-16
                1.8000e+02   6.6613e-16
                1.8100e+02   6.6613e-16
                1.8200e+02   6.6613e-16
                1.8300e+02   6.6613e-16
                1.8400e+02   6.6613e-16
                1.8500e+02   6.6613e-16
                1.8600e+02   6.6613e-16
                1.8700e+02   6.6613e-16
                1.8800e+02   6.6613e-16
                1.8900e+02   6.6613e-16
                1.9000e+02   6.6613e-16
                1.9100e+02   6.6613e-16
                1.9200e+02   6.6613e-16
                1.9300e+02   6.6613e-16
                1.9400e+02   6.6613e-16
                1.9500e+02   6.6613e-16
                1.9600e+02   6.6613e-16
                1.9700e+02   6.6613e-16
                1.9800e+02   6.6613e-16
                1.9900e+02   6.6613e-16
                2.0000e+02   6.6613e-16            
        }; \addlegendentry{Punto fisso su $\Phi(x) = 2/x^2 + (x^3-2)/4$};
        \end{axis}
        \end{tikzpicture}
        \end{center}
    \caption{Stagnazione di un metodo iterativo attorno alla precisione di macchina.} \label{fig:iterativi2}
    \end{figure}    

\paragraph{Rappresentazione in base}

Scegliamo un intero $\beta > 1$ che sarà la \emph{base} della nostra rappresentazione. Quella che segue è sostanzialmente la notazione scientifica che già conoscete.
\begin{theorem}[rappresentazione scientifica in base $\beta$]
Fissato un intero $\beta > 1$ (la \emph{base}), ogni numero reale $x\neq 0$ si può scrivere come
\begin{equation} \label{rapprbase}
    x = \pm \beta^p \sum_{i=1}^\infty c_i \beta^{-i},   
\end{equation}
dove i $c_i$ (\emph{cifre}) sono interi $0 \leq c_i < \beta$.

Questa scrittura è unica se aggiungiamo le condizioni che $c_1 \neq 0$, e che $c_i$ non sono tutti uguali a $\beta-1$ da un certo punto in poi.
\end{theorem}
Per esempio, $x = -764.88888\dots$ (periodico) si scrive in base $\beta=10$ come
\[
x = - 10^3 (7\cdot 10^{-1} + 6\cdot 10^{-2} + 4\cdot 10^{-3} + 8 \cdot 10^{-4} + 8 \cdot 10^{-5} + 8 \cdot 10^{-6} + \dots)
\]
Terminologia: $p$ si chiama \emph{esponente} di $x$, la quantità nella sommatoria si chiama \emph{mantissa}.

Non ci interessa qui dimostrare questo teorema: ``sappiamo che è vero'' fin dalla scuola primaria, e più si va verso fatti base e più bisogna essere puntigliosi e formali nelle dimostrazioni. Però ha senso soffermarsi sulle questioni di unicità.

La prima condizione $c_1 \neq 0$ serve a escludere scritture alternative con zeri iniziali, per esempio
\[
-764.88888 = - 10^5 (0 \cdot 10^{-1} + 0 \cdot 10^{-2} + 7\cdot 10^{-3} + 6\cdot 10^{-4} + 4\cdot 10^{-5} + \dots)
\]
Questa rappresentazione senza zeri iniziali si chiama \emph{normalizzata}.

La seconda è per escludere scritture come $0.999999\dots$ (periodico): se vi ricordate come si sommano le serie, questa scrittura è uguale a 1, ed è un modo diverso di scriverlo che vogliamo escludere.

\paragraph{Numeri di macchina}
Su un computer, possiamo rappresentare solo una quantità finita di numeri.
\begin{definition}
    L'insieme dei \emph{numeri di macchina (o floating-point) normalizzati}, $\mathbb{F}(\beta, t, m, M)$ è l'insieme dei numeri della forma
    \[
        \pm \beta^p \sum_{i=1}^t c_i \beta^{-i}, \quad p \in \{m, m+1, \dots, M\}  
    \]
\end{definition}
Ci sono due grossi cambiamenti rispetto alla~\eqref{rapprbase}: $t$ cifre (anziché infinite) nella mantissa, e un range finito per gli esponenti, da $m$ a $M$.

\paragraph{Esempio} Prendiamo i numeri di macchina costruiti con $\beta=10$, $t=2$, $m=-3$, $M=3$.

Il numero di macchina positivo più piccolo è $10^{-3}(1 \cdot 10^{-1} + 0 \cdot 10^{-2}) = 0.00010$. I numeri di macchina successivi sono:

si ottengono incrementando le cifre: $0.00011, 0.00012, \dots, 0.00099$. Difatti numeri intermedi, ad esempio $0.000101$, non si possono scrivere con sole due cifre più un esponente. A questo punto abbiamo elencato tutti i numeri con esponente $-3$; il numero di macchina ancora successivo ha esponente $-2$: $10^{-2}(1 \cdot 10^{-1} + 0 \cdot 10^{-2}) = 0.0010$. Si prosegue in questo modo, ottenendo
\begin{align*}
    &0.00010, 0.00011, 0.00012, \dots, 0.00099 & & \text{esponente $p=-3$}\\
    &0.0010, 0.0011, 0.0012, \dots, 0.0099 & & \text{esponente $p=-2$}\\
    &0.010, 0.011, 0.012, \dots, 0.099 & & \text{esponente $p=-1$}\\
    &0.10, 0.11, 0.12, \dots, 0.99 & & \text{esponente $p=0$}\\
    &1.0, 1.1, 1.2, \dots, 9.9 & & \text{esponente $p=1$}\\
    &10, 11, 12, \dots, 99 & & \text{esponente $p=2$}\\
    &100, 110, 120, \dots, 990 & & \text{esponente $p=3$}\\
\end{align*}
L'elenco che abbiamo fatto qui sopra quindi riporta tutti i numeri di macchina normalizzati positivi dell'insieme $\mathbb{F}(10, 2, -3, 3)$. A questi vanno aggiunti quelli negativi, che sono gli stessi ma con un segno meno davanti.

Notiamo che i numeri con esponente $-3$ hanno distanza $10^{-5}$ l'uno dal successivo; i numeri con esponente $-2$ hanno distanza $10^{-4}$ l'uno dal successivo, fino ai numeri con esponente $3$ che hanno distanza $10$.

\begin{esercizio}
    Qual è il più piccolo intero positivo che non appartiene all'insieme $\mathbb{F}(10, 2, -3, 3)$ riportato qui sopra?
\end{esercizio}
    
Se segniamo sulla retta reale i numeri di macchina quindi vediamo che i numeri più vicini allo zero ($p$ piccolo) hanno uno spazio minore tra l'uno e l'altro; non sono equispaziati. Vedremo però che queste spaziature variabili sono proprio quello che consente una buona approssimazione relativa.


Se $x$ è un numero di macchina, anche $-x$ lo è; quindi per enunciare le proprietà successive ci restringiamo ai numeri positivi; saranno valide anche per numeri negativi, ed è facile adattare le dimostrazioni.

\paragraph{Numero di macchina più piccolo, più grande, successivo}  
Il numero (positivo) più piccolo rappresentabile, che chiamiamo $\omega$, si ottiene scegliendo $p=m$ e mantissa $1000\dots 0$. Il numero più grande rappresentabile, $\Omega$, si ottiene scegliendo $p=M$ e mantissa con tutte cifre $\beta-1$.

Dato un numero di macchina normalizzato positivo $x = \beta^p \sum_{i=1}^t c_i \beta^{-i}$, il numero di macchina immediatamente successivo è quello che si ottiene aggiungendo $1$ all'ultima cifra, cioè $x + \beta^{p-t}$. Questo è chiaro se l'ultima cifra è diversa da $\beta-1$; se l'ultima cifra è $\beta-1$, aggiungendo 1 all'ultima cifra ci sono dei riporti, e la mantissa del risultato potrebbe avere $t+1$ cifre; però l'ultima cifra è $0$ e quindi si può omettere.


\paragraph{Altri valori rappresentabili}

Un computer oltre a questi numeri rappresenta alcuni valori speciali:
\begin{itemize}
    \item Lo zero (difficile fare senza, e non è un numero normalizzato!)
    \item $+\infty, -\infty, -0$: vengono aggiunti, con regole aritmetiche ispirate dall'analisi come $1/-\infty = -0$, per far sì che gli algoritmi possano funzionare anche in alcuni casi limite.
    \item \texttt{NaN}, che viene restituito come ``codice d'errore'' da alcune operazioni non valide come $0/0$.
    \item Alcuni numeri in più compresi tra $0$ e $\omega$, chiamati \emph{numeri denormalizzati}; non ci interessano qui.
\end{itemize}

\paragraph{Approssimazione con numeri di macchina}

\begin{theorem} Dato un numero reale $x \in [-\Omega, -\omega] \cup [\omega, \Omega]$, esiste un numero di macchina $\tilde{x}$ tale che
\begin{equation} \label{roundingerror}
    \frac{\abs{\tilde{x}-x}}{\abs{x}} < \beta^{1-t}.    
\end{equation}
\end{theorem}
\begin{proof}
Possiamo assumere che $x$ sia positivo (il caso negativo è analogo), e che non sia esso stesso un numero di macchina (altrimenti il risultato è ovvio). Allora $x$ è compreso tra due numeri di macchina successivi, chiamiamoli $\underline{x}$ e $\overline{x}$. In particolare, $\underline{x}$ si ottiene troncando la rappresentazione~\eqref{rapprbase}, cioè arrestando la sommatoria a $t$ anziché a $\infty$, e ha lo stesso esponente $p$ del numero $x$. Possiamo scegliere se prendere $\tilde{x} = \underline{x}$ (troncamento o arrotondamento verso $0$), $\tilde{x} = \overline{x}$ (arrotondamento verso infinito), o quello dei due che ha un errore minore (arrotondamento al più vicino); tutti questi forniscono arrotondamenti che soddisfano la~\eqref{roundingerror}. In ogni caso, visto che $x \in (\underline{x}, \overline{x})$, si ha 
\begin{equation}
    \tilde{x}-x < \overline{x} - \underline{x} = \beta^{p-t}.
\end{equation}
Inoltre, visto che la prima cifra di $x$ è almeno $1$ e le altre sono positive o nulle,
\begin{equation}
    x \geq \beta^{p-1}.
\end{equation}
Dividendo membro a membro queste due disuguaglianze (notare che i versi sono quelli giusti per farlo!) si ha la tesi.
\end{proof}

\paragraph{Errore relativo}
Data un'approssimazione $\tilde{x}$ di un numero reale $x \neq 0$, il suo \emph{errore relativo} è
\begin{equation} \label{relerr}
    \varepsilon = \frac{\tilde{x}-x}{x}.    
\end{equation}
È un oggetto molto naturale da considerare: l'errore assoluto $\abs{\tilde{x}-x}$ da solo non dice nulla: possiamo fare degli esempi dalla ``vita reale'' di errori su lunghezze e prezzi. Per esempio, aver misurato una lunghezza con un errore di $0.5 \text{ cm}$ da solo non vuol dire nulla: è molto diverso se questa lunghezza è la distanza dalla terra alla luna, o una tolleranza di fabbricazione sulla cover del vostro cellulare.

Possiamo riscrivere la~\eqref{relerr} come $\tilde{x} = x(1+\varepsilon)$. Quindi la~\eqref{roundingerror} dice che per ogni $x$ in quegli intervalli esiste un numero di macchina $\tilde{x} = x(1+\varepsilon)$ che lo approssima con un errore relativo che soddisfa $\abs{\varepsilon} \leq \beta^{1-t}$. La quantità $\mathsf{u} = \beta^{1-t}$ (\emph{precisione di macchina}) non dipende da $x$, ma solo dall'insieme di numeri di macchina scelto.


\paragraph{Numeri a doppia precisione}
Esiste uno standard (IEEE 754) per l'aritmetica di macchina che specifica quali parametri scegliere e il risultato di ogni operazione. Il formato più comune è quello noto come \texttt{double}, \texttt{float64} o \texttt{binary64}. Corrisponde a $\beta = 2, t=53, m=-1022, M = 1023$. Ogni numero viene rappresentato in 64 bit (=valori 0/1). Con questi valori ogni numero compreso tra $\omega \approx 2.2 \cdot 10^{-308}$ e $\Omega \approx 1.8 \cdot 10^{308}$ viene rappresentato con errore relativo $\mathsf{u} \approx 2.2 \cdot 10^{-16}$. Matlab (che useremo per programmare in questo corso) usa questo formato.

C'è anche un altro formato comune, chiamato \texttt{single} o \texttt{float32}, che ha un errore relativo di $\approx 10^{-8}$. È più impreciso, ma permette di memorizzare più numeri nello stesso spazio (32 bit l'uno).

Quando scriviamo (per esempio) \texttt{x = 0.3} in Matlab, questo numero non viene memorizzato esattamente: non appartiene a $\mathbb{F}(2, 53, -1022, 1023)$, ma anzi in base 2 è il numero periodico $0.0\overline{1001}$. Questo numero periodico viene troncato a $t=53$ cifre. Quindi il numero con cui il computer lavora non è \emph{esattamente} $0.3$, bensì
\[
\tilde{x} = 0.2\underbrace{999999999999999}_{\text{15 volte 9}}88897769753748434595763683319091796875,
\]
che ha un errore relativo minore di $2.2 \cdot 10^{-16}$, come promesso dal teorema.

Per fare qualche esperimento: \url{https://www.exploringbinary.com/floating-point-converter/}.

\paragraph{Operazioni di macchina}

Una volta memorizzati due numeri, possiamo chiedere al computer di calcolarne la somma, per esempio se scrivete in Matlab
\texttt{x = 0.3; y = 0.4; x + y} viene visualizzato un risultato.

Sappiamo già che il computer memorizza approssimazioni $\tilde{x}$ e $\tilde{y}$ di 0.3 e 0.4, che soddisfano $\tilde{x} = 0.3(1+\varepsilon_1), \tilde{y} = 0.4(1+\varepsilon_2)$, con $\abs{\varepsilon_i} \leq \mathsf{u}$. Ma c'è una terza fonte di errore: anche se $\tilde{x}$ e $\tilde{y}$ sono numeri di macchina, la loro somma $\tilde{x} + \tilde{y}$ potrebbe non esserlo; quindi va approssimata anche lei con un numero di macchina. L'operazione ``calcola la somma di $\tilde{x}$ e $\tilde{y}$ e rimpiazzala con il numero di macchina più vicino'' viene indicata con $\tilde{x} \oplus \tilde{y}$. Analogamente definiamo $\ominus, \odot, \oslash$. Quindi $ \tilde{x} \oplus \tilde{y} = (\tilde{x}+\tilde{y})(1+\varepsilon)$, per un opportuno errore $\varepsilon$ che soddisfa $\abs{\varepsilon} \leq \mathsf{u}$, e analogamente per le altre operazioni.

\paragraph{Underflow/overflow}

Eseguendo queste operazioni, si possono incontrare numeri più grandi di $\Omega$ in valore assoluto. Questi numeri vengono rimpiazzati con $+\infty$ o $-\infty$. Questo fenomeno si chiama \emph{overflow}. Similmente, quando le operazioni producono numeri più piccoli di $\omega$ in valore assoluto, questi vengono rimpiazzati con $0$ (\emph{underflow}).

\paragraph{Esempi} Consideriamo di nuovo il sistema di numerazione con $\beta=10, t=2, m=-3, M=3$. Qual è il risultato delle seguenti operazioni (arrotondando al più vicino)? $0.1 \ominus 0.001$; $1.01 \ominus 1.01$; $(0.77 \oplus 0.44) \oplus 1$; $0.077 \oplus (0.044 \oplus 1)$; $(1 \oslash 3) \otimes 3$; $500 \oplus 500$; $0.001 \odot 0.001$; $50 \oplus 0.01$.


\paragraph{Commenti} Perché è stato scelto questo sistema per rappresentare i numeri reali sul computer? Esistono alternative, come fare i conti con razionali esatti (ma i numeratori diventano presto \emph{molto} grandi anche quando si fanno operazioni semplici) o tenere traccia degli errori calcolando esplicitamente degli intervalli di inclusione per ogni quantità calcolata (ma gli intervalli diventano presto \emph{molto} grandi anche quando si fanno operazioni semplici). Alla fine questo sistema è quello che si è affermato negli anni come il più comodo con cui fare i conti nelle applicazioni, ed è diventato lo standard. Ciononostante ci sono delle approssimazioni, per cui è importante comprendere teoricamente il loro impatto.

\chapter{Analisi dell'errore}

Con un computer, possiamo calcolare il risultato di problemi numerici, come ``trovare quanto fa $(0.7)^3$'' o ``trovare la radice cubica di $2$'', che ora sappiamo risolvere perché equivale a ``trovare $\alpha\in [0,2]$ che sia uno zero della funzione $x^3-2$.''.

La maggior parte dei problemi numerici dipendono da uno o più dati in ingresso, per esempio il problema ``trovare la radice cubica del numero $a$'' dipende da $x\in\mathbb{R}$. Possiamo quindi considerarli come il calcolo di una funzione $x = f(a,b,c,\dots,)$ che dipende da uno o più dati di ingresso (input) $a,b,c,\dots$.

Supponiamo di voler usare il calcolatore per calcolare una quantità $x = f(a)$ che dipende da un numero reale $a$. Attenzione che in generale questa non è la stessa $f$ del problema della ricerca di zeri! Se stiamo cercando la radice cubica di un numero $a$, per esempio, la funzione che vogliamo calcolare è $f(a) = x^{1/3}$.

Supponiamo per ora che $f$ sia una funzione razionale, cioè che si scrive combinando solo le quattro operazioni. Per esempio, $f(a) = a^2 - 3/a$, e vogliamo calcolare il suo valore nel punto $a = 0.2$. Per esempio con Matlab
\begin{lstlisting}
a = 0.2;
x = a^2 - 3/a
\end{lstlisting}
Ci sono due diverse fonti di errore che fanno sì che la quantità calcolata non sia il risultato esatto.
\begin{description}
    \item[Errore inerente] Il computer lavora non con il dato di partenza esatto $a$, ma con una sua approssimazione $\tilde{a}$ affetta da un errore relativo $\varepsilon$. Questo succede sicuramente tutte le volte che $a$ non è un numero di macchina, perché per utilizzarlo il computer deve approssimarlo con un numero di macchina $\tilde{a} = a(1+\varepsilon)$, commettendo un errore relativo $\abs{\varepsilon} \leq \mathsf{u}$. Però ci possono essere altre fonti di errori: per esempio, $a$ potrebbe essere a sua volta il risultato di operazioni precedenti, o potrebbe venire da una misurazione nel mondo reale (quindi affetto da un errore che tipicamente è molto più grande di $\mathsf{u}$). Quindi il computer in realtà può calcolare solo $f(\tilde{a})$ commettendo un \emph{errore inerente} pari a
    \begin{equation} \label{e_in}
        e_{in} = \frac{f(\tilde{a}) - f(a)}{f(a)}.    
    \end{equation}
    IMMAGINE illustrativa: grafico di una funzione in floating point ``per punti''.

    \item[Errore algoritmico] Per quanto visto sopra, il computer può effettuare le operazioni aritmetiche solo approssimando il loro risultato con numeri di macchina; quindi può calcolare non $f(\tilde{a})$, bensì un'altra funzione $h(\tilde{a})$. Per esempio, dando i comandi più sopra, invece di $f(\tilde{a}) = a^2 - 3/a$, il computer calcolerà $h(\tilde{x}) = \tilde{a} \otimes \tilde{a} \ominus 3 \oslash \tilde{a}$. La differenza tra queste due funzioni determina un \emph{errore algoritmico}
    \[
    e_{alg} = \frac{h(\tilde{a}) - f(\tilde{a})}{f(\tilde{a})}.
    \]
\end{description}

\paragraph{Errore totale} Combinando i due concetti, è naturale considerare l'\emph{errore totale}, cioè
\[
e_{tot} = \frac{h(\tilde{a}) - f(a)}{f(a)}.
\]
Vediamo ora un teorema che consente di darne un'espressione approssimata. Essa è approssimata perché assumiamo che entrambi questi errori siano piccoli, e ignoriamo termini che contengono il prodotto di due errori: un po' come approssimare $\exp(x) \approx 1 + x$ per valori di $x$ piccoli, ignorando i termini di grado superiore $x^2, x^3, \dots$ perché sono molto più piccoli di $x$. 

Nel seguito, usiamo il simbolo $a \doteq b$ per indicare che $a$ e $b$ sono uguali a patto di ignorare ``termini di ordine superiore''. Cosa siano esattamente dipende dal contesto: in questo caso, termini che sono il prodotto di due o più errori.

\begin{theorem}
\[
e_{tot} \doteq e_{in} + e_{alg}.
\]
\end{theorem}
\begin{proof} Notiamo innanzitutto che riarrangiando la~\eqref{e_in} si ottiene
\[
f(\tilde{a}) = f(a)(1+e_{in}).
\]
Ora possiamo scrivere
\begin{align*}
e_{tot} &= \frac{h(\tilde{a}) - f(a)}{f(a)} = \frac{h(\tilde{a}) - f(\tilde{a})}{f(a)} + \frac{f(\tilde{a}) - f(a)}{f(a)}\\
&= e_{alg}\frac{f(\tilde{a})}{f(a)} + e_{in} = e_{alg}(1+e_{in}) + e_{in}\\
&= e_{alg} + e_{in} + e_{alg}e_{in} \doteq e_{alg} + e_{in}.
\end{align*}
\end{proof}

\paragraph{Approssimazione al prim'ordine dell'errore inerente}
Supponiamo che $f$ sia derivabile due volte, e ricordiamo che abbiamo $\tilde{a} = a(1+\varepsilon)$.
Allora,
\[
f(\tilde{a}) = f(a) + f'(a)(\tilde{a} - a) + \frac{f''(\xi)}{2}(\tilde{a}-a)^2 = f(a) + f'(a)\varepsilon a + \frac{f''(\xi)}{2}(\varepsilon a)^2
\]
da cui
\[
\frac{f(\tilde{a}) - f(a)}{f(a)} = \frac{f'(a)a}{f(a)}\varepsilon + \frac{f''(\xi)}{2f(a)}\varepsilon^2 a`^2 \doteq \frac{f'(a)a}{f(a)}\varepsilon.
\]
La quantità
\[
\kappa_{f,a} = \abs*{\frac{f'(a)a}{f(a)}}
\]
è detta \emph{numero di condizionamento} della funzione $f$ rispetto ad $a$. Mostra di quanto un piccolo errore (relativo) su $a$ viene ``amplificato'' dal calcolo di $f$.

\paragraph{Esempio} La funzione $f(a) = \frac{a}{1-a}$ ha numero di condizionamento
\[
\kappa_{f,a} = \abs*{\frac{f'(a)a}{f(a)}} = \abs*{\frac{\frac{1}{(1-a)^2}a}{\frac{a}{1-a}}} = \frac{1}{\abs{1-a}}.
\]
Questa quantità è grande quando $a\approx 1$. Un errore relativo piccolo, per esempio $a=0.9991$, $\tilde{a} = 0.999$, causa un errore relativo grande $\frac{f(\tilde{a})-f(a)}{f(a)}$.

Una funzione che ha un numero di condizionamento grande viene detta \emph{mal condizionata}.

(Esempio su Matlab)

\paragraph{Condizionamento delle quattro operazioni}

Possiamo studiare il condizionamento delle quattro operazioni rispetto a perturbazioni dei dati in ingresso. Notiamo che le operazioni dipendono da due valori in ingresso, quindi ha senso calcolare \emph{due} numeri di condizionamento (che in realtà spesso saranno uguali, per simmetria). Per esempio, $f(a,b) = a \cdot b$; cosa succede perturbando $a$ in $a(1+\varepsilon_a)$? 
\[
\kappa_{f,a} = \abs*{\frac{\frac{\partial f(a,b)}{\partial a} a}{f(a)}} = \abs*{\frac{b \cdot a}{ab}} = 1.
\]
Quindi la moltiplicazione è un'operazione sempre ben condizionata.

Possiamo fare un calcolo simile per $f(a,b) = a + b$.
\[
\kappa_{f,a} = \abs*{\frac{\frac{\partial f(a,b)}{\partial a} a}{f(a,b)}} = \abs*{\frac{1 \cdot a}{a + b}} = \abs*{\frac{a}{a+b}}.
\]
Questo errore diventa molto grande quando la somma $a+b$ è molto più piccola (in valore assoluto) degli addendi $a$ e $b$; questo succede quando sono vicini e hanno segno opposto. In questo caso, piccole perturbazioni (relative) agli addendi $a,b$ possono portare a una perturbazione molto grande (relativa) sulla somma $a+b$.

Esempio: $a = 1.0011$, $b = -1$. $\tilde{a} = 1.001$. La perturbazione relativa sul dato in ingresso è $\frac{\tilde{a}-a}{a} \approx 10^{-4}$, ma la perturbazione relativa sulla differenza è mille volte più grande,
\[
\abs*{\frac{f(\tilde{a},b) - f(a,b)}{f(a,b)}} \approx 10^{-1}.
\]

L'analisi della sottrazione è analoga a quella dell'addizione, poiché basta rimpiazzare $b$ con $-b$.

Analogamente si può vedere che la divisione $f(a,b) = a / b$ è sempre ben condizionata, esattamente come la moltiplicazione.

% Esempio: operazione di macchina (di nuovo con $\beta=10, t=3$), $1.25 \ominus 1.24$ e $1.24987 - 1.24367$; l'effetto combinato di approssimazioni precedenti e sottrazione è ``cancellazione catastrofica''.

\paragraph{Approssimazione al prim'ordine dell'errore algoritmico}

Data un'espressione, per esempio $x = f(x,y) = a^2 - b^2$ (anche con più di un ``valore di ingresso''), possiamo stimarne l'errore algoritmico. Dati numeri di macchina $\tilde{a}, \tilde{b}$, possiamo scrivere
\begin{align*}
h(\tilde{a}, \tilde{b}) &= \tilde{a} \otimes \tilde{a} \ominus \tilde{b} \otimes \tilde{b} = \tilde{a}^2(1+\varepsilon_1) \ominus \tilde{b}^2(1+\varepsilon_2)\\
&= \left( \tilde{a}^2(1+\varepsilon_1) - \tilde{b}^2(1+\varepsilon_2) \right)(1+\varepsilon_3) \\
& \doteq \underbrace{\tilde{a}^2-\tilde{b}^2}_{\text{valore esatto $f(\tilde{a},\tilde{b})$}} {}+{} \underbrace{\tilde{a}^2\varepsilon_1 - \tilde{b}^2\varepsilon_2 + (\tilde{a}^2-\tilde{b}^2)\varepsilon_3}_{\text{errore algoritmico}}.
\end{align*}
Nell'ultima parentesi abbiamo omesso tutte le quantità ``del secondo ordine'', vale a dire che contengono il prodotto di due (o più) $\varepsilon_i$: visto che sappiamo che $\abs{\varepsilon_i} \leq \mathsf{u}$ per $i=1,2,3$, queste quantità sono dell'ordine di $\mathsf{u}^2$ e sono presumibilmente molto più piccole di tutti gli altri numeri coinvolti.


Visto che tutto quello che sappiamo è che $\abs{\varepsilon_i} \leq \mathsf{u}$ per $i=3,4,5$, la stima migliore che possiamo fare è
\[
\frac{\abs{h(\tilde{a},\tilde{b}) - f(\tilde{a},\tilde{b})}}{\abs{f(\tilde{a},\tilde{b})}} = \frac{\abs{\tilde{a}^2\varepsilon_1 - \tilde{b}^2\varepsilon_2 + (\tilde{a}^2-\tilde{b}^2)\varepsilon_3}}{\abs{\tilde{a}^2-\tilde{b}^2}} \leq \abs*{\frac{a^2}{\tilde{a}^2-\tilde{b}^2}}\mathsf{u} + \abs*{\frac{b^2}{\tilde{a}^2-\tilde{b}^2}}\mathsf{u} + \mathsf{u}.
\]
Un calcolo analogo si può impostare per sequenze più lunghe di operazioni: l'idea è sempre espandere le definizioni, eliminare tutti i termini con più di un $\varepsilon_i$, e stimare l'errore tramite valori assoluti. Per algoritmi più complessi questo calcolo diventa presto proibitivo, purtroppo.

Notare che l'errore algoritmico dipende non dalla funzione in sé, ma dalla sequenza di operazioni che usiamo per calcolarlo: per esempio $f(a,b) = (a+b)(a-b)$ è la stessa funzione matematica, ma $h_2(\tilde{a},\tilde{b}) = (\tilde{a} \oplus \tilde{b})\odot (\tilde{a}\ominus \tilde{b})$ porta a un calcolo dell'errore algoritmico che a priori può essere completamente diverso.

Un'altra osservazione è che gli algoritmi che causano problemi solitamente sono quelli che contengono differenze tra due valori molto vicini: in questo caso per esempio i termini $\frac{a^2}{\abs{a^2-b^2}}\mathsf{u}$, $\frac{b^2}{\abs{a^2-b^2}}\mathsf{u}$ possono essere molto grandi, se il denominatore è molto minore del numeratore. Questo segue dall'analisi del condizionamento delle quattro operazioni.

\paragraph{Errore analitico}
Anche supponendo di avere valori di $a,b$ esatti e ignorando gli errori dovuti all'aritmetica di macchina, spesso i nostri algoritmi non restituiscono la soluzione esatta, ma solo una sua approssimazione. Per esempio, se vogliamo calcolare $\sqrt{a}$ tramite il metodo di punto fisso con una certa funzione $\Phi(a)$ (che supponiamo razionale, cioè ottenuta solo componendo le quattro operazioni), e ci arrestiamo dopo 3 passi, la funzione che calcoliamo in aritmetica esatta non è $f(a) = \sqrt{a}$, bensì $g(a) = \Phi(\Phi(\Phi(x_1)))$.

Difatti per la maggior parte degli $a$ il numero $\sqrt{a}$ non è razionale, quindi non abbiamo speranza di calcolarlo esattamente con solo le quattro operazioni.

In generale, supponiamo di voler calcolare a partire da un valore in ingresso $\tilde{a}$ (già perturbato da errore in ingresso) una funzione $f(\tilde{a})$ (questa volta non per forza una funzione razionale), e di avere un algoritmo che calcola una sua approssimazione $g(\tilde{a})$; per esempio $f(a) = \sqrt{a}$ e $g(a) = \Phi(
\Phi(\Phi(1)))$, dove $\Phi(t)$ è la funzione $\Phi(x) = x - \frac{x^2-a}{2x}$ (quella risultante dal metodo di Newton). Possiamo definire allo stesso modo un \emph{errore analitico}
\[
e_{an} = \frac{g(\tilde{a}) - f(\tilde{a})}{f(\tilde{a})}.
\]
Il computer questa volta calcolerà una versione modificata $h(a)$ di $g(a)$, anziché di $f(a)$, ottenuta con operazioni di macchina.
Con una dimostrazione analoga a quella sopra ma con tre termini anziché due, possiamo dimostrare che
\[
e_{tot} = \frac{h(\tilde{a}) - f(a)}{f(a)} \doteq e_{in} + e_{an} + e_{alg}.
\]
Gli errori $e_{in}$ ed $e_{alg}$ sono dovuti all'aritmetica di macchina (almeno assumendo che non ci siano altre perturbazioni sui dati in ingresso), e quindi possiamo aspettarci (in molti casi!) che siano dell'ordine di $\mathsf{u}$: il fattore che limita l'accuratezza che possiamo ottenere è l'accuratezza dell'aritmetica di macchina. Invece $e_{an}$ va studiato algoritmo per algoritmo, e potrebbe essere anche molto più grande, e quindi dominare la somma. Abbiamo già studiato l'errore analitico dei metodi di ricerca di zeri, dicendo che converge a zero con il numero di passi e dandone delle stime. Allo stesso modo analizzeremo l'errore analitico di vari algoritmi che studieremo.

In un problema più facile (che si risolve solo con le quattro operazioni) come risolvere un sistema di equazioni lineari, abbiamo formule esatte e quindi $e_{an} = 0$. In problemi più difficili come risolvere equazioni differenziali o calcolare integrali, $e_{an}$ è non-zero, e spesso è più grande degli altri errori, quindi è la componente più importante.

Questi concetti di errore spiegano bene il comportamento della figura~\ref{fig:iterativi2}. Nell'analizzare i metodi abbiamo già stimato l'errore analitico, e sappiamo che si comporta come $cr^k$, dove $k$ è il numero di passi, quindi scende come una retta su un grafico in scala semi-logaritmica. Nelle prime 150 iterazioni l'errore analitico è più grande di $10^{-16}$, ed è la quantità dominante nella somma degli errori; più avanti, l'errore analitico è minore, e quello dominante è l'errore algoritmico, che è dell'ordine di $10^{-16}$.

\chapter{Equazioni lineari e autovalori}

\section{Richiami di algebra lineare}

Ricordiamo che il prodotto matrice-vettore $A \mathbf{x}$ è definito come $(Ax)_i = \sum_{j=1}^n A_{ij}x_j$ (riga per colonna). Più geometricamente, crea una combinazione lineare $\mathbf{v}_1 x_1 + \mathbf{v}_2 x_2 + \dots + \mathbf{v}_n x_n)$ delle colonne $\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_n$ di $A$. 

% Prodotto matrice-matrice: $AB$ definito come $(AB)_{ij} = \sum_{k=1}^{n} A_{ik}B_{kj}$, prodotti scalari nello stesso modo. Ben definito solo quando $A\in\mathbb{C}^{m\times n}$ e $B\in\mathbb{C}^{n\times p}$ hanno la dimensione ``interna'' uguale, e produce una matrice $AB\in\mathbb{C}^{m\times p}$. L'ordine dei fattori conta! $AB \neq BA$ (e può anche darsi che uno sia ben definito e l'altro no).

% A parte questo, valgono le ``normali'' proprietà di addizione e moltiplicazione: $(A+B)C = AC+BC$, $A(BC)=(AB)C$. Un'altra che non vale è l'annullamento del prodotto: $AB=0$ può verificarsi anche se $A,B\neq 0$. (Esempio: $\begin{bmatrix}
%     -1 & 1\\
%     1 & -1
% \end{bmatrix}\begin{bmatrix}
%     1 & 1\\
%     1 & 1
% \end{bmatrix} = 0_{2\times 2}$.)

% Possiamo moltiplicare matrici e vettori anche per degli \emph{scalari} (cioè dei numeri $\in\mathbb{C}$). In questo caso, l'ordine non conta e possiamo ``portare fuori'' scalari da un prodotto, $A(\alpha B) = \alpha (AB)$.

Un \emph{sistema lineare} è il problema inverso del prodotto: data $A\in\mathbb{R}^{n\times n}$ e $\mathbf{b} \in \mathbb{R}^n$, trovare il vettore di coefficienti $\mathbf{x}$ che servono per scrivere $\mathbf{b}$ come combinazione lineare delle colonne di $A$.

Partiamo studiando sistemi quadrati, cioè $A \in \mathbb{R}^{n\times n}$ (o $\mathbb{C}^{n\times n}$). Un sistema ha \emph{una e una sola} soluzione quando le righe/colonne di $A$ formano una base di $\mathbb{R}^n$ (in particolare, quando sono linearmente indipendenti). Ci concentriamo su sistemi che soddisfano questa ipotesi. Dall'algebra lineare, sappiamo che se $A$ è invertibile esiste una matrice $A^{-1}\in\mathbb{R}^{n\times n}$ tale che la soluzione si scrive come prodotto $\mathbf{x} = A^{-1}\mathbf{b}$. Questa matrice è unica e soddisfa $A^{-1}A=AA^{-1}= I$, la matrice con uni sulla diagonale e zeri altrove.

\emph{Non} possiamo scrivere $\mathbf{x} = \mathbf{b}A^{-1}$ (dimensioni non compatibili per il prodotto; l'ordine dei fattori conta!), né $\mathbf{x} = \frac{\mathbf{b}}{A}$ (non vuol dire nulla, e non mi specifica l'ordine!).

In Matlab, esiste una funzione \lstinline{inv(A)} che calcola l'inversa, quindi potremmo scrivere \lstinline{inv(A) * b}; però questo metodo è più costoso (e spesso anche più inaccurato) di altri algoritmi. C'è una notazione diversa per risolvere un sistema, \lstinline{x = A \ b}. Occhio: la barra è la ``backslash'' \lstinline!\!, non \lstinline{/}. Per non confondere le barre, pensate a questa operazione come a una sorta di ``divisione da un lato'': c'è una barra di frazione, e la \lstinline{A} sta al di sotto.

Intuitivamente, calcolare un'inversa richiede risolvere gli $n$ sistemi lineari $A^{-1}e_1, A^{-1}e_2,\dots A^{-1}e_n$; per questo è più lento.

\paragraph{Determinanti} Altri algoritmi da evitare sono quelli basati su determinanti, come il \emph{metodo di Cramer}. Il \emph{determinante} è una particolare funzione di una matrice quadrata; le proprietà che ci interessa ricordare qui sono queste:
\begin{itemize}
    \item Una matrice è invertibile se e solo se $\det(A) \neq 0$.
    \item Se una matrice è \emph{triangolare}, il suo determinante è il prodotto degli elementi sulla diagonale.
    \item $\det(AB) = \det(A) \det(B)$ (teorema di Binet).
\end{itemize}
Tipicamente i determinanti sono più lenti da calcolare, e per matrici grandi vanno spesso in overflow/underflow; per esempio, $\det(10 I_{400\times 400})$ restituisce $0$ su Matlab. Quindi essi sono inaffidabili anche solo per dire se una matrice è singolare o no. 

Nelle prossime sezioni vedremo invece gli algoritmi che Matlab utilizza per risolvere sistemi lineari. Ma prima studiamo il condizionamento del problema.

\section{Condizionamento della soluzione di sistemi lineari}

Partiamo studiando il condizionamento della soluzione di sistemi lineari. Per farlo, introduciamo alcuni strumenti teorici.

\paragraph{Norme vettoriali} Notate che l'analisi dell'errore che avevamo fatto assumeva di avere funzioni $f: \mathbb{R} \to \mathbb{R}$, funzioni $x=f(a)$ di un reale $a$. La soluzione di un sistema lineare invece è una funzione $x = f(A,b)$ che prende una matrice e un vettore e restituisce un vettore. Potremmo studiare separatamente il condizionamento di ogni componente rispetto a ogni componente dell'input, ma si preferisce un approccio diverso che passa attraverso il misurare ``distanze'' tra vettori e matrici.

Lo strumento teorico che ci serve è una \emph{norma vettoriale}, cioè una funzione che ``assomiglia al valore assoluto'' per vettori.

Si definisce \emph{norma vettoriale} una funzione $f: \mathbb{C}^n \to \mathbb{R}$ che ha queste proprietà.
\begin{enumerate}
    \item $f(v) \geq 0$ per ogni vettore $v\in\mathbb{C}^n$, e l'uguaglianza vale solo per il vettore zero.
    \item $f(\alpha v) = \abs{\alpha} f(v)$ per ogni vettore $v\in\mathbb{C}^n$ e scalare $\alpha \in \mathbb{C}$.
    \item $f(v+w) \leq f(v) + f(w)$ per ogni $v,w\in\mathbb{C}^n$.
\end{enumerate}

Notate che queste rispecchiano le proprietà del valore assoluto; per esempio l'ultima è la disuguaglianza triangolare. Difatti non è complicato verificare che il valore assoluto è una norma per $n=1$.

Una norma di solito non si indica con $f(v)$, ma con $\norm{v}$ (due stanghette).

Le norme più usate sono le seguenti.

\begin{itemize}
    \item Norma-1: $\norm{v}_1 = \sum_{i=1}^n \abs{v_i}$.
    \item Norma-2 (o Euclidea): $\norm{v}_2 = \sqrt{\sum_{i=1}^n \abs{v_i}^2} = \sqrt{v^*v}$.
    \item Norma infinito: $\norm{v}_\infty = \max_{i\in \{1,2,\dots,n\}} \abs{v_i}$.
\end{itemize}
Si dimostra che tutte e tre soddisfano le proprietà qui sopra. L'unica un po' più difficile è la disuguaglianza triangolare per la norma-2; le altre potete provare a farle come esercizio.

Esempio: calcola le tre norme di $\begin{bmatrix}
    2\\-3\\-1
\end{bmatrix}$.

Data una norma, $\norm{v-w}$ fornisce un modo di misurare la distanza tra $v$ e $w$. Ogni norma fornisce valori diversi, che danno modi leggermente diversi di definire questa distanza. In generale, si dimostra che date due norme qualunque queste differiscono per una costante; vale a dire, esistono due reali $c_1,c_2 > 0$ tali che \emph{per ogni} vettore $v\in\mathbb{C}^n$ si ha
\[
c_1\norm{v}_\alpha \leq \norm{v}_\beta \leq c_2 \norm{v}_\alpha.
\]
Queste costanti spesso sono una funzione della dimensione; per esempio, per ogni $v\in\mathbb{C}^n$ si ha
\[
\norm{v}_0 \leq \norm{v}_2 \leq \sqrt{n}\norm{v}_0.
\]
(esercizio: dimostrarlo.)

Esempio: disegnare le ``sfere'' $\norm{v}=1$ in $\mathbb{R}^2$ nelle tre norme.

\paragraph{Norme matriciali}

Similmente ai vettori, possiamo definire norme su matrici. Si dice \emph{norma matriciale} una funzione $f: \mathbb{C}^{n\times n} \to \mathbb{R}$ che soddisfa queste proprietà:
\begin{enumerate}
    \item $f(A) \geq 0$ per ogni matrice $A\in\mathbb{C}^{n\times n}$, e l'uguaglianza vale solo per la matrice zero.
    \item $f(\alpha A) = \abs{\alpha} f(A)$ per ogni $A\in\mathbb{C}^{n\times n}$ e scalare $\alpha \in \mathbb{C}$.
    \item $f(A+B) \leq f(A) + f(B)$ per ogni $A,B\in\mathbb{C}^{n\times n}$.
    \item $f(AB) \leq f(A)f(B)$ per ogni $A,B\in\mathbb{C}^{n\times n}$.
\end{enumerate}
Rispetto al caso dei vettori, abbiamo aggiunto una proprietà che lega la norma al prodotto di matrici. Notate stavolta una differenza rispetto al valore assoluto; non abbiamo $\norm{AB} = \norm{A}\norm{B}$. (Sarebbe impossibile ottenere norme con questa proprietà più forte.)

\paragraph{Norme matriciali indotte}

È possibile costruire una norma matriciale a partire da ogni norma vettoriale in questo modo. Fissata una norma vettoriale $\norm{\cdot}$ (per esempio le norme $1,2,\infty$) definiamo
\begin{equation} \label{normamatriciale}
    \norm{A}_p = \max_{\substack{u\in\mathbb{R}^n \\ \norm{u}_p=1}} \norm{Au}_p.
\end{equation}
In generale la matrice $A$ manderà gli infiniti vettori con norma uguale a $1$ in vettori di lunghezza diversa; prendiamo il più lungo, e definiamolo come la norma. Si può dimostrare (non lo faremo) che questa definizione soddisfa tutte le proprietà di una norma matriciale.

La definizione fatta in questo modo serve per assicurare un'ulteriore proprietà.
\begin{theorem}[compatibilità della norma matriciale indotta] \label{thm:compatibilita}
La norma matriciale $\norm{A}_p$ definita qui sopra soddisfa $\norm{Av}_p \leq \norm{A}_p\norm{v}_p$ per ogni matrice $A\in\mathbb{C}^{n\times n}$ e vettore $v\in\mathbb{C}^n$.
\end{theorem}
Notare che mi serve usare \emph{la stessa} norma: per esempio se misuro i vettori in una norma $p$ con $p\in\{1,2,\infty\}$, dovrò usare la norma matriciale costruita usando la norma $p$ nella~\eqref{normamatriciale}.
\begin{proof}
Prima un caso particolare: se $v=0$, allora anche $Av=0$ e sia il membro di sinistra che quello di destra si annullano. Possiamo quindi proseguire considerando $v\neq 0$, e quindi $\norm{v}_p \neq 0$.

Mi basta considerare il vettore $u = v \frac{1}{\norm{v}_p}$. Questo vettore ha norma uguale a 1, per le proprietà delle norme vettoriali (considerandolo come il prodotto dello scalare $\frac{1}{\norm{v}_p}$ e del vettore $v$); quindi
\[
\frac{1}{\norm{v}}_p \norm{Av}_p  = \norm{Au}_p \leq \norm{A}_p,
\]
ed eliminando il denominatore otteniamo la tesi.
\end{proof}

\paragraph{Norma di Frobenius}

Non tutte le norme matriciali si ottengono da questa costruzione. Un altro esempio è la \emph{norma di Frobenius},
\[
\norm{A}_F = \sqrt{\sum_{i,j=1}^n \abs{A_{ij}}^2}.
\]
Questa funzione soddisfa tutte le proprietà di una norma matriciale, ma non è una norma matriciale \emph{indotta}. Un modo veloce di vederlo è considerando la norma della matrice identità: $\norm{I}_F = \sqrt{n}$, ma per una norma matriciale indotta segue dalla definizione che $\norm{I} = 1$.

\paragraph{Norme, autovalori e raggio spettrale}

Data una matrice quadrata $A$, ricordiamo che quando $Av = v\lambda$ per un qualche vettore $v\in\mathbb{C}^n$ (diverso dal vettore nullo!) e scalare $\lambda \in \mathbb{C}$ si dice che $\lambda$ è un \emph{autovalore} e $v$ è un \emph{autovettore} di $A$. Avete visto ad algebra lineare diverse proprietà degli autovalori. Prendendo norme, abbiamo che
\[
\norm{v}_p \abs{\lambda} = \norm{v\lambda}_p = \norm{Av}_p \leq \norm{A}_p \norm{v}_p.
\]
Possiamo semplificare $\norm{v}_p \neq 0$, quindi $\abs{\lambda} \leq \norm{A}$ per ogni autovalore.

Data una matrice $A \in \mathbb{C}^{n\times n}$ (quindi gli autovalori esistono sempre), si chiama \emph{spettro} l'insieme dei suoi autovalori, e \emph{raggio spettrale} (e si indica $\rho(A)$) il valore assoluto più grande degli autovalori, $\rho(A) = \max_{\lambda \text{ autoval.}} \abs{\lambda}$. Notate che questo non è per forza un autovalore; per esempio potremmo avere $A$ con autovalori $\{-2, i, -i\}$, e quindi $\rho(A)=2$ non è un autovalore.

In ogni caso, dalla formula qui sopra segue
\[
\rho(A) \leq \norm{A}_p
\]
per ogni norma matriciale indotta.

\paragraph{Formule per le norme matriciali $1,2,\infty$}
È abbastanza scomodo calcolare le norme matriciali indotte usando la loro definizione (c'è un massimo su un insieme infinito di vettori\dots). Per le norme $1,2,\infty$ ci sono delle formule più semplici. Le enunciamo senza dimostrazione.
\begin{align*}
\norm{A}_{\infty} &= \max_{i=1}^n \sum_{j=1}^n \abs{A_{ij}},\\
\norm{A}_{1} &= \max_{j=1}^n \sum_{i=1}^n \abs{A_{ij}},\\
\norm{A}_2 &= \rho(A^TA)^{1/2}.
\end{align*}
(Qui $\rho(\cdot)$ è di nuovo il raggio spettrale.)

Esempio: calcolare le tre norme (quattro con Frobenius) sulla matrice
\[
A = \begin{bmatrix}
    -2 & -1\\
    -2 & 1
\end{bmatrix},
\]
e verificare (aiutandosi eventualmente con Matlab) che $\rho(A)\leq \norm{A}_p$ per $p=1,2,\infty$. (La disuguaglianza è vera anche per $\norm{A}_F$, ma la dimostrazione che abbiamo fatto funziona solo per norme matriciali indotte.)

\paragraph{Condizionamento della soluzione di sistemi lineari} La soluzione di sistemi lineari è un problema che ha come ``input'' $A,b$ e come ``output'' $x$. Ha senso chiederci come cambia $x$ se perturbiamo $A$ oppure $b$ (o anche tutti e due insieme). Analogamente al caso scalare, possiamo definire errori relativi in termini di norme: $\frac{\norm{\tilde{x}-x}}{\norm{x}}$, $\frac{\norm{\tilde{A}-A}}{\norm{A}}$, $\frac{\norm{\tilde{b}-b}}{\norm{b}}$ (occhio che $\norm{\frac{\tilde{b}-b}{b}}$ non vuol dire niente, non possiamo dividere per vettori!)

Qui vediamo cosa succede quando perturbiamo il vettore dei termini noti $b$. 

\begin{theorem}
    Sia $A\in \mathbb{C}^{n\times n}$ una matrice invertibile, e $b,\tilde{b} \in \mathbb{C}^n$ due vettori, con $\norm{b}\neq 0$. Siano $x$ e $\tilde{x}$ le soluzioni dei due sistemi lineari $Ax=b$, $A\tilde{x}=\tilde{b}$. Allora, per una qualunque norma vettoriale $\norm{\cdot}_p$ si ha
    \begin{equation} \label{conditionbound}
        \frac{\norm{\tilde{x}-x}_p}{\norm{x}_p} \leq \norm{A}_p\norm{A^{-1}}_p \frac{\norm{\tilde{b}-b}_p}{\norm{b}_p}.    
    \end{equation}
\end{theorem}
Qui $\norm{A}_p$, $\norm{A^{-1}}_p$ utilizzano la norma matriciale indotta dalla norma vettoriale data.
\begin{proof}
Possiamo calcolare
\[
\norm{\tilde{x}-x}_p = \norm{A^{-1}\tilde{b} - A^{-1}b}_p = \norm{A^{-1}(\tilde{b}-b)}_p \leq \norm{A^{-1}}_p\norm{f}_p = \norm{A^{-1}}_p\norm{\tilde{b}-b}_p,
\]
utilizzando la proprietà di compatibilità della norma matriciale indotta (Teorema~\ref{thm:compatibilita}). Per la stessa proprietà abbiamo
\[
\norm{b}_p = \norm{Ax}_p \leq \norm{A}\norm{x}_p.
\]
Possiamo dividere membro a membro le due disuguaglianze (i versi sono quelli corretti per farlo!), ottenendo la~\eqref{conditionbound}.
\end{proof}

Questa disuguaglianza è valida non solo al prim'ordine, ma per tutti gli $A,x,b$. La quantità $\kappa_p(A) = \norm{A}_p\norm{A^{-1}}_p$ si definisce ``numero di condizionamento'' (in norma-$p$) della matrice $A$ (con un piccolo abuso di notazione, visto che finora abbiamo definito il condizionamento di un \emph{problema} o di una \emph{funzione}).


La quantità $\kappa(A)$ è sempre maggiore di $1$, perché per ogni norma matriciale indotta $1 = \norm{I}_p = \norm{AA^{-1}}_p \leq \norm{A}_p\norm{A^{-1}}_p$. Una matrice si dice ``ben condizionata'' se questa quantità è vicina a 1, e ``mal condizionata'' se è molto maggiore di 1 (qualche migliaio almeno, di solito; non c'è una soglia precisa).

Così per vostra conoscenza, si può dimostrare che $\kappa(A)$ limita anche l'errore inerente dovuto a perturbazioni della matrice $A$:
\[
\frac{\norm{\tilde{x}-x}_p}{\norm{x}_p} \mathrel{\stackrel{.}{\leq}} \norm{A}_p\norm{A^{-1}}_p \frac{\norm{\tilde{A}-A}_p}{\norm{A}_p}.
\]
Occhio al punto sopra il $\leq$: a differenza del precedente, in questo caso si tratta di un risultato solo a meno di termini dell'ordine del quadrato di $\frac{\norm{\tilde{A}-A}_p}{\norm{A}_p}$: se $\frac{\norm{\tilde{A}-A}_p}{\norm{A}_p}$ è grande, questa disuguaglianza può essere ben lontana dall'essere verificata.

\paragraph{Esempio} Con Matlab, è problematico fare esempi di perturbazioni dell'ordine della precisione di macchina $\mathsf{u}\approx 2.2\times 10^{-16}$, visto che i calcoli stessi sono affetti da un errore dello stesso ordine di grandezza. Possiamo però vedere cosa succede con perturbazioni molto più grandi.
\begin{lstlisting}
>> A = [1 2; 3 4]
A =
        1     2
        3     4
>> b = [3;7];
>> x = A \ b
x =
    1.0000e+00
    1.0000e+00
>> btilde = [3.0001; 6.9999];
>> xtilde = A \ btilde
xtilde =
    9.9970e-01
    1.0002e+00
>> norm(btilde - b, inf) / norm(b, inf) % errore relativo
ans =
    1.4286e-05
>> norm(xtilde - x, inf) / norm(x, inf)
ans =
    3.0000e-04
>> norm(A, inf) * norm(inv(A), inf) % numero di condizionamento
ans =
    2.1000e+01
>> cond(A, inf)  % funzione Matlab per calcolarlo direttamente
ans =
    2.1000e+01
\end{lstlisting}
La matrice $A$ ha numero di condizionamento 21. Quindi l'errore relativo sulla soluzione $x$ calcolata è pari ad al più 21 volte l'errore relativo sul dato in ingresso $b$. Visto che questo fattore 21 è sufficientemente piccolo, diciamo che la matrice $A$ è \emph{ben condizionata}.
\begin{lstlisting}
>> A = [1 2; 2.0001 4]
A =
    1.0000e+00   2.0000e+00
    2.0001e+00   4.0000e+00
>> b = A*[1;1]
b =
    3.0000e+00
    6.0001e+00
>> btilde = [2.9999; 6.0002]
btilde =
    2.9999e+00
    6.0002e+00
>> x = A \ b
x =
    1.0000e+00
    1.0000e+00
>> xtilde = A \ btilde
xtilde =
    4.0000e+00
    -5.0005e-01
>> norm(btilde - b, inf) / norm(b, inf)
ans =
    1.6666e-05
>> norm(xtilde - x, inf) / norm(x, inf)
ans =
    3.0000e+00
>> norm(A, inf) * norm(inv(A), inf)
ans =
    1.8000e+05
>> cond(A, inf)
ans =
    1.8000e+05        
\end{lstlisting}
Questa nuova matrice $A$ ha un numero di condizionamento molto più grande, $1.8\times 10^{-5}$. Diciamo che è \emph{mal condizionata}. L'errore relativo sul termine noto $b$ pari a $1.66 \times 10^{-5}$ produce un errore relativo sulla soluzione $x$ pari a $3$; cioè la soluzione ottenuta è completamente sbagliata. La disuguaglianza~\eqref{conditionbound} comunque è rispettata anche in questo caso.


\section{Condizionamento del calcolo di autovalori (*)}
Un altro problema classico dell'algebra lineare è il calcolo di autovalori e autovettori. Non vediamo nel dettaglio algoritmi per farlo, perché sono molto più complicati; ci fideremo di \texttt{eig(A)} di Matlab. Però, almeno per studiare il problema teoricamente, è importante vedere quale è il condizionamento di questa operazione, in modo da sapere quando anche Matlab rischia di calcolare un risultato errato.

Ci limitiamo a un caso più facile, quello di \emph{autovalori semplici}: un autovalore si dice \emph{semplice} se la sua molteplicità geometrica e algebrica è uguale a 1, cioè, se è uno zero semplice del polinomio caratteristico $\det(\lambda I - A)$. In questo caso, esistono e sono unici (a meno di multipli) un autovalore destro $\mathbf{x}$ e uno sinistro $\mathbf{y}^*$ associati a $\lambda$; cioè, $A\mathbf{x} = \mathbf{x}\lambda$ e $\mathbf{y}^* A = \lambda \mathbf{y}^*$. Si può dimostrare che per un autovalore semplice $\mathbf{x}$ e $\mathbf{y}^*$ non sono mai ortogonali. Il risultato di perturbazione che enunciamo dipende dal coseno dell'angolo che essi formano, cioè
\[
\cos \theta = \frac{\abs{\mathbf{y}^* \mathbf{x}}}{\norm{\mathbf{y}}_2 \norm{\mathbf{x}}_2}.
\]
\begin{theorem}[Perturbazione di autovalori (*)]
Sia $\lambda$ un autovalore \emph{semplice} della matrice $A \in \mathbb{C}^{n\times n}$. Sia $\tilde{A}$ una perturbazione di $A$; allora esiste un autovalore $\tilde{\lambda}$ di $\tilde{A}$ tale che
\[
\abs{\tilde{\lambda} - \lambda} \stackrel{.}{\leq} \frac{1}{\cos \theta}\norm{\tilde{A}-A}_2,
\]
dove $\theta$ è l'angolo tra l'autovettore destro $\mathbf{x}$ e quello sinistro $\mathbf{y}^*$ associati a $\lambda$.
\end{theorem}
Occhio al punto sopra il $\leq$: anche in questo caso il risultato è valido solo al prim'ordine, cioè ignorando termini dell'ordine di $\norm{\tilde{A}-A}_2^2$.

In particolare, quando $A$ è una matrice simmetrica gli autovalori destri e sinistri coincidono, cioè $\mathbf{x}=\mathbf{y}$; quindi il coseno è uguale a 1 e il calcolo degli autovalori di una matrice simmetrica è sempre un'operazione ben condizionata.

\begin{proof}
Scriviamo $\tilde{A} - A = \varepsilon E$, dove $\norm{E}_2 = 1$ e $\varepsilon = \norm{\tilde{A}-A}_2$. Consideriamo la funzione $A(t) = A + t E$. È possibile dimostrare usando il teorema della funzione implicita che esistono funzioni differenziabili $\lambda(t), \mathbf{x}(t)$ tali che $\lambda(t)$ è un autovalore di $A(t)$ e $\mathbf{x}(t)$ è il suo autovettore, e tali che $\lambda(0)=\lambda$, $\mathbf{x}(0) = \mathbf{x}$. Quindi, in particolare, vale la relazione
\[
A(t)\mathbf{x}(t) = \mathbf{x}(t) \lambda(t).
\]
Possiamo derivare entrambi i termini rispetto a $t$, per ottenere
\[
\underbrace{\dot{A}(t)}_{=E} \mathbf{x}(t) + A(t)\dot{\mathbf{x}}(t) = \dot{\mathbf{x}}(t) \lambda(t) + \mathbf{x}(t) \dot{\lambda}(t).
\]
Valutiamo in $t=0$, e otteniamo
\[
E \mathbf{x} + A \dot{\mathbf{x}}(0) = \dot{\mathbf{x}}(0) \lambda + \mathbf{x} \dot{\lambda}(0)
\]
Moltiplichiamo a sinistra per $\mathbf{y}^*$, e usiamo il fatto che $\mathbf{y}^* A = \lambda \mathbf{y}^*$ per semplificare due termini della relazione
\[
\mathbf{y}^* E \mathbf{x} +  \mathbf{y}^*A \dot{\mathbf{x}}(0) = \lambda\mathbf{y}^* \dot{\mathbf{x}}(0)  + \mathbf{y}^* \mathbf{x} \dot{\lambda}(0).
\]
Quindi otteniamo
\[
\dot{\lambda}(0) = \frac{1}{\mathbf{y}^*\mathbf{x}} \mathbf{y}^* E \mathbf{x}.
\]
Possiamo scrivere, a meno di termini di ordine superiore in $\varepsilon$, lo sviluppo di Taylor
\begin{equation} \label{eigperturb}
\tilde{\lambda} = \lambda(\varepsilon) \stackrel{.}{=} \lambda + \varepsilon \dot{\lambda}(0) = \lambda + \varepsilon \frac{1}{\mathbf{y}^*\mathbf{x}} \mathbf{y}^* E \mathbf{x}
\end{equation}
da cui
\[
\abs{\tilde{\lambda} - \lambda} \stackrel{.}{=} \varepsilon \frac{1}{\mathbf{y}^*\mathbf{x}} \mathbf{y}^* E \mathbf{x}
\]

Per concludere dimostriamo che $\abs{\mathbf{y}^* E \mathbf{x}} \leq \norm{\mathbf{y}}_2\norm{\mathbf{x}}_2$. Poiché $\mathbf{y}^* E \mathbf{x}$ è il prodotto scalare tra $\mathbf{y}$ e $E \mathbf{x}$, chiamando $\alpha$ l'angolo che formano abbiamo
\[
    \abs{\mathbf{y}^* E \mathbf{x}} = \norm{\mathbf{y}}_2 \norm{E \mathbf{x}}_2 \cos\alpha \leq \norm{\mathbf{y}}_2 \norm{E \mathbf{x}}_2
\]
Infine, poiché $\norm{E}_2 = 1$, dalle proprietà delle norme matriciali abbiamo $\norm{E\mathbf{x}}_2 \leq \norm{E}_2\norm{\mathbf{x}}_2$. Combinando le disuguaglianze e ricordando che $\varepsilon = \norm{\tilde{A}-A}_2$, otteniamo la tesi.
\end{proof}
Nel caso di autovalori non semplici, le perturbazioni agli autovalori possono essere molto più grandi. Per esempio, consideriamo la matrice $n\times n$ che ha uni sulla sopradiagonale, $\varepsilon$ in posizione $(n,1)$, e zero in tutte le altre posizioni
\[
A(\varepsilon) = \begin{bmatrix}
    0 & 1\\
    & 0 & \ddots\\
    & & \ddots & 1\\
    \varepsilon & & &  0\\
\end{bmatrix}.
\]
Se $\varepsilon=0$, chiaramente tutti gli autovalori sono zero, perché la matrice è triangolare superiore. Per $\varepsilon \neq 0$, è possibile dimostrare che gli autovalori di $A(\varepsilon)$ sono le radici $n$-esime complesse di $\varepsilon$, che hanno tutte modulo $\varepsilon^{1/n}$. Quindi
\[
\abs{\tilde{\lambda} - \lambda} = \varepsilon^{1/n},
\]
che è molto più grande di $\varepsilon$. Per esempio, se $\varepsilon=10^{-16}$, $n=8$, abbiamo $\varepsilon^{1/n} = 10^{-2}$: una perturbazione alla matrice $A(0)$ di norma $10^{-16}$ fa spostare gli autovalori di una distanza $10^{-2}$.

\section{Teorema dei cerchi di Gershgorin (*)}

È possibile ottenere anche un risultato di inclusione per gli autovalori, cioè un risultato teorico che ci dice in quali regioni del piano complesso si possono trovare gli autovalori di una matrice. Per introdurlo, definiamo i \emph{cerchi di Gershgorin} di una matrice $A\in\mathbb{C}^{n\times n}$ come gli insiemi
\[
K_i = \left\{z\in \mathbb{C} \colon \abs{z - A_{ii}} \leq \sum_{\substack{j=1\\ j \neq i}}^n \abs{A_{ij}} \right\}, \quad i=1,2,\dots,n.
\]
Le equazioni definiscono l'interno di $n$ cerchi, che hanno centro negli elementi diagonali di $A$ e raggio uguale alla somma dei moduli degli elementi al di fuori della riga.

\begin{theorem}[Teorema dei cerchi di Gershgorin]
Sia $A\in\mathbb{C}^{n\times n}$, e $\lambda$ un suo autovalore. Allora $\lambda$ appartiene all'unione dei cerchi $K_i$ definiti sopra (al variare di $i=1,2,\dots,n$).
\end{theorem}
\begin{proof}
Prendiamo un autovettore $\mathbf{x}$ associato a $\lambda$. Scrivendo componente per componente la relazione $A\mathbf{x} = \mathbf{x}\lambda$ otteniamo
\[
\sum_{j=1}^n A_{ij}x_j = x_i \lambda, \quad i=1,2,\dots,n.
\]
Riarrangiando termini e prendendo i moduli otteniamo
\[
\abs{\lambda - A_{ii}}\abs{x_i} = \abs{x_i\lambda - A_{ii}x_i} = \abs*{\sum_{\substack{j=1\\ j \neq i}}^n A_{ij}x_j} \leq \sum_{\substack{j=1\\ j \neq i}}^n \abs{A_{ij}}\abs{x_j}.
\]
Questa uguaglianza è valida per ogni $i=1,2,\dots,n$. Scegliamo ora come $i$ l'indice $p$ (o uno degli indici) tale che il modulo $\abs{x_p}$ sia massimo. Poiché $\mathbf{x}\neq 0$, avremo $\abs{x_p} \neq 0$. Possiamo quindi riscrivere l'uguaglianza precedente per $i=p$ e dividere per $\abs{x_p}$ entrambi i lati, ottenendo
\[
\abs{\lambda - A_{pp}} \leq \sum_{\substack{j=1\\ j \neq p}}^n \abs{A_{pj}}\frac{\abs{x_j}}{\abs{x_p}} \leq \sum_{\substack{j=1\\ j \neq i}}^n \abs{A_{pj}}.
\]
L'ultima disuguaglianza segue dal fatto che $\abs{x_p}$ è massimo. Questa catena di disuguaglianze dimostra che $\lambda$ sta all'interno del cerchio $K_p$. Poiché $\lambda$ sta all'interno di almeno un cerchio, sta anche all'interno della loro unione.
\end{proof}


\section{Soluzione di equazioni lineari: casi speciali}

\paragraph{Sistemi diagonali}

Il caso più semplice è quello di $A$ \emph{diagonale}, vale a dire
\[  
A = \begin{bmatrix}
    A_{11} \\
    & A_{22}\\
    && \ddots\\
    &&& A_{nn}
\end{bmatrix} \in \mathbb{R}^{n \times n}.
\]
In questo caso i prodotti sono semplici da fare, e $Ax=b$ implica
\begin{align*}
x_i = \frac{b_i}{A_{ii}}, \quad i=1,2,\dots,n.
\end{align*}
Il costo chiaramente è di $n$ operazioni aritmetiche.

\paragraph{Sistemi triangolari}

Un caso particolare  è quello in cui la matrice è \emph{triangolare inferiore}, cioè contiene zeri al di sopra della diagonale ($A_{ij} =0$ se $i<j$), oppure è \emph{triangolare superiore} ($A_{ij}=0$ se $i>j$).

(Una matrice può essere al tempo stesso \emph{triangolare} e \emph{quadrata}!)

Ricordiamo che una matrice triangolare è invertibile se gli elementi sulla sua diagonale sono tutti diversi da zero. Per dimostrarlo, per esempio notiamo che una matrice è invertibile se tutti i suoi autovalori sono diversi da zero, e che gli autovalori di una matrice triangolare sono uguali agli elementi sulla diagonale.

Se la matrice è triangolare inferiore, possiamo risolvere il sistema per \emph{sostituzione in avanti} partendo dalla prima equazione, che contiene solo la prima incognita:
\begin{align*}
 x_1 &= \frac{b_1}{A_{11}},\\
 x_2 &= \frac{b_2 - A_{21}x_1}{A_{22}},\\
 \vdots & \quad \quad \quad \vdots\\
 % x_i &= \frac{b_i - A_{i1}x_1 - \dots -A_{i,i-1}x_{i-1}}{A_{ii}},\\
 % \vdots & \vdots\\
 x_n &= \frac{b_n - A_{n1}x_1 - A_{n2}x_2 - \dots -A_{n,n-1}x_{n-1}}{A_{nn}}.\\
 \end{align*} 
Notare che ad ogni passo compaiono a destra dell'uguale solo valori $x_i$ che abbiamo già calcolato nei passi precedenti.
Possiamo contare il numero di operazioni in ogni riga, ottenendo
\[
1 + 3 + 5 + \dots + (2n-1) = n^2
\]
(questa ultima uguaglianza si può dimostrare per induzione).

Diciamo che la complessità del metodo è di $n^2$ operazioni aritmetiche. Notare che in questo caso non ci sono funzioni sconosciute da valutare, quindi questa è davvero tutta la complessità. Inoltre queste operazioni calcolano esattamente la soluzione, quindi quello che abbiamo chiamato ``errore analitico'' è zero.

Spesso quando si parla di complessità ci interessa solo l'ordine di grandezza, e quindi si scrive $O(n^2)$. Come in analisi, questa è una notazione che include complessità come $2n^2$, $\frac{1}{3}n^2 + 2n - 5$, ecc. Si intende che lavoriamo nel limite $n\to \infty$, quindi ignoriamo potenze \emph{inferiori} della $n$ che crescono più lentamente di $n^2$. 

Per una matrice triangolare superiore, la tecnica è analoga, ma dobbiamo partire dall'ultima equazione e risolvere ``andando al contrario'' (\emph{sostituzione all'indietro}):
\begin{align*}
x_n &= \frac{b_n}{A_{nn}},\\
x_{n-1} &= \frac{b_{n-1} - A_{n-1,n}x_n}{A_{n-1,n-1}},\\
\vdots & \quad \quad \quad \vdots\\
x_1 &= \frac{b_1 - A_{1,n}x_n - A_{1,n-1}x_{n-1} - \dots -A_{1,2}x_{2}}{A_{11}}.\\
\end{align*}

La complessità è di nuovo $n^2$ operazioni.

Se una matrice triangolare ha molti elementi uguali a zero (si dice che è \emph{sparsa}), 


\section{Eliminazione di Gauss e fattorizzazione LU}

Si chiama \emph{fattorizzazione LU} di $A$ una decomposizione di una matrice $A\in\mathbb{C}^{n\times n}$ come prodotto $A=LU$, dove $L$ è una matrice triangolare inferiore con elementi tutti uguali a $1$ sulla diagonale, e $U$ è una matrice triangolare superiore. Vediamo ora un metodo che permette di calcolare una fattorizzazione LU di una matrice $A \in \mathbb{C}^{n\times n}$; questo algoritmo è sostanzialmente una variante dell'eliminazione di Gauss che avete già visto ad algebra lineare.

Ricordiamo come funziona l'eliminazione di Gauss (senza considerare scambi di righe, per ora). Partiamo definendo $U_1 = A$, e vogliamo applicare ripetutamente delle trasformazioni in modo da generare una sequenza di matrici $U_2, U_3, \dots, U_n$, dove l'ultima matrice $U_n$ è triangolare superiore. Supponiamo di aver già fatto $k-1$ passi ed essere al $k$esimo. Abbiamo generato a partire da $A$ una matrice $A_k \in\mathbb{C}^{n\times n}$ che è parzialmente in forma triangolare superiore: in ogni colonna $j<k$, gli elementi sotto la diagonale sono nulli. 
\[
U_k = \begin{bmatrix}
    \ast & \dots & \ast & \ast & \ast & \dots & \ast\\
    0 & \ddots & \ast& \ast & \ast& \dots & \ast\\
    \vdots & \ddots & \ast & \ast& \ast & \dots & \ast\\
    0& 0  &0 & (U_k)_{kk} & \ast & \dots & \ast\\
    0& 0  &0 & (U_k)_{k+1,k} & \ast & \dots & \ast\\
    0& 0  &0 & \vdots & \ast & \dots & \ast\\
    0& 0  &0 & (U_k)_{n,k} & \ast & \dots & \ast\\
\end{bmatrix}
\]
(abbiamo chiamato $(A_k)_{ij}$ gli elementi della matrice $A_k$).
Nel $k$-esimo passo, introdurremo zeri anche nella $k$-esima colonna, ottenendo una nuova matrice 
\[
U_{k+1} = \begin{bmatrix}
    \ast & \dots & \ast & \ast & \ast & \dots & \ast\\
    0 & \ddots & \ast& \ast & \ast& \dots & \ast\\
    \vdots & \ddots & \ast & \ast& \ast & \dots & \ast\\
    0& 0  &0 & (U_k)_{kk} & \ast & \dots & \ast\\
    0& 0  &0 & 0 & \ast & \dots & \ast\\
    0& 0  &0 & \vdots & \ast & \dots & \ast\\
    0& 0  &0 & 0 & \ast & \dots & \ast\\
\end{bmatrix}.
\]
Lo facciamo sottraendo ogni riga $i>k$ un opportuno multiplo della $k$-esima riga, in modo da eliminare l'elemento in posizione $(i,k)$. Tale multiplo quindi dev'essere $\frac{(U_k)_{ik}}{(U_k)_{kk}}$. Le prime $k$ righe rimangono invariate.

\paragraph{Matrici elementari di Gauss} La parte che probabilmente non avete visto ad algebra lineare è che questa trasformazione si può vedere come una moltiplicazione a sinistra per una matrice: $U_{k+1} = E_k U_k$. La matrice $E_k$ si può scrivere come
\[
E_k = I - \ell_k e_k^T,
\]
dove $\ell_k$ è il vettore tale che 
\[
(\ell_k)_i = \ell_{i,k} = \begin{cases}
0 & i \leq k,\\
\frac{(U_k)_{ik}}{(U_k)_{kk}} & i>k,
\end{cases}
\]
e $e_k$ è il $k$-esimo vettore della base canonica. La matrice $E_k$ differisce dalla matrice identità solo per una sequenza di elementi diversi da zero nella $k$-esima colonna sotto la diagonale:
\[
E_k = \begin{bmatrix}
    1 \\
    & 1\\
    && \ddots\\
    & & & 1\\
    & & & -\ell_{k+1,k} & 1\\
    & & & -\ell_{k+2,k} & & 1\\
    & & & \vdots & & & \ddots \\
    & & & -\ell_{n,k} & & & & 1
\end{bmatrix}.
\]
Una matrice di questo tipo si chiama \emph{matrice elementare di Gauss}: nel dettaglio, una matrice si chiama \emph{matrice elementare di Gauss} se si scrive (per un qualche $k$) nella forma $I - \ell_k e_k^T$, dove $(\ell_k)_i = 0$ per ogni $i\leq k$.

Difatti, è semplice verificare che per ogni vettore $x\in\mathbb{R}^n$ 
\[
E_k \begin{bmatrix}
    x_1\\x_2\\ \vdots \\ x_n
\end{bmatrix}
=
\begin{bmatrix}
    x_1 \\ x_2\\ \vdots \\ x_k \\ x_{k+1} - \ell_{k+1,k}x_k\\
    \vdots \\
    x_n - \ell_{n,k}x_k
\end{bmatrix}.
\]

\paragraph{Esempio} Vediamo ora un esempio.
% >> rng(0)
\begin{lstlisting}
>> A = rand(4, 4)
A =
    0.8147    0.6324    0.9575    0.9572
    0.9058    0.0975    0.9649    0.4854
    0.1270    0.2785    0.1576    0.8003
    0.9134    0.5469    0.9706    0.1419
>> U1 = A;
>> E1 = eye(4); E1(2:4, 1) = -U1(2:4, 1) / U1(1, 1)
E1 =
    1.0000         0         0         0
   -1.1118    1.0000         0         0
   -0.1559         0    1.0000         0
   -1.1211         0         0    1.0000
>> U2 = E1 * U1
U2 =
    0.8147    0.6324    0.9575    0.9572
         0   -0.6055   -0.0996   -0.5788
         0    0.1799    0.0084    0.6511
         0   -0.1620   -0.1029   -0.9312
>> E2 = eye(4); E2(3:4, 2) = -U2(3:4, 2) / U2(2, 2)
E2 =
    1.0000         0         0         0
         0    1.0000         0         0
         0    0.2972    1.0000         0
         0   -0.2676         0    1.0000
>> U3 = E2 * U2
U3 =
    0.8147    0.6324    0.9575    0.9572
         0   -0.6055   -0.0996   -0.5788
         0         0   -0.0212    0.4791
         0         0   -0.0762   -0.7763
>> E3 = eye(4); E3(4:4, 3) = -U3(4:4, 3) / U3(3, 3)
E3 =
    1.0000         0         0         0
         0    1.0000         0         0
         0         0    1.0000         0
         0         0   -3.5869    1.0000
>> U4 = E3 * U3
U4 =
    0.8147    0.6324    0.9575    0.9572
         0   -0.6055   -0.0996   -0.5788
         0         0   -0.0212    0.4791
         0         0         0   -2.4948
\end{lstlisting}
Andiamo ora a scrivere in una funzione una versione più generale del metodo. Andremo ad utilizzare due sole variabili, una che chiamiamo $U$ e che contiene $U_k$ ad ogni passo, e una che chiamiamo $L$, che inizialmente è uguale alla matrice identità, e in cui scriviamo di volta in volta (senza il segno meno) i moltiplicatori usati: quindi avremo $L_1=I$, e dopo il passo $k$
\[
    L_{k+1} = \begin{bmatrix}
        1\\
        \ell_{21} & \ddots\\
        \vdots & \ddots & 1\\
        \vdots & \vdots & \ell_{k+1,k} & 1\\
        \vdots & \vdots & \ell_{k+2,k} & 0 & 1\\
        \vdots & \vdots & \vdots & 0 & 0 & \ddots\\
        \ell_{n1} & \dots & \ell_{n,k} & 0 & \dots & \dots & 1\\
    \end{bmatrix}.
\]
\begin{lstlisting}
function [L, U] = fattorizzazioneLU(A)

[m, n] = size(A);
if not(m == n)
    error('A dev''essere quadrata');
end

L = eye(n); % qui scriveremo i moltiplicatori
U = A;      % qui scriveremo U1, U2, ... U(n-1)
for k = 1:n-1
    if U(k,k) == 0
        error('Pivot nullo');
    end
    L(k+1:n, k) = U(k+1:n, k) / U(k, k);
    % sappiamo che questi elementi diventano 0varranno 
    U(k+1:n, k) = 0;
    % aggiorniamo le righe una ad una
    for i = k+1:n
        U(i, k+1:n) = U(i, k+1:n) - L(i,k)*U(k,k+1:n);
    end
end
\end{lstlisting}
Vogliamo dimostrare che dopo ogni passo del ciclo \lstinline{for} si ha $L_k U_k = I$. Per questo ci servirà innanzitutto un lemma.
\begin{lemma}[Proprietà delle matrici elementari di Gauss] Valgono le seguenti due proprietà:
\begin{enumerate}
    \item $E_k^{-1} = I + \ell_k e_k^T$.
    \item $E_1^{-1}E_2^{-1}\dots E_k^{-1} = I + \ell_1 e_1^T + \ell_2 e_2^T + \dots + \ell_k e_k^T$.
\end{enumerate}
\end{lemma}
\begin{proof}
\begin{enumerate}
    \item Basta verificare che
    \[
    E_k(I+\ell_ke_k^T) = (I-\ell_ke_k^T)(I+\ell_ke_k^T) = I - \ell_ke_k^T + \ell_ke_k^T - \ell_k\underbrace{e_k^T\ell_k}_{=0}e_k^T = I.
    \]
    Difatti il prodotto scalare $e_k^T\ell_k$ fa zero perché $\ell_k$ ha uno zero in posizione~$k$.
    \item Possiamo verificarlo per induzione: il caso $k=1$ l'abbiamo dimostrato al passo precedente. Supponendo che sia vero per un certo $k-1$, si ha
    \begin{align*}
    E_1^{-1}E_2^{-1}\dots E_k^{-1} = (I + \ell_1 e_1^T + \ell_2 e_2^T + \dots + \ell_{k-1} e_{k-1}^T)(I+\ell_ke_k^T).
    \end{align*}
    Ora espandiamo le parentesi e utilizziamo il fatto che $e_i^T\ell_k=0$ per $i<k$, vero perché $\ell_k$ ha le prime componenti uguali a zero.
\end{enumerate}
\end{proof}
Notiamo che la matrice $E_1^{-1}E_2^{-1}\dots E_k^{-1} = I + \ell_1 e_1^T + \ell_2 e_2^T + \dots + \ell_k e_k^T$ è esattamente quella che abbiamo chiamato $L_{k+1}$ più sopra.

Possiamo ora enunciare il risultato promesso.

\begin{theorem}
    Supponiamo che la funzione \lstinline{FattorizzazioneLU} arriva alla fine senza mai incontrare un pivot \lstinline{U(k,k)} nullo. Allora, dopo ogni passo del ciclo \lstinline{for}, si ha $L_k U_k = A$. In particolare, dopo il passo $n-1$, abbiamo la fattorizzazione LU $A = LU = L_{n-1}U_{n-1}$.
\end{theorem}
\begin{proof}
    All'inizio, abbiamo $L_1 = I$, $U_1 = A$, quindi la proprietà è vera per $k=1$. Otteniamo la matrice $U_{k+1}$ moltiplicando $A$ di volta in volta per le matrici elementari $E_1, E_2,\dots, E_k$, quindi (occhio all'ordine!)
    \[
        U_{k+1} = E_k E_{k-1} \dots E_2 E_1 A.
    \]
    Abbiamo già osservato al termine della dimostrazione del lemma che $L_{k+1} = E_1^{-1} E_2^{-1} \dots E_{k-1}^{-1} E_k^{-1}$, quindi il prodotto di queste due matrici fa $A$.
\end{proof}
Quindi dopo il passo $k$ abbiamo
\begin{equation} \label{fattLU}
A = 
\underbrace{
\begin{bmatrix}
    1\\
    \ell_{21} & \ddots\\
    \vdots & \vdots & 1\\
    \vdots & \vdots & \ell_{k+1,k} & 1\\
    \vdots & \vdots & \ell_{k+2,k} & 0 & 1\\
    \vdots & \vdots & \vdots & 0 & 0 & \ddots\\
    \ell_{n1} & \dots & \ell_{n,k} & 0 & \dots & \dots & 1\\
\end{bmatrix}
}_{L_{k+1} = E_1^{-1}E_2^{-1}\dots E_k^{-1}}
\underbrace{
\begin{bmatrix}
    U_{11} & U_{12} & \dots & & & &U_{1,n} \\
    0 & \ddots  & \dots & \dots & \dots &\dots & \vdots\\
    0 & & U_{kk} & \dots & \dots & \dots & \vdots\\
    0 & \dots & 0 & U_{k+1,k+1} & \dots & \dots & U_{k+1,n}\\
    0 & \dots & 0 & U_{k+2,k+1} & & &\vdots\\
    0 & \dots & 0 & \vdots & & & \vdots\\
    0 & \dots & 0 & U_{n,k+1} & \dots & \dots & U_{n,n}\\
\end{bmatrix}.
}_{U_{k+1}}
\end{equation}
In particolare, dopo $n-1$ passi, abbiamo ottenuto matrici $L=L_n$ e $U=U_n$ tali che
\[
A = L U,
\]
$U = U_n$ è una matrice triangolare superiore, e 
\[
L = E_1^{-1}E_2^{-1}\dots E_{n-1}^{-1} = \begin{bmatrix}
    1\\
    \ell_{21} & 1\\
    \ell_{31} & \ell_{32} & 1\\
    \ell_{41} & \ell_{42} & \ell_{43} & 1\\
    \vdots & \vdots & \vdots & \ddots & \ddots\\
    \ell_{n1} & \ell_{n2} & \ell_3 & \dots & \ell_{n,n-1} & 1
\end{bmatrix},
\]
è una matrice triangolare inferiore con $1$ sulla diagonale.

\paragraph{Costo computazionale dell'eliminazione di Gauss}

Il grosso del costo è dato dall'aggiornamento del blocco $A_{k:n, k:n}$ ad ogni passo del ciclo for; questo richiede $2(n-1)^2$ operazioni al primo passo, $2(n-2)^2$ al secondo, \dots $2\cdot 1^2$ al $n-2$-esimo passo, $2\cdot 0^2$ al $n-1$-esimo passo. Un'identità algebrica (che possiamo dimostrare per induzione) ci dice che
\[
0^2+1^2 + 2^2 + \dots + (n-1)^2 = \frac{1}{6}(n-1)n(2n-1) = \frac13n^3 + \mathcal{O}(n^2).
\]
I termini che abbiamo omesso e indicato con $O(n^2)$ sono \emph{di ordine inferiore} a $\frac13 n^3$, cioè contengono potenze più basse della $n$. Similmente, se teniamo traccia delle operazioni nelle altre righe (ad esempio, il calcolo degli $L_{ij}$) otteniamo termini di ordine inferiore. Quindi il costo della fattorizzazione LU (o dell'eliminazione di Gauss) è $\frac23 n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche.

Notiamo che nel codice non abbiamo mai scritto esplicitamente moltiplicazioni di matrici \lstinline{Ek*Uk}, ma abbiamo invece usato del codice che ne calcola il risultato usando la struttura particolare di queste matrici $E_k$. Se invece lo avessimo scritto come prodotto, Matlab avrebbe usato l'algoritmo generale per calcolare un prodotto matrice-matrice, che costa $2n^3 + \mathcal{O}(n^2)$. Una sola moltiplicazione di matrici costa più che non tutto l'algoritmo!

\paragraph{Soluzione di sistemi lineari tramite la fattorizzazione LU} 
Una volta calcolata $A = LU$, abbiamo decomposto $A$ in un prodotto di matrici più semplici, e possiamo usare questa decomposizione per risolvere sistemi lineari. 

Notiamo inoltre che la matrice $L$ è sempre invertibile (perché ha 1 sulla diagonale), e in più abbiamo $\det(A) = \det(LU) = \det(L) \det(U)$, quindi $U$ è invertibile se e solo se $A$ lo è. Quindi possiamo risolvere sistemi lineari con matrici $L$ e $U$. Abbiamo $\b = A\x = LU\x$.

L'algoritmo è composto di tre passi:
\begin{enumerate}
    \item Calcolo la fattorizzazione $A=LU$.
    \item Calcolo il vettore $\mathbf{y}=U\x$ risolvendo il sistema lineare $\b=L\mathbf{y}$ (sostituzione in avanti).
    \item Calcolo il vettore $\x$ risolvendo il sistema lineare $\mathbf{y}=U\x$ (sostituzione all'indietro).
\end{enumerate}
Il costo del primo passo è di $\frac23 n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche. Il secondo e il terzo costano $n^2$ operazioni aritmetiche, quindi sono molto più economici e ``spariscono'' dentro l'$\mathcal{O}(n^2)$. In totale quindi abbiamo $\frac23 n^3 + \mathcal{O}(n^2)$.

Un'altra osservazione interessante è che se dobbiamo risolvere molti sistemi lineari con vettori $\b$ diversi ma la stessa matrice $A$, possiamo riutilizzare la stessa fattorizzazione LU più volte, e quindi effettuare il passo più costoso una volta sola.

\paragraph{Esistenza della fattorizzazione LU}

Cosa può andare storto? Una sola cosa: quando dobbiamo dividere per $(U_k)_{kk}$ (elemento \emph{pivot}), questo potrebbe essere zero. Possiamo dimostrare un criterio che mostra quando questo succede.

Definiamo le \emph{sottomatrici principali di testa} di una matrice $A$ come $A_{1:k,1:k}$. Questa notazione (che possiamo usare anche in Matlab) significa prendere le righe dalla $1$ alla $k$ e le colonne dalla $1$ alla $k$ della matrice $A$.

Esempio: sottomatrici principali di una ``matrice a freccia''; sono tutte uguali a matrici identità.

\begin{theorem}[Esistenza della fattorizzazione LU]
Data una matrice $A\in\mathbb{C}^{n\times n}$, supponiamo che le sottomatrici principali di testa $A_{1:k,1:k}$ di $A$, per $k=1,\dots,n-1$, siano tutte invertibili. Allora, è possibile portare a termine l'algoritmo di fattorizzazione LU senza mai incontrare pivot nulli, e quindi esiste una fattorizzazione LU di $A$.
\end{theorem}
\begin{proof}
Partiamo dall'equazione~\eqref{fattLU}, che mostra le matrici ottenute dopo i primi $k$ passi della fattorizzazione. Siamo quindi pronti per fare il passo $k+1$, e vogliamo controllare se il pivot $(U_{k+1}){k+1,k+1}$ è zero.

Notiamo che le prime $k+1$ \emph{righe} (e non solo $k$) di $L$ e di $U$ sono già quelle definitive: non verranno più modificate nei passi successivi. Inoltre, per come sono messi gli zeri nelle matrici, se facciamo il prodotto tra le prime $k+1$ righe di $L_{k+1}$ e le prime $k+1$ colonne di $U_{k+1}$ otteniamo $A_{1:k+1,1:k+1}$; cioè
\[
A_{1:k+1,1:k+1} = L_{1:k+1,1:k+1} U_{1:k+1,1:k+1}:
\]
Questa è una fattorizzazione LU della matrice $A_{1:k+1,1:k+1}$. In particolare, abbiamo
\[
\det A_{1:k+1,1:k+1} = (\det L_{1:k+1,1:k+1}) (\det U_{1:k+1,1:k+1}) = (1\cdot 1 \cdot \dots \cdot 1) (U_{11}U_{22}\cdots U_{k+1,k+1}).
\]
Quindi se $\det A_{1:k+1,1:k+1} \neq 0$, allora anche l'elemento $U_{k+1,k+1}$ è diverso da zero e possiamo effettuare il passo $k$-esimo dell'eliminazione di Gauss. Visto che ho $n-1$ passi, mi basta guardare fino a $A_{1:n-1,1:n-1}$: la matrice $A$ stessa potrebbe essere singolare, e quindi potrei avere $U_{nn}=0$, ma tanto non devo più effettuare divisioni.
\end{proof}
Notiamo che quello che abbiamo dimostrato qui sopra in realtà è un ``se e solo se'': se $A_{1:k+1,1:k+1}$ è la prima sottomatrice principale di testa non invertibile, allora possiamo effettuare i primi $k$ passi, e $U_{11},\dots,U_{k,k}$ sono diversi da zero. Ma arrivati al passo $k+1$ si ha che $\det A_{1:k+1,1:k+1} = 0$ implica $U_{k+1,k+1}=0$ e quindi l'eliminazione di Gauss fallisce.

\paragraph{Categorie di matrici per cui esiste sempre la fattorizzazione LU}

Ci sono alcune categorie di matrici particolari per cui esiste sempre la fattorizzazione LU. Una sono le matrici \emph{dominanti diagonali}. Una matrice $A\in\mathbb{C}^{n\times n}$ si dice \emph{dominante diagonale per righe} se
\[
\abs{A_{ii}} > \sum_{j\neq i} \abs{A_{ij}}, \quad i=1,2,\dots,n
\]
vale a dire, in ogni riga il valore assoluto dell'elemento sulla diagonale è maggiore della somma di tutti gli altri.
\begin{theorem}
Una matrice dominante diagonale è invertibile.
\end{theorem}
\begin{proof}
Supponiamo invece (per assurdo) che $A\mathbf{x}=0$ per un qualche vettore $\mathbf{x}\neq 0$. Allora, $\mathbf{x}$ è un autovettore con autovalore $\lambda=0$. Per il teorema dei cerchi di Gershgorin, dovrà esistere un indice $p\in \{1,2,\dots,n\}$ tale che $0 \in K_p$. Ma questa relazione vuol dire che
\[
\abs{A_{pp}} = \abs{0 - A_{pp}} \leq \sum_{j\neq i} \abs{A_{ij}},
\]
e quindi contraddice la dominanza diagonale.
\end{proof}
Osserviamo che se $A$ è dominante diagonale, allora lo sono anche tutte le sue sottomatrici principali di testa (le disuguaglianze diventano più forti perché stiamo omettendo dei termini!). Quindi se $A$ è dominante diagonale allora ammette fattorizzazione LU.

Analogamente, possiamo definire matrici dominanti diagonali per colonne, quando
\[
\abs{A_{jj}} > \sum_{i\neq j} \abs{A_{ij}}, \quad j=1,2,\dots,n.
\]
Una matrice $A$ è dominante diagonale per colonne se $A^T$ è dominante diagonale per righe, quindi valgono gli stessi risultati.

Esempio: la matrice
\[
\begin{bmatrix}
    -5 & 2 & 2\\
    1 & 3 & -1\\
    1 & 1 & 3
\end{bmatrix}
\]
è dominante diagonale per righe, ma non per colonne (valgono uguaglianze). Le sue sottomatrici principali di testa sono di nuovo pred. diag. per righe (e questa volta anche per colonne).



\paragraph{Stabilità e necessità del pivoting}

Su un computer, difficilmente gli ``zeri'' vengono calcolati esattamente come zero! L'eliminazione di Gauss tecnicamente fallisce solo se c'è un pivot \emph{esattamente} uguale a zero, ma un pivot molto vicino a zero è comunque problematico. Non facciamo un'analisi dettagliata dell'errore algoritmico, ma vediamo direttamente un esempio in cui le cose vanno storte. Supponiamo di avere (per un $\varepsilon>0$ molto piccolo) la matrice
\[
\begin{bmatrix}
    \varepsilon & 1 & 1\\
    1 & 1 & 1\\
    1 & 1 & -1
\end{bmatrix}.
\]
Questa matrice è ben condizionata (il condizionamento nelle tre norme è minore di 10), ma dopo il primo passo di eliminazione di Gauss otteniamo
\[
\begin{bmatrix}
    \varepsilon & 1 & 1\\
    0 & 1-\frac{1}{\varepsilon} & 1-\frac{1}{\varepsilon}\\
    0 & 1-\frac{1}{\varepsilon} & -1-\frac{1}{\varepsilon}
\end{bmatrix}.
\]
Se $\varepsilon$ è molto piccolo, $\frac{1}{\varepsilon}$ è molto grande. In particolare, se per esempio $\varepsilon = 2^{-60}$, il numero di macchina più vicino sia a $1-\frac{1}{\varepsilon}$ che a $-1-\frac{1}{\varepsilon}$ è $\frac{1}{\varepsilon}$, e quindi le ultime due righe diventano uguali quando andiamo a scrivere quei numeri su un calcolatore: pertanto l'algoritmo di fattorizzazione LU si blocca affermando (erroneamente) che la matrice è singolare. Ma in realtà la matrice è molto lontana dall'esserlo. Anche senza arrivare a valori così estremi, dobbiamo sommare un numero molto grande a tutti gli elementi della sottomatrice $A_{2:3,2:3}$, e poi andare a fare una sottrazione tra due valori molto grandi e molto vicini tra loro, al passo successivo dell'eliminazione. Questo causa perdita di precisione e problemi numerici.

La soluzione, in questo caso e in molti problemi simili, è scambiare tra loro le righe. In particolare, vogliamo scambiarle in modo da avere in posizione $(k,k)$ (cioè come pivot) il numero \emph{più grande} in valore assoluto tra quelli della sottomatrice $(U_k)_{k:n,k}$.

Notare che questo è il contrario rispetto a quello che facevate ad algebra lineare facendo i conti a mano: se per esempio i numeri della prima colonna erano $2,-4,-3,1$, tipicamente volevate $1$ come pivot in modo da non avere denominatori. Questa volta invece l'obiettivo è diverso: vogliamo pivot più grandi possibili, quindi scegliamo $-4$ come pivot.

\paragraph{Matrici di permutazione}
La fattorizzazione che vedremo corrisponde essenzialmente a calcolare la fattorizzazione LU di una matrice ottenuta dalla $A$ permutando le righe in un ordine opportuno: quindi per esempio
\[
A = \begin{bmatrix}
    A_{1,:} \\
    A_{2,:} \\
    A_{3,:} \\
    A_{4,:}
\end{bmatrix}, \quad
PA = \begin{bmatrix}
    A_{4,:}\\
    A_{2,:}\\
    A_{1,:}\\
    A_{3,:}
\end{bmatrix}.
\]
Abbiamo indicato la matrice di destra con $PA$ perché effettivamente è ottenuta moltiplicando la matrice $A$ a sinistra per una matrice $P\in\mathbb{R}^{n\times n}$: questa è la matrice ottenuta dalla matrice identità applicando alcuni scambi di righe (gli stessi applicati in $A$); ad esempio,
\[
P = 
\begin{bmatrix}
    \mathbf{e}_4^T\\
    \mathbf{e}_2^T\\
    \mathbf{e}_1^T\\
    \mathbf{e}_3^T
\end{bmatrix}
=
\begin{bmatrix}
    0 & 0 & 0 & 1\\
    0 & 1 & 0 & 0\\
    1 & 0 & 0 & 0\\
    0 & 0 & 1 & 0
\end{bmatrix}.
\]
Una matrice di questo tipo è detta \emph{matrice di permutazione}, perché il suo effetto su vettori e matrici è quello di permutarne le entrate:
\[
P\mathbf{x}
=
\begin{bmatrix}
    0 & 0 & 0 & 1\\
    0 & 1 & 0 & 0\\
    1 & 0 & 0 & 0\\
    0 & 0 & 1 & 0
\end{bmatrix}
\begin{bmatrix}
    x_1\\x_2\\x_3\\x_4
\end{bmatrix} = \begin{bmatrix}
    x_4\\x_2\\x_1\\x_3
\end{bmatrix}.
\]
La stessa cosa succede quando effettuiamo il prodotto $PA$; la stessa permutazione viene applicata calcolando ogni colonna separatamente, quindi l'effetto netto è quello di permutare le righe di $A$.

\paragraph{Eliminazione di Gauss con pivoting (parziale)}

Partiamo da una matrice $P_1 = I$. Al primo passo dell'eliminazione di Gauss, una volta individuata la riga $p$ dove sta l'elemento con $\abs{A_{p1}} = \max \abs{A_{i1}}$, scambiamo la riga $p$ e la riga $1$ in $A$. Questo corrisponde a rimpiazzare la matrice $A$ con una matrice $P_2A$, dove $P_2$ è la matrice che differisce dall'identità solo per lo scambio delle righe $1$ e $p$.

Similmente, prima di ogni passo $k$, individuiamo la riga dove sta il pivot $\abs{(U_k)_{pk}} = \max \abs{(U_k)_{k:n,k}}$, e scambiamo la riga $k$ con la riga $p$ nella matrice $P_k A$. Quella che otteniamo quindi è un'altra matrice ottenuta permutando le righe della matrice $A$, che possiamo quindi scrivere come $P_{k+1} A$, dove $P_k$ è un'opportuna matrice di permutazione.

Notiamo che fino a questo punto l'algoritmo di fattorizzazione LU ha lavorato indipendentemente sulle righe da $k:n$: se queste righe fossero state in un altro ordine nella matrice $A$, avremmo ottenuto le stesse matrici $L_k$ e $U_k$, solo con gli elementi calcolati nelle ultime righe in ordine diverso. Quindi per ottenere il risultato dei primi $k$ passi di fattorizzazione LU su questa matrice $P_{k+1} A$, dobbiamo semplicemente prendere le matrici $L_k$ e $U_k$ che abbiamo già calcolato, e scambiare le righe $p$ e $k$ negli elementi che abbiamo calcolato finora. (Sulla matrice $L_k$, questo scambio si limita alle prime $k-1$ colonne, quelle contenenti gli elementi che abbiamo calcolato: gli elementi uguali a $1$ sulla diagonale restano al loro posto.)

A questo punto, effettuiamo normalmente un passo di eliminazione di Gauss sulle matrici ottenute, ottenendo due nuove matrici $L_{k+1}$ e $U_{k+1}$. Per come abbiamo lavorato, vale ad ogni passo la relazione $P_k A = L_k U_k$.

Vediamo insieme il codice Matlab di questo algoritmo.
\begin{lstlisting}
function [L, U, P] = fattorizzazioneLU_pivoting(A)
% fattorizzazione LU con pivoting
% restituisce matrici tali che L*U = P*A
[m, n] = size(A);
if not(m == n)
    error('A deve essere quadrata');
end

L = eye(n);
U = A;
P = eye(n);
for k = 1:n-1
    % ad ogni iterazione, abbiamo L*U == P*A

    % calcola riga p del pivot
    [valore, posizione] = max(abs(U(k:n,k)));
    % converte una posizione in k:n in un indice di riga
    p = posizione + k-1;
    if valore == 0
        error('matrice esattamente singolare');
    end

    % esegue gli scambi
    L([p k], 1:k-1) = L([k p], 1:k-1);
    U([p k], k:n) = U([k p], k:n);
    P([p k], 1:n) = P([k p], 1:n);

    % prosegue con l'eliminazione di Gauss
    L(k+1:n, k) = U(k+1:n, k) / U(k, k);
    U(k+1:n, k) = 0;
    for i = k+1:n
        U(i, k+1:n) = U(i, k+1:n) - L(i,k)*U(k,k+1:n);
    end
end    
\end{lstlisting}
Notiamo che \lstinline{posizione} restituisce un indice all'interno del vettore di $n-k+1$ elementi $U_{k:n,n}$: se per esempio l'elemento di modulo massimo fosse il primo, \lstinline{posizione = 1}, però questa posizione 1 corrisponde alla riga $k$ delle matrici con cui stiamo lavorando. Per convertire questa posizione in un indice di riga, dobbiamo sommare $k-1$.

Qual è il costo computazionale di questo algoritmo? Le uniche operazioni che abbiamo aggiunto sono la ricerca del massimo e gli scambi di righe. Queste sono operazioni che richiedono un certo tempo per essere effettuate sul computer, però non sono operazioni aritmetiche, strettamente parlando. Quindi il costo in termini di operazioni aritmetiche è di nuovo di $\frac23 n^3$ operazioni aritmetiche.

In Matlab, questa funzione già esiste, con un nome diverso: \lstinline{[L, U, P] = lu(A)}.

\paragraph{Errore algoritmico dell'eliminazione di Gauss con pivoting}
Non vediamo un'analisi completa dell'errore algoritmico dell'eliminazione di Gauss (che è abbastanza complessa), ma il messaggio principale è che l'errore algoritmico è circa dello stesso ordine dell'errore inerente (e quindi l'algoritmo è ``il migliore possibile'') a patto che gli elementi della $L$ e della $U$ non crescano troppo durante l'algoritmo.

Il pivoting assicura che gli elementi della $L$ siano tutti minori o uguali a $1$ in valore assoluto. Però anche con il pivoting esistono esempi particolarmente sfortunati in cui $\norm{U}/\norm{A}$ cresce come $2^n$, dove $n$ è la dimensione. Nella maggior parte dei casi, però, l'eliminazione di Gauss con pivoting è un algoritmo stabile, cioè l'errore algoritmico $e_{alg}$ è dello stesso ordine di grandezza di quello inerente $e_in$. (L'errore analitico, invece, è $0$, visto che l'algoritmo calcola la soluzione esatta di $Ax=b$, non una successione convergente ad essa).

Questo è l'algoritmo più usato per risolvere sistemi lineari; in Matlab anche \lstinline{A \ b} utilizza questo algoritmo.

\paragraph{Soluzione di sistemi lineari tramite fattorizzazione LU con pivoting}

La fattorizzazione LU con pivoting restituisce quindi $L,U,P$ tali che $LU = PA$. Possiamo usare questa fattorizzazione per risolvere un sistema lineare $A\x=\b$, in questo modo.

Il sistema $A\x = \b$ ha la stessa soluzione di $PA\x = P\b$; difatti, moltiplicare per $P$ ha il solo effetto di riordinare le equazioni del sistema. Possiamo quindi risolvere $LU\x=P\b$, e per farlo procediamo come nel caso della fattorizzazione LU: chiamiamo $\mathbf{y}=U\x$, e risolviamo nell'ordine
\[
L\mathbf{y} = P\b, \quad U\x = \mathbf{y}
\]
per sostituzione in avanti e all'indietro rispettivamente.

\paragraph{Calcolo del determinante mediante fattorizzazione LU con pivoting} Abbiamo visto nell'introduzione del corso che usare le formule classiche dell'algebra lineare (espansione di Laplace, formule ricorsive sui minori, \dots) non è un modo efficace di calcolare il determinante: il loro costo computazionale cresce troppo velocemente. Vediamo qui invece un metodo basato sulla fattorizzazione LU per calcolarlo.

\begin{theorem}
Sia $PA = LU$ una fattorizzazione LU con pivoting della matrice $A \in \mathbb{C}^{n \times n}$. Allora,
\[
\det(A) = (-1)^s U_{11} U_{22} \dots U_{nn},
\]
dove $s$ è il numero di scambi di riga effettuati durante il calcolo della fattorizzazione.
\end{theorem}
\begin{proof}
Usando il teorema di Binet, abbiamo
\begin{equation} \label{detconti}
    \det P \det A = \det PA = \det LU = \det L \det U.    
\end{equation}
Poiché $L$ e $U$ sono triangolari, i loro determinanti sono i prodotti degli elementi lungo la diagonale:
\begin{align*}
\det L = 1 \cdot 1 \cdot 1 \cdot \dots \cdot 1 = 1;
\det U = U_{11} U_{22} \dots U_{nn}.
\end{align*}
La matrice di permutazione $P$ è ottenuta applicando alla matrice identità gli scambi di riga effettuati lungo la fattorizzazione; sappiamo dall'algebra lineare che ogni scambio di riga fa cambiare il segno del determinante, quindi
\[
\det P = (-1)^s \det I = (-1)^s.
\]
Possiamo quindi ricavare $\det A$ dalla~\eqref{detconti}, ottenendo la tesi.
\end{proof}


\section{Fattorizzazioni per matrici simmetriche}

\paragraph{Fattorizzazione $LDL^T$}

Supponiamo di effettuare l'eliminazione di Gauss su una matrice simmetrica, cioè $A = A^T$. Non è difficile vedere che dopo il primo passo la matrice $U_2$ ottenuta non è più simmetrica; la ``struttura'' della matrice viene distrutta. Esiste però una variante dell'eliminazione di Gauss che evita questo problema e lavora unicamente con matrici simmetriche. L'idea è la seguente: ad ogni passo, anziché definire $U_{2} = E_1 U_1$, definiamo $U_{2} = E_1 U_1 E_1^T$ (moltiplicando a destra e a sinistra). Questa matrice è simmetrica, difatti $(E_1 U_1 E_1^T)^T = (E_1^T)^T (U_1)^T E_1^T = E_1 U_1 E_1^T$.

L'effetto della moltiplicazione per $E_1^T$ è quello di sommare ad ogni colonna un multiplo della prima; quindi gli unici elementi che cambiano rispetto a $E_1 U_1$ sono quelli della prima riga successivi al primo, che diventano zero: quindi $U_2 = E_1 U_1 E_1^T$ ha la forma
\[
U_2 = \begin{bmatrix}
    A_{11} & 0 & 0 & 0\\
    0 & \star & \star & \star\\
    0 & \star & \star & \star\\
    0 & \star & \star & \star\\
\end{bmatrix}.  
\]
Il blocco di elementi indicati con $\star$ è simmetrico, e possiamo continuare nello stesso modo, definendo $U_3 = E_2 U_2 E_2^T$, e così via. Alla fine della procedura, otteniamo una matrice diagonale, che possiamo chiamare $D$. Più nel dettaglio, abbiamo
\[
D = E_{n-1}E_{n-2}\dots E_2 E_1 A E_1^T E_2^T\dots E_{n-2}^T E_{n-1}^T.
\]
Moltiplicando per le inverse delle $E_k$ (che esistono) dai lati opportuni, abbiamo
\[
A = \underbrace{(E_1^{-1}E_2^{-1}\dots E_{n-1}^{-1}) }_{=L}D \underbrace{(E_{n-1}^T)^{-1}  (E_{n-2}^T)^{-1} \dots (E_{2}^T)^{-1} (E_{1}^T)^{-1}}_{=L^T} = LDL^T.
\]
Quella che abbiamo ottenuto, quindi, è una particolare fattorizzazione LU in cui la matrice $U$ è uguale a $DL^T$, il prodotto di $L$ per una matrice diagonale. Si chiama \emph{fattorizzazione $LDL^T$}.

\paragraph{Costo computazionale della fattorizzazione $LDL^T$}

Possiamo impostare un'analisi del costo computazionale analoga a quella che abbiamo fatto per la fattorizzazione LU. Di nuovo, la parte più consistente del costo viene dall'aggiornamento delle righe, 
\[
U_{i,k+1:n} \gets U_{i,k+1:n} - L_{i,k}U_{k,k+1:n}.
\]
Questa volta le matrici coinvolte sono simmetriche. Quindi non è necessario calcolare tutti gli elementi: basta calcolare quelli della parte triangolare superiore (inclusa la diagonale), e ignorare la parte triangolare inferiore che può essere ricavata per simmetria. Questo riduce il costo computazionale alla metà: da $\frac23 n^3 + \mathcal{O}(n^2)$ a $\frac13n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche.

Vediamo del codice per effettuarla, utilizzando questo accorgimento.
\begin{lstlisting}
function [L, D] = fattorizzazioneLDL(A)
% fattorizzazione A = L*D*L^T di una matrice simmetrica, senza pivoting
[m, n] = size(A);
if not(m == n)
    error('A deve essere quadrata');
end

L = eye(n);
U = A;     
for k = 1:n-1
    if U(k,k) == 0
        error('Pivot nullo');
    end
    L(k+1:n, k) = U(k+1:n, k) / U(k, k);
    for i = k+1:n
        % aggiorniamo la parte triangolare superiore della riga i...
        U(i, i:n) = U(i, i:n) - L(i,k)*U(k,i:n);
        % ...e copiamo gli elementi calcolati nella parte tr. inf.
        U(i+1:n, i) = U(i, i+1:n)';
    end
    % questi elementi sono 0, non serve calcolarli
    U(k+1:n, k) = 0;
    U(k, k+1:n) = 0;
end
D = U;        
\end{lstlisting}

\paragraph{Pivoting e fattorizzazione $LDL^T$}

In una fattorizzazione $LDL^T$, il pivoting diventa più complicato: difatti, scambiando righe si perde la simmetria. Per mantenerla, è necessario scambiare non solo le righe, ma anche le colonne corrispondenti, cioè considerare $PAP^T$. Anche con questa modifica, però, non si ottiene un algoritmo stabile.
In Matlab, la funzione \lstinline{[L,D,P] = ldl(A)} produce una fattorizzazione $LDL^T = P^TAP$, però (per avere una versione più stabile) la matrice $D$ può avere dei blocchi $2\times 2$ lungo la diagonale. Anche questa volta, però, abbiamo una categoria particolare di matrici per cui possiamo dimostrare che la fattorizzazione funziona sempre senza bisogno di ricorrere al pivoting.

\paragraph{Matrici SPD (simmetriche e positive definite)}

Una matrice $A\in\mathbb{R}^{n\times n}$ (serve che sia reale, questa volta!) si definisce \emph{simmetrica e positiva definita} (SPD) se:
\begin{enumerate}
    \item è simmetrica, cioè $A=A^T$;
    \item è positiva definita, cioè $\mathbf{x}^TA\mathbf{x} > 0$ per ogni vettore $\mathbf{x}\in \mathbb{R}^n$ tale che $\mathbf{x}\neq 0$.
\end{enumerate}
Spesso si dice solo ``positiva definita'' sottintendendo ``simmetrica''.

Si può dimostrare il seguente risultato (non vediamo qui la dimostrazione; talvolta si fa nei corsi di algebra lineare):
\begin{theorem}
Una matrice simmetrica $A$ è definita positiva se e solo se tutti i suoi autovalori sono reali (strettamente) positivi. 
\end{theorem}
Valgono le seguenti proprietà.
\begin{enumerate}
    \item Una matrice definita positiva ha tutti gli elementi sulla diagonale (strettamente) positivi; difatti $A_{kk} = e_k^T A e_k > 0$. (Notare che questo \emph{non} è un ``se e solo se'': esistono matrici simmetriche che hanno tutti gli elementi sulla diagonale positivi, ma non sono positive definite! Per esempio, $A = \begin{bsmallmatrix}
        1 & 1\\ 1 & 1
    \end{bsmallmatrix}$).
    \item Se $A$ è positiva definita e $M$ è invertibile, allora lo è anche $MAM^T$: difatti $\mathbf{x}^T MAM^T \mathbf{x} = (M^T\mathbf{x})^T A (M^T\mathbf{x}) > 0$.
\end{enumerate}
Utilizzando queste due proprietà, è facile dimostrare che ad ogni passo della fattorizzazione $LDL^T$ $U_k$ è positiva definita, e il pivot $U_{kk}$ è (strettamente!) positivo. Quindi una matrice SPD ammette sempre fattorizzazione $LDL^T$, e gli elementi diagonali $d_{kk}$ sono tutti (strettamente) positivi. In più, è possibile dimostrare che questa fattorizzazione è stabile senza bisogno di fare pivoting; gli elementi della matrice $D$ non crescono mai troppo rispetto agli elementi di $A$.

\paragraph{Fattorizzazione di Cholesky}
Per una matrice definita positiva, possiamo riscrivere la fattorizzazione LDL in un formato leggermente diverso. Visto che tutti gli elementi di $D$ sono positivi, possiamo scrivere $D = D^{1/2} D^{1/2}$, dove $D^{1/2}$ è la matrice diagonale che ha elementi diagonali $\sqrt{d_{11}}, \sqrt{d_{22}}, \dots, \sqrt{d_{nn}}$. Quindi
\[
A = LDL^T = (LD^{1/2})(D^{1/2}L^T) = R^TR,
\]
dove $R$ è una matrice triangolare superiore. Abbiamo quindi scritto $A$ come il prodotto di una matrice triangolare inferiore e di una triangolare superiore, che sono una la trasposta dell'altra. Questa fattorizzazione si chiama \emph{fattorizzazione di Cholesky}. 

Il costo computazionale è di nuovo di $\frac13n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche, con il dettaglio che tra le operazioni ci sono anche $n$ radici quadrate. In Matlab, c'è il comando \lstinline{R = chol(A)}.

\paragraph{Esercizio} Dato un parametro $\alpha \in \mathbb{C}$, consideriamo la matrice
\[
A_\alpha =
\begin{bmatrix}
    1  & & & & -\alpha\\
    -\alpha & 1 & & & \\
    & -\alpha & 1 & & \\
    & & \ddots & \ddots\\
    & & & -\alpha & 1
\end{bmatrix} \in \mathbb{C}^{n\times n}.
\]
\begin{enumerate}
    \item Per quali valori di $\alpha$ il teorema dei cerchi di Gershgorin ci permette di concludere che la matrice è invertibile?
    \item Per quali valori di $\alpha$ è soddisfatta la condizione di esistenza della fattorizzazione LU?
    \item Sapreste trovare la fattorizzazione LU di $A$?
    \item Per quali valori di $\alpha$ la matrice è invertibile?
\end{enumerate}
Soluzione:
\begin{enumerate}
    \item I cerchi di Gershgorin hanno tutti centro $1$ e raggio $\abs{\alpha}$. Se $\abs{\alpha} < 1$, allora $0$ non appartiene all'unione dei cerchi di Gershgorin, quindi non è un autovalore della matrice $A_\alpha$; pertanto $A_\alpha$ è invertibile. Se invece $\abs{\alpha} \geq 1$, allora $1$ sta all'interno dell'unione dei cerchi, quindi il teorema non ci permette di concludere nulla: $0$ potrebbe essere autovalore oppure no.
    \item Le sottomatrici di testa fino all'ordine $n-1$ sono tutte triangolare inferiori con $1$ sulla diagonale; quindi sono invertibili per ogni valore di $\alpha\in\mathbb{C}$.
    \item Eseguiamo l'eliminazione di Gauss: al primo passo, l'unico elemento da eliminare è quello in posizione $(2,1)$, e per farlo dobbiamo sottrarre $-\alpha$ volte la riga 1 dalla riga 2 (occhio al doppio segno $-$).
    \[
        U_1 = A; \, U_2 = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& -\alpha & 1 & \dots  & 0 & 0\\
            & & \alpha & 1\\
            & & & \ddots & \ddots & \\
            & & &  &-\alpha & 1      
        \end{bmatrix}
    \]
    Continuando nello stesso modo, al passo successivo dobbiamo eliminare l'elemento in posizione $(3,2)$, di nuovo con moltiplicatore $-\alpha$, ottenendo
    \[
        U_3 = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& 0 & 1 & \dots  & 0 & 0\\
            & & \alpha & 1\\
            & & & \ddots & \ddots & \\
            & & &  &-\alpha & 1      
        \end{bmatrix}.
    \]
    L'unico passo leggermente diverso è l'ultimo, in cui abbiamo
    \[
        U_{n-1} = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& 0 & 1 & \dots  & 0 & 0\\
            & & \ddots & \ddots\\
            & & & 0 & 1 & -\alpha^{n-1}\\
            & & &  &-\alpha & 1      
        \end{bmatrix},
        \quad
        U_n = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& 0 & 1 & \dots  & 0 & 0\\
            & & \ddots & \ddots\\
            & & & -\alpha & 1 & -\alpha^{n-1}\\
            & & &  & 0 & 1-\alpha_n
        \end{bmatrix}.
    \]
    Quindi otteniamo la fattorizzazione $A=LU$ con
    \[
        L = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  0\\
            -\alpha & 1 & 0 & \dots & 0 & 0\\
            0& -\alpha & 1 & \dots  & 0 & 0\\
            & & \alpha & 1\\
            & & & \ddots & \ddots & \\
            & & &  &-\alpha & 1      
        \end{bmatrix}, \quad U = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& 0 & 1 & \dots  & 0 & 0\\
            & & \ddots & \ddots\\
            & & & 0 & 1 & -\alpha^{n-1}\\
            & & &  & 0 & 1-\alpha_n
        \end{bmatrix}.
    \]
    Ricordiamo che la matrice $L$ è ottenuta a partire dalla matrice identità inserendo sotto la diagonale tutti i moltiplicatori utilizzati nell'eliminazione.
    \item Dalla fattorizzazione LU calcolata, abbiamo $\det A_\alpha = \det U = 1\cdot 1 \cdot \dots \cdot 1 \cdot (1-\alpha^n) = 1-\alpha^n$. Quindi il determinante si annulla se e solo se $\alpha$ è una radice $n$-esima complessa dell'unità. Notiamo che questo risultato è coerente con quanto visto sopra con il teorema dei cerchi di Gershgorin.
\end{enumerate}

% \section{Laboratorio su LDL ed esistenza LU}

% Esercizio: scriviamo una \lstinline{function s = somma_fuori_diagonale(A, i)} che, data in input una matrice $A$, calcola $\sum_{\substack{j=1\\ j\neq i}}^n \abs{A_{ij}}$. Mostrare soluzioni fatte sia con \lstinline{for j=1:n; if j ~= i} che con\\ \lstinline{sum(abs(A(i,1:i-1))) + sum(abs(A(i,i+1:n)))}.

% Poi usiamola per scrivere una 
% funzione che controlla se una matrice è predominante diagonale per righe. Come facciamo a restituire valori vero/falso?
% \begin{lstlisting}
% function result = isdominant(A)
%   % cicli, condizioni, eccetera
%   result = true;
%   return

%   result = false;
%   % "return" non serve alla fine
% \end{lstlisting}

% Altro esercizio: scriviamo una funzione che controlla se una matrice è predominante diagonale per colonne. Facile se riutilizziamo il codice dell'altra funzione!

% Buona norma di programmazione: se potete, meglio riutilizzare che riscrivere! E meglio usare funzioni corte che fanno una cosa sola, come stiamo facendo qua. Sono più facili da testare.

% Altro esercizio: proviamo a scrivere una \lstinline{function result = issymmetric(A)} che testa se la matrice $A$ è simmetrica.

% Come facciamo a farlo? Occhio che \lstinline{A == A'} non fa quello che volete: in Matlab, \lstinline{A == B} restituisce una matrice $n\times n$ di valori vero/falso (o 0/1) che ci dice quali elementi $A_{ij}$ sono uguali a quali elementi $B_{ij}$. Ci servono due cicli for, oppure \lstinline{isequal(A, A')}.

% Altro esercizio: calcoliamo la fattorizzazione LDL di una matrice simmetrica $A$ (senza pivoting).

% Il punto delicato è come calcolare l'update $A_{k+1:n,k+1:n} \gets A_{k+1:n,k+1:n} - L_{k+1:n,k}A_{k,k+1:n}$ facendo operazioni solo per parte triangolare inferiore. Per questo, andiamo a scrivere questo update come
% \[
% A_{ij} \gets A_{ij} - L_{ik}A_{kj}, \quad i,j=k+1,k+2,\dots,n
% \]
% ed usiamo dei cicli for che effettuano il calcolo solo su una delle due parti. Definiamo una funzione ausiliaria \lstinline{symmetric_update(A, l, u)}.

% Possibile errore: un ciclo del tipo
% \begin{lstlisting}
% for i = k+1:n
%   for j = k+1:n
%     if j>i
%       A(i,j) = A(j,i);
%     else
%       A(i,j) = ... ;
%     end
%   end
% end
% \end{lstlisting}
% rischia di copiare un valore dalla parte triangolare inferiore prima che questo venga assegnato; quindi copia solo uno zero!

% Domanda aperta: come fareste a controllare se una matrice è positiva definita, oltre che simmetrica? Impossibile testare che $x^T A x > 0$ su un numero infinito di vettori! Un modo è testare solo su alcuni vettori casuali. Oppure calcolare gli autovalori di $A$ e controllare se sono strettamente maggiori di zero. In alternativa: è vero che se portiamo a termine la fattorizzazione LDL (e otteniamo solo valori positivi sulla diagonale) allora $A$ è SPD? Abbiamo (brevemente) dimostrato l'altra implicazione a lezione; ora vediamo che anche questa è un ``se e solo se''. 

% Esercizio extra se avanza tempo: fattorizzazione LU di una matrice di Hessenberg superiore.

\section{Metodi iterativi per sistemi lineari}

\paragraph{Matrici sparse} Spesso nelle applicazioni compaiono matrici che hanno molti elementi uguali a zero. Per esempio, alcuni metodi di soluzione di equazioni differenziali conducono a matrici \emph{tridiagonali}, oppure a matrici che hanno elementi diversi da zero solo lungo alcune diagonali (non per forza vicine a quella principale). In una matrice $n\times n$ di questo tipo, il numero di elementi diversi da zero (``non-zeri'') è proporzionale a $n$, (possiamo scriverlo come $\mathcal{O}(n)$), quindi molti meno degli $n^2$ elementi.

Alcune operazioni su matrici sparse si possono effettuare più velocemente. Per esempio, per calcolare il prodotto con un vettore, $Av$, mi basta considerare nella somma gli elementi di $A$ diversi da zero. Il costo computazionale di questo prodotto quindi è di $2nnz$ operazioni, dove con $nnz$ indichiamo il ``numero di non-zeri'' della matrice $A$.

In Matlab, abbiamo alcuni comandi per gestire matrici sparse. Per esempio, \lstinline{sparse(A)} restituisce una copia della matrice $A$, memorizzata in un formato diverso che elenca i soli ``non-zeri''. Similmente, \lstinline{sparse(m, n)} e \lstinline{speye(m)} creano, in questo formato, rispettivamente una matrice nulla e l'identità. Lavorare con questo formato comincia a diventare conveniente solo quando la $A$ ha una densità di non-zeri molto bassa, $10\%$ o meno: se una matrice triangolare ha semplicemente zeri nella parte triangolare inferiore, o superiore, ma a parte questo è densa, allora i non-zeri sono circa il $50\%$, e i costi collegati alla gestione delle matrici sparse sono maggiori dei risparmi ottenuti usando questo formato. Ve lo dico solo per conoscenza, ma non vediamo dettagli su come gestire matrici sparse in questo corso.

I metodi che abbiamo visto finora per risolvere sistemi lineari non sono l'ideale per matrici sparse, perché spesso l'eliminazione di Gauss elimina anche la sparsità, introducendo molti elementi diversi da zero. Per esempio, data una matrice della forma
\[
\begin{bmatrix}
    * & * & * & * & * & *\\
    * & * \\
    * & & *\\
    * & & &*\\
    * & & & & *\\
    * & & & & & *\\
\end{bmatrix}
\]
già dopo il primo passaggio otteniamo una matrice con molti più non-zeri di quella di partenza:
\[
\begin{bmatrix}
    * & * & * & * & * & *\\
    0 & * & * & * & * & *\\
    0 & * & * & * & * & *\\
    0 & * & * & * & * & *\\
    0 & * & * & * & * & *\\
    0 & * & * & * & * & *\\
\end{bmatrix}.
\]
Esistono metodi per risolvere sistemi lineari che riescono a sfruttare il fatto che $A$ sia una matrice sparsa, ottenendo un minore costo computazionale rispetto a $\mathcal{O}(n^3)$. Questi metodi sono molto simili a quelli che abbiamo visto nella prima sezione: producono, passo dopo passo, una successione di vettori, $\x^{(1)}, \x^{(2)}, \x^{(3)},\dots,\x^{(3)}, \dots$ (ogni $\x^{(i)}$ è un vettore; mettiamo l'indice in alto per non confonderci con gli elementi). Sotto condizioni opportune (che vedremo), questa successione converge alla soluzione $\x$ di $A\x=\b$.

\paragraph{Metodi iterativi generici}

Descriviamo ora un modo per ottenere un metodo iterativo a partire da uno \emph{splitting} della matrice $A$, cioè una scrittura del tipo $A = M - N$, dove $M\in\mathbb{C}^{n\times n}$ è una matrice invertibile. La soluzione $\x\in\mathbb{C}^{n\times n}$ del sistema lineare soddisfa
\begin{equation} \label{solsistema}
    A\x = \b \iff (M-N)\x=\b \iff M\x = N\x + \b \iff \x = M^{-1}(N\x + \b)
%    \underbrace{M^{-1}N}_{=H}x + \underbrace{M^{-1}b}_{=c}.
\end{equation}
Questo suggerisce di impostare un'iterazione di punto fisso
\begin{equation} \label{iterlin}
    \begin{cases}
    \x^{(1)} \in \mathbb{C}^n & \text{fissato};\\
    \x^{(k+1)} = M^{-1}(N\x^{(k)} + \mathbf{b}) & k=1,2,3,\dots
    \end{cases}
\end{equation}
Notiamo che questa iterazione si può implementare in modo efficiente se abbiamo un modo efficiente di risolvere il sistema lineare $M\x^{(k+1)} = N\x^{(k)} + \b$: per esempio, se $M$ è triangolare possiamo usare un processo di sostituzione. Tipicamente \emph{non} vogliamo calcolare $M^{-1}$ (né tantomeno $M^{-1}N$), perché questo andrebbe a costare più di quello che possiamo permetterci.

La~\eqref{iterlin} è una versione ``multidimensionale'' del metodo di punto fisso $\x_{k+1} = \Phi(\x_k)$ che abbiamo già visto. Parlando di quel metodo, avevamo visto che spesso la convergenza avviene solo quando $\x^{(1)}$ è sufficientemente vicino alla soluzione esatta $\x$. Per questi metodi, invece, la convergenza solitamente \emph{non} dipende dal punto iniziale, come vedremo.

Partiamo introducendo una definizione. Diciamo che il metodo iterativo è \emph{convergente} se \emph{per ogni scelta} di $\x^{(1)}\in\mathbb{C}^n$ la successione generata dal metodo converge alla soluzione $\x$ del sistema lineare.

Per studiare la convergenza, definiamo $\e^{(k)} = \x^{(k)} - \x$ l'errore (assoluto) al passo $k$. Usando la~\eqref{solsistema} e la~\eqref{iterlin} abbiamo per ogni $k=1,2,\dots$
\begin{equation} \label{ekiter}
    \e^{(k+1)} = \x^{(k+1)} - \x = M^{-1}(N\x^{(k)} + \b) - M^{-1}(N\x + \b) = M^{-1}(N\x^{(k)}-N \x) = M^{-1}N \e^{(k)}.    
\end{equation}
Definiamo la \emph{matrice di iterazione} del metodo come $H = M^{-1}N$.

\begin{theorem}
Il metodo iterativo~\eqref{iterlin} è convergente se e solo se $\rho(H) < 1$.
\end{theorem}
\begin{proof}
In questo corso dimostriamo il teorema solo nel caso particolare in cui $H$ è diagonalizzabile (ma in realtà è vero sempre).

Usando ripetuatamente la~\eqref{ekiter} is ha
\[
\e^{(k+1)} = H\e^{(k)} = H H \e^{(k-1)} = \dots = H^{k} \e^{(1)}.
\]
Supponiamo che la matrice $H$ sia diagonalizzabile, cioè che esistano una matrice $V$ invertibile e $D$ diagonale tali che $H = VDV^{-1}$; sappiamo dall'algebra lineare che gli elementi diagonali di $D$ sono proprio gli autovalori di $H$. Possiamo scrivere
\[
H^k = \underbrace{(VDV^{-1})(VDV^{-1}) \dots (VDV^{-1})}_{\text{$k$ volte}} = VD^kV^{-1}.
\]
Se $\rho(H) < 1$, allora $\abs{D_{ii}} < 1$ per ogni $i=1,2,\dots,n$, e quindi $\lim_{k\to\infty} D^k = 0$. Sostituendo più sopra abbiamo allora anche $\lim_{k\to\infty} \e^{(k+1)} = 0$.

Questo conclude (con l'ipotesi aggiuntiva che $k$ sia diagonalizzabile) la dimostrazione che se $\rho(H)<1$ allora il metodo è convergente. Visto che questo è un ``se e solo se'', vogliamo però dimostrare anche l'implicazione opposta. Per fare questo, ci basta dimostrare che se $H$ ha un autovalore $H\mathbf{v} = \mathbf{v} \lambda$, $\abs{\lambda} \geq 1$, allora esiste una scelta di $\x^{(1)}$ per cui l'errore $\e^{(k)}$ non converge a zero. Per farlo, prendiamo $\x^{(1)} = \x + \mathbf{v}$. Allora abbiamo $\e^{(1)} = \x^{(1)} - \x = \mathbf{v}$, e 
\begin{equation} \label{nonconverge}
    \e^{(k+1)} = H^k \mathbf{v} = \mathbf{v} \lambda^k    
\end{equation}
(notare infatti che ogni volta che facciamo un prodotto $H\mathbf{v}$ otteniamo il vettore $\mathbf{v}\lambda$, quindi\dots)


Se $\abs{\lambda} \geq 1$ (e $\mathbf{v}\neq 0$, visto  che $\mathbf{v}$ è un autovettore), allora la quantità $\mathbf{v} \lambda^k$ non converge a zero, che era quello che volevamo dimostrare.
\end{proof}
Visto che $\rho(H) \leq \norm{H}_p$ per ogni norma matriciale indotta, abbiamo anche il seguente risultato.
\begin{corollary}
Se $\norm{H}_p \leq 1$ per una qualunque norma matriciale indotta, allora il metodo iterativo~\eqref{iterlin} è convergente.
\end{corollary}
Questo \emph{non} è un ``se e solo se''! In particolare, possiamo anche avere situazioni in cui alcune norme matriciali indotte sono minori di 1 e altre maggiori di 1.

È possibile dimostrare anche che per ogni norma vettoriale vale
\[
\lim_{k\to\infty} \frac{\norm{\e^{(k+1)}}}{\norm{\e^{(k)}}} \leq \rho(H),
\]
con uguaglianza per quasi tutti i vettori di partenza $\x^{(1)}$. Pertanto il metodo converge linearmente. La convergenza è tanto più veloce (pendenza della retta in scala logaritmica più vicina a $-\infty$) quanto più $\rho(H)$ è piccolo.

\paragraph{Criteri di arresto per metodi iterativi per sistemi lineari}
Abbiamo due scelte naturali come criteri di arresto per il metodo:
\begin{enumerate}
    \item Ci fermiamo quando $\norm{\x^{(k)} - \x^{(k+1)}} \leq \varepsilon$, per una certa norma e un valore $\varepsilon > 0$ fissato.
    \item Ci fermiamo quando $\norm{A \x^{(k+1)} - \b} \leq \varepsilon$.
\end{enumerate}
Il primo è facile e veloce da calcolare, ma (esattamente come abbiamo visto per il metodo del punto fisso nel caso scalare), quando la convergenza è lenta, $\norm{\x^{(k)} - \x^{(k+1)}}$ può essere molto più piccolo di $\norm{\x^{(k+1)} - \x}$, quindi rischiamo di sottostimare l'errore.

% Cosa possiamo affermare sull'errore $\e^{(k+1)} = \x^{(k+1)}-\x$ quando è verificato uno di questi criteri? Analizziamoli a partire dal primo. 

% \begin{theorem}[Errore di un metodo iterativo]
% Consideriamo il metodo iterativo~\eqref{iterlin}; supponiamo che sia convergente (quindi $\rho(H)<1$) e che per un certo valore di $k$ sia verificato (in una certa norma vettoriale) il criterio di arresto $\norm{\x^{(k)} - \x^{(k+1)}} \leq \varepsilon$. Allora, 
% \[
% \norm{\e^{(k+1)}} \leq \norm{H(I-H)^{-1}} \varepsilon,
% \]
% dove la norma è la norma matriciale indotta dalla norma vettoriale usata.
% \end{theorem}
% \begin{proof}
% Notiamo innanzitutto che la matrice $I-H$ è invertibile, se $\rho(H)<1$: difatti, se per un vettore $\mathbf{v}\neq \mathbf{0}$ valesse $(I-H)\mathbf{v} = \mathbf{0}$, allora $H\mathbf{v} = \mathbf{v}$; quindi $\mathbf{v}$ sarebbe un autovettore di $H$ con autovalore $1$, ma questo è impossibile per la definizione di raggio spettrale.

% Abbiamo
% \[
% \x^{(k)} - \x^{(k+1)} = (\x^{(k)} - \x) - (\x^{(k+1)}-\x)) = \e^{(k)} - \e^{(k+1)} = \e^{(k)} - H\e^{(k+1)} = (I-H)\e^{(k)}.
% \]

% Quindi quando ci arrestiamo
% \begin{align*}
% \norm{\e^{(k+1)}} &= \norm{H\e^{(k)}} = \norm{H(I-H)^{-1}(\x^{(k)} - \x^{(k+1)})} 
% \\ & \leq \norm{H(I-H)^{-1}}\norm{\x^{(k)} - \x^{(k+1)}} \leq \norm{H(I-H)^{-1}} \varepsilon. \qedhere
% \end{align*}
% \end{proof}
% Si può vedere che la quantità $\norm{H(I-H)^{-1}}$ può essere molto grande; in particolare questo succede quando $\rho(H)$ è vicino a 1. Quindi questo criterio di arresto non è particolarmente buono: diventa meno accurato quanto più lentamente converge il metodo.

\paragraph{Residuo e stabilità all'indietro (*)}  Se $\x$ è la soluzione esatta del sistema lineare $A\x = \b$, allora chiaramente $\norm{A\x-\b} = 0$. Ma se per un vettore $\tilde{\x} \in \mathbb{C}^n$ il \emph{residuo} $\mathbf{r} = A\tilde{\x}-\b$ è piccolo, questo implica che $\tilde{\x}$ e $\x$ sono vicini? Intuitivamente sì, ma vediamo un risultato quantitativo che dice cosa succede.

\begin{theorem}[Stima sul residuo]
Siano $A \in \mathbb{C}^{n\times n}$, $\b\in\mathbb{C}^n$. Sia $\x$ la soluzione del sistema lineare $A\x=\b$, sia $\tilde{\x}\in\mathbb{R}^n$ un altro vettore, e sia $\mathbf{r} = A\tilde{\x}-\b$. Allora,
\[
\frac{\norm{\tilde{\x}-\x}}{\norm{\x}} \leq \kappa(A) \frac{\norm{\mathbf{r}}}{\norm{\b}}.
\]
\end{theorem}
\begin{proof}
Abbiamo $A\tilde{\x} = \b + \mathbf{r}$. Allora, $\tilde{\x}$ è la soluzione del sistema lineare $A\tilde{\x} = \widehat{\b}$, in cui abbiamo perturbato il termine noto in $\widehat{\b} = \b + \mathbf{r}$. Pertanto possiamo applicare la disuguaglianza~\eqref{conditionbound}, che ci dà la tesi.
\end{proof}
Questo risultato non si applica solo all'iterata $\x^{(k+1)}$ prodotta da un metodo iterativo, ma a una qualunque soluzione approssimata di un sistema lineare, non importa come l'abbiamo ottenuta. È quindi particolarmente interessante perché ci permette di ottenere una stima esplicita sull'errore.

%%%
% Per il futuro: eliminare D, E, F; creano solo confusione
%%%

\paragraph{Metodi di Jacobi e Gauss--Seidel} Due metodi iterativi sono particolarmente comuni per la loro semplicità.

Scriviamo $A = D - E - F$, dove $D$ è la parte diagonale di $A$, $E$ è la parte strettamente triangolare inferiore (con un segno $-$), e $F$ è la parte triangolare superiore.

Il \emph{metodo di Jacobi} si ottiene scegliendo $M = D$. È applicabile quando $D$ è invertibile (cioè quando $A_{ii} \neq 0$ per ogni $i$). La soluzione di sistemi lineari con $M$ è particolarmente veloce perché $M$ è diagonale.

Il \emph{metodo di Gauss--Seidel} si ottiene scegliendo $M = D - E$. È applicabile, di nuovo, quando $A_{ii} \neq 0$ per ogni $i$. La soluzione di sistemi lineari con $M$ è particolarmente veloce perché $M$ è triangolare.

\paragraph{Implementazione del metodo di Jacobi}

Partiamo scrivendo la relazione $M\x^{(k+1)} = \b + N\x^{(k)}$:
\[
\begin{bmatrix}
    A_{11}\\
    & A_{22}\\
    & & \ddots \\
    & & & A_{nn}
\end{bmatrix}
\begin{bmatrix}
    x_1^{(k+1)}\\
    x_2^{(k+1)}\\
    \vdots\\
    x_n^{(k+1)}\\
\end{bmatrix}
=
\begin{bmatrix}
    b_1\\
    b_2\\
    \vdots\\
    b_n\\
\end{bmatrix}
-
\begin{bmatrix}
    0 & A_{12} & \dots & A_{1n}\\
    A_{21} & 0 & \dots & A_{2n}\\
    \vdots & \vdots & \ddots & \vdots\\
    A_{n1} & A_{n2} & \dots & 0
\end{bmatrix}
\begin{bmatrix}
    x_1^{(k)}\\
    x_2^{(k)}\\
    \vdots \\
    x_n^{(k)}\\
\end{bmatrix}
\]
La $i$-esima riga corrisponde a
\[
A_{ii}x_i^{(k+1)} = b_i - \sum_{\substack{j=1\\ j \neq i}}^n A_{ij}x_j^{(k)}
\]
da cui possiamo ricavare $x_i^{(k+1)}$ ottenendo
\[
x_i^{(k+1)} = \frac{b_i - \sum_{\substack{j=1\\ j \neq i}}^n A_{ij}x_j^{(k)}}{A_{ii}} = \frac{b_i - \sum_{j=1}^{i-1} A_{ij}x_j^{(k)} - \sum_{j=i+1}^n A_{ij}x_j^{(k)} }{A_{ii}}, \quad i=1,2,\dots,n.
\]
Queste equazioni sono indipendenti tra loro per ogni $i$, possiamo risolverle una dopo l'altra in qualunque ordine per ottenere $\x^{(k+1)}$ a partire da $\x^{(k)}$. Questo costituisce un'iterazione del metodo.

Il costo computazionale è di $2n$ operazioni aritmetiche per ogni $i$, quindi in totale $2n^2$ per ogni iterazione (il numero di iterazioni che servono per ottenere convergenza non è noto a priori, anzi, il metodo potrebbe non convergere del tutto). Inoltre, se so a priori che alcuni elementi $A_{ij}$ sono zero, posso restringere la somma agli elementi non-nulli; questo modifica il costo totale in $2nnz(A)$.

\paragraph{Implementazione del metodo di Gauss--Seidel}

Di nuovo, partiamo scrivendo la relazione $M\x^{(k+1)} = \b + N\x^{(k)}$:
\[
\begin{bmatrix}
    A_{11}\\
    A_{21} & A_{22}\\
    A_{31}& \ddots & \ddots \\
    A_{n1}& A_{n2} &\dots & A_{nn}
\end{bmatrix}
\begin{bmatrix}
    x_1^{(k+1)}\\
    x_2^{(k+1)}\\
    \vdots\\
    x_n^{(k+1)}\\
\end{bmatrix}
=
\begin{bmatrix}
    b_1\\
    b_2\\
    \vdots\\
    b_n\\
\end{bmatrix}
-
\begin{bmatrix}
     0& A_{12} & \dots & A_{1n}\\
     & 0 & \ddots & \vdots\\
     &  & \ddots & A_{n-1,n}\\
     & &  & 0
\end{bmatrix}
\begin{bmatrix}
    x_1^{(k)}\\
    x_2^{(k)}\\
    \vdots \\
    x_n^{(k)}\\
\end{bmatrix}.
\]
L'equazione corrispondente alla riga $i$-esima è
\[
\sum_{j=1}^i A_{ij}x_j^{(k+1)} = b_i - \sum_{j=i+1}^n A_{ij}x_j^{(k)}. 
\]
Risolvendola per $x_{i}^{(k+1)}$ otteniamo
\begin{equation} \label{GS}
    x_{i}^{(k+1)} = \frac{b_i - \sum_{j=1}^n A_{ij}x_j^{(k+1)} - \sum_{j=i+1}^n A_{ij}x_j^{(k)} }{A_{ii}}, \quad i=1,2,\dots,n.
\end{equation}
Possiamo risolvere queste equazioni una dopo l'altra per $i=1,2,\dots,n$ (in quest'ordine!) per calcolare tutti gli elementi di $\x^{(k+1)}$. Questo corrisponde a risolvere il sistema lineare $M\x^{(k+1)} = \b + N\x^{(k)}$ per sostituzione in avanti; il sistema è triangolare inferiore, quindi non ci stupisce che questo sia possibile!

La~\eqref{GS} differisce dalla corrispondente formula per il metodo di Jacobi solo per il fatto che abbiamo $x_j^{(k+1)}$ anziché $x_j^{(k)}$ nella prima sommatoria. Questo corrisponde ad usare immediatamente gli elementi più nuovi $x_j^{(k+1)}$ appena li abbiamo calcolati invece di aspettare l'iterazione successiva del metodo. Intuitivamente, questo metodo fornisce un'approssimazione migliore della soluzione, perché usiamo approssimazioni più accurate ad ogni passo. Questa intuizione non sempre corrisponde a realtà; esistono matrici per cui il metodo di Jacobi converge più velocemente di quello di Gauss--Seidel. (Lo vedremo in laboratorio.)

Un'osservazione interessante che il metodo di Gauss--Seidel può essere implementato in Matlab usando \emph{una sola} variabile (vettore) $\x$ che contiene ad ogni passo le approssimazioni più recenti degli elementi di $\x$; ad ogni passo $i=1,2,\dots,n$ rimpiazziamo un elemento $x_i^{(k)}$ con $x_i^{(k+1)}$:
\[
\x^{(k)} = \begin{bmatrix}
    x^{(k)}_1\\ 
    x^{(k)}_2\\ 
    \vdots \\
    x^{(k)}_{n-1}\\ 
    x^{(k)}_n\\ 
\end{bmatrix} \stackrel{i=1}{\to}
\begin{bmatrix}
    x^{(k+1)}_1\\ 
    x^{(k)}_2\\ 
    \vdots \\
    x^{(k)}_{n-1}\\ 
    x^{(k)}_n\\ 
\end{bmatrix} \stackrel{i=2}{\to}
\begin{bmatrix}
    x^{(k+1)}_1\\ 
    x^{(k+1)}_2\\ 
    \vdots \\
    x^{(k)}_{n-1}\\ 
    x^{(k)}_n\\ 
\end{bmatrix} \stackrel{i=3}{\to}
\dots
\stackrel{i=n-1}{\to}
\begin{bmatrix}
    x^{(k+1)}_1\\ 
    x^{(k)}_2\\ 
    x^{(k)}_3\\ 
    \vdots \\
    x^{(k+1)}_{n-1}\\ 
    x^{(k)}_n\\ 
\end{bmatrix} \stackrel{i=n}{\to}
\begin{bmatrix}
    x^{(k+1)}_1\\ 
    x^{(k)}_2\\ 
    x^{(k)}_3\\ 
    \vdots \\
    x^{(k+1)}_{n-1}\\ 
    x^{(k+1)}_n\\ 
\end{bmatrix} = \x^{(k+1)}.
\]
Lavorando in questo modo, in ogni momento abbiamo a disposizione tutti gli elementi che ci servono per calcolare l'elemento successivo.

\paragraph{Convergenza per matrici $A$ dominanti diagonali}

Non è facile prevedere a priori per quali matrici $A$ questi due metodi convergono. Ci sono matrici in cui uno converge e l'altro no, per esempio. Un risultato che possiamo dimostrare è il seguente.

\begin{theorem}
Se $A$ è dominante diagonale, i metodi di Jacobi e Gauss--Seidel sono applicabili e convergenti.
\end{theorem}
\begin{proof}
Innanzitutto notiamo che i metodi sono applicabili; difatti $A_{ii} \neq 0$:
\[
\abs{A_{ii}} > \sum_{\substack{j=1\\j\neq i}}^n \abs{A_{ij}} \geq 0, \quad i=1,2,\dots,n.
\]
Vogliamo dimostrare che $\rho(H)<1$, in modo da avere la convergenza. Scriviamo il polinomio caratteristico
\[
\det (H - \lambda I) = \det (M^{-1}(N-\lambda M)) = \det M^{-1} \det (N-\lambda M).
\]
Poiché $\det M^{-1} \neq 0$, il polinomio caratteristico si annulla solo quando $\det (N-\lambda M) = 0$, cioè $N-\lambda M$ è singolare. Quindi ci basta mostrare che $N-\lambda M$ è invertibile quando $\abs{\lambda} \geq 1$.

La matrice $N-\lambda M$ ha elementi
\[
N-\lambda M = -
\begin{bmatrix}
    \lambda A_{11} & A_{12} & \dots & A_{1n}\\
    A_{21} & \lambda A_{22} & \dots & A_{2n}\\
    \vdots & \vdots & \ddots & \vdots\\
    A_{n1} & A_{n2} & \dots & \lambda A_{nn}
\end{bmatrix}
\]
nel caso del metodo di Jacobi (rispetto a $-A$, la diagonale è moltiplicata per $\lambda$), e 
\[
N-\lambda M = -
\begin{bmatrix}
    \lambda A_{11} & A_{12} & \dots & A_{1n}\\
    \lambda A_{21} & \lambda A_{22} & \dots & A_{2n}\\
    \vdots & \vdots & \ddots & \vdots\\
    \lambda A_{n1} & \lambda A_{n2} & \dots & \lambda A_{nn}
\end{bmatrix}
\]
nel caso del metodo di Gauss--Seidel (la parte triangolare inferiore è moltiplicata per $\lambda$). In entrambi i casi, questa matrice è predominante diagonale: difatti, la predominanza diagonale di $A$ assicura che
\[
\abs{\lambda A_{ii}} = \abs{\lambda}\abs{ A_{ii}} > \sum_{j\neq i} \abs{\lambda} \abs{A_{ij}}
\]
e il membro di destra (quando $\abs{\lambda} \geq 1$) è più grande del termine corrispondente agli elementi fuori dalla diagonale di $N-\lambda M$.
\end{proof}

% \section{Laboratorio su metodi iterativi per sistemi lineari}

% \begin{itemize}
%     \item Fatto insieme: scrivere una funzione che esegue $k$ iterazioni del metodo di Jacobi. Lasciato a voi: cambiare criterio di arresto; scrivere il metodo di Gauss--Seidel. Fornire matrici di test.
%     \item Controllo della condizione di convergenza per le matrici date (con \lstinline{M = tril(A)} e \lstinline{M = diag(diag(A))}).
%     \item Esercizio: scrivere una versione dei due metodi per matrici tridiagonali.
% \end{itemize}

\section{Sistemi di equazioni non lineari}

\paragraph{Introduzione} Facciamo qualche accenno anche a metodi per risolvere sistemi di equazioni \emph{non} lineari: data una $F: D \subseteq \mathbb{R}^n \to \mathbb{R}^n$, come possiamo trovare \emph{una} soluzione del sistema?

Ad esempio, supponiamo di voler risolvere $F(\mathbf{x})=0$, dove
\begin{equation} \label{esempiosistemanonlin}
    F\left(\begin{bmatrix}
        x_1\\ x_2
    \end{bmatrix}\right) = \begin{bmatrix}
        2x_1 + \cos(x_2)\\
        \sin(x_1) + 2x_2 - \pi
    \end{bmatrix}.
\end{equation}
Questo è un sistema (\emph{non} lineare) di due equazioni in due incognite; una soluzione per esempio è $(x_1, x_2) = (0,\pi)$.

Un sistema di questo tipo è un problema molto più complicato che non un sistema lineare; tanto per cominciare, in generale si possono avere zero soluzioni, una, più di una, o anche infinite, e non c'è un criterio generale per capire quando questi casi si verificano.

 Non c'è un modo facile di estendere il metodo di bisezione, più che altro perché non abbiamo un analogo facile del teorema di Weierstrass in più dimensioni: anche se $F(\mathbf{x})$ ha tutte le componenti $<0$ e $F(\mathbf{y})$ ha tutte le componenti $>0$, non è detto che ci sia una soluzione simultanea di tutte le equazioni né nella retta che congiunge $(x_1,x_2)$ a $(y_1,y_2)$ né nel ``rettangolo'' che li comprende. I metodi di punto fisso invece si riescono a generalizzare facilmente, come abbiamo già visto. In particolare ci concentriamo su uno particolarmente efficiente, il metodo di Newton.

\paragraph{Metodo di Newton multivariato}
Possiamo definire, generalizzando la derivata prima di una funzione, la \emph{matrice Jacobiana}
\[
J_F(\x) = 
\begin{bmatrix}
    \frac{\partial F_1}{\partial x_1}(x) & \frac{\partial F_1}{\partial x_2}(x) & \dots & \frac{\partial F_1}{\partial x_n}(x)\\
    \frac{\partial F_2}{\partial x_1}(x) & \frac{\partial F_2}{\partial x_2}(x) & \dots & \frac{\partial F_2}{\partial x_n}(x)\\
    \vdots & \vdots & \ddots & \vdots\\
    \frac{\partial F_n}{\partial x_1}(x) & \frac{\partial F_n}{\partial x_2}(x) & \dots & \frac{\partial F_n}{\partial x_n}(x)\\
\end{bmatrix} \in \mathbb{R}^{n\times n}
\]
Per evitare di confondere $J_F$ con la sua trasposta, possiamo usare questa tecnica mnemonica per ricordarci la posizione degli indici: le diverse componenti di $F(\x)$ sono elementi successivi di un vettore colonna, e anche nello Jacobiano vediamo che le diverse componenti di ogni derivata parziale stanno nella stessa colonna una sopra l'altra. 

Per esempio per la~\eqref{esempiosistemanonlin} abbiamo
\[
J_F(\x) = \begin{bmatrix}
    2 & -\sin(x_2)\\
    \cos(x_1) & 2
\end{bmatrix}.
\]
Vale, per funzioni sufficientemente regolari, una generalizzazione dello sviluppo di Taylor:
\begin{equation} \label{taylormulti}
    F(\x+\mathbf{h}) = F(\x) + J_F(\x) \mathbf{h} + O(\norm{\mathbf{h}}^2),
\end{equation}
con $\x,\mathbf{h} \in\mathbb{R}^n$; notiamo in particolare che nel membro di destra compare il prodotto matrice-vettore $J_F(\x) \mathbf{h}$. Ragionando come nel metodo di Newton in una sola variabile, possiamo trascurare il termine di resto $O(\norm{\mathbf{h}}^2)$ e cercare una nuova approssimazione $\x_{k+1} = \x_k+\mathbf{h}$ imponendo che
\[
    0 = F(\x_k+\mathbf{h}) = F(\x_k) + J_F(\x_k) \mathbf{h}.
\]
Questo produce il metodo
\[
\begin{cases}
\x^{(0)} \in \mathbb{R}^n & \text{assegnato}\\
\x^{(k+1)} = \x^{(k)} - \left(J_F(\x^{(k)})\right)^{-1} F(\x^{(k)}), & k=0,1,2,\dots.
\end{cases}
\]
Valgono risultati analoghi a quelli del caso scalare: su funzioni sufficientemente regolari, il metodo converge a patto di prendere $\x^{(0)}$ sufficientemente vicino a una soluzione $\x$, e la convergenza è quadratica se $J_F(\x)$ è invertibile. 

Nella pratica, ad ogni passo, possiamo evitare di calcolare esplicitamente la matrice inversa: troviamo il valore di $J_F(\x^{(k)})$, e poi risolviamo il sistema lineare
\[
    J_F(\x^{(k)}) \mathbf{h} = F(\x^{(k)}), \quad \mathbf{h} = \x^{(k)} - \x^{(k+1)}
\]
con una fattorizzazione LU o altri metodi: i passi del metodo quindi sono, nell'ordine
\begin{enumerate}
    \item calcolare $F(\x^{(k)})$;
    \item calcolare $J_F(\x^{(k)})$;
    \item risolvere il sistema lineare $J_F(\x^{(k)}) \mathbf{h} = F(\x^{(k)})$ per trovare $\mathbf{h}$;
    \item calcolare $\x^{(k+1)} = \x^{(k)} - \mathbf{h}$.
\end{enumerate}
È impossibile dire qualcosa in generale su come si confrontano i costi dei vari passi senza sapere quanto costa calcolare $F$ e $J_F$. Però possiamo osservare che se utilizziamo una fattorizzazione LU, il costo del terzo passo è $O(n^3)$, e spesso questa risulta essere l'operazione più costosa. Per questo, spesso si utilizzano varianti del metodo di Newton che cercano di ridurre il costo di questo passo. Ne vediamo in particolare uno, il metodo delle corde.

\paragraph{Metodo delle corde multivariato}  Nel metodo delle corde, una volta calcolata una matrice $A$ da invertire, per esempio come $A = J_F(\x^{(0)})$, la teniamo fissa per più iterazioni.

Pseudocodice: per ogni $k=0,1,2,\dots$
\begin{itemize}
    \item Calcolo $F(\x^{(k)})$;
    \item In alcune iterazioni, valuto $A = J_F(\x^{(k)})$ e calcolo una sua fattorizzazione $PA = LU$; altrimenti, riutilizzo $P,L,U$ da un passo precedente. Per esempio, posso scegliere di ricalcolare la fattorizzazione ogni $5$ passi;
    \item Utilizzo la fattorizzazione per risolvere il sistema lineare $ A \mathbf{h} = F(\x^{(k)})$;
    \item Calcolo $\x^{(k+1)} = \x^{(k)} - \mathbf{h}$.
\end{itemize}
Costo computazionale: ad ogni passaggio dobbiamo fare una valutazione di $F$ e una soluzione di un sistema lineare ($O(n^2)$). Inoltre, ogni volta che vogliamo ricalcolare la fattorizzazione facciamo $O(n^3)$ operazioni più una valutazione di $J_F$. 

Come nel caso scalare, la convergenza è garantita solo se partiamo all'interno di un certo intorno della soluzione (che può essere anche molto piccolo!).

La velocità di convergenza del metodo di Newton è quadratica. Nel metodo delle corde, è più complicato. La convergenza in linea teorica è sempre quadratica, ma diventa più lenta se ricalcoliamo lo Jacobiano e la sua fattorizzazione meno spesso: questo perché se la matrice $A$ è fissata il metodo si comporta come un metodo con convergenza lineare.

\section{Sistemi lineari sovradeterminati (minimi quadrati)}

Supponiamo di avere un sistema del tipo
\[
A\x = \b, \quad A \in \mathbb{R}^{m\times n}, \, \b\in\mathbb{R}^m, \, \x\in\mathbb{R}^n.
\]
Se $m>n$ ($A$ alta e stretta), la soluzione spesso non esiste: abbiamo più equazioni che incognite. Dall'algebra lineare, sappiamo che $A\x$ produce una combinazione lineare delle colonne di $A$, e queste sono solo un sottospazio di $\mathbb{R}^m$ (iperpiano).

[Figura in 3D: piano che corrisponde all'immagine di $A$, vettore $\b$ al di fuori di esso.]

Possiamo però risolvere un problema diverso, quello di calcolare la combinazione lineare delle colonne di $A$, cioè il vettore $A\x$, che va più vicino al vettore $\b$. In altre parole, cerchiamo 
\begin{equation} \label{minresiduo}
    \min_{\x\in\mathbb{R}^n} \norm{A\x-\b}.    
\end{equation}
Come nei sistemi lineari, dato un vettore $\tilde{\x}$, chiamiamo \emph{residuo} la quantità $\mathbf{r} = A \tilde{\x} - \b$. Attenzione: in questo problema, anche quando lo calcoliamo nella soluzione esatta $\x$, il residuo non vale $\mathbf{0}$!

\paragraph{Equazioni normali} Il problema~\eqref{minresiduo} ha una soluzione particolarmente semplice se usiamo la norma-2. Difatti, minimizzare la norma-2 di $\mathbf{r}$ equivale a minimizzare $\sum r_i^2  = \mathbf{r}^T\mathbf{r}$, ovvero
\begin{equation} \label{minimiquadrati}
    \min_{\x\in\mathbb{R}^n} \mathbf{r}^T \mathbf{r} = \min_{\x\in\mathbb{R}^n} (A\x-\b)^T(A\x-\b).    
\end{equation}
Il problema~\eqref{minimiquadrati} è detto \emph{problema dei minimi quadrati}, visto che compaiono per l'appunto i quadrati delle componenti del residuo $\mathbf{r}$. Dimostriamo il seguente risultato.
\begin{theorem}
Sia $\x\in\mathbb{R}^n$ un vettore tale che $A^T \mathbf{r} = A^T(A\x-\b) = 0$. Allora, $\x$ risolve il problema di minimo~\eqref{minimiquadrati}.
\end{theorem}
\begin{proof}
Prendiamo un qualunque vettore diverso da $\x$: possiamo scriverlo come $\x+\mathbf{z}$, con $\mathbf{z}\in\mathbb{R}^n, \mathbf{z} \neq \mathbf{0}$; il suo residuo vale
\[
A(\x+\mathbf{z})-\b = \underbrace{A\x-\b}_{=\mathbf{r}} + \underbrace{A\mathbf{z}}_{=\mathbf{s}} = \mathbf{r}+\mathbf{s}.
\]
Vogliamo dimostrare che la norma di questo residuo è maggiore o uguale a quella di $\mathbf{r}$; questo ci permette di concludere che $\x$ è la soluzione del problema. Il quadrato di questa norma vale
\[
\norm{A(\x+\mathbf{z})-\b}^2 = (\mathbf{r}+\mathbf{s})^T(\mathbf{r}+\mathbf{s}) = \mathbf{s}^T \mathbf{s} + \mathbf{s}^T\mathbf{r} + \mathbf{r}^T \mathbf{s} + \mathbf{r}^T \mathbf{r}.
\]
Notiamo però che il prodotto scalare $\mathbf{r}^T\mathbf{s} = \mathbf{s}^T\mathbf{r}$ si annulla: difatti,
\[
\mathbf{s}^T \mathbf{r} = (A\mathbf{z})^T \mathbf{r} = \mathbf{z}^T A^T \mathbf{r} = 0.
\]
Allora si ha
\[
\norm{A(\x+\mathbf{z})-\b}^2 = \mathbf{s}^T \mathbf{s} + \mathbf{r}^T \mathbf{r} \geq \mathbf{r}^T\mathbf{r}.
\]
Difatti $\mathbf{s}^T\mathbf{s} = s_1^2 + s_2^2 + \dots + s_m^2 \geq 0$.
\end{proof}
Quindi per trovare la soluzione $\x$ di questo problema ci basta risolvere il sistema di equazioni
\begin{equation} \label{eqnormali}
    A^T A \x = A^T \b,    
\end{equation}
che si ottiene moltiplicando per $A^T$ il sistema originale (che era rettangolare e quindi potenzialmente senza soluzione) $A \x= \b$. La~\eqref{eqnormali} si chiama \emph{metodo delle equazioni normali}, perché le equazioni corrispondenti dicono (in termini geometrici) che il residuo $\mathbf{r}=A \x-\b$ è ortogonale (prodotto scalare nullo) alle colonne di $A$.

È semplice vedere che $A^T A$ è quadrata e simmetrica; inoltre, si può dimostrare che è positiva definita (quindi invertibile!) tutte le volte che le colonne di $A$ sono linearmente indipendenti. Possiamo allora risolvere~\eqref{eqnormali} usando la fattorizzazione di Cholesky. 

Questo metodo però in alcuni casi risulta instabile: il condizionamento del sistema lineare~\eqref{eqnormali} può essere molto più alto di quello del problema originale (che non abbiamo studiato). Esiste un altro metodo più costoso ma più stabile.

\paragraph{Fattorizzazione QR}

Si può dimostrare (noi non lo facciamo) il seguente risultato.
\begin{theorem}
    Per ogni $A \in \mathbb{R}^{m\times n}$, esistono una matrice $Q\in\mathbb{R}^{m\times m}$ \emph{ortogonale} (cioè che soddisfa $Q^TQ=I$) e una matrice $R \in \mathbb{R}^{m\times n}$ triangolare superiore tali che $A = QR$.
\end{theorem}
La matrice $R$ è rettangolare: quando scriviamo ``triangolare'' intendiamo che
\[
R = \begin{bmatrix}
    R_1\\ O
\end{bmatrix},
\]
dove $R_1 \in \mathbb{R}^{n\times n}$ è una ``normale'' matrice quadrata triangolare, e $O\in\mathbb{R}^{(m-n)\times n}$ è un blocco di zeri. Se suddividiamo nello stesso modo
\[
Q = \begin{bmatrix}
    Q_1 & Q_2
\end{bmatrix}, \quad Q_1 \in \mathbb{R}^{m\times n}, \, Q_2 \in \mathbb{R}^{m\times (m-n)},
\]
vediamo che gli elementi di $Q_2$ si ``scontrano'' con il blocco di zeri quando facciamo il prodotto, quindi $A = QR = Q_1 R_1$.

Con alcune manipolazioni algebriche (che non vediamo nel dettaglio) si può vedere che la soluzione $x$ delle~\eqref{eqnormali} è una soluzione anche del sistema lineare triangolare
\begin{equation} \label{qrsystem}
    R_1 x = Q_1^T b.    
\end{equation}
Questo ci suggerisce un altro algoritmo per la soluzione del problema dei minimi quadrati:
\begin{itemize}
    \item Calcoliamo la fattorizzazione $A=QR$ (o anche solo i blocchi $A = Q_1 R_1$).
    \item Risolviamo per sostituzione all'indietro il sistema~\eqref{qrsystem}.
\end{itemize}
Questo metodo è più costoso del precedente (facendo un'analisi più accurata, è possibile dimostrare che quando $m\gg n$ richiede $2mn^2$ operazioni più termini di ordine inferiore, contro $mn^2$ per il metodo delle equazioni normali) ma è più stabile in alcuni problemi in cui $A^TA$ è mal condizionata.

\paragraph{Soluzione tramite Matlab} In Matlab, risolvere un problema ai minimi quadrati~\eqref{minimiquadrati} è semplice: basta il comando \lstinline{A \ b}, lo stesso che avreste usato per risolvere il sistema lineare se $A$ fosse quadrata. Matlab usa il metodo più stabile basato sulla fattorizzazione QR.

\chapter{Interpolazione, approssimazione, e integrazione numerica}

\section{Approssimazione e interpolazione}

In diversi problemi applicativi, abbiamo una serie di misurazioni che corrispondono a punti del piano $(x_1, y_1), \dots, (x_n, y_n) \in \mathbb{R}^2$, e siamo interessati a determinare una funzione che passa (esattamente o approssimativamente) per questi punti.

Ad esempio: supponiamo di avere un impianto industriale in cui stiamo eseguendo una reazione chimica, e di averne misurato la temperatura per $13$ volte successive, alle 0:00, alle 1:00, alle 2:00, e così via fino alle 12:00. In che modo possiamo trovare una stima della temperatura a un'altra ora, ad esempio alle 5:45? O anche in un'ora al di fuori dell'intervallo di misurazione, per esempio alle 14:00? (In questo caso a volte si usa il termine \emph{estrapolazione}.)

Magari abbiamo dei modelli che ci dicono che la temperatura decresce linearmente o esponenzialmente, ma questi modelli dipendono da parametri che dobbiamo calcolare. Oppure qualche volta non abbiamo proprio un modello e stiamo genericamente cercando una funzione `semplice' che approssima i valori trovati.

\begin{itemize}
    \item Si chiama \emph{interpolazione} il problema di trovare una funzione $\phi$ (all'interno di una certa classe) tale che $\phi(x_i) = y_i$ per ogni $i=1,2,\dots, n$.
    \item Si chiama \emph{approssimazione} (o, dall'inglese, \emph{fit}) il problema di trovare una funzione $\phi$ tale che $\phi(x_i) \approx y_i$, minimizzando un qualche tipo di residuo.
\end{itemize}

\section{Interpolazione polinomiale}

Vediamo più nel dettaglio il problema dell'\emph{interpolazione polinomiale}. Fissiamo un grado $d$ (usiamo questa lettera dall'inglese \emph{degree}). Supponiamo di avere $d+1$ punti dati nel piano $(x_0, y_0), (x_1, y_1), \dots, (x_{d}, y_{d})$ (attenzione: per comodità con gli indici partiamo da $0$ questa volta) e di voler trovare un polinomio di grado minore o uguale a $d$ il cui grafico passa esattamente per questi punti; cioè, stiamo cercando coefficienti incogniti $\alpha_0, \alpha_1, \dots, \alpha_d$ tali che il polinomio
\[
p(x) = \alpha_0 + \alpha_1 x + \alpha_2 x^2 + \dots + \alpha_d x^d
\]
soddisfa le relazioni
\begin{equation} \label{interpolazione_polinomiale}
p(x_i) = y_i, \quad i=0,1,\dots,d.
\end{equation}
I punti $x_i$ qui sono detti \emph{nodi} dell'interpolazione, e i punti $y_i$ \emph{valori} da interpolare. Possiamo immaginare che questi punti $y_i$ siano calcolati come $y_i = f(x_i)$ a partire da una funzione $f$ più complicata da calcolare (perché è data da una formula più complicata, o perché è il risultato di misurazioni che non possiamo ripetere); in questo modo costruiamo un polinomio che fa da `modello' più semplice di questa funzione.

Possiamo osservare che le relazioni~\eqref{interpolazione_polinomiale} sono equivalenti a un sistema lineare di $d+1$ equazioni nelle $d+1$ incognite $\alpha_0,\dots,\alpha_d$:
\[
\underbrace{
\begin{bmatrix}
    1 & x_0 & x_0^2 & \dots x_0^{d}\\
    1 & x_1 & x_1^2 & \dots x_1^{d}\\
    1 & x_2 & x_2^2 & \dots x_2^{d}\\
    \vdots & \vdots & \ddots & \vdots\\
    1 & x_d & x_d^2 & \dots x_d^{d}\\
\end{bmatrix}
}_{=X}
\begin{bmatrix}
    \alpha_0 \\ \alpha_1 \\ \vdots \\ \alpha_d
\end{bmatrix}=
\begin{bmatrix}
    y_0 \\ y_1 \\ \vdots \\ y_d
\end{bmatrix}.
\]
Attenzione: non ci facciamo ingannare dalle lettere usate: le $x_i$ e le $y_i$ non sono incognite: qui sono note, e sono i dati del problema.

La matrice associata a questo sistema, che abbiamo indicato con $X$, si chiama \emph{matrice di Vandermonde}.

%%% TODO: inserire un esempio %%%

\paragraph{Risolubilità} È possibile dimostrare il seguente risultato.
\begin{theorem}
Per ogni scelta di $x_0,x_1,\dots, x_d$ \emph{distinti}, la matrice di Vandermonde è invertibile.
\end{theorem}
\begin{proof} (*)
Sia
\[
\mathbf{a} = \begin{bmatrix}
    a_0\\
    a_1\\
    \vdots\\
    a_d
\end{bmatrix}
\]
un vettore nel kernel della matrice $X$, cioè tale che $X\mathbf{a} = \mathbf{0}$. Vogliamo dimostrare che dev'essere $\mathbf{a} = \mathbf{0}$; questo implica che la matrice $X$ è invertibile.

Se scriviamo l'uguaglianza $X\mathbf{a} = \mathbf{0}$ riga per riga, vediamo che essa corrisponde a
\[
1\cdot a_0 + x_i \cdot a_1 + x_i^2 \cdot a_2 + \dots + x_i^d \cdot a_d = 0, \quad i=0,1,\dots,d;
\]
Questo equivale a dire che il polinomio $a(x) = a_0 + a_1 x + a_2 x^2 + \dots + a_d x^d$ si annulla nei punti $x_0, x_1, \dots, x_d$. Ma dalle proprietà dei polinomi sappiamo che un polinomio di grado al più $d$ che si annulla in $d+1$ punti dev'essere necessariamente il polinomio nullo\footnote{Per il teorema di Ruffini, un polinomio che si annulla in $x_0,x_1,\dots,x_d$ è un multiplo del polinomio $(x-x_0)(x-x_1)\dots (x-x_d)$; quindi o è il polinomio nullo, oppure ha grado almeno $d+1$.}. Questo quindi dimostra che $\mathbf{a}=\mathbf{0}$ e quindi che $X$ è invertibile.
\end{proof}
Dall'invertibilità di questa matrice segue che il problema dell'interpolazione polinomiale è sempre risolubile, cioè vale questo risultato.
\begin{theorem}[esistenza e unicità del polinomio di interpolazione]
Date $n+1$ coppie di punti $(x_0,y_0),\dots,(x_d,y_d)$, con gli $x_i$ tutti diversi tra loro, esiste uno e un solo polinomio $p(x)$ di grado minore o uguale a $d$ tale che $p(x_i)=y_i$ per ogni $i=0,1,\dots,d$.
\end{theorem}

Notare che sul grado abbiamo solo una disuguaglianza: nulla vieta che il coefficiente $\alpha_d$ (o anche quelli precedenti) sia uguale a zero per una particolare scelta dei punti $(x_i,y_i)$. Per esempio, se scelgo $(0,3), (1,4), (2,5)$, allora il polinomio di grado $d\leq 2$ che passa esattamente per questi punti è $p(x)=x+4$, che in realtà ha grado $1$.

Solitamente l'interpolazione polinomiale si usa con pochi nodi; $d \leq 10$ per esempio. Questo perché per valori grandi di $d$ in molti casi la matrice di Vandermonde, seppure invertibile, risulta mal condizionata. Questo significa che a piccole variazioni dei dati $x_i$ o $y_i$ corrispondono grandi variazioni nei coefficienti del polinomio. Pertanto i coefficienti calcolati sono affetti da un errore inerente molto grande. Un altro problema è che, anche in aritmetica esatta, spesso al crescere di $d$ il polinomio di interpolazione di una funzione $f$ soddisfa sì $p(x_i)=f(x_i)$, ma i valori di $p$ e di $f$ al di fuori di questi valori possono differire anche di molto, con il polinomio che oscilla eccessivamente. [TODO: Immagine di esempio] In molti casi, approssimare i dati utilizzando un polinomio di di grado basso, anche a patto di commettere un errore (come vedremo più avanti) fornisce risultati graficamente migliori che non un polinomio di interpolazione. Questo fenomeno è detto \emph{overfitting}.

\paragraph{Polinomi di Lagrange}

Possiamo dare una formula esplicita per la soluzione del problema dell'interpolazione polinomiale. Fissati i nodi distinti $x_0,x_1,\dots,x_d$, definiamo i \emph{polinomi di Lagrange}
\[
L_k(x) = \frac{\prod_{j\neq k}(x - x_j)}{\prod_{j\neq k}(x_k - x_j)}, \quad k=1,2,\dots,d.
\]
Ad esempio, se i nodi sono $x_0 = 1, x_1 = 2, x_2 = 4$, abbiamo
\[
L_0(x) = \frac{(x-2)(x-4)}{(1-2)(1-4)}, \quad L_1(x) = \frac{(x-1)(x-4)}{(2-1)(2-4)}, \quad L_2(x) = \frac{(x-1)(x-2)}{(4-1)(4-2)}.
\]
Notare che il denominatore non si annulla mai se i nodi sono distinti, e che sono tutti polinomi di grado $d$, visto che il numeratore è il prodotto di $d$ fattori di grado $1$. Inoltre, vale il seguente risultato.
\begin{lemma} \label{lem:polylagrange}
Si ha
\[
L_k(x_i) = \begin{cases}
1 & i=k,\\
0 & \text{altrimenti}.
\end{cases}
\]
\end{lemma}
\begin{proof}
Sostituendo $x = x_k$, numeratore e denominatore diventano identici, quindi il polinomio vale $1$. Sostituendo $x = x_i$ con $i\neq k$, uno dei fattori nella produttoria al numeratore diventa $(x_i-x_i)$, quindi $L_k(x_i) = 0$.
\end{proof}
Quindi il $k$-esimo polinomio di Lagrange fornisce la soluzione al problema di interpolazione con $\mathbf{y} = \e_k$ ($k$-esimo vettore della base canonica). Con queste soluzioni, possiamo ottenere la soluzione a un problema di interpolazione polinomiale generico.
\begin{theorem}
Siano $(x_0,y_0),\dots,(x_d,y_d)$ dati. La soluzione del problema di interpolazione polinomiale (cioè l'unico polinomio $p$ di grado $\leq d$ tale che $p(x_i)=y_i$ per ogni $i=0,1,\dots,d$) è data da
\[
p(x) = \sum_{k=0}^d y_k L_k(x).
\]
\end{theorem}
\begin{proof}
Sappiamo già che la soluzione del problema è unica. Basta verificare che $p(x_i) = y_i$ per ogni $i$ (cosa che segue dal Lemma~\ref{lem:polylagrange}) e che $p(x)$ ha grado minore o uguale a $d$ (perché è una combinazione lineare dei polinomi di Lagrange, che hanno tutti grado $d$). 
\end{proof}

%%% TODO: inserire un esempio %%%

\paragraph{Resto dell'interpolazione}

Vale il seguente risultato.
\begin{theorem}
Sia $f\in \mathcal{C}^{n+1}([a,b])$, $x_0,x_1,\dots,x_d$ nodi distinti in $[a,b]$, e $p(x)$ il polinomio di interpolazione (di grado al più $d$) di $f$ sui nodi dati. Allora per ogni $x\in [a,b]$ esiste un punto $\xi \in (a,b)$ tale che
\[
f(x) - p(x) = \frac{f^{(d+1)}(\xi)}{(d+1)!} (x-x_0)(x-x_1) \dots (x-x_d).
\]
\end{theorem}
Non lo dimostriamo ma facciamo qualche commento. Notare che questo risultato assomiglia a uno sviluppo di Taylor con resto di Lagrange: abbiamo che $f(x)$ è uguale a un polinomio $p(x)$ (che arriva ad avere potenze fino al grado $d$) più un resto che dipende dalla derivata $d+1$-esima. Poiché abbiamo $d+1$ punti, anziché un ``centro'' solo dello sviluppo di Taylor, nella formula per il resto $\frac{f^{(d+1)}(\xi)}{(d+1)!}(x-x_0)^{d+1}$, il termine $(x-x_0)^{d+1}$ viene rimpiazzato da $\prod_{j=0}^d (x-x_i)$.

Non ci stupisce che ci siano dei fattori $(x-x_i)$ nel membro di destra: difatti, se sostituiamo $x=x_i$, per un qualche $i=0,1,\dots,d$, il termine di sinistra si annulla, quindi deve annullarsi anche quello di destra.

Un altro caso speciale in cui possiamo verificare il risultato direttamente è quello in cui $f(x)$ è essa stessa un polinomio di grado minore o uguale a $d$. In questo caso il polinomio di interpolazione coincide con $f(x)$ stessa, quindi il termine di sinistra è nullo per ogni $x$; e anche il termine di destra si annulla perché per un polinomio di grado al più $d$ abbiamo $f^{(d+1)} \equiv 0$.

Da questa formula segue una stima per l'errore massimo (differenza tra $f(x)$ e $p(x)$), cioè
\[
\abs{f(x) - p(x)} \leq \frac{C_{d+1}}{(d+1)!}(b-a)^{d+1},
\]
dove $C_{d+1} = \max_{x\in [a,b]} \abs{f^{(d+1)}(x)}$.

\section{Altri problemi di interpolazione e approssimazione}
Quello dell'interpolazione polinomiale è un problema che si rivela sorprendentemente lineare: anche se nella formulazione del problema compaiono polinomi di grado più alto di 1, la dipendenza dai coefficienti incogniti $\alpha_0,\dots, \alpha_d$ è lineare. 

Possiamo risolvere nello stesso modo un problema più generale: fissiamo $n$ funzioni $\phi_1(x), \dots, \phi_n(x)$, e cerchiamo coefficienti incogniti $\alpha_1,\dots,\alpha_n$ in modo da ottenere una funzione
\begin{equation} \label{phi}
    \phi(x) = \alpha_1 \phi_1(x) + \alpha_2 \phi_2(x) + \dots + \alpha_n \phi_n(x)    
\end{equation}
che rispetti certe condizioni.

Più nel dettaglio, supponiamo di avere a disposizione $m$ coppie di valori $(x_1,y_1), \dots, (x_m,y_m)$. Di nuovo, assumiamo che gli $x_i$ siano \emph{distinti}.

Se imponiamo le condizioni $\phi(x_i) = y_i$ per $i=1,2,\dots, m$, abbiamo il seguente sistema lineare di $m$ equazioni in $n$ incognite
\[
\underbrace{
\begin{bmatrix}
    \phi_1(x_1) & \phi_2(x_1) & \dots & \phi_n(x_1)\\
    \phi_1(x_2) & \phi_2(x_2) & \dots & \phi_n(x_2)\\
    \vdots & \vdots & \ddots & \vdots\\
    \phi_1(x_m) & \phi_2(x_m) & \dots & \phi_n(x_m)
\end{bmatrix}}_{=X}
\underbrace{\begin{bmatrix}
    \alpha_1\\ \alpha_2 \\ \vdots \\ \alpha_n
\end{bmatrix}
}_{=\mathbf{\alpha}}
= \underbrace{\begin{bmatrix}
    y_1\\ y_2 \\ \vdots \\ y_m
\end{bmatrix}}_{=\mathbf{y}}
\]
Se $m=n$, cioè se ho tanti punti quante funzioni incognite, questo è un sistema lineare quadrato e posso risolverlo esattamente (ammesso che la matrice $X$ sia invertibile). Questa problema si chiama \emph{interpolazione} di funzioni. 

\paragraph{Approssimazione / fit} Il caso più comune però è che $m>n$, e quindi ho più equazioni che incognite. Posso risolvere il sistema nel senso dei minimi quadrati come visto nella sezione precedente; questo corrisponde a risolvere questo problema: sono date delle coppie $(x_i,y_i)$ che soddisfano approssimativamente $\phi(x_i) \approx y_i$, per una funzione $\phi$ come in~\eqref{phi}, e voglio trovare i coefficienti $\alpha_1,\dots,\alpha_n$ che risolvono il problema di minimo
\[
\min_{\alpha \in \mathbb{R}^n} (\phi(x_i) - y_i)^2.
\]
Questo problema si chiama \emph{approssimazione} di funzioni, o, dall'inglese, \emph{fitting}. 

I problemi di interpolazione e di approssimazione si risolvono utilizzando gli algoritmi per risolvere sistemi lineari e sistemi sovradeterminati, che abbiamo visto nella sezione precedente; non ci servono strumenti nuovi. Vediamo un po' di casi particolari.

\paragraph{Retta dei minimi quadrati} Corrisponde a trovare la retta che approssima meglio un insieme di punti dati (disegno, mostrando che lo scarto misurato è ``in verticale''). In questo caso, le funzioni sono $\phi_1(x) = 1, \phi_2(x) = x$. A differenza dell'interpolazione polinomiale, però, i punti sono solitamente più di due, e quindi non esiste una retta che passa esattamente per tutti questi punti. Quindi
\[
X = \begin{bmatrix}
    1 & x_1\\
    1 & x_2\\
    \vdots & \vdots\\
    1 & x_m
\end{bmatrix}, \quad \alpha = (X^TX)^{-1} X^T y,
\]
dove l'ultima formula corrisponde ad usare le equazioni normali per risolvere questo problema. Possiamo ottenere una formula più esplicita espandendo i conti e usando la formula per l'inversa di una matrice $2\times 2$; questo spesso viene fatto se avete già visto la retta di interpolazione in altri corsi; per noi rifare questo conto non è particolarmente interessante.

%%% TODO: inserire un esempio %%%

\paragraph{Approssimazione polinomiale}
Analogamente a quanto fatto con la retta dei minimi quadrati, possiamo fissare un grado massimo $d$, e trovare il polinomio di grado al più $d$ che meglio approssima una sequenza di punti. Questo corrisponde a scegliere le $n = d+1$ funzioni di base
\begin{equation} \label{basepolinomi}
    \phi_1(x) = 1, \quad \phi_2(x) = x, \quad \phi_3(x) = x^2, \dots, \phi_{d+1}(x) = x^{d}.    
\end{equation}

\paragraph{Polinomi trigonometrici} Se desideriamo interpolare (o approssimare) una funzione che sappiamo essere periodica di periodo $\pi$, una base ``naturale'' da usare è
\begin{align*}
\phi_1(x) &= 1,\\
\phi_2(x) &= \sin x, & \phi_3(x) &= \cos x,\\
\phi_4(x) &= \sin 2x, & \phi_5(x) &= \cos 2x,\\
\vdots & & \vdots &\\
\phi_{2k}(x) &= \sin kx, & \phi_{2k+1}(x) &= \cos kx.
\end{align*}
Queste sono, in un certo senso, le funzioni periodiche ``più semplici'' di periodo $\pi$. Non vediamo i dettagli qui, ma è un approccio molto usato, e collegato alla cosiddetta \emph{trasformata di Fourier}, che probabilmente avrete occasione di incontrare in futuro in altri corsi.

\section{Formule di integrazione}

In questa sezione consideriamo il problema di approssimare numericamente l'integrale di una funzione, $I = \int_a^b f(x) dx$. Questo problema si chiama \emph{integrazione numerica}, o \emph{quadratura}.

Sappiamo dall'analisi che il problema di calcolare esattamente integrali (con una formula risolutiva) è un problema difficile: a differenza delle derivate, non ci sono delle formule da applicare meccanicamente ma soltanto una serie di tecniche che a volte funzionano e a volte no. Per questo diventa prezioso avere dei metodi numerici per approssimare la soluzione.

Le formule che vedremo sono tutte del tipo
\[
I \approx \sum_{i=1}^n w_i f(x_i),
\]
dove $w_i$ sono detti \emph{pesi} e $x_i$ \emph{nodi} della formula, e sono scelti indipendentemente da $f$ (ma tipicamente dipendono dall'intervallo $[a,b]$).

% Spesso a queste formule chiediamo che siano esatte su alcune funzioni semplici; per esempio, polinomi di grado basso. Notiamo che una formula è esatta sulla funzione $f(x) \equiv 1$ se $\sum_{i=1}^n w_n = b-a$, per esempio.

Partiamo analizzando due formule semplici.

\paragraph{Formula del punto medio}
È la formula
\[
I_M = (b-a)f(c),
\]
dove $c=\frac{a+b}{2}$ è il punto medio dell'intervallo di integrazione. Corrisponde a rimpiazzare l'integrale con l'area del rettangolo di base $[a,b]$ e altezza $f(m)$, quindi una somma di Riemann con un solo rettangolo. Notiamo che se $f(x)$ è una funzione lineare (polinomio di grado 1), allora questa formula calcola esattamente l'integrale. Difatti, [disegno] la differenza tra i due integrali è pari all'area di due triangoli uguali, una presa con il segno $+$ e una presa con il segno $-$.

Diremo che una formula di integrazione numerica ha \emph{grado di esattezza} (o qualche volta \emph{di precisione, di accuratezza}) $d$ se fornisce il valore esatto dell'integrale per tutte le funzioni $f$ che sono polinomi di grado $d$ o inferiore.

La formula del punto medio ha grado di esattezza $1$. Difatti, se prendiamo un polinomio di grado $2$, per esempio $x^2$, la formula non fornisce più valori esatti.

Esempio: per calcolare l'integrale di $f(x)=x^2$ su $[a,b]=[0,1]$
\[
    I = \int_0^1 x^2\, dx = \frac{1}{3},
\]
la formula del punto medio fornisce
\[
    I_M = (b-a)f(c) = (1-0)f(0.5) = \frac{1}{4}.
\]
Questo risultato è minore del valore esatto.

Possiamo dimostrare una formula per l'errore $I_M-I$ in termini della derivata seconda di $f$.
\begin{theorem}
Sia $f\in\mathcal{C}^2([a,b])$. Allora,
\[
\abs{I_M-I} \leq \frac{1}{24}C_2 (b-a)^3,
\]
dove $C_2 = \max_{x\in [a,b]} \abs{f''(x)}$.
\end{theorem}
\begin{proof}
Scriviamo uno sviluppo di Taylor in $c$ di ordine 2,
\[
f(x) = f(c) + f'(c)(x-c) + \frac12 f''(\xi)(x-c)^2.
\]
Ora sostituiamo
\begin{align*}
    I_M - I &= f(c)(b-a) - \int_{a}^b \left(f(c) + f'(c)(x-c) + \frac12 f''(\xi)(x-c)^2\right)dx\\
    &= \underbrace{f(c)(b-a) - \int_{a}^b \biggl(f(c) + f'(c)(x-c)\biggr)dx}_{=0} - \int_a^b \frac12 f''(\xi)(x-c)^2dx.
\end{align*}
Il primo termine si annulla perché la formula del punto medio ha grado di esattezza $1$, quindi calcola esattamente l'integrale della funzione $f(c) + f'(c)(x-c)$, che è un polinomio di grado $1$ che assume il valore $f(c)$ per $x=c$. Possiamo allora stimare l'errore come
\begin{align*}
\abs{I_M - I} &= \abs*{\int_a^b \frac12 f''(\xi)(x-c)^2 dx}
    \leq \int_a^b \frac12 \abs{f''(\xi)}(x-c)^2 
    \\ &\leq \frac12  \int_a^b C_2(x-c)^2 dx = \frac1{24}C_2 (b-a)^3,
\end{align*}
visto che $\int_a^b (x-c)^2 dx = \frac{1}{12}(b-a)^3$ (la primitiva di $(x-c)^2$ è $\frac{1}{3}(x-c)^3$).
\end{proof}
Con un po' più di attenzione, possiamo dimostrare un risultato più forte: se $m \leq f''(x) \leq M$ (cioè $m$ e $M$ sono il minimo e il massimo di $f''(x)$) allora
\[
\frac{m}{12}(b-a)^3 \leq \int_a^b m(x-c)^2 dx \leq \int_a^b f''(x)(x-c)^2 dx \leq \int_a^b M(x-c)^2 dx \leq \frac{M}{12}(b-a)^3,
\]
e quindi (per la continuità di $f''$) esiste un valore di $\xi$ per cui
\[
I_M - I = -\frac{f''(\xi)}{24}(b-a)^3.
\]
Questa formula ci dà anche informazioni sul segno: se la derivata seconda di $f$ è sempre positiva (cioè $f$ è convessa), allora $I_M < I$; e al contrario se la derivata seconda è sempre negativa e $f$ è concava, allora $I_M > I$.

\paragraph{Formula dei trapezi}

È la formula $I \approx I_T = \frac{b-a}{2}(f(a)+f(b))$; cioè, rimpiazziamo l'integrale con l'area del trapezio con basi $f(a)$ e $f(b)$ (disegno sulla lavagna). Abbiamo due pesi $w_1=w_2=\frac{b-a}{2}$ e due nodi $a,b$. Questa formula calcola esattamente l'integrale $I_T$ della retta di interpolazione per $f$ con i due nodi $x_1=a$, $x_2=b$. In particolare, da questo segue che ha grado di esattezza almeno $1$. Di nuovo, è facile mostrare che il grado di esattezza è proprio 1.

Esempio: $I = \int_0^1 x^2\, dx = 1/3$. La formula dei trapezi fornisce
\[
    I_T = \frac{b-a}{2}(f(0)+f(1)) = \frac{1-0}{2}(0^2+1^2) = \frac{1}{2}.
\]
Questa volta l'errore è per eccesso. Difatti $f(x)=x^2$ è una funzione convessa, e quindi sta al di sotto della retta che congiunge $(0,f(0))$ e $(1,f(1))$.

Possiamo dimostrare un risultato analogo a quello visto poco fa per il metodo del punto medio.
\begin{theorem}
Sia $f\in\mathcal{C}^2([a,b])$. Allora,
\[
\abs{I_T-I} \leq \frac{1}{12}C_2 (b-a)^3,
\]
dove $C_2 = \max_{x\in [a,b]} \abs{f''(x)}$.
\end{theorem}
Notare che il coefficiente è il doppio di quello ottenuto per la formula del punto medio.
\begin{proof}
Scriviamo la formula del resto dell'interpolazione,
\[
f(x) - p(x) = \frac{f''(\xi)}{2}(x-a)(x-b),
\]
dove $p(x)$ è il polinomio di grado 1 ($d=1$) che interpola $f(x)$ nei due nodi $a$ e $b$; abbiamo detto poco fa che $I_T = \int_a^b p(x) dx$. Allora,
\[
I_T - I = \int_a^b (p(x)-f(x)) dx = \int_a^b \frac{f''(\xi)}{2}(x-a)(b-x) dx,
\]
dove abbiamo cambiato segno a $x-b$. Scegliendo i segni in questo modo, $(x-a)(b-x)\geq 0$ per ogni $x\in [a,b]$, e quindi è sempre uguale al suo valore assoluto. Ora possiamo scrivere
\begin{align*}
\abs{I_T - I} &= \abs*{\int_a^b \frac{f''(\xi)}{2}(x-a)(b-x) dx} \leq \int_a^b \frac{\abs{f''(\xi)}}{2}(x-a)(b-x) dx \\
& \leq \frac{C_2}{2} \int_a^b (x-a)(b-x)dx = \frac{C_2}{12}(b-a)^3,
\end{align*}
visto che $\int_a^b (x-a)(x-b)dx = \frac{1}{6}(b-a)^3$ (di nuovo è un conto su un integrale di un polinomio di grado 2).
\end{proof}
Come prima, un ragionamento più accurato porta a
\[
I_T - I = \frac{f''(\xi)}{12}(b-a)^3.
\]
Quindi questa formula restituisce un risultato più \emph{grande} di $I$ per funzioni convesse, e più \emph{piccolo} per funzioni concave; cosa che è evidente anche da un disegno (TODO).

\paragraph{Formule di Newton--Cotes} La dimostrazione che abbiamo fatto suggerisce una strategia generale: per calcolare un integrale, possiamo scegliere un grado $d$, fissare a nostro piacere $d+1$ nodi in $[a,b]$, calcolare il polinomio di interpolazione $p(x)$ su questi nodi, e rimpiazzare $I = \int_a^b f(x) dx$ con $I_d = \int_a^b p(x) dx$. Questo ci fornisce una formula con grado di esattezza almeno $d$, visto che se $f(x)$ è un polinomio di grado al più $d$ allora coincide con il suo polinomio di interpolazione. Le \emph{formule di Newton--Cotes} si ottengono prendendo $n = d+1$ nodi \emph{equispaziati} $x_0=a, x_1=a+h,\dots x_{d}=b$, con $h = \frac{b-a}{d}$.

Utilizzando la forma di Lagrange del polinomio di interpolazione, abbiamo
\[
I_d = \int_a^b p(x) dx = \int_a^b \sum_{k=0}^d L_k(x)f(x_k) dx = \sum_{k=0}^d f(x_k) \underbrace{\int_a^b L_k(x) dx}_{=w_k}.
\]

Calcoliamo per esempio i pesi che risultano per $[a,b]=[-1,1]$ e $d=2$ intervalli: i tre punti equispaziati sono $x_0=-1,x_1=0,x_2 = 1$, e 
\begin{align*}
L_0(x) &= \frac{(x-0)(x-1)}{(-1-0)(-1-1)} = \frac{x(x-1)}{2}, & w_0 = \int_{-1}^1 L_0(x) = \frac13, \\
L_1(x) &= \frac{(x+1)(x-1)}{(0+1)(0-1)} = 1-x^2, & w_1 = \int_{-1}^1 L_0(x) = \frac43, \\
L_2(x) &= \frac{(x+1)(x-0)}{(1+1)(1-0)}  = \frac{(x+1)x}{2}, & w_2 = \int_{-1}^1 L_0(x) = \frac13.
\end{align*}

\paragraph{Cambio di variabile} A priori, sembrerebbe che per ogni scelta dell'intervallo $[a,b]$ dobbiamo ricalcolare da capo queste formule. È possibile però fare un cambio di variabile lineare che ci permette di ricondurre un generico intervallo $[a,b]$ all'intervallo $[-1,1]$. Definiamo come in precedenza $c=\frac{a+b}{2}$ il punto medio di $[a,b]$, e $x = c + \frac{b-a}{2}y$. È semplice verificare che $y=-1,y=1$ corrispondono a $x=a,x=b$ rispettivamente. 

Quindi abbiamo $dx = \frac{b-a}{2}dy$ e 
\[
\int_{a}^b f(x)dx = \frac{b-a}{2}\int_{-1}^1 f\left(\frac{2}{b-a}(x-c)\right) dy.
\]
Questa formula di cambio di variabile si può utilizzare non solo per integrare la funzione $f$, ma anche per integrare i polinomi di Lagrange $L_k(x)$.

Inoltre, visto che il cambio di variabile è lineare, $d+1$ punti equispaziati $x_0,\dots,x_d$ su $[a,b]$ diventano $d+1$ punti equispaziati $y_0,\dots,y_d$ su $[-1,1]$, e il polinomio di Lagrange $L_k(x)$ costruito sui punti $x_0,\dots,x_d$ diventa il polinomio di Lagrange $L_k(y)$ costruito sui punti $y_0,\dots,y_d$. Questo ci dice che per un intervallo generico i pesi di $I_2$ saranno
\[
w_0 = \frac16(b-a), \quad w_1 = \frac46 (b-a), \quad w_2 = \frac16 (b-a).
\]
Otteniamo quindi, per $d=2$, la formula
\[
I \approx I_2 = \frac{b-a}{6}\left(f(a) + 4f(c) + f(b)\right),
\]
che è detta \emph{formula di Cavalieri--Simpson}. Analogamente è possibile costruire formule di Newton--Cotes di grado più alto.

\paragraph{Grado di esattezza delle formule di Newton--Cotes}

La formula di Cavalieri--Simpson che abbiamo costruito ha necessariamente grado di esattezza almeno 2: difatti, corrisponde a prendere il polinomio di interpolazione $p(x)$ a $f(x)$ di grado al più 2, e calcolarne l'integrale; quindi se $f(x)$ è già di partenza un polinomio di grado al più $2$ riotteniamo l'integrale di partenza. La cosa sorprendente è che questa formula in realtà ha grado di esattezza 3, cioè restituisce il risultato esatto anche per polinomi di grado $3$. Possiamo verificare facilmente che per $[a,b]=[-1,1]$ e $f(x)=x^3$, per simmetria $I = \int_{a}^b f(x) dx = 0$, e la  formula di Cavalieri--Simpson fornisce $I_2=0$. Non vediamo i dettagli, ma poiché sia gli integrali che le nostre formule di integrazione sono lineari nella $f$, questo è sufficiente per concludere che la formula è esatta per \emph{ogni} polinomio di grado 3.

Più in generale, per le formule di Newton--Cotes valgono espressioni dell'errore simili a quella dimostrata per il metodo dei trapezi.
\begin{theorem}
La formula di Newton--Cotes di grado $d$ (con $d+1$ punti equispaziati) ha grado di esattezza $d$ se $d$ è dispari, $d+1$ se $d$ è pari.
Inoltre, se chiamiamo $p-1$ il grado di esattezza (di modo che $p$ sia sempre pari) abbiamo la stima per l'errore
\[
\abs{I_d - I} \leq \kappa_d C_{p} (b-a)^{p+1},
\]
dove $\kappa_d$ è un'opportuna costante che dipende dal grado.
\end{theorem}
Per il metodo dei trapezi, già sappiamo che $\kappa_1 = \frac{1}{12}$. Per il metodo di Cavalieri--Simpson, vale $\kappa_2 = \frac{1}{90}$. Non lo dimostriamo qui, così come non dimostriamo questo teorema.

\section{Formule di integrazione composite}

In realtà, utilizzare formule di Newton--Cotes con valori grandi di $d$ non è una buona idea, visto che si incorre negli stessi problemi di cattivo condizionamento che abbiamo visto con l'interpolazione polinomiale. Tipicamente, si scelgono formule di grado al massimo 4, e se si vuole ridurre ancora l'errore si usa una strategia diversa.

Dividiamo l'intervallo $[a,b]$ in $N$ intevalli uguali, scegliendo gli $N+1$ punti equispaziati
\[
x_0=a, x_1=a+h, \dots,x_n = a+nh,\dots, x_N=b,
\]
con $h= \frac{b-a}{N}$ la lunghezza di ogni intevallo. (Stiamo riutilizzando la stessa notazione della sezione precedente, anche se qui utilizziamo in modo diverso gli $N$ sottointervalli uguali in cui abbiamo diviso $[a,b]$.)

Abbiamo
\[
\int_a^b f(x) dx = \sum_{n=1}^N \int_{x_{n-1}}^{x_n} f(x) dx.
\]
Poi approssimiamo ognuno degli $n$ integrali nel termine di destra con una delle formule viste al passo precedente. In questo modo otteniamo i seguenti metodi.

\begin{description}
    \item[Metodo del punto medio composito]
\[
I_{M,N} = \sum_{n=1}^N \underbrace{(x_{n}-x_{n-1})}_{h}f\left(\frac{x_{n-1}+x_n}{2}\right) = \frac{b-a}{n} \sum_{n=1}^N f\left(\frac{x_{n-1}+x_n}{2}\right).
\]
\item[Metodo dei trapezi composito]
\[
I_{T,N} = \sum_{n=1}^N \frac{x_{n}-x_{n-1}}2 \left(f(x_{n-1})+f(x_n)\right) = \frac{b-a}{2n} \sum_{n=1}^N\left(f(x_{n-1})+f(x_n)\right).
\]
\item[Metodo di Cavalieri--Simpson composito]
\begin{align*}
    I_{2,N} &= \sum_{n=1}^N  \frac{x_{n}-x_{n-1}}6  \left(f(x_{n-1})+4f\left(\frac{x_{n-1}+x_n}{2}\right) + f(x_n)\right)\\
    &= \frac{b-a}{6n} \sum_{n=1}^N \left(f(x_{n-1})+4f\left(\frac{x_{n-1}+x_n}{2}\right) + f(x_n)\right)\\
    &= \frac{2}{3}I_{M,N} + \frac13 I_{T,N}.
\end{align*}
\end{description}
Il costo del metodo del punto medio composito è $N$ valutazioni di funzione, nei punti medi di ognuno degli intervalli della suddivisione. (Più $O(N)$ somme che sono solitamente trascurabili rispetto alle valutazioni di funzione.)

Il costo del metodo dei trapezi apparentemente è di $2N$ valutazioni di funzione; però possiamo osservare che tutti i punti a parte il primo e l'ultimo compaiono due volte: una volta come estremo destro di un intervallo, una volta come estremo sinistro. Quindi possiamo riscrivere la sommatoria che compare in $I_{T,N}$ come
\[
\frac12\sum_{n=1}^N\left(f(x_{n-1})+f(x_n)\right) = \frac12 f(x_0) + \frac12 f(x_N) + \sum_{n=1}^{N-1} f(x_n),
\]
che richiede solo $N+1$ valutazioni di funzione. Sarà un'accortezza necessaria quando lo implementeremo.

Analogamente, il metodo di Cavalieri--Simpson richiede $2N+1$ valutazioni di funzione. Vedremo però che questo costo maggiore è compensato da un errore minore.

Questo trucco per ridurre il numero di valutazioni si può applicare non solo per la formula dei trapezi e di Cavalieri--Simpson, ma tutte le volte che una formula di integrazione include come nodi gli estremi dell'intervallo di valutazione. Le formule che soddisfano questa proprietà sono dette \emph{chiuse} (per analogia con gli intervalli chiusi, che includono gli estremi).

\paragraph{Errore delle formule composite}

\begin{theorem}
Se per una formula di integrazione vale una stima sull'errore del tipo $\abs{\tilde{I} - I} \leq \kappa C_{p} (b-a)^{p+1}$, allora per la sua versione composita con $N$ sottointervalli vale la stima
\[
\abs{\tilde{I}_N - I} \leq \kappa C_{p} \frac{(b-a)^{p+1}}{N^{p}} = \kappa (b-a) C_{p}  h^{p}.
\]
\end{theorem}
\begin{proof}
È sufficiente sommare tra loro le stime degli errori sugli $N$ sottointervalli, ognuno di lunghezza $h=\frac{b-a}{N}$:
\begin{align*}
\abs{\tilde{I}_N - I} \leq \sum_{n=1}^N \abs*{\tilde{I}_{[x_{n-1},x_n]} -\int_{x_{n-1}}^{x_n} f(x)dx } \leq \sum_{n=1}^N \kappa C_{p} h^{p+1} =  N \kappa C_{p+1} \frac{(b-a)^{p+1}}{N^{p+1}}.
\end{align*}
\end{proof}

\paragraph{Ordine di convergenza} Al crescere del numero di punti $N$, quindi, l'errore di una formula composita $e_N = \abs{I_N - I}$ tende a zero come una potenza dell'inverso del numero di punti $\frac{1}{N}$, o, equivalentemente, come una potenza di $h$. Possiamo quindi scrivere
\[
e_N = O(\frac{1}{N^p}) = O(h^p).
\]
Il numero $p$ è detto \emph{ordine di convergenza} della formula di integrazione. Quindi, per esempio, la formula dei trapezi composita e la formula del punto medio composita hanno ordine di convergenza $p = 2$, mentre la formula di Cavalieri--Simpson ha ordine $p=4$. 

L'ordine di convergenza ci permette di prevedere come decresce l'errore al crescere del numero di punti $N$: se il numero di punti raddoppia, passando da $N$ a $2N$, cioè la distanza tra due punti successivi dimezza, passando da $h$ a $\frac{h}{2}$, allora l'errore si riduce di un fattore $2^p$ (approssimativamente, visto che la relazione è vera solo nel limite per $N\to\infty$).

\paragraph{Diverse nozioni di ordine di convergenza}
Attenzione: è importante notare che questo è un concetto di ``ordine di convergenza'' diverso da quello visto per i metodi iterativi. Nel caso dei metodi iterativi, la convergenza si riferiva a un numero di iterazioni $n$: convergenza di ordine $p$ significa che
\[
e_{n+1} = O(e_n^p),
\]
cioè, l'errore al passo $n+1$ è dell'ordine della potenza $p$-esima di \emph{quello al passo precedente}.

Nel caso di questi metodi, invece, non c'è un concetto di ``iterazioni successive'', e non ha molto senso confrontare $e_{N+1}$ con $e_N$: il risultato di una formula di integrazione con $N+1$ punti non si può calcolare facilmente a partire da quello con $N$ punti, visto che tutti i punti necessari per calcolarla sono diversi.

Anche il comportamento dei due errori al crescere di $n$ è diverso. Ad esempio, supponiamo di avere un metodo iterativo con ordine di convergenza $1$; esso soddisfa
\[
\lim_{n\to\infty} \frac{e_{n+1}}{e_n} = r < 1,
\]
quindi $e_n \approx C r^n$. In particolare, passando dall'iterazione $n$ all'iterazione $2n$ l'erore si riduce di un fattore $r^n$, non di un fattore $2$.

\paragraph{Struttura delle formule per l'errore} Notiamo che tutte le formule per l'errore che abbiamo ottenuto hanno una struttura simile: sono il prodotto di:
\begin{itemize}
    \item Una costante (per esempio $\frac{1}{24}$);
    \item La lunghezza dell'intervallo su cui stiamo lavorando (tipicamente $b-a$);
    \item La costante $C_p$, cioè, il massimo della derivata di un certo \emph{ordine} $p$, per la funzione su cui stiamo lavorando;
    \item La lunghezza $h$ dei sottointervalli su cui lavoriamo, elevata alla $p$.
\end{itemize}

\paragraph{Stima dell'errore per le formule composite} Sia $N$ un intero pari. Applicando una formula di integrazione composita con ordine di convergenza $p$ prima con $N$ intervalli e poi con $N/2$ sottointervalli, ci aspettiamo quindi che
\[
I_N = I + e_N, \quad I_{N/2} = I + e_{N/2} \approx I + 2^{p}e_N.
\]
Da queste due relazioni possiamo eliminare $I$ e ricavare approssimativamente il valore di $e_N$ come
\[
\frac{I_{N/2} - I_{N}}{2^p -1} \approx \frac{I + 2^p e_N -(I+e_N)}{2^p-1} = e_N.
\]
Per le formule dei trapezi e di Cavalieri--Simpson (ma non per tutti i metodi!) il calcolo di $I_{N/2}$ non richiede ulteriori valutazioni rispetto a quelle già utilizzate per il calcolo di $I_N$; e, a patto di fare le somme in un ordine appropriato durante l'implementazione, neppure somme aggiuntive. Quindi calcolare questa stima dell'errore ha un costo aggiuntivo trascurabile, per questi due metodi.


\section{Quadratura Gaussiana}
Ci poniamo ora (insieme a Gauss) il problema di quanto alto può essere il grado di esattezza di una formula di quadratura, se scegliamo bene pesi e nodi. Perché una formula $\tilde{I}$ con $n$ nodi sia esatta su tutti i polinomi di grado $ \leq d$, è necessario e sufficiente che sia esatta su $1, x, x^2, \dots, x^{d}$, visto che i polinomi di grado $\leq d$ sono combinazioni lineari di queste funzioni. Questo porta a $d+1$ equazioni (non lineari!) nelle $2n$ incognite $w_1,x_1,\dots, w_n,x_n$: per esempio, con $[a,b]=[-1,1]$ abbiamo
\[
\sum_{k=1}^n w_k 1 = 2, \quad \sum_{k=1}^n w_k x_k = 0, \quad \sum_{k=1}^n w_k x_k^2 = \frac23, \dots
\]
Visto che abbiamo $d+1$ equazioni in $2n$ incognite, possiamo aspettarci che il sistema abbia delle soluzioni quando $d+1=2n$.  Questo è vero: esiste una (e una sola) scelta di $x_1,\dots,x_n,w_1,\dots,w_n$ che risolve le equazioni, e fornisce una formula con grado di esattezza $2n-1$. Non vediamo la dimostrazione qui; non è semplice, anche perché queste equazioni non sono lineari!

Per ogni scelta di $n$ quindi possiamo quindi trovare nodi e pesi $x_1,\dots,x_n,w_1,\dots,w_n$, che dipendono solo dall'intervallo $[a,b]$. Nodi e pesi di queste formule, dette di \emph{quadratura Gaussiana}, si possono trovare su diverse fonti online, per esempio \url{https://en.wikipedia.org/wiki/Gaussian_quadrature}. Per esempio con $n=2$ abbiamo
\[
x_1 = \frac{1}{\sqrt{3}} = 0.57735\dots, \quad x_2 = -\frac{1}{\sqrt{3}} = -0.57735\dots, w_1=w_2=1
\]
che sono i nodi e i pesi dell'unica formula di quadratura su $[-1,1]$ con grado di esattezza $3$. Con un cambio di variabile simile a quello visto sopra è possibile adattarle ad altri intervalli. Non essendo formule chiuse, tipicamente non vengono usate nella versione composita, ma sono particolarmente utili nella loro versione semplice, quando basta un'approssimazione dell'integrale con bassa precisione ma calcolabile con poche valutazioni di funzione.

\chapter{Equazioni differenziali ordinarie}

\paragraph{Il problema} In questo capitolo, ci poniamo il problema di risolvere numericamente un'equazione differenziale, o più precisamente un \emph{problema ai valori iniziali} (o \emph{problema di Cauchy})
\begin{equation} \label{cauchy}
    \begin{cases}
    \y'(t) = \f(t, \y(t)), \quad t \in [a,b],\\
    \y(a) = \y_0.
    \end{cases}
\end{equation}
Qui $\y: [a,b]\to \mathbb{R}^m$ è una funzione a valori vettori (anche se nella maggior parte degli esempi che vedremo $m=1$), e $\f(t,\y(t))$ è una funzione $f:[a,b] \times \mathbb{R}^m \to \mathbb{R}^m$ che specifica il problema. Il simbolo $\y'$ indica la derivata di $\y$ rispetto alla variabile $t$ (che possiamo pensare come `tempo'), e $\y_0\in \mathbb{R}^m$ è un valore iniziale dato.

Questa è la formulazione più generale, ma in molti esempi $m=1$ e quindi il problema riguarda una funzione reale di variabile reale. Per esempio, uno degli esempi che vedremo molto spesso è il seguente (detto \emph{problema test})
\begin{equation} \label{testproblem}
    \begin{cases}
    y'(t) = \lambda y(t), \quad y: [0,1] \to \mathbb{R}\\  
    y(0) = y_0,
    \end{cases}
\end{equation}
in cui quindi abbiamo $f(t, y) = \lambda y$. La soluzione di questo problema è $y(t) = \exp( \lambda t)$.

\paragraph{Altri esempi}
Un esempio famoso di un'equazione differenziale con più variabili è l'\emph{equazione di Lotka--Volterra}, o \emph{modello preda--predatore}. Fu studiata proprio qui a Pisa dal matematico Vito Volterra. L'equazione simula (approssimandoli con variabili continue) la quantità $u$ di prede e $v$ di predatori in un certo ambiente, e dice che
\[
    \begin{cases}
        u' = (A-Bv)u,\\
        v' = (Cu-D)v,
    \end{cases}
\]
per certe costanti $A,B,C,D>0$. Notiamo che qui non abbiamo scritto esplicitamente $u(t)$ ma solo $u$, anche se $u$ è una funzione del tempo; questo è abbastanza comune

Più grande è il numero di predatori $v$, e più lentamente cresce il numero di prede $u$. Più grande è il numero di prede $u$, e più velocemente cresce la popolazione dei predatori. Ponendo
\[
    \y(t) = 
    \begin{bmatrix}
        y_1(t) \\ 
        y_2(t)
    \end{bmatrix} = 
    \begin{bmatrix}
        u(t)\\
        v(t)
    \end{bmatrix},
\]
Abbiamo
\[
    \frac{d}{dt} \y(t) = \f(t,\y) = \begin{bmatrix}
        (A-By_2)y_1,\\
        (Cy_1-D)y_2,
    \end{bmatrix}.
\]
Notiamo che negli esempi che abbiamo visto finora la funzione $\f(t,\y)$ dipende solo dalla $\y$ e non dal tempo $t$; questo è abbastanza comune nelle equazioni differenziali.

Equazioni che contengono derivate di ordine superiore si possono sempre riscrivere nella forma~\eqref{cauchy} introducendo variabili ausiliarie: per esempio, l'equazione scalare di ordine 2
\[
\begin{cases}
x'' = 3t^2 x' + 5(t+1)x - t, \quad x:[a,b]\to\mathbb{R}, \\
x(a) = 1, \, x'(a) = 0
\end{cases}
\]
diventa, ponendo $\mathbf{y}(t) = \begin{bmatrix}
    y_1(t)\\
    y_2(t)
\end{bmatrix} = \begin{bmatrix}
    x(t)\\
    x'(t)
\end{bmatrix}$,
\[
\frac{d}{dt} \mathbf{y} = 
\frac{d}{dt}
\begin{bmatrix}
    y_1\\ y_2
\end{bmatrix} = \begin{bmatrix}
    y_2\\
    3t^2y_2 + 5(t+1)y_1 - t
\end{bmatrix}.
\]
Questa volta la funzione $\f(t,\y)$ al membro di destra dipende sia dalla $t$ che dagli elementi del vettore $\y$.

La maggior parte degli algoritmi che vedremo mirano a calcolare un'approssimazione dei valori assunti dalla soluzione $\y(t)$ su una griglia di punti equispaziati in $[a,b]$: useremo la notazione già vista nel capitolo scorso
\[
h = \frac{b-a}{N}, \quad t_n = a + nh, \quad n = 0,1,2,\dots,N.
\]
Chiameremo questi valori $\y_i \approx \y(t_i)$, per $t = 1,2,\dots, N$.

Vediamo subito alcuni algoritmi particolarmente semplici.

\section{Metodi a un passo}

\paragraph{Metodo di Eulero esplicito}

Facendo uno sviluppo di Taylor in $t_n$, abbiamo
\begin{equation} \label{euleroesp_taylor}
    \y(t_{n+1}) = \y(t_n) + \y'(t_n)h + \mathcal{O}(h^2) = \y(t_n) + \f(t_n, \y_n)h + \mathcal{O}(h^2)
\end{equation}
Se ignoriamo il resto $\mathcal{O}(h^2)$ e rimpiazziamo $\y(t_n), \y(t_{n+1})$ con le loro approssimazioni sui punti della griglia, otteniamo
\[
\y_{n+1} = \y_n + h \f(t_n, \y_n).
\]
Questa può essere vista come una formula che ci permette di calcolare $\y_{n+1}$ a partire da $\y_n$. Otteniamo quindi il \emph{metodo di Eulero esplicito}
\begin{equation} \label{euleroesplicito}
    \y_{n+1} = \y_n + h \f_n, \quad n = 0,1,2,\dots,N-1,
\end{equation}
dove abbiamo posto $\f_n = \f(t_n, \y_n)$ per brevità.

Il costo computazionale è di $N$ valutazioni di $\f$, più $\mathcal{O}(mN)$ operazioni aritmetiche. Come per altri metodi, l'operazione più costosa qui è la valutazione della funzione, quindi sostanzialmente il costo è di $N$ valutazioni della funzione, una per passo.

\paragraph{Metodo di Eulero implicito}

Facendo invece uno sviluppo di Taylor con centro in $t_{n+1}$, abbiamo
\[
\y(t_n) = \y(t_{n+1}) - \y'(t_{n+1})h + \mathcal{O}(h^2),
\]
che operando nello stesso modo conduce alla relazione
\begin{equation} \label{euleroimplicito}
    \y_{n+1} = \y_n + h \underbrace{\f(t_{n+1}, \y_{n+1})}_{\f_{n+1}}.    
\end{equation}
La differenza importante è che questa volta la $\y_{n+1}$ compare anche al secondo termine, eventualmente nascosta dentro il termine $\f_{n+1}$. Quindi non possiamo calcolare direttamente $\y_{n+1}$ a partire da $\y_n$. Invece, l'equazione \eqref{euleroimplicito} è un'equazione che definisce implicitamente $\y_{n+1}$. È necessario risolverla per calcolare $\y_{n+1}$. 

Per alcune equazioni differenziali, questa equazione è semplice da risolvere. Per esempio, consideriamo il problema test~\eqref{testproblem}: si ha
\[
    y_{n+1} = y_n + h\lambda y_{n+1};
\]
questa è un'equazione di grado 1 nella $y_{n+1}$, quindi possiamo risolverla facilmente ottenendo
\[
y_{n+1} = \frac{1}{1-h\lambda} y_n.
\]

Per equazioni differenziali più complicate, possiamo per esempio vedere la~\eqref{euleroimplicito} come un'equazione di punto fisso: per ogni $n$ fissato generiamo una successione
\[
\z_0 = \y_n, \quad \z_{k+1} = \y_n + h \f(t_{n+1}, \z_k), \quad k=0,1,2,\dots
\]
che (sperabilmente) converge a una soluzione $\lim_{k\to\infty} \z_k = \y_{n+1}$. Oppure possiamo utilizzare il metodo di Newton. 

In ogni caso, si chiama \emph{metodo di Eulero implicito} il metodo in cui si calcola $\y_{n+1}$ a partire da $\y_n$ risolvendo la~\eqref{euleroimplicito} (in qualche modo) ad ogni passo per $n=0,1,2,\dots,N-1$. Il costo computazionale dipende dal modo in cui risolviamo la~\eqref{euleroimplicito}.

\paragraph{Metodo dei trapezi}
È il metodo
\begin{equation} \label{mettrapezi}
    \y_{n+1} = \y_n + h\left(\frac12 \f_n + \frac12 \f_{n+1}\right).    
\end{equation}
È una sorta di ``media'' tra il metodo di Eulero esplicito e di quello implicito. Ha questo nome perché si può ottenere scrivendo
\[
\y(t_{n+1}) = \y(t_n) + \int_{t_n}^{t_{n+1}} \y'(t) dt = \y(t_n) + \int_{t_n}^{t_{n+1}} \f(t,\y(t)) dt
\]
e approssimando l'integrale con la formula dei trapezi otteniamo la~\eqref{mettrapezi}. Il vantaggio di questo metodo rispetto ai due metodi di Eulero è che l'errore che commettiamo è minore: difatti, applicando il metodo dei trapezi per integrare una funzione su un intervallo di lunghezza $h$, commettiamo un errore dell'ordine di $\mathcal{O}(h^3)$:
\[
    \y(t_{n+1}) = \y(t_n) + \int_{t_n}^{t_{n+1}} \f(t,\y(t)) dt = \y(t_n) + \frac{h}{2}(\f_n + \f_{n+1}) + \mathcal{O}(h^3).
\]

\paragraph{Convergenza del metodo di Eulero esplicito (*)}
Vedremo tra poco l'enunciato di un risultato generale che dice che le sequenze di approssimazioni prodotte da questi metodi convergono alla soluzione esatta dell'equazione~\eqref{cauchy}. Vogliamo però dare una dimostrazione esplicita della convergenza almeno per il caso più semplice, quello del metodo di Eulero esplicito per un problema scalare con $m=1$.

Prima di tutto, definiamo cosa intendiamo per ``convergenza''. Data un'equazione differenziale~\eqref{cauchy} con soluzione $\y(t)$, e una sequenza di approssimazioni $\y_n \approx \y(t_n)$ su una griglia $(t_0,t_1,\dots,t_N)$, chiamiamo \emph{errore globale} la quantità
\begin{equation} \label{globalerror}
    E_N = \max_{n=1,2,\dots,N} e_n, \quad e_n = \norm{\y_n - \y(t_n)},
\end{equation}
cioè il massimo tra gli errori $e_n$ calcolati su tutti punti della griglia; ognuno di questi errori è la differenza (in norma, o in valore assoluto se $m=1$) tra la sequenza e la funzione che essa vuole approssimare. Al crescere del numero di punti $N$, ci aspettiamo che l'errore globale $E_N$ ottenuto con il metodo di Eulero diminuisca.

Intuitivamente, l'errore $e_{n+1}$ al passo $n+1$ viene da due fonti: la prima è che abbiamo un errore $e_n$ ``ereditato'' dai passi precedenti, per cui non applichiamo la nostra formula a partire dal valore esatto $\y(t_n)$, ma dalla sua approssimazione $\y_n$. La seconda è che, anche se partissimo dal valore esatto, la formula che usiamo per calcolare il passo successivo è approssimata: difatti l'abbiamo ottenuta trascurando il resto $\mathcal{O}(h^2)$ dallo sviluppo di Taylor~\eqref{euleroesp_taylor}.

Per dimostrare il nostro teorema, chiediamo un'ipotesi sulla funzione $\f(t,\y)$ che compare nella~\ref{cauchy}. Diciamo che $\f$ è \emph{Lipschitziana} nella variabile $\y$ (con costante $L$) se esiste un numero reale $L \geq 0$ tale che per ogni $t\in [a,b]$ e $\y_1,\y_2\in\mathbb{R}^m$ vale
\[
\norm{f(t, \y_1) - f(t, \y_2)} \leq L\norm{\y_1 - \y_2}.
\]
Questa proprietà ricorda un po' le proprietà di buon condizionamento: facendo una piccola perturbazione (assoluta, questa volta) dell'input $\y$, l'output $\f(t,\y)$ varia di al più questa perturbazione moltiplicata per un fattore $L$. Forse avete già visto questa proprietà ad analisi, perché è la stessa che serve per dimostrare l'esistenza di soluzioni di un problema ai valori iniziali~\eqref{cauchy}.

Quando $m=1$ (e quindi al posto delle norme abbiamo dei valori assoluti), un modo di assicurare questa proprietà, per esempio, è provare che la $f$ ha derivata parziale limitata $\abs*{\frac{\partial f}{\partial y}(t,y)} \leq L$ per ogni valore di $t,y$: difatti, il teorema di Lagrange ci assicura che per un certo $\xi$ compreso tra $y_1$ e $y_2$ vale
\[
f(t, y_1) - f(t, y_2) = \frac{\partial f}{\partial y}(t,\xi) (y_1 - y_2).
\]

\begin{theorem}
Sia dato un problema ai valori iniziali~\eqref{cauchy} con $m=1$. Supponiamo che la funzione $f$ sia Lipschitziana nella $y$ con costante $L$, e che la soluzione $y(t)$ sia di classe $\mathcal{C}^2$ su $[a,b]$. Allora, $\lim_{N\to \infty} E_N = 0$, e più precisamente $E_N = \mathcal{O}(h)$ (cioè, esiste una costante $C>0$ tale che $E_N \leq Ch$).
\end{theorem}
Solitamente gli errori si scrivono come ordini rispetto a $h = \frac{b-a}{N}$, come qui sopra, ma visto che $b-a$ è costante questo vuol dire che al crescere del numero di punti $N$ la soluzione tende a zero come $1/N$.
\begin{proof}
Innanzitutto, poiché la soluzione $y(t)$ è una funzione di classe $\mathcal{C}^2$, per il teorema di Weierstrass esiste
\[
C_2 = \max_{t\in [a,b]} \abs{y''(t)}.
\]
Andiamo quindi a enunciare il nostro risultato di convergenza.
    
Siamo interessati a stimare la quantità $e_n = \abs{y_n - y(t_n)}$ per ogni $n=0,1,\dots,N$. Chiaramente $e_0 = \abs{y_0 - y(t_0)} = 0$. Possiamo scrivere
\begin{align*}
y_{n+1} &= y_n + h f(t_n, y_n),\\
y(t_{n+1}) &= y(t_n) + h \underbrace{y'(t_n)}_{=f(t_n,y(t_n))} + \frac{h^2}{2} y''(\xi),
\end{align*}
dove la seconda equazione è uno sviluppo di Taylor. Sottraendo membro a membro e prendendo valori assoluti abbiamo
\begin{align*}
    e_{n+1} &= \abs*{y_{n+1} - y(t_{n+1})} = \abs*{y_n - y(t_n) + h(f(t_n,y_n) - f(t_n,y(t_n))) - \frac{h^2}{2} y''(\xi)}\\
            & \leq \abs*{y_n - y(t_n)} + h \abs*{f(t_n,y_n) - f(t_n,y(t_n))} + \frac{h^2}{2} \abs*{y''(\xi)}\\
            & \leq e_n + hL e_n + \frac{h^2}{2}C_2 = (1+hL) e_n + \frac{h^2}{2}C_2.
\end{align*}
Poniamo $M = \frac{h^2}{2}C_2$; iterando, abbiamo
\begin{align*}
    e_n &\leq M + (1+hL)e_{n-1} \\&\leq M + (1+hL)M + (1+hL)^2e_{n-2}\\ &\leq M + (1+hL)M + (1+hL)^2M + (1+hL)^3 e_{n-3}\\
    & \leq \dots\\\
    & \leq M\left(1 + (1+hL) + (1+hL)^2 + \dots + (1+hL)^{n-1}\right)    + (1+hL)^n \underbrace{e_0}_{=0}\\
    & = M\frac{(1+hL)^n-1}{(1+hL)-1}\\
    & = \frac{M}{hL}\left(\left(1+\frac{t_n-t_0}{n}L\right)^n-1\right);
\end{align*}
l'ultima uguaglianza segue dal fatto che $t_n - t_0 = nh$. 

Quando nei corsi di analisi avete studiato il limite notevole
\[
    \lim_{n\to\infty} \left(1+\frac{x}{n}\right)^n = e^x,
\]
probabilmente avete dimostrato che questa convergenza avviene in modo crescente, cioè, per ogni $n$ si ha $\left(1+\frac{x}{n}\right)^n \leq e^x$. Quindi per questa disuguaglianza abbiamo
\[
\left(1+\frac{t_n-t_0}{n}L\right)^n \leq e^{(t_n-t_0)L}.
\]
Quindi rimettendo tutto insieme abbiamo per ogni $n=1,2,\dots,N$
\[
e_n \leq \frac{C_2 h}{2L}(e^{(t_n-t_0)L}-1) \leq \frac{C_2 h}{2L}(e^{(b-a)L}-1) = \mathcal{O}(h). \qedhere
\]

\end{proof}

\paragraph{Metodi generali a un passo}

In generale possiamo scrivere un metodo a un passo come
\begin{equation} \label{metodoaunpasso}
    \y_{n+1} = \y_n + h\Phi(t_n,\y_n)    
\end{equation}
per un'opportuna funzione $\Phi$: anche se nella sua espressione compaiono $t_{n+1},\y_{n+1}$, ecc., possiamo comunque considerarla come una funzione di quei soli due argomenti, perché il valore $\y_{n+1}$ si può calcolare a partire dai soli $t_n$ e $\y_n$ (conoscendo il valore di $h$ e l'espressione per $\f$); non serve conoscere altre quantità come per esempio il valore di $\y_{n-1}$.

Vogliamo dare un risultato generale di convergenza per questi metodi. Per questo ci serve introdurre alcune definizioni. Innanzitutto, diciamo che un metodo è \emph{convergente di ordine $p$} (per un qualche $p>0$) se $E_N = \mathcal{O}(h^p)$; quindi per esempio più sopra abbiamo dimostrato che il metodo di Eulero esplicito è convergente di ordine $1$.

Oltre all'errore globale $E_N$ definito più sopra, definiamo anche l'\emph{errore locale di troncamento} come
\[
T_N = \max_{n=0,1,\dots,N-1} \norm{\boldsymbol{\tau}_n}, \quad \boldsymbol{\tau}_n = \y(t_{n+1}) - \y(t_n) - h\Phi(t_n, \y(t_n)) ,
\]
cioè la differenza tra il valore esatto della soluzione $\y(t_{n+1})$ e il valore $\y(t_n) + h\Phi(t_n, \y(t_n))$ calcolato tramite un passo dell'algoritmo a partire dal valore esatto $\y(t_n)$. Anche questa è una quantità che compariva nella nostra dimostrazione.

Un metodo si dice \emph{consistente di ordine $p$} se $T_N = \mathcal{O}(h^{p+1})$ nel limite quando il numero di passi tende a $N\to \infty$ (e quindi $h \to 0$). La logica dietro a questa definizione è la stessa dietro a quella delle formule per l'errore nelle formule di integrazione: visto che stiamo considerando un intervallo di lunghezza $h$, diciamo che l'ordine del metodo è $p$ se la distanza tra $\y(t_{n+1})$ e $\y(t_n) - h\Phi(t_n, \y(t_n))$ si scrive nella forma $h \cdot \mathcal{O}(h^p)$.

Queste definizioni si applicano quando abbiamo un'equazione differenziale con soluzione $\y(t)$ sufficientemente regolare; per esempio, ci serve avere una funzione di classe almeno $\mathcal{C}^2$ per scrivere la~\eqref{euleroesp_taylor}.

Il metodo di Eulero esplicito è consistente di ordine $1$; difatti abbiamo ottenuto
\[
\y(t_{n+1}) = \y(t_n) + \y'(t_n)h + \mathcal{O}(h^2),
\]
quindi
\[
\norm*{\y(t_{n+1}) - \y(t_n) - h \f(t_n, \y(t_n))} = \mathcal{O}(h^2) = h \cdot \mathcal{O}(h^1).
\]
Stessa cosa per il metodo di Eulero implicito. Invece il metodo dei trapezi è consistente di ordine $2$.

\paragraph{Convergenza dei metodi a un passo}
Vale il seguente risultato. Non lo dimostriamo, ma la dimostrazione è simile a quella che abbiamo visto sopra per il metodo di Eulero esplicito e $m=1$.
\begin{theorem}
Supponiamo di avere un metodo a un passo in cui la funzione $\Phi(t,\y)$ sia continua in $[a,b] \times \mathbb{R}^m$ e Lipschitziana nella $\y$, con una costante $L$ che non dipende da $h$.
Allora, un metodo è convergente di ordine~$p$ se e solo se è consistente di ordine~$p$.
\end{theorem}


\paragraph{Metodi di Runge--Kutta} I metodi di Runge--Kutta sono una classe più generale di metodi a un passo (quindi definiti da una $\Phi(t_n,\y_n)$ come nella~\eqref{metodoaunpasso}). Avendo una maggiore quantità di parametri, essi possono raggiungere ordini di consistenza e convergenza maggiori. Un metodo di Runge--Kutta si definisce tramite parametri che vengono convenzionalmente raccolti in una tabella, detta \emph{tavola} (o \emph{tableau}) \emph{di Butcher}:
\[
\begin{array}{c|cccc}
c_1 & a_{11} & a_{12} & \dots & a_{1s}\\
c_2 & a_{21} & a_{22} & \dots & a_{2s}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
c_s & a_{s1} & a_{s2} & \dots & a_{ss}\\
\hline
& b_1 & b_2 & \dots & b_s
\end{array}.
\]
L'intero $s$ è detto \emph{numero di stadi} del metodo. A partire dai coefficienti in questa tabella possiamo definire la funzione $\Phi(t_n,y_n)$ in questo modo: definiamo
\begin{align*}
    \mathbf{k}_i &= \mathbf{f}\left(t_n + c_i h, \y_n + h\left(\sum_{j=1}^s a_{ij}\mathbf{k}_j\right)\right), & i&=1,2,\dots,s,\\
    \Phi(t_n, \mathbf{y}_n) &= \sum_{j=1}^s b_j \mathbf{k}_j.
\end{align*}
La funzione $\Phi(t_n, \mathbf{y}_n)$ definita in questo modo è quella che compare nella definizione di metodo a un passo~\eqref{metodoaunpasso}.

I metodi che abbiamo visto finora sono casi particolari dei metodi di Runge--Kutta. Per il metodo di Eulero esplicito abbiamo $s=1$ e tavola di Butcher
\[
\begin{array}{c|c}
0 & 0\\
\hline
 & 1
\end{array},
\]
per il metodo di Eulero implicito
\[
\begin{array}{c|c}
1 & 1\\
\hline
 & 1
\end{array},
\]
e per il metodo dei trapezi $s=2$ (difatti ci sono due diverse valutazioni di funzione) e 
\[
\begin{array}{c|cc}
0 & 0 & 0\\
1 & \frac12 & \frac12\\
\hline
& \frac12 & \frac12
\end{array}.
\]
Per derivare le tavole degli ultimi due metodi abbiamo dovuto risostituire la relazione finale per scrivere il termine $\y_{n+1}$ che compare dentro $\mathbf{f}_{n+1}$ nella forma $\y_n + h(\dots)$.

Un metodo di Runge--Kutta è \emph{esplicito} se nella tavola di Butcher la matrice
\[
    A = \begin{bmatrix}
        a_{11} & \dots & a_{1s}\\
        \vdots & \ddots & \ddots\\
        a_{s1} & \dots & a_{ss}
    \end{bmatrix}
\]
è strettamente triangolare superiore, cioè $a_{ij}=0$ se $i \leq j$ (inclusi gli elementi sulla diagonale). In questo caso è possibile calcolare esplicitamente i valori di $\mathbf{k}_i$ uno per volta a partire dal primo. Altrimenti abbiamo un metodo \emph{implicito}: è necessario risolvere un sistema di equazioni non-lineari per calcolare i $\mathbf{k}_i$, analogamente a quello che succede nel metodo di Eulero implicito.

Nella pratica, questi metodi sono usati con scelte particolari dei coefficienti fatte in modo da ottenere un alto ordine di consistenza (e quindi di convergenza). Per esempio Matlab utilizza in una delle sue funzioni per risolvere equazioni differenziali (\lstinline{ode45}) un metodo con tavola di Butcher
\[
\begin{array}{c|ccccccc}
    0\\
    1/5 &    1/5\\
    3/10 &   3/40 &   9/40\\
    4/5 &    44/45 &  -56/15 &  32/9\\
    8/9   &  19372/6561 & -25360/2187  &   64448/6561 & -212/729\\
    1 &  9017/3168  & -355/33   &  46732/5247 & 49/176 & -5103/18656\\
    1 &  35/384 & 0 &  500/1113  &  125/192   &  -2187/6784 & 11/84   \\
    \hline
    &  35/384 & 0 &  500/1113  &  125/192   &  -2187/6784 & 11/84 & 0  \\
%    & \frac{5179}{57600} & 0 & \frac{7571}{16695} & \frac{393}{640} & -\frac{92097}{339200} & \frac{187}{2100} & \frac{1}{40}
\end{array},
\]
che ha $s=7$ stadi e ordine di convergenza $p=5$ (\emph{metodo di Dormand--Prince}).

Esistono molte altre possibili scelte dei coefficienti; si veda per esempio \href{https://en.wikipedia.org/wiki/List_of_Runge%E2%80%93Kutta_methods}{questa lista} su Wikipedia.

\paragraph{Problemi stiff}

Il risultato di convergenza che abbiamo visto ci dice cosa succede al limite $h \to 0$; però ci sono differenze importanti tra un metodo e l'altro che riguardano quello che succede con un valore \emph{finito} di $h$. In particolare, non è difficile osservare in esperimenti numerici che prendendo $h$ troppo grande il metodo di Eulero esplicito produce sequenze $\y_n$ oscillanti anche quando la soluzione vera converge a zero in modo monotono.

Un modo per investigare cosa succede è attraverso il ``problema test'', \eqref{testproblem}. Prendiamo un problema test con $\lambda < 0$; la soluzione esatta $y(t) = e^{\lambda t}$ quindi è decrescente e ha $\lim_{t\to+\infty} y(t) = 0$. Applicando il metodo di Eulero esplicito a questo problema, come abbiamo già visto, otteniamo $y_n = (1+h\lambda)^n$. Se $\lambda < -\frac{2}{h}$, abbiamo $\abs{1+h\lambda} > 1$, quindi il metodo produce iterate $y_n$ che diventano sempre più grandi in valore assoluto, e magari oscillano con segni alterni. Questo succede quando scegliamo un passo $h$ troppo grande, e la limitazione esatta dipende dal valore di $\lambda$: più grande è $\lambda$, più piccolo dev'essere $h$. Notiamo però anche che se $\lambda$ è negativo e molto grande la funzione $y(t) = e^{\lambda t}$ tende a zero molto rapidamente. Potremmo quindi pensare che la ``scala'' di $h$ sia dettata dal grafico della funzione, in un qualche senso.

Le cose però si complicano per problemi in più variabili, in cui possono comparire contemporaneamente valori diversi di $\lambda$; per esempio pensiamo al problema
\[
\underbrace{
\begin{bmatrix}
    u'(t)\\
    v'(t)\\
    w'(t)
\end{bmatrix}}_{\y'(t)} = \begin{bmatrix}
    \lambda_1 u(t)\\
    \lambda_2 v(t)\\
    \lambda_3 w(t)
\end{bmatrix} = \begin{bmatrix}
    \lambda_1 \\ 
    & \lambda_2\\
    && \lambda_3
\end{bmatrix} \underbrace{\begin{bmatrix}
    u(t)\\ v(t)\\ w(t)
\end{bmatrix}}_{\y(t)},
\]
con $\lambda_1 < \lambda_2 < \lambda_3 < 0$: la norma $\norm{\y(t)}$ tende a zero come l'esponente più vicino a zero $e^{\lambda_3 t}$, ma il passo massimo che possiamo scegliere dipende dall'esponente più lontano da zero $\lambda_1$. Quindi per approssimare la soluzione con il metodo di Eulero esplicito dobbiamo scegliere per un passo molto piccolo rispetto alla scala del problema.

Le cose diventano ancora più complicate per problemi non lineari; spesso non è possibile fare un'analisi esatta e possiamo solo confrontare il comportamento con quello di problemi lineari dal comportamento simile. In generale, esistono problemi per cui il metodo di Eulero (e con lui molti altri metodi) presenta oscillazioni eccessive a meno che la scelta del passo sia estremamente piccola; questi si chiamano \emph{problemi stiff}, o in italiano \emph{rigidi}. Una definizione precisa è complicata; in generale questo fenomeno è associato a:
\begin{itemize}
    \item componenti della soluzione $\y$ che hanno improvvisi cambiamenti;
    \item fenomeni che avvengono a diverse scale di tempi;
    \item funzioni del tipo $\mathbf{f}(t,\y)=A\y$ con $A$ mal condizionata, o funzioni non lineari $\mathbf{f}(t,\y)$ con Jacobiano $\frac{\partial \mathbf{f}}{\partial \mathbf{y}}$ mal condizionato.
\end{itemize}
A differenza del mal condizionamento di sistemi lineari, non è un fenomeno che riusciamo a quantificare esattamente e misurare con un numero.

In ogni caso, alcuni metodi sono più adatti ai problemi \emph{stiff} del metodo di Eulero; tipicamente si tratta dei metodi impliciti. Facciamo un'analisi di stabilità più generale per stabilirlo.

\paragraph{Funzione di stabilità e A-stabilità}

Possiamo replicare l'analisi fatta per il metodo di Eulero e applicarla a un metodo di Runge--Kutta generico. Scrivendo esplicitamente un qualunque metodo di Runge--Kutta per il problema test~\eqref{testproblem}, si può vedere che questo assume sempre la forma
\[
y_{n+1} = R(q)y_n, \quad q = h\lambda.
\]
Per esempio, per il metodo dei trapezi abbiamo
\[
y_{n+1} = y_n + h \frac12(\lambda y_n + \lambda y_{n+1}) \iff y_{n+1} = \underbrace{\frac{1+\frac12 q}{1-\frac12q}}_{=:R(q)}y_n
\]
Ogni volta che $\lambda$ è un numero complesso con $\operatorname{Re}(\lambda) < 0$, abbiamo $\lim_{t\to\infty} y(t) = 0$. Ci chiediamo quindi quando la successione generata $y_n$ ha lo stesso comportamento al limite, $\lim_{n\to\infty} y_n = 0$.

La successione $y_n = R(q)^n y_0$ converge a zero se e solo se $\abs{R(q)} < 1$. Si definisce \emph{regione di (assoluta) stabilità} del metodo l'insieme $S_A = \{z \in \mathbb{C} : \abs{R(z)}<1\}$. Quindi $y_n$ converge a zero (per il problema test) se e solo se $h$ è scelto in modo che $h\lambda \in S_A$. La soluzione esatta del problema test $y(t) = e^{\lambda t}$ invece converge a zero se (e solo se) $\lambda$ sta nel semipiano sinistro. Questo motiva una definizione: un metodo di Runge--Kutta si dice \emph{A-stabile} se la sua regione di stabilità contiene tutto il semipiano sinistro $\{z\in \mathbb{C} : \operatorname{Re}(z) < 0\}$. Esistono diverse varianti di questa definizione: per esempio un metodo si dice \emph{$A_0$-stabile} se la regione di stabilità contiene la semiretta reale negativa $\{z\in\mathbb{R}: z<0\}$; imparare tutti i loro nomi non è importante.

Per il metodo di Eulero esplicito, $R(q)= 1+q$; quindi la regione di stabilità $\{q\in\mathbb{C} \colon \abs{1+q}<1\}$ è un cerchio di centro $-1$ e raggio $1$. Essa \emph{non} contiene tutto il semipiano sinistro, e difatti già abbiamo visto che questo metodo non è $A$-stabile.
\begin{figure}
    \begin{tikzpicture}
        \draw[thick,->] (-2,0) -- (2,0);
        \draw[thick,->] (0,-2) -- (0,2);
        \draw[red, fill=red, opacity=0.5] (-1,0) circle (1);
    \end{tikzpicture}
    \begin{tikzpicture}[even odd rule]
        \draw[thick,->] (-2,0) -- (2,0);
        \draw[thick,->] (0,-2) -- (0,2);
        \draw[red, fill=red, opacity=0.5] (-2,-2) rectangle (2,2) (1,0) circle (1);
    \end{tikzpicture}
    \begin{tikzpicture}
        \draw[thick,->] (-2,0) -- (2,0);
        \draw[thick,->] (0,-2) -- (0,2);
        \draw[red, fill=red, opacity=0.5] (-2,-2) rectangle (0,2);
    \end{tikzpicture}
    \caption{Regioni di stabilità del metodo di Eulero esplicito, Eulero implicito, e dei trapezi.}
\end{figure}

La regione di stabilità del metodo dei trapezi è precisamente il semipiano sinistro; possiamo dimostrarlo con un ragionamento geometrico. Si ha
\[
\abs{R(q)} = \frac{\abs{1+\frac12q}}{\abs{1-\frac12q}} = \frac{d(-1,\frac12q)}{d(1,\frac12q)},
\]
e questo è il rapporto tra le distanze del punto $\frac12q$ da $1$ e da $-1$. Se $q$ sta nel semipiano sinistro, allora è più vicino a $-1$ che a $1$, e quindi il rapporto è minore di $1$.


Potete calcolare come esercizio la regione di stabilità del metodo di Eulero implicito, e verificare che essa è l'\emph{esterno} di un cerchio di centro $1$ e raggio $1$; in particolare anche questo metodo è A-stabile. Anzi, è anche ``troppo stabile'', visto che $y_n$ converge a zero anche in casi in cui $\lambda$ sta nel semipiano destro e quindi $y(t) = e^{\lambda t}$ dovrebbe tendere a infinito per $t\to+\infty$. La definizione che abbiamo dato non cattura questo problema però.

Il risultato principale (che non dimostriamo) è il seguente:
\begin{theorem}
Nessun metodo di Runge--Kutta esplicito è $A$-stabile.
\end{theorem}
Quindi in presenza di un problema stiff è solitamente meglio usare un metodo implicito; altrimenti il metodo potrebbe richiedere un passo $h$ molto piccolo per fornire risultati non oscillanti. Questo giustifica l'utilità dei metodi impliciti, che utilizzano un metodo più complicato per calcolare $\y_{n+1}$ ad ogni passo rispetto a quelli espliciti.

\section{Metodi a più passi}

Vediamo ora un'altra famiglia di metodi, i \emph{metodi a più passi} (o \emph{multistep} in inglese). In particolare ci concentriamo sui \emph{metodi lineari a più passi}.

L'idea è la seguente: i metodi di Runge--Kutta ci consentono di ottenere metodi con alto ordine di convergenza, ma al costo di avere $s>1$ valutazioni della $\mathbf{f}$ all'interno di ogni passo $n$. Possiamo però ottenere ordini più alti a costo computazionale minore con un'altra strategia: quella di riutilizzare anche i valori precedenti già calcolati di $\y_{n-1}, \y_{n-2}, \dots$ e $\f_{n-1},\f_{n-2},\dots$ per ottenere una migliore approssimazione. Per esempio, il metodo
\begin{equation} \label{ab2}
    \y_{n+2} = \y_{n+1} + h\left(\frac32 \f_{n+1} - \frac12 \f_n\right)    
\end{equation}
è tale che $\y(t_{n+2}) - \y_{n+2} = h\mathcal{O}(h^2)$ (ordine $p=2$), se $\y_{n+1}$ e $\y_n$ sono approssimazioni sufficientemente accurate di $\y(t_{n+1})$ e $\y(t_n)$ \footnote{Una dimostrazione sta su \url{https://en.wikiversity.org/wiki/Adams-Bashforth_and_Adams-Moulton_methods}. L'idea è usare uno sviluppo di Taylor di $\y'(t)$ in $t_{n+1}$ per scrivere $\f_n$, e uno sviluppo di Taylor di ordine 2 in $t_{n+1}$ per scrivere $\y(t_{n+2})$.}. Se supponiamo di avere a disposizione \emph{due} valori iniziali $\y_0, \y_1$, anziché uno solo, possiamo usare la~\eqref{ab2} per $n=0,1,2,\dots$ per calcolare tutti i valori successivi con un errore locale di troncamento migliore del metodo di Eulero (ordine 2 anziché 1), mantenendone comunque il costo di una sola nuova valutazione della $\f$ per passo.

In generale, definiamo un \emph{metodo lineare a $k$ passi} con una formula del tipo
\begin{equation} \label{linearmultistep}
    \sum_{j=0}^k \alpha_j \y_{n+j} = h\sum_{j=0}^k \beta_j \f_{n+j}, \quad n=0,1,2,\dots,    
\end{equation}
dove abbiamo posto $\f_i := \f(t_i, \y_i)$ come già fatto in passato, per un'opportuna scelta delle costanti reali $\alpha_i, \beta_i$. Per evitare casi degeneri, supponiamo che $\alpha_0,\beta_0$ non siano entrambi nulli, così come $\alpha_k$ e $\beta_k$. Se $\beta_k=0$, allora possiamo calcolare esplicitamente $\y_{n+k}$, e il metodo si dice \emph{esplicito}; altrimenti il metodo si dice \emph{implicito} e abbiamo bisogno di un algoritmo per risolvere l'equazione~\eqref{linearmultistep} ad ogni passo $n$.

\paragraph{Scelta dei valori iniziali} Per poter applicare il metodo~\eqref{linearmultistep}, abbiamo bisogno di opportuni valori iniziali $\y_1,\y_2,\dots, \y_{k-1}$, in aggiunta a $\y_0$. Questi non sono tra i dati iniziali del problema, quindi vanno calcolati in qualche modo. Solitamente si utilizza un metodo a un passo per calcolarli; quindi ogni metodo a più passi ha bisogno di essere ``inizializzato'' calcolando questi primi valori tramite un opportuno metodo a un passo.

Perché il metodo possa convergere alla soluzione esatta, è necessario imporre una condizione su come questi valori iniziali vengono scelti. Visto che $h\to 0$ al crescere del numero di intervalli, anche $t_1,t_2,\dots,t_{k-1} \to t_0$, e quindi $\y(t_1),\dots,\y(t_k) \to \y_0$. Diciamo che un modo di scegliere i dati iniziali $\y_1,\y_2,\dots,\y_{k-1}$ in un metodo a più passi è \emph{compatibile} se soddisfa 
\[
\lim_{N\to\infty} \y_i = \y_0, \quad i=1,2,\dots,k-1.
\]

\paragraph{Famiglie di metodi} Ci sono diverse famiglie di metodi lineari a più passi: tra queste i \emph{metodi di Adams--Bashforth} (tra cui ricade anche il nostro primo esempio~\eqref{ab2}), espliciti, e i \emph{metodi di Adams--Moulton} e le \emph{Backward differentiation formulas (BDF)}, entrambi impliciti. Per esempio, i primi metodi della famiglia BDF sono
\begin{align*}
\y_{n+1} - \y_n &= h\f_{n+1}, & \text{(Eulero implicito)}\\
\y_{n+2} - \frac43 \y_{n+1} + \frac13 \y_n &= \frac23 h\f_{n+2},\\
\y_{n+3} - \frac{18}{11}\y_{n+2} + \frac{9}{11}\y_{n+1} - \frac{2}{11}\y_n &= \frac{6}{11}h \f_{n+3},
\end{align*}
e i successivi sono fatti in modo simile, con un solo valore $\beta_k\neq 0$ a destra dell'uguale e opportune combinazioni lineari delle $\y_{n+j}$ a sinistra.

In tutti questi, i valori numerici dei coefficienti sono scelti in modo da assicurare l'ordine di convergenza $p$ il più alto possibile.

Per altri metodi, potete vedere per esempio \url{https://en.wikipedia.org/wiki/Linear_multistep_method} e \url{https://en.wikipedia.org/wiki/Backward_differentiation_formula}.

\paragraph{Consistenza e convergenza}

Come nei metodi a un passo, definiamo l'\emph{errore locale di troncamento}
\[
\boldsymbol{\tau}_n = \sum_{j=0}^k \alpha_j \y(t_{n+j}) - h\sum_{j=0}^k \beta_j \f(t_{n+j}, \y(t_{n+j})).
\]
Questa quantità a volte viene normalizzata diversamente dividendola per $\alpha_k$, o per la somma dei $\beta_j$. in ogni caso, $\boldsymbol{\tau}_n$ misura di quanto $\y(t_{n+k})$ differisce dalla quantità $\y_{n+k}$ calcolata dal metodo assumendo che tutti i passi precedenti siano esatti. Come nel caso dei metodi a un passo, un metodo si dice \emph{consistente di ordine $p$} se $T = \max_{n} \norm{\boldsymbol{\tau}_n}$ è $\mathcal{O}(h^{p+1})$.

Analogamente, un metodo si dice \emph{convergente di ordine $p$} se l'errore globale~\eqref{globalerror} (definito esattamente come nei metodi a un passo) è $\mathcal{O}(h^p)$.

Possiamo dimostrare che (sotto opportune ipotesi) questi due concetti sono equivalenti, proprio come nei metodi a un passo.

Ci serve però prima introdurre uno strumento tecnico che permette di studiare le successioni prodotte dal metodo.

\paragraph{Equazioni alle differenze}

Consideriamo innanzitutto cosa succede applicando il metodo a più passi al problema (scalare, $m=1$) $y'=0$, con condizioni iniziali $y_0,y_1,\dots,y_{k-1}$ qualunque. La successione delle $y_i$ allora soddisfa la relazione
\begin{equation} \label{ricorrenza}
    \alpha_0 y_n + \alpha_1 y_{n+1} + \dots + \alpha_k y_{n+k} = 0, \quad n = 0,1,2,\dots.
\end{equation}
Relazioni della forma~\eqref{ricorrenza} si chiamano \emph{equazioni alle differenze (lineari a coefficienti costanti)}; sono una sorta di analogo discreto delle equazioni differenziali lineari a coefficienti costanti. Forse l'esempio più celebre di una successione di questo tipo è quello dei numeri di Fibonacci, che soddisfano la relazione
\[
y_n + y_{n+1} - y_{n+2} = 0.
\]
Esiste una teoria per calcolare le soluzioni delle~\eqref{ricorrenza} che è molto simile a quella per calcolare le soluzioni delle equazioni differenziali lineari a coefficienti costanti. Enunciamo cosa succede, per semplicità limitandoci al caso scalare $(m=1)$.

\begin{theorem}
Data l'equazione alle differenze~\eqref{ricorrenza}, definiamo
\[
p_1(z) = \alpha_0 + \alpha_1 z + \dots + \alpha_k z^k
\]
il suo polinomio associato. 
\begin{itemize}
    \item Se $p_1(z)$ ha $k$ zeri distinti nel piano complesso $\lambda_1, \lambda_2,\dots, \lambda_k$, allora ogni soluzione della~\eqref{ricorrenza} si scrive come combinazione lineare delle soluzioni di base $\lambda_1^n, \lambda_2^n, \dots, \lambda_k^n$.
    \item Per ogni zero $\lambda$ di $p_1(z)$ ripetuto con molteplicità $m>1$, come soluzioni di base invece di prendere $k$ copie di $\lambda$ dobbiamo prendere $\lambda^n, n\lambda^n, n^2\lambda^n,\dots, n^{m-1}\lambda^n$.
\end{itemize}
\end{theorem}

\paragraph{Esempi}
\begin{itemize}
    \item Quali sono le successioni tali che $y_{n+1} = \frac{1}{2}y_n$? Questa formula si può riscrivere come $y_{n+1}-\frac{1}{2}y_n=0$, e ha polinomio caratteristico $z-\frac{1}{2}$, con un solo zero $\lambda=\frac{1}{2}$. le sue soluzioni sono del tipo $y_n = C \frac{1}{2}^n$. Se ci viene dato un valore iniziale, per esempio $y_0=1$, possiamo determinare il valore corrispondente di $C$ (in questo caso $C=1$), esattamente come avete visto nel corso di analisi per le equazioni differenziali lineari a coefficienti costanti.
    \item Quali sono le successioni tali che $y_{n+2} - y_{n+1} = y_{n+1}-y_n$? La successione ha come polinomio caratteristico $z^2-2z+1$, che ha uno zero doppio $\lambda=1$. Le soluzioni sono le successioni del tipo $y_n = C_1 1^n + C_2 n 1^n = C_1 + C_2 n$, cioè tutte le funzioni lineari affini.
    \item Quali sono le successioni tali che $y_{n+2} = y_n + y_{n+1}$? Sono tutte le successioni del tipo
    \[
        y_n = C_1 \left(\frac{1+\sqrt{5}}{2}\right)^n + C_2 \left(\frac{1-\sqrt{5}}{2}\right)^n.
    \]
    Una di esse è la famosa \emph{sequenza di Fibonacci}, che è ottenuta prendendo come valori iniziali $y_0 = 0$, $y_1=1$.
\end{itemize}
In particolare, vale il seguente risultato.
\begin{theorem} \label{thm:eq-differenze} Per un'equazione alle differenze~\eqref{ricorrenza}:
\begin{itemize}
    \item Se (e solo se) tutti gli zeri del polinomio $p_1(z)$ hanno valore assoluto strettamente minore di $1$, allora per ogni scelta dei valori iniziali $y_0, y_1,\dots, y_{k-1}$ la soluzione della~\eqref{ricorrenza} tende a zero quando $n\to\infty$.
    \item Se (e solo se) tutti gli zeri del polinomio $p_1(z)$ hanno valore assoluto minore o uguale a $1$, e in più tutte le radici di modulo $1$ sono semplici (molteplicità $=1$), allora per ogni scelta dei valori iniziali $y_0, y_1,\dots, y_{k-1}$ la soluzione della~\eqref{ricorrenza} è limitata, cioè $\sup_{n\in\mathbb{N}} \abs{y_n}$ è finito.
\end{itemize}
\end{theorem}
La seconda di queste condizioni si chiama \emph{condizione delle radici} (root condition).

\paragraph{Zero-stabilità}
Quando gli $\alpha_i$ sono i coefficienti di un metodo a più passi~\eqref{linearmultistep}, il polinomio caratteristico $p_1(z)$ definito sopra si chiama \emph{primo polinomio caratteristico} del metodo.

Un metodo lineare a più passi si dice \emph{zero-stabile} se il suo primo polinomio caratteristico $p_1(z)$ soddisfa la condizione delle radici; questo in particolare implica che le successioni che genera per la soluzione del problema $y'=0$ sono sempre limitate (uniformemente in $n$), indipendentemente dalla scelta dei valori iniziali. Questo è quello che ci aspettiamo se il metodo deve ``funzionare bene'' su questa equazione, visto che tutte le soluzioni di $y'=0$ sono costanti (e quindi limitate).

\paragraph{Esempio} Consideriamo il metodo~\eqref{ab2}. Il primo polinomio caratteristico è $z^2-z$; difatti, $\alpha_2=1, \alpha_1=-1, \alpha_0 = 0$. Questo polinomio ha zeri $\lambda=1$ e $\lambda=0$. In particoalre, esso soddisfa la condizione delle radici, quindi il metodo è zero-stabile.

Notiamo che $\alpha = 1$ è sempre una radice del primo polinomio caratteristico, per ogni metodo consistente: altrimenti è impossibile che si abbia $\boldsymbol{\tau}_n \to \mathbf{0}$, già solo considerando il problema $y'=0$.

La zero-stabilità sembra un concetto di poco rilievo, visto che ci concentriamo su un problema molto facile e di poco interesse; in realtà ha una conseguenza importante, perché ci assicura che eventuali piccoli errori nei dati iniziali $\y_1,\dots,\y_{k-1}$ non causano errori più consistenti sulle iterate successive.

\paragraph{Teorema di equivalenza di Dahlquist}
Possiamo ora enunciare un teorema di convergenza per i metodi a più passi.
\begin{theorem}
Consideriamo un metodo lineare a più passi~\eqref{linearmultistep}, con una scelta compatibile dei dati iniziali. Se il metodo è zero-stabile e consistente, allora è convergente. Inoltre, su un problema con soluzione $\y \in \mathcal{C}^{p+1}([a,b])$, se un metodo è consistente di ordine $p$ allora è anche convergente di ordine $p$.
\end{theorem}
La dimostrazione è complicata, quindi ci accontentiamo dell'enunciato.

Le famiglie di metodi che vengono usate in pratica sono tutte zero-stabili.

\paragraph{A-stabilità}

Come nel caso dei metodi a un passo, la sola convergenza non ci dice nulla riguardo al passo $h$ che serve per avere un'approssimazione accettabile della soluzione. Possiamo quindi studiare la A-stabilità dei metodi a più passi, esattamente nello stesso modo in cui abbiamo affrontato quelli a un passo; questo ci dà informazioni su quali metodi sono adatti per problemi stiff.

Applicando il metodo~\eqref{linearmultistep} al problema test~\eqref{testproblem}, otteniamo
\begin{equation} \label{multistep-test}
    \sum_{j=0}^k (\alpha_j - \underbrace{\lambda h}_{:=q} \beta_j) y_{n+j} = 0.    
\end{equation}
Analogamente a quanto richiesto per i metodi a un passo, vogliamo vedere per quali valori di $q$ le successioni generate dal metodo tendono a zero, in modo da replicare il comportamento della soluzione esatta $y(t) = e^{\lambda t}$ quando $\operatorname{Re}(\lambda) < 0$.

Fissato il valore di $q$, la~\eqref{multistep-test} è un'equazione alle differenze. Quindi, per il Teorema~\ref{thm:eq-differenze}, la successione generata converge a zero (per ogni scelta dei valori iniziali) quando tutte le radici del polinomio associato
\[
\pi_q(z) = \sum_{j=0}^k (\alpha_j - q\beta_j) z^j
\]
hanno modulo \emph{strettamente} minore di $1$. Il polinomio $\pi_q(z)$ (che dipende dal valore di $q$, che supponiamo fissato) si chiama \emph{polinomio di stabilità}; possiamo scriverlo come
\[
\pi_q(z) = p_1(z) - q p_2(z)
\]
in termini del primo polinomio caratteristico (che già abbiamo incontrato) e del \emph{secondo polinomio caratteristico}
\[
p_2(z) = \beta_0 + \beta_1 z + \dots + \beta_k z^k.
\]
Si dice \emph{regione di (assoluta) stabilità} di un metodo a più passi l'insieme
\[
  S_A = \{q \in \mathbb{C} \colon \text{tutte le radici del polinomio $\pi_q(z)$ hanno modulo minore di $1$}\}.
\]
Un metodo a più passi si dice \emph{A-stabile} se $S_A$ contiene tutto il semipiano sinistro. 

\paragraph{Esempio} Consideriamo di nuovo il problema~\eqref{ab2}. Il suo polinomio di stabilità è 
\[
    \pi_q(z) = (z^2 -z) - q\left(\frac{3}{2}z - \frac{1}{2}\right) = z^2 - \left(1+\frac32 q\right) z + \frac12 q.
\]
Possiamo calcolare le sue soluzioni (in funzione di $q$), ma la formula ottenuta non è particolarmente illuminante. È più interessante vedere cosa succede per qualche valore di $q$ fissato. Per $q=-1$, il polinomio diventa $\pi_{-1}(z) = z^2 - \frac12 q - \frac12$, che ha zeri $\lambda=-1$ e $\lambda=1/2$. Queste soluzioni \emph{non} sono entrambe minori di $1$, quindi $q=-1$ non appartiene alla regione di stabilità del metodo. (In particolare, questo ci dice anche che il metodo \emph{non} è A-stabile).

\paragraph{Barriere di Dahlquist} Anche in questo caso la A-stabilità è una condizione abbastanza stringente, che in particolare esclude tutti i metodi espliciti. Questo è dimostrato in teorema che contiene una serie di risultati noti come ``barriere di Dahlquist''.
\begin{theorem} Valgono i seguenti risultati.
\begin{itemize}
    \item Non esistono metodi lineari a più passi \emph{espliciti} A-stabili.
    \item I metodi lineari a più passi \emph{impliciti} A-stabili hanno ordine $p \leq 2$.
    \item Tra i metodi lineari a più passi A-stabili impliciti di ordine $p=2$, quello per cui l'errore converge a zero più velocemente è il metodo dei trapezi.
\end{itemize}
\end{theorem}
Quindi nessun metodo lineare a più passi A-stabile migliora in termini di accuratezza il metodo dei trapezi (che in realtà è a un passo, $k=1$). Una famiglia di metodi (quelli BDF) in realtà si avvicina molto ad essere A-stabile, visto che le loro regioni di stabilità includono tutto il semipiano negativo tranne una regione molto piccola\footnote{Queste regioni di stabilità sono raffigurate per esempio su~\url{https://en.wikipedia.org/wiki/Backward_differentiation_formula}}. Questi metodi sono tra quelli più usati per problemi stiff.

\section{Solutori di equazioni differenziali in Matlab}

Nel laboratorio abbiamo implementato noi da soli alcuni metodi numerici, ma Matlab contiene già al suo interno diverse funzioni che possono essere usate per risolvere numericamente problemi ai valori iniziali~\eqref{cauchy}. La più usata è \lstinline{function [T, Y] = } \lstinline{ode45(f, [a,b], y0)}. Essa prende in input una \emph{function handle} alla funzione $\f(t,\y)$ (che dev'essere \emph{sempre} una funzione di due variabili), un vettore di due elementi \lstinline{[a,b]} (attenzione: qui la sintassi è diversa rispetto alle funzioni che abbiamo scritto in laboratorio), e un valore iniziale \lstinline{y0} (scalare o vettore). Essa restituisce un vettore colonna $T$ e una matrice $Y$ che contiene le iterate $\y_n$ prodotte dal metodo come \emph{righe}; quindi essi sono i trasposti dei valori di output prodotti dalle funzioni che abbiamo scritto noi nel laboratorio.

La funzione \lstinline{ode45} utilizza un metodo di Runge--Kutta esplicito di ordine $p=5$, ma contiene uno stimatore dell'errore e lo usa per modificare la lunghezza del passo $h$, adattandola in modo da non fare mai passi più corti o più lunghi del necessario per ottenere una soluzione accurata (metodo di Dormand--Prince o RK45). Pertanto il vettore \lstinline{T} restituito non contiene una sequenza di punti equispaziati, ma una sequenza di punti opportunamente scelti. Tipicamente sono necessari più punti negli intervalli in cui la $\y(t)$ varia più velocemente. Le $\y_n$ restituite corrispondono alla funzione valutata su questa sequenza di punti, cioè $\y_n \approx \y(t_n)$.

È possibile usare il comando \lstinline{odeset} per specificare alcune opzioni, per esempio la tolleranza richiesta sulla soluzione. Si usa in questo modo:
\begin{lstlisting}
>> opzioni = odeset('AbsTol', 1e-6, 'RelTol', 1e-3);
\end{lstlisting}
specifica una tolleranza assoluta sulla soluzione calcolata di $10^{-6}$ (cioè, vogliamo che $\norm{\y_n - \y(t_n)}_\infty \leq 10^{-6}$) e una relativa di $10^{-3}$ (cioè, $\frac{\norm{\y_n - \y(t_n)}}{\norm{\y(t_n)}} \leq 10^{-3}$).

Le opzioni impostate vengono salvate in una variabile \lstinline{opzioni} che possiamo poi passare al solutore come ultimo argomento:
\begin{lstlisting}
>> ode45(f, [a,b], y0, opzioni);
\end{lstlisting}
Guardando la documentazione di \lstinline{odeset} (con il comando \lstinline{>> doc odeset} da dentro Matlab) trovate altre opzioni.

Indipendentemente da questi miglioramenti, \lstinline{ode45} usa un metodo esplicito, quindi ha sempre il problema di richiedere passi $h$ molto corti (e quindi un alto numero di iterazioni e costo computazionale) per risolvere adeguatamente problemi stiff.

Matlab contiene anche funzioni per risolvere equazioni differenziali che utilizzano metodi impliciti; la più comune è la funzione \lstinline{ode15s}. Essa accetta e ritorna gli stessi argomenti di \lstinline{ode45}, ma utilizza un metodo implicito e quindi è adatta anche a problemi stiff (come indica la \lstinline{s} nel nome della funzione). Utilizza diversi metodi impliciti a più passi, di ordine variabile da 1 a 5, cambiando il metodo e la lunghezza del passo a seconda dell'accuratezza richiesta. I metodi usati sono una variante dei metodi BDF che già abbiamo citato. Notare che cambiare la lunghezza del passo è più complicato per metodi a più passi, visto che non è più possibile riutilizzare direttamente i valori di $\f(t_{n+j},\y_{n+j})$ calcolati nei passi precedenti.

\begin{lstlisting}
>> A = [-10 -10; -10 -11];
>> f = @(t, y) A*y;
>> ode15s(f, [0,1], [1,0])
\end{lstlisting}

Nel caso dei metodi impliciti, un'opzione aggiuntiva particolarmente utile per migliorare le performance dei metodi è fornire a Matlab la matrice Jacobiana $\frac{\partial \f}{\partial \y}$. Difatti \lstinline{ode15s} (e varianti) utilizzano un metodo tipo-Newton per calcolare $\y_{n+k}$ dall'equazione implicita che lo definisce; e se lo ricordate questi metodi necessitano al loro interno della derivata della funzione che definisce l'equazione da risolvere. Lo Jacobiano può essere inserito tramite un'altra coppia di parametri \lstinline{'Jacobian', J} passati ad \lstinline{odeset}; qui \lstinline{J} può essere una matrice costante oppure una function handle \lstinline{J(t, y)}.

\begin{lstlisting}
>> ode15s(f, [0,1], [1,0], odeset('Jacobian', A));
\end{lstlisting}

In questo caso il problema è comunque semplice, quindi le performance dei due metodi non cambiano di molto.

Esistono anche altre funzioni, per esempio \lstinline{ode23} che utilizza un metodo di Runge--Kutta di ordine inferiore, o \lstinline{ode23s} che (come indica la \lstinline{s}) è un altro metodo adatto per problemi stiff.
\section{Esempio: problema di Robertson}


Un esempio classico di problema stiff deriva dalla modellizzazione del sistema di reazioni chimiche
\[
\begin{cases}
    A \stackrel{k_1}{\to} B\\
    B + B \stackrel{k_2}{\to} B+C\\
    B + C \stackrel{k_3}{\to} A + C.
\end{cases}
\]
Qualitativamente, la prima e la terza reazione convertono la specie $A$ nella specie $B$ e viceversa, mentre la seconda reazione ``rimuove'' la specie $B$ dal sistema trasformandola irreversibilmente nella specie $C$. Quindi sul lungo periodo ci aspettiamo che le specie $A$ e $B$ vengano convertite interamente in $C$. Inoltre, la quantità totale $[A] + [B] + [C]$ è conservata.

Il sistema di equazioni differenziali che fornisce la quantità delle tre specie presente rispetto al tempo è
\[
\frac{d}{dt}
\begin{bmatrix}
    y^{(1)}\\
    y^{(2)}\\
    y^{(3)}
\end{bmatrix}
=
\begin{bmatrix}
    -k_1y^{(1)} + k_3 y^{(2)} y^{(3)}\\
    k_1 y^{(1)} - k_2 (y^{(2)})^2 - k_3 y^{(2)} y^{(3)}\\
    k_2 (y^{(2)})^2
\end{bmatrix}.
\]
Solitamente, si sceglie il valore iniziale $\y_0 = [1,0,0]^T$ e tre valori su scale molto diverse per le tre costanti cinetiche, $k_1=0.04, k_2=3\cdot 10^7, k_3 = 10^4$. Questa differenza di scale rende il problema fortemente stiff.

Osservazioni numeriche:

\begin{itemize}
    \item \lstinline{ode45} richiede un numero estremamente alto di passi intermedi: anche su $[a,b]=[0,100]$ sono necessari più di 400.000 punti intermedi. Tentare periodi più lunghi è senza speranza.
    \item \lstinline{ode15s} risolve il problema con molti meno passi.
    \item È necessaria una simulazione su un intervallo di tempo molto lungo prima di confermare le proprietà viste teoricamente che tutta la massa viene convertita da $A$ a $C$; si ha $\y(10^6) \approx [0.002, 0, 0.998]$.
    \item Si apprezza molto meglio il comportamento disegnando il grafico in scala semilogaritmica (\lstinline{semilogx(t, y, '-x')}).
    \item La seconda componente (quantità di $B$) resta sempre molto bassa e va plottata a parte perché si veda qualcosa (\lstinline{semilogx(t,y(:,2), '-x')}).
    \item Ci sono poche speranze con metodi ``semplici'' come Eulero esplicito o implicito.
    \item Possiamo anche calcolare lo Jacobiano del sistema e fornirlo come argomento a \lstinline{ode15s}.
\end{itemize}

\end{document}