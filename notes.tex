\documentclass[a4paper]{report}

\usepackage{amsmath,amsthm,amssymb,mathtools}

% Needed for \comment
\usepackage{verbatim}

\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{decorations.pathmorphing}

\usepackage{listings}

\lstdefinestyle{matlab}{
  language=Matlab, % Use Matlab syntax highlighting
  basicstyle=\ttfamily\small, % Font style and size for the code
  keywordstyle=\color{blue}\bfseries, % Style for keywords
  commentstyle=\color{green!60!black}\itshape, % Style for comments
  stringstyle=\color{purple}, % Style for strings
  numbers=left, % Display line numbers on the left
  numberstyle=\tiny\color{gray}, % Style of line numbers
  stepnumber=1, % Line number increment
  numbersep=10pt, % Space between line numbers and code
  breaklines=true, % Line wrapping
  breakatwhitespace=true, % Wrap lines only at whitespace
  showspaces=false, % Don't display spaces
  showstringspaces=false, % Don't display string spaces
  tabsize=4, % Set tab width to 4 spaces
  frame=single, % Put a frame around the listings
  rulecolor=\color{gray}, % Frame color
  morekeywords={matlabFunction,syms,ezplot}, % Add more MATLAB-specific keywords
}
\lstset{style=matlab}

\usepackage{etoolbox}
\usepackage{xstring}

\usepackage[italian]{babel}

\usepackage{float}
\usepackage{algorithm2e}
\usepackage{booktabs}
\usepackage{subcaption}

\usepackage{pgfplotstable}

\usepackage{changebar}

\usepackage{hyperref}
\usepackage{microtype}

\addto\captionsitalian{%
  \renewcommand{\algorithmcfname}{Algoritmo}%
  \renewcommand{\listalgorithmcfname}{Elenco degli algoritmi}%
}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollario}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definizione}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Osservazione}
\newtheorem{esercizio}[theorem]{Esercizio}
\newtheorem{esempio}[theorem]{Esempio}

\newcommand{\x}{\mathbf{x}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\f}{\mathbf{f}}
\renewcommand{\b}{\mathbf{b}}
\renewcommand{\v}{\mathbf{v}}

\pgfplotsset{compat=1.17}

%\newcommand{\doteq}{\mathrel{\stackrel{\dot}{=}}}

\title{Note --- Calcolo Numerico}
\author{\texttt{federico.poloni@unipi.it}}
\date{Versione del \today}

\newbool{showcontent}

\newcommand{\eforcsvlist}[2]{%
  \edef\expandedlist{#2}% Fully expand the second argument
  \forcsvlist{#1}{\expandedlist}% Use the expanded list
}

\IfEndWith{\jobname}{\detokenize{-inf}}{
    \newcommand{\checkkey}[1]{%
        \ifstrequal{#1}{inf}{\setbool{showcontent}{true}}{}%
    }
    \newenvironment{conditional}[1][]{%
        \setbool{showcontent}{false}%
        \forcsvlist\checkkey{#1}%
        \ifbool{showcontent}{\begingroup}{\expandafter\comment}%
    }{%
        \ifbool{showcontent}{\endgroup}{\expandafter\endcomment}%
    }
}{}

\IfEndWith{\jobname}{\detokenize{-ich}}{
    \newcommand{\checkkey}[1]{%
        \ifstrequal{#1}{ich}{\setbool{showcontent}{true}}{}%
    }
    \newenvironment{conditional}[1][]{%
        \setbool{showcontent}{false}%
        \forcsvlist\checkkey{#1}%
        \ifbool{showcontent}{\begingroup}{\expandafter\comment}%
    }{%
        \ifbool{showcontent}{\endgroup}{\expandafter\endcomment}%
    }
}{}

\IfEndWith{\jobname}{\detokenize{notes}}{
\NewDocumentEnvironment{conditional}{o}
    {%
    \begingroup
    \cbstart
    \IfValueT{#1}{%
        \marginpar{\raggedright\footnotesize #1}%
    }%
    }
    {%
    \cbend
    \endgroup
    }    
}{}


\begin{document}

\begingroup\let\newpage\relax\maketitle\endgroup

Queste note sono nate per fare da `scaletta' per me mentre tengo le lezioni; sono anche a vostra disposizione per essere usate come dispense per lo studio.

Scelta degli argomenti, dimostrazioni ed esempi sono in parte presi dalle dispense di Luca Gemignani, Paolo Ghelardoni, Cecilia Magherini. Dei Large Language Model (GPT 4.1 e GPT 5) sono stati utilizzati per scrivere il codice Latex che genera alcune delle immagini.

\bigskip

Queste note vengono generate in versioni diverse (con più o meno argomenti) a seconda del corso di laurea a cui sono destinate. 

\begin{conditional}[]
    Quella che state leggendo è una versione completa che include \textbf{tutte le parti opzionali}. Le parti specifiche per un solo corso di laurea sono indicate con un'etichetta come qui sotto:
\end{conditional}

\medskip

\begin{conditional}[inf]
    Quella che state leggendo è la versione per il corso di laurea in \textbf{informatica}.
\end{conditional}

\medskip

\begin{conditional}[ich]
    Quella che state leggendo è la versione per il corso di laurea in \textbf{ingegneria chimica}.
\end{conditional}



\chapter{Motivazione}

In questo corso, vedremo algoritmi per risolvere al computer alcuni problemi che avete visto nei corsi di analisi e algebra lineare. Come mai questi algoritmi richiedono un trattamento speciale?

\paragraph{Problemi senza soluzione esatta} Alcuni problemi non hanno una soluzione esatta data da una formula, per esempio $\int_0^1 e^{-x^2} \mathrm{d}x$, ma si riescono a calcolare approssimazioni di queste soluzioni: per esempio, un integrale si può approssimare tramite somme di aree di rettangolini.

\paragraph{Algoritmi lenti} Non sempre gli algoritmi che si vedono in un corso `teorico' funzionano bene su un computer. Ad esempio, il calcolo del determinante di una matrice $A \in \mathbb{R}^{n\times n}$ tramite la formula di Laplace lungo la prima riga:
\[
    \det A = \sum_{j=1}^n (-1)^{j+1} a_{1j} A^{(1,j)}
\]
Qui $A^{(1,j)}$ il determinante della sottomatrice $(n-1)\times (n-1)$ che si ottiene eliminando da $A$ la riga 1 e la colonna $j$. Per calcolare il determinante di una matrice $11\times 11$ con questa formula bisogna calcolare $11$ determinanti di matrici $10\times 10$, che a loro volta richiedono ognuno il calcolo di $10$ determinanti di matrici $9\times 9$, e così via.

A meno che non ci siano proprietà particolari nella matrice $A$, come entrate uguali a zero, il calcolo di un determinante con questa formula è molto lento, non solo per un umano ma anche per un computer. Esempio su un computer moderno::
\begin{center}
\begin{tikzpicture}
    \begin{axis}[ymode = log, xlabel={$n$}, ylabel={tempo / $s$}]
        \addplot[
    color=blue,
    mark=square,
    ]
    coordinates {
   (1.0000e+00,3.3700e-04)
   (2.0000e+00,8.9820e-04)
   (3.0000e+00,1.1920e-03)
   (4.0000e+00,2.5600e-03)
   (5.0000e+00,4.1300e-03)
   (6.0000e+00,1.3605e-02)
   (7.0000e+00,5.7616e-02)
   (8.0000e+00,3.0071e-01)
   (9.0000e+00,1.4279e+00)
   (1.0000e+01,1.4244e+01)
   (1.1000e+01,1.7992e+02)
   };    
    \end{axis}
\end{tikzpicture}
\end{center}
Per calcolare il determinante di una matrice $11\times 11$ ci vogliono più di 100 secondi! Un algoritmo così lento è poco utile.

\paragraph{Algoritmi inaccurati} Un altro fattore è \emph{come} il computer implementa certe operazioni. Numeri come $1/3$ o $\sqrt{2}$ hanno infinite cifre; non possiamo fare le operazioni ``in colonna''. Ci sono diverse soluzioni possibili, ma per la maggior parte delle applicazioni l'esperienza ha insegnato che la strategia migliore è tenere (essenzialmente) solo un certo numero di cifre significative, come si fa su una calcolatrice. Questo significa che le operazioni sono approssimate: per esempio $\frac13 + \frac13 + \frac13 \approx 0.33333 + 0.33333 + 0.33333 = 0.99999 \neq 1$. Gli algoritmi vanno implementati con attenzione per evitare che queste approssimazioni un grosso impatto sul risultato. Per esempio: l'eliminazione di Gauss, o anche formule semplici come quella per risolvere un'equazione di secondo grado.

\paragraph{Importanza} Risolvere problemi computazionali al computer è diventato sempre più importante negli ultimi anni. Pensate per esempio a chi deve progettare un aereo. Quanto spessa deve essere la parete di metallo da usare nelle ali? Se è troppo spessa, il nostro aereo consuma più carburante del necessario. Se è troppo sottile, l'ala potrebbe rompersi. Una volta c'era un solo modo di scoprirlo: costruendo un prototipo di aereo. Oggi, la maggior parte di questi esperimenti possono essere rimpiazzati da simulazioni al computer. Va trovato il modo più efficiente di farle (un aereo è un oggetto molto complesso), ed è fondamentale capire quando gli errori diventano così grandi da compromettere il risultato.

\paragraph{Programmazione} L'altro scopo importante di questo corso è come \emph{programmare} un computer, cioè scrivere delle istruzioni per far eseguire sequenze specifiche di operazioni: non vogliamo calcolare noi le somme di Riemann di $\int_0^1 e^{x^2} \mathrm{d}x$, o il determinante di una matrice $11\times 11$, ma vogliamo imparare a fare in modo che il computer esegua questo calcolo per noi. Non vogliamo affidarci a un'app o un sito già fatto per ogni singolo problema, ma imparare come \emph{programmare} il computer in modo da saper risolvere da soli qualunque nuovo problema ci capiti davanti.

\chapter{Equazioni non lineari (zeri di funzione)}

\begin{conditional}[ich]
    %%%
    % Pannocchia dice che è più comune un'altra variante, la formula di Peng--Robinson; usare quella invece
    %%%
    \paragraph{Un esempio pratico} In termodinamica, esistono diverse formule che modificano l'equazione di stato dei gas perfetti e forniscono leggi che legano temperatura, pressione e volume. Una delle più famose è la \emph{formula di van der Waals}
    \[
        P = \frac{RT}{V-B} - \frac{A}{V^2}.
    \]
    Qui $P$ è la pressione, $T$ è la temperatura, $V$ è il cosiddetto ``volume molare'', cioè il volume occupato da una mole del gas, e $R,A,B$ sono costanti (con $A,B$ che dipendono dal gas in questione). Supponiamo di sapere la pressione $P$ e la temperatura $T$, e voler calcolare il volume occupato da un gas. Questo è equivalente a trovare il valore $x$ che risolve
    \[
        \frac{RT}{x-B} - \frac{A}{x^2} - P = 0.
    \]
    Lavorando con applicazioni dell'ingegneria è normale incontrare problemi come questi; in qualche caso siamo in grado di espandere i calcoli e risolvere esattamente l'equazione (per esempio quando si riconduce a un'equazione di secondo grado); ma in generale è utile avere a disposizione un metodo per calcolare approssimatamente la soluzione di equazioni anche più complicate.
\end{conditional}

\begin{conditional}[inf]
    \paragraph{Un esempio pratico} Consideriamo l'equazione
    \[
    T = \frac{1}{\mu - \lambda 2^{-T}}, 
    \]
    dove $\mu,\lambda > 0$ sono costanti, e $T$ è un'incognita che dobbiamo determinare. Questa equazione compare nella cosiddetta \emph{teoria delle code}, che si occupa di studiare sistemi che coinvolgono dei buffer. Per esempio, consideriamo un server web: ogni tanto arrivano utenti che richiedono di caricare una pagina. Il server lavora con un processo solo, cioè, risponde a una sola richiesta alla volta; se una seconda richiesta arriva quando il server sta ancora rispondendo alla prima, il client deve mettersi in attesa. Questa equazione serve per calcolare il tempo medio di attesa $T$. Il termine $\mu$ dice (raccontato molto informalmente) quanto il server è veloce a gestire richieste; e il termine $\lambda 2^{-T}$ dice quanto spesso arrivano richieste dai client. Questo termine dipende a sua volta dalla media $T$, nella nostra equazione: più un server è lento, più gli utenti si stufano e tendono ad abbandonarlo.

    Per trovare il tempo medio di attesa $T$, dobbiamo risolvere un'equazione; questa non è un'equazione né di primo né di secondo grado, ma una più complicata, che non ammette una formula risolutiva. Nonostante questo, vogliamo comunque determinare un'approssimazione della soluzione. Possiamo riscrivere questo problema in termini di una funzione: la soluzione è il punto in cui
    \[
    f(x) = \frac{1}{\mu - \lambda 2^{-x}} - x
    \]
    tocca l'asse delle ascisse. Questa è una famiglia di problemi molto generale, che andiamo a studiare.
\end{conditional}

\paragraph{Il problema} Data una funzione $f: [a,b] \to \mathbb{R}$, vogliamo calcolare uno \emph{zero della funzione}, cioè un punto $\alpha$ tale che $f(\alpha) = 0$. Un altro esempio semplice è il calcolo di radici $n$-esime: calcolare $\sqrt[n]{K}$ è equivalente a trovare uno zero della funzione $f(x) = x^n - K$.

Ci potrebbero essere più soluzioni in un dato intervallo (a priori anche infinite!). Un modo conveniente di dimostrare che esiste \emph{almeno} una soluzione in un dato intervallo $[a,b]$ è mostrare che è un \emph{intervallo di separazione}, cioè $f(a)$ e $f(b)$ hanno segni opposti: $f(a)>0,f(b)<0$ oppure $f(a)>0,f(b)<0$. Un modo semplice di scrivere questa condizione è $f(a)f(b) < 0$. Difatti, ricordiamo questo teorema che avete visto ad analisi.
\begin{theorem}[Teorema di esistenza degli zeri]
Sia $f \in \mathcal{C}^0([a,b])$. Se $f(a)$ e $f(b)$ hanno segno opposto (uno positivo e uno negativo), allora esiste almeno un reale $\alpha \in (a,b)$ tale che $f(\alpha) = 0$.
\end{theorem}
Detto in altro modo, se $f$ è una funzione continua e $[a,b]$ è un intervallo di separazione, allora esso contiene uno zero della funzione.

Questo risultato non ci assicura che lo zero sia unico. Possiamo concludere che è unico per esempio se riusciamo a mostrare che $f$ è strettamente crescente o decrescente in $[a,b]$; per esempio, usando le derivate, quando la funzione è derivabile.

Esempio: siano fissati $n \geq 2, K > 0$, e consideriamo la funzione $f(x) = x^n - K$. Si ha $f(0) = -K < 0$, mentre per $x$ sufficientemente grande si ha $f(x) > 0$ (difatti $x \to \infty$). Per esempio, se $K>1$, abbiamo $f(K) = K^n - K > 0$. Quindi $[0,K]$ è un intervallo di separazione, ed esiste una soluzione nell'intervallo. Questa soluzione è unica? La funzione $f$ ha derivata $f'(x) = nx^{n-1}$; quindi $f'(x) > 0$ per ogni $x > 0$, e $f'(0) = 0$. Questo permette di concludere che la soluzione è una sola. 
% Come dimostrarlo formalmente? Un modo è tramite il teorema di Rolle, che avete sicuramente visto ad analisi. Lo enunciamo qui, con delle ipotesi forse un pochino più restrittive di quelle che avete visto ad analisi.
% \begin{theorem}[Teorema di Rolle]
% Sia $f:[a,b] \to \mathbb{R}$ una funzione di classe $\mathcal{C}^1$. Se $f(a) = f(b)$, allora esiste almeno un punto $c\in (a,b)$ in cui $f'(c) = 0$.
% \end{theorem}

% Se per assurdo esistessero due punti $a,b \in [0,\infty)$ tali che $f(a) = f(b) = 0$ (supponiamo per semplicità di avere scelto i nomi in modo che $a<b$), allora esisterebbe un punto $c \in (a,b) \subset (0,\infty)$ tale che $f'(c) = 0$, ma questo è impossibile perché abbiamo detto che $f'(x) > 0$ per $x>0$.

\section{Metodo di bisezione}

È un metodo che funziona con poche ipotesi sulla $f$: serve solo che $f \in \mathcal{C}^0([a,b])$, e che $[a,b]$ sia un intervallo di separazione.

\paragraph{Descrizione del metodo} L'idea del metodo è la seguente: voglio costruire una sequenza di intervalli di separazione sempre più piccoli. Per prima cosa, calcolo il punto medio tra $a$ e $b$, che chiameremo $c$. Se $f(c) = 0$, allora ho trovato uno zero della funzione e posso fermarmi. Altrimenti, uno dei due intervalli $[a,c]$ e $[c,b]$ è un intervallo di separazione, come si può vedere facilmente considerando i casi possibili per i segni. A questo punto, posso ripetere la procedura per questo intervallo e continuare.

\begin{center}
    \begin{tikzpicture}[scale=0.5]
    \draw [->, very thick] (0,0) -- (10,0);
    \fill (2,0) node[below] {$\mathstrut a$} circle (3pt);
    \fill (8,0) node[below] {$\mathstrut b$} circle (3pt);
    \fill (5,0) node[below] {$\mathstrut c$} circle (3pt);
\end{tikzpicture}
\end{center}

Associamo degli indici ai punti con cui lavoriamo, in modo da poter parlare più agevolmente dei punti $a,b,c$ in passi diversi. Chiameremo $a_0 = a$, $b_0=b$ i due punti iniziali, e $c_0$ il loro punto medio. A questo punto, dopo aver fatto il primo passo abbiamo i punti $[a_1,b_1] = [a_0,c_0]$ oppure $[c_0,b_0]$. Chiamiamo $c_1$ il loro punto medio, e così via.

Questa convenzione è particolarmente comoda per ragionare teoricamente sui passi dell'algoritmo: l'indice $0$ si usa per i punti di partenza, da cui iniziamo l'algoritmo, e l'indice $k$ denota i punti calcolati al $k$-esimo passo. (Vedremo però che il linguaggio di programmazione che usiamo, Matlab, spesso ci costringerà a partire da $1$ anziché da $0$.)

Due semplici formule saranno fondamentali per proseguire:
\begin{itemize}
    \item La formula che dà il punto medio tra due numeri reali $a$ e $b$ è $c = \frac{a+b}{2}$;
    \item La formula che dà la distanza tra $a$ e $b$ è $b-a$ (supponendo che $b$ sia il punto più a destra; altrimenti possiamo scrivere $\abs{b-a}$).
\end{itemize}
\begin{center}
    \begin{tikzpicture}[scale=0.5]
    \draw [->, very thick] (0,0) -- (10,0);
    \fill (2,0) node[below] {$\mathstrut a$} circle (3pt);
    \fill (8,0) node[below] {$\mathstrut b$} circle (3pt);
    \fill (5,0) node[below] {$\mathstrut c=\tfrac{a+b}{2}$} circle (3pt);
    \draw (2,0.5) -- (2,1.2) -- (8,1.2) -- (8,0.5);
    \node at (5,1.8) {$b-a$};
\end{tikzpicture}
\end{center}

\begin{algorithm}
$a_0=a,b_0=b$\;
\For{$k=0,1,\dots$}{
    $c_k = \frac{a_k + b_k}{2}$\;
    \uIf{$f(c_k) = 0$}{
        $\alpha = c_k$\;
        \textbf{break}\;
    }
    \uElseIf{$f(a_k)f(c_k) < 0$}{
        $a_{k+1} = a_k$, $b_{k+1} = c_k$\;
    }
    \uElse{
        $a_{k+1} = c_k$, $b_{k+1} = b_k$\;
    }
}
\caption{Il metodo di bisezione}
\end{algorithm}

\paragraph{Esempio} Prendiamo $f(x) = x^2 - 2$. L'intervallo $[a,b] = [0,2]$ è un intervallo di separazione, quindi contiene (almeno) uno zero $\alpha$ di $f$. Sappiamo già in realtà che ne contiene esattamente uno, $\alpha=\sqrt{2}$.

\begin{center}
    \begin{tabular}{cccccccc}
        \toprule
        $k$ & $a_k$ & $c_k$ & $b_k$ & $f(a_k)$ & $f(c_k)$ & $f(b_k)$\\
        \midrule
        0 & 0 & 1 & 2 & -2 & -1 & 2\\
        1 & 1 & 1.5 & 2 & -1 & 0.25 & 2\\
        2 & 1 & 1.25 & 1.5 & -1 & -0.4375 & 0.25\\
        $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ &$\vdots$ \\
        \bottomrule
    \end{tabular}
\end{center}

\begin{lstlisting}
% Script Matlab: metodo di bisezione

f = @(x) x^2 - 2;
a = 0; b = 2;
n = 10;

% salviamo questi valori in variabili
% per non doverli ricalcolare piu' volte
fa = f(a); 
fb = f(b);

if fa*fb >= 0
    error('Non ho un intervallo di separazione')
end

for k = 1:n
    c = (a+b) / 2;
    fc = f(c);
    % per visualizzare cosa sta succedendo
    valori = [a, c, b, fa, fc, fb]

    if fc == 0   % caso fortunato
        break
    end
    if fa*fc < 0
        b = c;   % [a,b] <-- [a,c]
        fb = fc; % si puo' omettere (perche'?)
    else
        a = c;   % [a,b] <-- [c,b]
        fa = fc; % si puo' omettere (perche'?)
    end
end
\end{lstlisting}


\paragraph{Costo computazionale} Una delle domande importanti quando abbiamo un metodo numerico per calcolare qualcosa è: quanto tempo ci mette? Approssimativamente, il tempo impiegato da un computer per eseguire un calcolo dipende dal numero di operazioni coinvolte. Per esempio, calcolare la somma $1+2+3+\dots+10$ richiede $9$ somme; calcolare $1+2+3+\dots+20$ richiede $19$ somme, cioè circa il doppio, e quindi ci aspettiamo che ci metta il doppio del tempo.

Nel caso del metodo di bisezione, la difficoltà maggiore nel calcolare il tempo è che non sappiamo quante operazioni sono necessarie per calcolare la $f$. Spesso il metodo viene usato con funzioni $f$ date da formule molto complicate, per cui anche solo calcolare la $f$ in un punto è dispendioso. Per questo ha senso chiedersi quante volte viene va calcolato il valore della funzione $f$ in ogni passo. Nei passi del metodo sono necessarie anche poche altre operazioni, quelle per calcolare $\frac{a_k+b_k}{2}$, ma il loro costo è tipicamente trascurabile rispetto a quello del calcolo della $f$, quindi possiamo ignorarle.

Guardando la tabella più sopra, possiamo vedere che, a parte il passo iniziale in cui abbiamo calcolato la $f$ tre volte, in $a_0,b_0,c_0$, in ogni passo successivo abbiamo calcolato il valore in \emph{un} solo nuovo punto, cioè $c_k$. Difatti, i valori di $f(a_k)$ e $f(b_k)$ sono già noti dal passo precedente, e ci è bastato ricopiarli dalla riga precedente della tabella.

Per questo diciamo che il costo per passo del metodo di bisezione è di una valutazione della funzione.

\paragraph{Errore analitico}
L'altra domanda chiave per un algoritmo numerico è: quanto vicino andiamo alla soluzione vera del problema? È semplice vedere che ad ogni passo la lunghezza dell'intervallo si dimezza:
\begin{align*}
    b_1 - a_1 &= \frac{b_0-a_0}{2}\\
    b_2 - a_2 &= \frac{b_1-a_1}{2} = \frac{b_0-a_0}{4}\\
    b_3 - a_3 &= \frac{b_2-a_2}{2} = \frac{b_1-a_1}{4} = \frac{b_0-a_0}{8}\\
    \vdots \,\,&= \,\,\vdots\\
    b_{k} - a_{k} &= \frac{b_{k-1} - a_{k-1}}{2} = \frac{b_{k-1} - a_{k-1}}{4} = \dots = \frac{b_{0} - a_{0}}{2^k}
\end{align*}
Se ci fermiamo dopo $n$ iterazioni del metodo, abbiamo un intervallo di ampiezza $\frac{b_0-a_0}{2^{n}}$, e sappiamo che esso contiene uno zero $\alpha$ della funzione. A questo punto, se vogliamo restituire \emph{un} valore reale che sia la migliore approssimazione possibile di $\alpha$ con le informazioni a nostra disposizione, la cosa migliore da fare è restituire il punto medio $c_n = \frac{a_n + b_n}{2}$. Difatti $\alpha$ è un punto di cui sappiamo solo che sta nell'intervallo $(a_n,b_n)$, di ampiezza $\ell = \frac{b_0-a_0}{2^{n}}$; quindi la distanza tra $\alpha$ e il punto medio dell'intervallo è al massimo $\ell/2$. Se restituissi $a_n$ o $b_n$ invece nel caso peggiore l'errore è quasi uguale a $\ell$.
\begin{figure}[H]
\begin{center}
    \begin{tikzpicture}[scale=0.5]
        \draw [very thick, ->] (0,0) -- (10,0);
        \fill (2,0) node[below] {$\mathstrut a_n$} circle (3pt);
        \fill (8,0) node[below] {$\mathstrut b_n$} circle (3pt);
        \fill (5,0) node[below] {$\mathstrut c_n$} circle (3pt);
        \fill[red] (2.5,0) node[above] {$\alpha$} circle (3pt);
    \end{tikzpicture}\\
    \begin{tikzpicture}[scale=0.5]
        \draw [very thick, ->] (0,0) -- (10,0);
        \fill (2,0) node[below] {$\mathstrut a_n$} circle (3pt);
        \fill (8,0) node[below] {$\mathstrut b_n$} circle (3pt);
        \fill (5,0) node[below] {$\mathstrut c_n$} circle (3pt);
        \fill[red] (7.5,0) node[above] {$\alpha$} circle (3pt);
    \end{tikzpicture}
\end{center}
\caption{Nella figura sopra, $\alpha$ è molto vicino a $a_n$, quindi $\abs{\alpha - b_n}$ è quasi uguale a $\ell$, la lunghezza dell'intervallo $[a_n,b_n]$. Nella figura sotto, invece, $\alpha$ è molto vicino a $b_n$, quindi $\abs{\alpha - a_n}$ è quasi uguale a $\ell$. In entrambi i casi, $\abs{\alpha-c_n}\leq \ell/2$.}
\end{figure}

Quindi, dato il valore $c_n$ restituito dopo $n$ passi del metodo di bisezione, siamo sicuri che esiste uno zero $\alpha$ di $f$ tale che 
\begin{equation} \label{tolleranza bisezione}
    \abs{c_n - \alpha} \leq \frac{b_0-a_0}{2^{n+1}}.    
\end{equation}

\paragraph{Criterio di arresto} Possiamo trasformare il calcolo fatto sopra in un criterio per scegliere quante iterazioni fare. Fissiamo una tolleranza $\varepsilon>0$; vogliamo arrestare il metodo quando siamo sicuri di aver determinato il valore di \emph{uno} zero $\alpha$ della funzione $f$ (non per forza l'unico!) a meno di questa tolleranza. Per avere questa sicurezza, il termine di destra della~\eqref{tolleranza bisezione} deve essere minore di $\varepsilon$. Quindi prendiamo il più piccolo intero $n$ tale che
\[
\frac{b_0 - a_0}{2^{n+1}} \leq \varepsilon \iff 2^{n+1} \geq \frac{b_0 - a_0}{\varepsilon} \iff n \geq \log_2 \left(\frac{b_0 - a_0}{\varepsilon}\right)-1.
\]

\paragraph{Criterio di arresto euristico (**)} Un'altra idea naturale è che possiamo fermarci quando $f(c_k)$ è ``sufficientemente piccolo''. Abbiamo già accennato al fatto che su un computer i calcoli non vengono effettuati esattamente, ma solo con un certo numero di cifre significative. In particolare, la condizione di arresto $f(c_k) = 0$ potrebbe non essere mai verificata esattamente, ma quando $f(c_k)$ è molto piccolo potremmo decidere di essere soddisfatti e fermare il calcolo. È però vero che se abbiamo trovato un valore $c$ per cui $f(c)$ è piccolo, allora siamo vicini a uno zero $\alpha$? È facile costruire funzioni per cui questo non succede: basta prendere una funzione positiva che diminuisce fino ad arrivare molto vicino a zero e poi risale. Però possiamo introdurre un \emph{criterio euristico}, cioè un criterio non rigoroso (e di cui non è garantito il successo). 

Supponiamo di avere calcolato la funzione in un punto $c_k$, ottenendo $f(c_k)$. Una delle idee fondamentali dell'analisi è che se ``zoomiamo il grafico'' e ne guardiamo una sezione sufficientemente piccola, una funzione $f$ che sia \emph{differenziabile} si avvicina molto alla sua retta tangente. Pertanto, se $f$ è differenziabile in $c_k$,
\begin{equation} \label{fapprox}
    f(x) \approx y = f(c_k) + f'(c_k)(x-c_k),
\end{equation}
dove a destra dell'uguale abbiamo l'equazione della retta tangente in $c_k$. Un modo di trasformare questa relazione in un'uguaglianza esatta è tramite lo sviluppo di Taylor: $f$ è una funzione di classe $\mathcal{C}^2$, allora per $x-c_k$ sufficientemente piccolo vale
\[
    f(x) = f(c_k) + f'(c_k)(x-c_k) + \frac{1}{2}f''(\xi) (x-c_k)^2,
\]
dove $\xi$ è un punto compreso nell'intervallo tra $c_k$ e $x$ (in qualunque ordine essi siano). Ci aspettiamo che l'ultimo termine sia piccolo, se stiamo guardando in una sezione abbastanza piccola del grafico: se $x-c_k$ è piccolo, $(x-c_k)^2$ lo è molto di più.

Supponiamo che ci sia uno zero $x = \alpha$ vicino a $c_k$; siamo in grado di valutare la distanza $\abs{\alpha - c_k}$ usando le formule sopra? Possiamo ricavare dalla~\eqref{fapprox}
\[
\abs{c_k-\alpha} \approx \frac{\abs{f(c_k)}}{\abs{f'(c_k)}}.
\]
Rovesciando il ragionamento, se $\frac{\abs{f(c_k)}}{\abs{f'(c_k)}} \leq \varepsilon$ ci possiamo aspettare (ma non è garantito!) che $c_k$ disti circa $\varepsilon$ da uno zero $\alpha$ della funzione. Questo procedimento non è rigoroso però: può essere che la funzione $f$ vari più di quanto ci aspettiamo; questo succede per esempio quando $f''(\xi)$ è grande, o la funzione non è $\mathcal{C}^2$.

Notiamo il fatto interessante che non importa che $f$ sia piccolo in assoluto in $c_k$, ma che sia piccolo \emph{rispetto alla sua derivata}. Valore piccolo e derivata piccola vuol dire semplicemente che la nostra funzione è molto ``piatta'', non per forza che siamo vicini a uno zero, come in figura: la funzione assume un valore $f(c_k)$ piccolo, ma $c_k$ è lontano da $\alpha$.
\begin{center}
    \begin{tikzpicture}
        \draw[->] (-2,0) -- (5,0) node[right] {$x$};
        \draw[->] (0,-1) -- (0,2) node[above] {$y$};
        \fill (4.5,0) node[below] {$c_k$} circle (1pt);
        \fill (2,0) node[below] {$\alpha$} circle (1pt);
        \fill (4.5,0.125) node[above] {$f(c_k)$} circle (1pt);
        
        \draw[domain=-1.5:4.5,smooth,variable=\x,blue] plot ({\x},{0.05*(\x-2)});      
    \end{tikzpicture}
\end{center}
È utile cercare di avere un criterio di arresto che non dipenda solo dal valore della funzione, perché i valori assunti dalla funzione possono variare molto a seconda delle applicazioni: se la funzione $f$ per esempio misurasse le distanze tra gli atomi di una molecola, la scala sull'asse delle $y$ sarà di circa $f(x) \approx 10^{-10}$ già di suo.

Ci manca ancora un ingrediente per completare questo criterio di arresto. Il valore di $f(c_k)$ viene calcolato lungo l'algoritmo, ma $f'(c_k)$ no, e calcolarlo può essere molto più complicato. Possiamo però rimpiazzarlo con un'altra approssimazione: se $c_k \in [a_k, b_k]$, allora
\[
f'(c_k) \approx \frac{f(b_k) - f(a_k)}{b_k - a_k}.
\]
Difatti questo è un rapporto incrementale fatto tra due punti sufficientemente vicini a $c_k$ (IMMAGINE). Ricordiamo anche un altro teorema di analisi, il teorema di Lagrange:
\begin{theorem}
    Se $f: [a,b] \to \mathbb{R}$ è una funzione di classe $\mathcal{C}^1$, allora esiste un punto $\xi \in (a,b)$ tale che
    \[
        f'(\xi) = \frac{f(b)-f(a)}{b-a}.
    \]
\end{theorem}
(Mettiamo ``di classe $\mathcal{C}^1$'' tra le ipotesi per semplicità, ma forse nel corso di analisi avete visto questo teorema con delle ipotesi leggermente diverse.) Questo risultato dice che la quantità che stiamo calcolando è la derivata di $f$ in un punto $\xi$, diverso da $c_k$ (e dallo $\xi$ del teorema precedente!), ma non troppo lontano da esso.

Quindi un possibile criterio di arresto è: se vogliamo calcolare $\alpha$ con un errore (circa) $\varepsilon$, possiamo fermare il metodo quando vale la disuguaglianza 
\[
\abs{f(c_k)} \leq \abs*{\frac{f(b_k) - f(a_k)}{b_k-a_k}} \varepsilon
\]
(\emph{criterio di arresto sul residuo}).

\paragraph{Vantaggi e svantaggi del metodo di bisezione}

Vantaggi:

\begin{itemize}
    \item Si applica a molte funzioni: richiede solo la continuità di $f$.
    \item Funziona \emph{sicuramente} se partiamo da un intervallo di separazione, restituendo un intervallo piccolo a piacere che contiene uno zero della funzione: come vedremo, non tutti i metodi offrono una garanzia di convergenza.
\end{itemize}

Svantaggi:

\begin{itemize}
    \item Serve avere a disposizione un intervallo di separazione da cui iniziare.
    \item La convergenza è lenta rispetto ad altri metodi (vedremo più avanti come misurarla).
\end{itemize}


\section{Metodo del punto fisso}

Un altro algoritmo che ci permette di cercare zeri di funzioni è il \emph{metodo del punto fisso}, o di \emph{iterazione funzionale}. Per usare questo metodo, è necessario fare delle manipolazioni algebriche per riscrivere l'equazione dalla forma $f(x) = 0$ alla forma $x = \Phi(x)$, per un'opportuna funzione $\Phi$. Per esempio, se stiamo cercando uno zero della funzione $f(x) = x^3 - 2$, possiamo riscrivere l'equazione $f(x)$ in vari modi; per esempio: 
\begin{itemize}
    \item $x = x^3 - 2 + x$;
    \item $x = x - \frac16 (x^3-2)$;
    \item $x = \frac{2}{x^2}$.
\end{itemize}
Ognuno di queste scritture porta a una definizione diversa di $\Phi(x)$, la funzione che sta a destra dell'uguale. In tutti questi casi, uno zero $\alpha$ di $f(\alpha)=0$ è anche un \emph{punto fisso} di $\Phi$, cioè soddisfa $\alpha = \Phi(\alpha)$. Tutte queste possibilità portano a scelte diverse di $\Phi(x)$, e quindi a metodi che hanno (potenzialmente) comportamenti molto diversi. Alcuni di questi metodi potrebbero generare successioni che convergono a $\alpha$ ed altri no. Studiamo in generale questi metodi.

Il metodo del punto fisso funziona in questo modo: fissata una certa $\Phi:[a,b] \to \mathbb{R}$ e scelto $x_0 \in [a,b]$, costruiamo la successione
\begin{equation} \label{puntofisso}
    x_{n+1} = \Phi(x_n), \quad n=0,1,2,\dots    
\end{equation}

\paragraph{Teorema del punto fisso} Per dimostrare un risultato di convergenza per questo metodo, ci sono due protagonisti fondamentali che dobbiamo introdurre. Il primo è che dobbiamo lavorare su un intervallo definito in modo particolare. Fissiamo una distanza (o raggio) $\rho>0$, e consideriamo l'insieme dei punti che hanno distanza da $\alpha$ minore o uguale a $\rho$, che possiamo scrivere in due modi:
\begin{equation} \label{intervallo centrato in alpha}
    I = \{x\in\mathbb{R} \colon \abs{x-\alpha} \leq \rho\} = [\alpha-\rho, \alpha + \rho].
\end{equation}
La situazione è simile a quella che avevamo nel metodo di bisezione, con un segmento e il suo punto medio, solo che ora le quantità che ci interessano di più sono il centro e il raggio.

\begin{center}
    \begin{tikzpicture}[scale=0.5]
    \draw [->, very thick] (0,0) -- (10,0);
    \fill (2,0) node[below] {$\mathstrut \alpha-\rho$} circle (3pt);
    \fill (8,0) node[below] {$\mathstrut \alpha+\rho$} circle (3pt);
    \fill (5,0) node[below] {$\mathstrut \alpha$} circle (3pt);
    \draw (2,0.5) -- (2,1.2) -- (4.95,1.2) -- (4.95,0.5);
    \node at (3.5,1.8) {$\rho$};
    \draw (5.05,0.5) -- (5.05,1.2) -- (8,1.2) -- (8,0.5);
    \node at (6.5,1.8) {$\rho$};
\end{tikzpicture}
\end{center}

Il secondo protagonista è la quantità
\begin{equation} \label{defL}
    L = \max_{x \in I} \, \abs{\Phi'(x)},    
\end{equation}
cioè il massimo (in valore assoluto) della derivata seconda di $\Phi$ su tutto l'intervallo. Notiamo innanzitutto che questo massimo esiste: ricordiamo il seguente teorema dell'analisi.
\begin{theorem}[Teorema di Weierstrass / di esistenza del massimo]
    Sia $[a,b]$ un intervallo chiuso e limitato, e sia $f$ una funzione di classe $\mathcal{C}^0$ (cioè continua) su $[a,b]$. Allora, esiste (almeno) un punto di massimo nell'intervallo $I$.
\end{theorem}
In questo caso, l'intervallo $I$ è chiuso e limitato, per come l'abbiamo definito in~\eqref{intervallo centrato in alpha}; se $\Phi$ è una funzione di classe $\mathcal{C}^1$, allora la sua derivata $\Phi'$ esiste ed è continua, e anche la funzione $f(x) = \abs{\Phi'(x)}$ è continua, in quanto composizione di due funzioni continue: la funzione valore assoluto, e la derivata $\Phi'$. Quindi le ipotesi del teorema sono verificate e la quantità $L$ esiste.

Con questi due ingredienti a disposizione, possiamo enunciare questo teorema.

\begin{theorem}[Convergenza locale del metodo del punto fisso]\label{thm:puntofisso}
Siano dati $\alpha\in\mathbb{R}$, $\rho>0$, e $\Phi$ una funzione tale che $\Phi(\alpha)=\alpha$. Supponiamo che $\Phi$ sia di classe $\mathcal{C}^1$ sull'intervallo $I = \{x\in\mathbb{R} \colon \abs{x-\alpha} \leq \rho\}$, e supponiamo inoltre che la quantità $L$ definita in~\eqref{defL} sia strettamente minore di $1$. Allora, il metodo~\eqref{puntofisso} è tale che per ogni $x_0 \in I$ si ha
\begin{itemize}
    \item $x_k \in I$ per ogni $k \geq 0$;
    \item $\lim_{k\to\infty} x_k = \alpha$.
\end{itemize}
\end{theorem}
Notare che il primo punto è importante perché il metodo sia ben definito: altrimenti, $\Phi$ potrebbe non essere definita nel punto $x_k$!

\begin{proof}
Consideriamo la quantità $\abs{x_k-\alpha}$, cioè la distanza tra $x_k$ e la soluzione esatta del nostro problema $\alpha$. Questa quantità viene chiamata l'\emph{errore al passo $k$} commesso dal metodo. La prima cosa che facciamo nella nostra dimostrazione è trovare una relazione tra l'errore al passo $k$ e quello al passo $k+1$. Si ha
\begin{equation} \label{riduzione errore punto fisso}
\frac{\abs{x_{k+1}-\alpha}}{\abs{x_k-\alpha}} = \abs*{
    \frac{\Phi(x_k)-\Phi(\alpha)}{x_k-\alpha}} = \abs{\Phi'(\xi_k)},
\end{equation}
per un certo punto $\xi_k$. Abbiamo usato il fatto che $x_{k+1} = \Phi(x_k)$, che $\alpha = \Phi(\alpha)$, e il teorema di Lagrange, che avete visto nel corso di analisi: esso ci dice che esiste un punto $\xi_k$ nell'intervallo aperto di estremi $x_k$ e $\alpha$ (non importa in che ordine sono) tale che $\frac{\Phi(x_k)-\Phi(\alpha)}{x_k-\alpha} = \Phi'(\xi_k)$. Chiamiamo questo punto $\xi_k$, indicando esplicitamente l'indice $k$, per sottolineare il fatto che per ogni iterazione $k$ si ha un punto $\xi_k$ diverso.

Ora vogliamo trasformare la~\eqref{riduzione errore punto fisso} in una formula per l'errore esplicita, in cui l'errore al passo $k$ non dipende dall'errore al passo $k-1$. Dimostreremo per induzione che per ogni $k\geq 0$ si ha
\begin{equation} \label{fpindu}
    \abs{x_k - \alpha} \leq L^k \rho.
\end{equation}
Ricordandoci come è fatta una dimostrazione per induzione, dobbiamo dimostrare queste due cose:
\begin{itemize}
    \item Per $k=0$, la~\eqref{fpindu} diventa $\abs{x_0 - \alpha} \leq \rho$, che è vera perché è equivalente a dire che $x_0 \in I$. 
    \item Supponiamo la~\eqref{fpindu} vera per un certo $k$, e dimostriamola per $k+1$. Vogliamo usare la relazione~\eqref{riduzione errore punto fisso} per dimostrare che l'errore viene ridotto di un fattore $L$. Per questo, il punto delicato è dimostrare che $\xi_k \in I$. Innanzitutto, per l'ipotesi induttiva abbiamo $\abs{x_k - \alpha} < L^k \rho$; poiché $L<1$, si ha anche $L^k\rho < \rho$ e quindi $\abs{x_k - \alpha}<\rho$, il che vuol dire che $x_k\in I$. Poiché $\xi_k$ è compreso tra $x_k$ e $\alpha$, anche esso appartiene all'intervallo $I$, e quindi abbiamo $\abs{\Phi'(\xi_k)} \leq L$. Possiamo dunque scrivere usando la relazione~\eqref{riduzione errore punto fisso}
    \begin{equation} \label{fpindu2}
        \abs{x_{k+1} - \alpha} = \abs{\Phi'(\xi_k)} \abs{x_k - \alpha} \leq L \cdot L^k \rho = L^{k+1}\rho.
    \end{equation}  
\end{itemize}
Questo completa la dimostrazione per induzione della~\eqref{fpindu}. Da questa relazione si ha che $x_k \in I$ per ogni $k$, come abbiamo già osservato nella dimostrazione. Inoltre
\[
0 \leq \abs{x_k - \alpha} \leq L^k \rho
\]
da cui per il teorema dei carabinieri segue che $\lim_{k\to \infty} x_k = \alpha$.
\end{proof}

\begin{esempio}
Consideriamo la funzione $\Phi(x) = x - \frac16 (x^3-2)$. Questa ha come punto fisso $\alpha =\sqrt[3]{2} \approx 1.26$. La sua derivata è $\Phi'(x) = 1 - \frac{1}{6}3x^2 = 1 - \frac{1}{2}x^2$. Si ha allora $\abs{\Phi'(x)}<1$ per $x \in (-2,0) \cup (0,2)$. Se prendiamo $r = 0.5$, abbiamo che su tutto l'intervallo
\[
    [\alpha-\rho,\alpha+\rho] \approx [1.26-0.5,1.26+0.5]
\]
si ha $\abs{\Phi'(x)}<1$. Possiamo quindi applicare il teorema, e concludere che il metodo converge per ogni scelta di $x_0$ in questo intervallo. Al posto di $0.5$, possiamo scegliere qualunque ampiezza $r < 2 - \sqrt[3]{2} \approx 0.74$ e la soluzione è analoga.
\end{esempio} 

\begin{esempio}
Consideriamo invece la funzione $\Phi(x) = \frac{2}{x^2}$, che ha sempre come punto fisso $x=\sqrt[3]{2}$. Questa volta si ha $\Phi'(x) = -\frac{4}{x^3}$, quindi $\Phi'(\alpha) = -2$. Non riusciremo mai a trovare un intervallo in cui applicare il teorema, perché già nel punto $\alpha$ che deve essere il centro dell'intervallo non vale la relazione $\abs{\Phi'(x)}< 1$. Si può difatti vedere che il metodo di punto fisso con questa funzione non converge ad $\alpha$: anche partendo da un $x_0$ molto vicino ad $\alpha$ (ma diverso da esso) le iterate si allontanano da esso.
\end{esempio}


\begin{remark} \label{oss:corpuntofisso}
    Se $\Phi(x) \in \mathcal{C}^1([a,b])$ e $\abs{\Phi'(\alpha)} < 1$ per un certo punto fisso $\alpha\in (a,b)$, allora per continuità possiamo prendere un $r$ sufficientemente piccolo da avere $\abs{\Phi'(x)} < 1$ per ogni $x \in I = [\alpha - \rho, \alpha + \rho]$. Quindi le ipotesi del teorema di convergenza locale~\ref{thm:puntofisso} sono verificate per questo $\rho$. Non è semplice stabilire a priori quanto dev'essere piccolo $\rho$.
\end{remark}
    
\begin{esercizio}
Esercizio: consideriamo l'equazione di punto fisso $x = \cos x$ (con $x$ in radianti). Quante soluzioni positive ha? Sappiamo individuare esplicitamente un intervallo $I$ in cui si applica il teorema del punto fisso?
\end{esercizio}
%%
% un po' palloso
%%

Svolgimento: una soluzione corrisponde a uno zero di $f(x) = x - \cos x$. Questa funzione è tale che $f(0) = -1$, $f(\pi/2) = \pi/2$, quindi esiste almeno uno zero in $(0,\pi/2)$. La derivata di questa funzione è $f'(x) = 1 + \sin(x) \geq 0$, che si annulla solo in punti isolati, quindi la funzione è strettamente crescente. Pertanto c'è \emph{solo} uno zero in $(0,\pi/2)$. Inoltre, non ci sono altri zeri in $[\pi/2, \infty)$ perché la funzione è strettamente positiva: su questo intervallo vale $f(x) \geq x - 1 > 0$. La derivata $\Phi'(x)$ è \emph{strettamente} minore di $1$ (in valore assoluto) al di fuori dei punti $-\pi/2, \pi/2$, e in generale tutti i punti della forma $\frac12 \pi + k\pi$, per $k\in\mathbb{Z}$. Quindi dobbiamo prendere un intervallo centrato in $\alpha \approx 0.7391$ che non contenga $-\pi/2 \approx -1.5708$ né $\pi/2 \approx 1.5708$.

\begin{esercizio}
    Consideriamo il metodo del punto fisso applicato a una funzione lineare $\Phi(x) = mx + q$. Sotto quali condizioni su $m$ e $q$ il metodo converge?
\end{esercizio}
\begin{esercizio}
    Applichiamo il metodo del punto fisso all'equazione $x = \Phi(x) = \frac13 + \frac23 x^2$. Quali sono gli zeri della funzione? Per quali valori di $x_0$ possiamo assicurare che il metodo converge usando il teorema visto?
\end{esercizio}

\section{Convergenza lineare di un metodo iterativo}

In questa sezione vediamo un modo di definire quanto velocemente converge un metodo numerico come quelli che abbiamo visto; 
questo è importante in modo da poter confrontare metodi diversi. Abbiamo una successione di approssimazioni $x_n$ di una certa soluzione esatta $\alpha$, ognuna calcolata da quella precedente. La successione si dice \emph{convergente} se l'errore $e_n := \abs{x_n - \alpha}$ tende a $0$. Partiamo con un esempio che mostra cosa succede in un caso reale; in Figura~\ref{fig:iterativi} abbiamo considerato diversi metodi iterativi per risolvere l'equazione $x^3-2 = 0$, e abbiamo tracciato per ognuno di essi un grafico dell'errore $e_n$ rispetto a $n$.
\begin{figure}
\begin{center}
    \begin{tikzpicture}
        \begin{axis}[width=0.7\textwidth, xlabel={iterazione}, ylabel={errore (in scala lineare)}]

            \addplot+[x=it, y=e] table{
                it e
           1.0000e+00   2.5992e-01
           2.0000e+00   4.9008e-01
           3.0000e+00   2.3298e-01
           4.0000e+00   3.0730e-02
           5.0000e+00   2.8083e-02
           6.0000e+00   2.0157e-02
           7.0000e+00   1.7687e-02
           8.0000e+00   1.3288e-02
           9.0000e+00   1.1349e-02
           1.0000e+01   8.7614e-03
           1.1000e+01   7.3487e-03
           1.2000e+01   5.7697e-03
           1.3000e+01   4.7814e-03
           1.4000e+01   3.7945e-03
           1.5000e+01   3.1195e-03
           1.6000e+01   2.4928e-03
           1.7000e+01   2.0385e-03
           1.8000e+01   1.6362e-03
           1.9000e+01   1.3334e-03
           2.0000e+01   1.0734e-03
           2.1000e+01   8.7269e-04
           2.2000e+01   7.0387e-04
           2.3000e+01   5.7139e-04
           2.4000e+01   4.6143e-04
           2.5000e+01   3.7421e-04
           2.6000e+01   3.0244e-04
           2.7000e+01   2.4511e-04
           2.8000e+01   1.9821e-04
           2.9000e+01   1.6057e-04
           3.0000e+01   1.2989e-04
           3.1000e+01   1.0519e-04
           3.2000e+01   8.5111e-05
           3.3000e+01   6.8917e-05
           3.4000e+01   5.5769e-05
           3.5000e+01   4.5153e-05
           3.6000e+01   3.6542e-05
           3.7000e+01   2.9583e-05
           3.8000e+01   2.3943e-05
           3.9000e+01   1.9383e-05
           4.0000e+01   1.5688e-05
           4.1000e+01   1.2700e-05
           4.2000e+01   1.0279e-05
           4.3000e+01   8.3208e-06
           4.4000e+01   6.7350e-06
           4.5000e+01   5.4518e-06
           4.6000e+01   4.4129e-06
            };
    
            \addplot+[x=it, y=e] table{
                it e
                   1.0000e+00   2.5992e-01
           2.0000e+00   2.4008e-01
           3.0000e+00   9.9210e-03
           4.0000e+00   1.1508e-01
           5.0000e+00   5.2579e-02
           6.0000e+00   2.1329e-02
           7.0000e+00   5.7040e-03
           8.0000e+00   2.1085e-03
           9.0000e+00   1.7977e-03
           1.0000e+01   1.5542e-04
           1.1000e+01   8.2114e-04
           1.2000e+01   3.3286e-04
           1.3000e+01   8.8716e-05
           1.4000e+01   3.3355e-05
           1.5000e+01   2.7681e-05
           1.6000e+01   2.8370e-06
           1.7000e+01   1.2422e-05
           1.8000e+01   4.7924e-06
           1.9000e+01   9.7769e-07
           2.0000e+01   9.2966e-07
           2.1000e+01   2.4019e-08
           2.2000e+01   4.5282e-07
           2.3000e+01   2.1440e-07
           2.4000e+01   9.5191e-08
           2.5000e+01   3.5586e-08
           2.6000e+01   5.7836e-09
           2.7000e+01   9.1175e-09
           2.8000e+01   1.6670e-09
           2.9000e+01   2.0583e-09
           3.0000e+01   1.9569e-10
           3.1000e+01   7.3564e-10
           3.2000e+01   2.6998e-10
           3.3000e+01   3.7145e-11
           3.4000e+01   7.9271e-11
           3.5000e+01   2.1063e-11
           3.6000e+01   8.0409e-12
           3.7000e+01   6.5110e-12
           3.8000e+01   7.6494e-13
           3.9000e+01   2.8730e-12
           4.0000e+01   1.0540e-12
           4.1000e+01   1.4455e-13
           4.2000e+01   3.1020e-13
            };
        
            \addplot+[x=it, y=e] table{
                it e
           1.0000e+00   7.4008e-01
           2.0000e+00   7.5992e-01
           3.0000e+00   2.9117e-01
           4.0000e+00   1.8458e-02
           5.0000e+00   3.1969e-03
           6.0000e+00   6.1883e-04
           7.0000e+00   1.1756e-04
           8.0000e+00   2.2414e-05
           9.0000e+00   4.2705e-06
           1.0000e+01   8.1376e-07
           1.1000e+01   1.5506e-07
           1.2000e+01   2.9547e-08
           1.3000e+01   5.6302e-09
           1.4000e+01   1.0728e-09
           1.5000e+01   2.0443e-10
           1.6000e+01   3.8955e-11
           1.7000e+01   7.4227e-12  
           1.8000e+01   1.4144e-12
           1.9000e+01   2.6956e-13
           2.0000e+01   5.1292e-14
            };
            
            \addplot+[x=it, y=e] table{
                it e
           1.0000e+00   7.4008e-01
           2.0000e+00   2.4008e-01
           3.0000e+00   3.6375e-02
           4.0000e+00   1.0112e-03
           5.0000e+00   8.1067e-07
           6.0000e+00   5.2158e-13
           7.0000e+00            0
            };
        \end{axis}
    \end{tikzpicture}
    
    \begin{tikzpicture}
    \begin{axis}[width=0.7\textwidth, ymode = log, xlabel={iterazione}, ylabel={errore (in scala logaritmica)}, legend style={at={(0.5,-0.15)},anchor=north}]

        \addplot+[x=it, y=e] table{
            it e
       1.0000e+00   2.5992e-01
       2.0000e+00   4.9008e-01
       3.0000e+00   2.3298e-01
       4.0000e+00   3.0730e-02
       5.0000e+00   2.8083e-02
       6.0000e+00   2.0157e-02
       7.0000e+00   1.7687e-02
       8.0000e+00   1.3288e-02
       9.0000e+00   1.1349e-02
       1.0000e+01   8.7614e-03
       1.1000e+01   7.3487e-03
       1.2000e+01   5.7697e-03
       1.3000e+01   4.7814e-03
       1.4000e+01   3.7945e-03
       1.5000e+01   3.1195e-03
       1.6000e+01   2.4928e-03
       1.7000e+01   2.0385e-03
       1.8000e+01   1.6362e-03
       1.9000e+01   1.3334e-03
       2.0000e+01   1.0734e-03
       2.1000e+01   8.7269e-04
       2.2000e+01   7.0387e-04
       2.3000e+01   5.7139e-04
       2.4000e+01   4.6143e-04
       2.5000e+01   3.7421e-04
       2.6000e+01   3.0244e-04
       2.7000e+01   2.4511e-04
       2.8000e+01   1.9821e-04
       2.9000e+01   1.6057e-04
       3.0000e+01   1.2989e-04
       3.1000e+01   1.0519e-04
       3.2000e+01   8.5111e-05
       3.3000e+01   6.8917e-05
       3.4000e+01   5.5769e-05
       3.5000e+01   4.5153e-05
       3.6000e+01   3.6542e-05
       3.7000e+01   2.9583e-05
       3.8000e+01   2.3943e-05
       3.9000e+01   1.9383e-05
       4.0000e+01   1.5688e-05
       4.1000e+01   1.2700e-05
       4.2000e+01   1.0279e-05
       4.3000e+01   8.3208e-06
       4.4000e+01   6.7350e-06
       4.5000e+01   5.4518e-06
       4.6000e+01   4.4129e-06
        }; \addlegendentry{Punto fisso su $\Phi(x) = 2/x^2 + (x^3-2)/4$};

        \addplot+[x=it, y=e] table{
            it e
               1.0000e+00   2.5992e-01
       2.0000e+00   2.4008e-01
       3.0000e+00   9.9210e-03
       4.0000e+00   1.1508e-01
       5.0000e+00   5.2579e-02
       6.0000e+00   2.1329e-02
       7.0000e+00   5.7040e-03
       8.0000e+00   2.1085e-03
       9.0000e+00   1.7977e-03
       1.0000e+01   1.5542e-04
       1.1000e+01   8.2114e-04
       1.2000e+01   3.3286e-04
       1.3000e+01   8.8716e-05
       1.4000e+01   3.3355e-05
       1.5000e+01   2.7681e-05
       1.6000e+01   2.8370e-06
       1.7000e+01   1.2422e-05
       1.8000e+01   4.7924e-06
       1.9000e+01   9.7769e-07
       2.0000e+01   9.2966e-07
       2.1000e+01   2.4019e-08
       2.2000e+01   4.5282e-07
       2.3000e+01   2.1440e-07
       2.4000e+01   9.5191e-08
       2.5000e+01   3.5586e-08
       2.6000e+01   5.7836e-09
       2.7000e+01   9.1175e-09
       2.8000e+01   1.6670e-09
       2.9000e+01   2.0583e-09
       3.0000e+01   1.9569e-10
       3.1000e+01   7.3564e-10
       3.2000e+01   2.6998e-10
       3.3000e+01   3.7145e-11
       3.4000e+01   7.9271e-11
       3.5000e+01   2.1063e-11
       3.6000e+01   8.0409e-12
       3.7000e+01   6.5110e-12
       3.8000e+01   7.6494e-13
       3.9000e+01   2.8730e-12
       4.0000e+01   1.0540e-12
       4.1000e+01   1.4455e-13
       4.2000e+01   3.1020e-13
        }; \addlegendentry{Bisezione su $f(x) = x^3-2$}
    
        \addplot+[x=it, y=e] table{
            it e
       1.0000e+00   7.4008e-01
       2.0000e+00   7.5992e-01
       3.0000e+00   2.9117e-01
       4.0000e+00   1.8458e-02
       5.0000e+00   3.1969e-03
       6.0000e+00   6.1883e-04
       7.0000e+00   1.1756e-04
       8.0000e+00   2.2414e-05
       9.0000e+00   4.2705e-06
       1.0000e+01   8.1376e-07
       1.1000e+01   1.5506e-07
       1.2000e+01   2.9547e-08
       1.3000e+01   5.6302e-09
       1.4000e+01   1.0728e-09
       1.5000e+01   2.0443e-10
       1.6000e+01   3.8955e-11
       1.7000e+01   7.4227e-12
       1.8000e+01   1.4144e-12
       1.9000e+01   2.6956e-13
       2.0000e+01   5.1292e-14
        }; \addlegendentry{Punto fisso su $\Phi(x) = x - (x^3-2)/4$};
        
        \addplot+[x=it, y=e] table{
            it e
       1.0000e+00   7.4008e-01
       2.0000e+00   2.4008e-01
       3.0000e+00   3.6375e-02
       4.0000e+00   1.0112e-03
       5.0000e+00   8.1067e-07
       6.0000e+00   5.2158e-13
       7.0000e+00            0
        }; \addlegendentry{Newton (punto fisso su $\Phi(x) = x-(x^3-2)/(3x^2)$)};
    
    \end{axis}
    \end{tikzpicture}
    \end{center}
\caption{Convergenza di diversi metodi iterativi per trovare uno zero di $f(x) = x^3-2$.}\label{fig:iterativi}
\end{figure}
La prima osservazione importante è che è utile usare una \emph{scala logaritmica} sull'asse delle $y$, come nel grafico in basso: con una scala lineare, non si riesce a valutare la velocità di convergenza dei metodi se non nelle primissime iterazioni, perché poi è tutto schiacciato sullo zero.

La seconda osservazione che possiamo fare è che nel secondo grafico i punti sono approssimativamente allineati secondo una retta. Vediamo perché questo succede.

\paragraph{Convergenza lineare} L'esempio più semplice che possiamo fare è quello in cui $e_n$ è una successione geometrica:
\[
e_0 = a,\, e_1 = ar,\, e_2 = ar^2,\, e_3 = ar^3, \dots
\]
Ad ogni passo, l'errore precedente viene moltiplicato per $r$. Ovviamente dobbiamo chiedere che $r < 1$, altrimenti $e_n$ non converge a $0$. In un grafico con scala logaritmica sulle $y$ (come quello della Figura~\ref{fig:iterativi}), la successione $e_k$ corrisponde a punti allineati lungo una retta di coefficiente angolare $\log r$ (che è negativo se $r<1$): difatti la differenza tra le ordinate di due punti successivi è il valore costante $\log e_{n+1} - \log e_n = \log r < 0$.

Molti metodi hanno un comportamento simile a questo al limite, quindi introduciamo una definizione che formalizza questo comportamento. Diciamo che un metodo iterativo \emph{converge linearmente} (o ha \emph{ordine di convergenza $1$}) quando
\begin{equation} \label{tassoconv}
    \lim_{n \to \infty }\frac{e_{n+1}}{e_n} = r \in (0,1).    
\end{equation}
Questo vuol dire che per $n$ sufficientemente grande (la~\eqref{tassoconv} contiene un simbolo di limite!) la successione degli errori si comporta come una successione geometrica. Questo corrisponde al comportamento che vediamo nel grafico per alcune delle successioni nella figura~\ref{fig:iterativi}: a parte i primissimi, i punti tendono ad essere allineati.

La convergenza è più veloce quanto più piccolo è $r$, che si chiama \emph{tasso di convergenza}; in inglese \emph{convergence rate}. Più informalmente, spesso si parla di \emph{velocità di convergenza} maggiore o minore.

Attenzione: se la~\eqref{tassoconv} vale con $r>1$, allora vuol dire che gli errori si comportano come una successione geometrica di ragione $>1$; quindi in particolare non vanno a zero. Se il limite nella~\eqref{tassoconv} vale $r=1$, può voler dire o che la successione converge a zero molto lentamente (ad esempio, $e_n = 1/n$), o che non converge proprio a zero. Questo può succedere perché abbiamo identificato erroneamente la radice $\alpha$ a cui si ha convergenza, come in questo esempio.
\begin{esempio}
    Per calcolare $\alpha = \sqrt{2}$, consideriamo il metodo di punto fisso $x_{n+1} = x + \frac{1}{2} (x^2-2)$, con $x_0 = -2$. Se calcoliamo con Matlab gli errori $e_n = \abs{x_n - \alpha}$ prodotti dal metodo, otteniamo
    \begin{lstlisting}
3.4142    2.4142    2.9142    2.7892    2.8439    2.8219    
2.8311    2.8273    2.8289    2.8282    2.8285    2.8284
2.8284    2.8284    2.8284    2.8284    ...
    \end{lstlisting}
    Notiamo che gli errori non stanno convergendo a zero. I valori assunti da $\frac{e_{n+1}}{e_n}$ sono
\begin{lstlisting}
0.5000    1.5000    0.9167    1.0398    0.9846    1.0065    
0.9973    1.0011    0.9995    1.0002    0.9999    1.0000
1.0000    1.0000    1.0000    1.0000    ...
\end{lstlisting}
In particolare questi numeri mostrano che $\frac{e_{n+1}}{e_n}$ converge a $r=1$, nella pratica. Questo succede perché in realtà la successione $x_k$ converge non a $\alpha = \sqrt{2}$, ma all'altra soluzione dell'equazione $x^2-2=0$, che è $-\sqrt{2}$.
\end{esempio}

\paragraph{Tasso di convergenza del metodo di punto fisso} Riprendendo il calcolo fatto nell'equazione~\eqref{fpindu2}, abbiamo
\[
\lim_{n \to \infty} \frac{\abs{x_{n+1} - \alpha}}{\abs{x_n - \alpha}} = \lim_{n\to\infty} \abs{\Phi'(\xi_n)} = \abs{\Phi'(\alpha)} \in [0,1).
\]
L'ultima uguaglianza vale perché abbiamo $0 \leq \abs{\xi_n - \alpha} \leq \abs{x_n - \alpha}$, e quindi $\xi_n \to \alpha$ per il teorema dei carabinieri. Inoltre usiamo il fatto che $x \mapsto \abs{\Phi'(x)}$ è una funzione continua, per dire che se $\xi_n\to\alpha$ allora $\abs{\Phi'(\xi_n)} \to \abs{\Phi'(\alpha)}$. Questa formula ci dice che il metodo del punto fisso ha tasso di convergenza $r = \abs{\Phi'(\alpha)}$.

Quindi quando $\abs{\Phi'(\alpha)}<1$ il metodo del punto fisso ha convergenza \emph{almeno lineare}. Diciamo ``almeno'', perché può succedere che $\abs{\Phi'(\alpha)} = 0$. In questo caso, si ha quindi anche
\[
    \lim_{n\to\infty} \frac{e_{n+1}}{e_n} = 0.
\]
Questo comportamento implica una convergenza più veloce di quella di qualunque retta su un grafico in scala logaritmica: per ogni $r>0$ si ha da un certo $n$ in poi $\frac{e_{n+1}}{e_n} < r$, e quindi la successione degli errori va a zero più velocemente di una retta di pendenza $\log r$. Questo per qualunque $r$; per esempio, i punti potrebbero formare una parabola con la concavità verso il basso, o un'altra curva la cui derivata tende a $-\infty$. Quando una successione soddisfa $\lim \frac{e_{n+1}}{e_n} = 0$, si dice che ha convergenza \emph{superlineare}. Un esempio è la quarta successione in Figura~\ref{fig:iterativi}, che difatti converge più velocemente degli altri metodi. Studieremo questo metodo nel dettaglio più avanti.

\begin{esercizio}
    Consideriamo il metodo del punto fisso applicato a una funzione lineare $\Phi(x) = mx + q$. Quanto vale il tasso di convergenza $r$?
\end{esercizio}
\begin{esercizio}
    Quanto vale $r$ per i diversi metodi del punto fisso studiati più sopra per $f(x) = x^3 - 2$?
\end{esercizio}
\begin{esercizio}
    Supponiamo di avere una funzione con uno zero $\alpha = 1$, e di avere un metodo numerico che produce una successione $x_k$ che converge invece a $\lim x_k = 2$ (per esempio, per un errore di programmazione). Quanto vale il limite $r$ in~\eqref{tassoconv}?
\end{esercizio}
Dall'esercizio precedente, ricaviamo che $r \geq 1$ può essere un'indicazione che il metodo non sta convergendo, o sta convergendo alla soluzione sbagliata!

\paragraph{Tasso di convergenza del metodo di bisezione}

Nel caso del metodo di bisezione, non riusciamo a dimostrare una convergenza secondo la definizione~\eqref{tassoconv}. Difatti può anche succedere che l'errore $e_k$ cresca da un passo all'altro: è facile costruire una situazione in cui lo zero $\alpha$ è più vicino a $c_k$ che a $c_{k+1}$. Ne abbiamo visto un esempio proprio quando abbiamo visto il nostro primo esempio per calcolare $\alpha=\sqrt{2}$: applicando il metodo di bisezione a quel problema, $\alpha=\sqrt{2}$ è più vicino a $c_2=1.5$ che a $c_3=1.25$. Il comportamento non monotono si vede chiaramente anche nella Figura~\ref{fig:iterativi}.

Riusciamo però a dimostrare che $e_n \leq \varepsilon_n$, dove $\varepsilon_n$ è una successione che converge linearmente: difatti abbiamo visto che
\[
e_n \leq \underbrace{\frac{b_0 - a_0}{2^{n+1}}}_{=\varepsilon_n},
\]
e
\[
\lim_{n\to\infty} \frac{\varepsilon_{n+1}}{\varepsilon_n} = \lim_{n\to\infty} \frac{1}{2} = \frac{1}{2}.
\]
Diciamo allora che il metodo di bisezione ha \emph{convergenza pressoché lineare}. Su un grafico in scala logaritmica, gli errori $e_n$ stanno al di sotto della retta data dai punti $\varepsilon_n$, e solitamente non se ne discostano troppo. Questo è confermato anche dalla nostra figura.

\paragraph{Criteri di arresto per il metodo del punto fisso}

Per un metodo come quello del punto fisso, il criterio di arresto più usato è quello di fermarsi quando due iterate successive sono vicine, cioè $\abs{x_{n} - x_{n-1}} < \varepsilon$. È importante però osservare che questo non garantisce che $\abs{x_n - \alpha} < \varepsilon$, quando $r$ è vicino a $1$ e la convergenza è lenta. Vediamo un esempio nella figura qui sotto.

\begin{figure}[H]
\centering
    \begin{tikzpicture}[scale=0.5]
    \draw [->, very thick] (-2,0) -- (12,0);
    \fill (10,0) node[below] {$\mathstrut x_0$} circle (3pt);
    \fill (9,0) node[below] {$\mathstrut x_1$} circle (3pt);
    \fill (8.1,0) node[below] {$\mathstrut x_2$} circle (3pt);
    \fill (7.29,0) node[below] {$\mathstrut x_3$} circle (3pt);
    \fill (6.561,0) node[below] {$\mathstrut x_4$} circle (3pt);
    \fill (5.9049,0) node[below] {$\mathstrut x_5$} circle (3pt);
    \foreach \k in {6,...,100} {
        \fill ({10*pow(0.9,\k)},0) circle (3pt);
    }
    \fill[red] (0,0) node[below,red] {$\mathstrut \alpha$} circle (3pt);
\end{tikzpicture}
    \caption{Una successione di punti che convergono ad $\alpha$ con tasso di convergenza $r = 0.9$. Osserviamo che anche quando $\abs{x_{k+1}-x_k}$ è piccolo (per esempio per $k=4$), l'errore $e_k = \abs{x_k-\alpha}$ è molto più grande.}
\end{figure}

\begin{esercizio}
    L'esempio della figura qui sopra è stato generato prendendo punti dati dalla formula $x_k = 10 \cdot 0.9^k$. Quanto vale il rapporto tra $\abs{x_{k+1}-x_k}$ e $\abs{x_k-\alpha}$ per questa successione? E per una successione geometrica generale $x_k = ar^k$ con tasso $r<1$?
\end{esercizio}



% Difatti, supponiamo per semplicità che le iterate si comportino esattamente come una successione geometrica, cioè $e_n = \abs{x_n-\alpha} = ar^n$ (almeno da un certo punto in poi). Supponiamo anche, per fissare le idee, che le iterate stiano convergendo ad $\alpha$ dal basso, cioè $x_{n-1} < x_{n} < \alpha$. Allora, $x_{n} - x_{n-1} = e_{n-1} - e_n = ar^{n-1} - ar^n = ar^{n-1}(1-r) = e_n \frac{1-r}{r}$. Se $r$ è molto vicino a $1$, $\frac{1-r}{r}$ è molto vicino a $0$. Quindi possiamo avere una situazione in cui $\abs{x_{n-1}-x_n} = e_n \frac{1-r}{r}$ è al di sotto di una certa soglia $\varepsilon$, ma l'errore vero $e_n$ è molto più grande.

% Quando $r$ è molto vicino a $1$, non solo il metodo converge lentamente, ma dobbiamo stare attenti a non arrestarlo troppo presto.


\paragraph{Vantaggi e svantaggi del metodo di punto fisso}

Svantaggi:
\begin{itemize}
    \item Convergenza non garantita se non in un intorno della soluzione. È difficile calcolare quanto è grande questo intorno: i teoremi non ci danno una formula facile da calcolare.
    \item Il criterio di arresto non garantisce un errore $\leq \varepsilon$.
\end{itemize}
Vantaggi del metodo:
\begin{itemize}
    \item A seconda della scelta della $\Phi$ (e quindi del valore di $r$), questo metodo può essere anche molto più veloce del metodo di bisezione.
    \item La convergenza è più regolare del metodo di bisezione, nel senso che la distanza da $\alpha$ scende sempre da un certo punto in poi. 
\end{itemize}


\section{Metodo di Newton}

Il \emph{metodo di Newton}, o \emph{metodo delle tangenti}, è un metodo per la ricerca di zeri che offre convergenza più veloce, ma richiede di utilizzare non solo $f \in \mathcal{C}^1([a,b])$, ma anche la sua derivata $f'$.

L'idea è una di quelle classiche dell'analisi: quando guardiamo ``abbastanza in piccolo'', ogni funzione derivabile è vicina alla sua retta tangente. Ad ogni passo, data un'approssimazione $x_n$ di una soluzione, otteniamo $x_{n+1}$ calcolando uno zero della \emph{retta tangente} al grafico di $f(x)$ in $x_n$. L'equazione della retta tangente è
\[
y = f(x_n) + f'(x_n) (x- x_n),
\]
quindi $x_{n+1}$ è il punto tale che
\[
0 = f(x_n) + f'(x_n) (x_{n+1}- x_n),
\]
ossia, risolvendo,
\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}.
\]

\begin{center}
\begin{tikzpicture}
    % Axes
    \draw[->] (-0.2,0) -- (8,0) node[right] {$x$};
    \draw[->] (0,-0.3) -- (0,3) node[above] {$y$};

    \draw[domain=0:8,smooth,variable=\x,blue, thick]
        plot ({\x},{0.03*(9-\x)^2 - 0.3});

    % Root
    \fill[red] (5.8377,0) circle (1.5pt) node[above,red] {$\alpha$};

    \node (x0) at (1,0) {};
    \node (x1) at (4.375,0) {};
    \node (x2) at (5.6064,0) {};
    \node (fx0) at (1,1.62) {};
    \node (fx1) at (4.375,0.3417) {};
    \node (fx2) at (5.6064,0.04592) {};

    % Newton iterates
    \fill (x0) circle (1.5pt) node[below] {$x_0$};
    \fill (x1) circle (1.5pt) node[below] {$x_1$};
    \fill (x2) circle (1.5pt) node[below] {$x_2$};

    % Function values
    \fill (fx0) circle (1.5pt) node[left] {$f(x_0)$};
    \fill (fx1) circle (1.5pt) node[right] {$f(x_1)$};

    % Vertical guides
    \draw[dashed] (x0) -- (fx0);
    \draw[dashed] (x1) -- (fx1);

    \draw[red,thick] (fx0) -- (x1);
    \draw[red,thick] (fx1) -- (x2);

\end{tikzpicture}
\end{center}

Il metodo di Newton quindi è definito dalla successione
\[
\begin{cases}
    x_0 \text{ dato},\\
    x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)} \quad n=0,1,2,\dots.
\end{cases}
\]
Il metodo di Newton quindi è un metodo di punto fisso con $\Phi(x) = x - \frac{f(x)}{f'(x)}$. Notiamo che questa funzione non è definita se $f'(x) = 0$: quando incontriamo un'iterata $x_n$ per cui si ha $f'(x_n) = 0$, il metodo di Newton non è applicabile, perché non riusciamo a calcolare l'iterata successiva.

Sotto l'ipotesi aggiuntiva $f'(\alpha) \neq 0$, riusciamo a dimostrare la convergenza locale del metodo di Newton.

\begin{theorem}
Sia $f \in \mathcal{C}^2([a,b])$, e sia $\alpha \in (a,b)$ tale che $f(\alpha) = 0$ e $f'(\alpha) \neq 0$. Allora, il metodo di Newton converge localmente: cioè, esiste un intervallo $I = [\alpha - \rho,\alpha + \rho]$ tale che per ogni successione generata dal metodo con $x_0 \in I$ si ha
\begin{itemize}
    \item $x_n \in I$ per ogni $n\geq 0$;
    \item $\lim_{n\to \infty } x_n = \alpha$.
\end{itemize}
\end{theorem}
\begin{proof}
Poiché $f'(\alpha) \neq 0$ e la funzione derivata $f'(x)$ è continua, in un intorno sufficientemente piccolo di $\alpha$, che possiamo prendere della forma $[\alpha-\hat{\rho}, \alpha+\hat{\rho}]$, si ha $f'(x) \neq 0$; quindi la funzione $\Phi(x)$ è ben definita. Inoltre, possiamo calcolare
\begin{equation} \label{Phiprime}
    \Phi'(x) = 1 - \frac{f'(x)f'(x) - f(x)f''(x)}{(f'(x))^2} = \frac{f(x)f''(x)}{(f'(x))^2};
\end{equation}
pertanto se $f'(\alpha) \neq 0$ abbiamo $\Phi'(\alpha) = 0$. Come nell'Osservazione~\ref{oss:corpuntofisso}, possiamo affermare che in un intorno sufficientemente piccolo di $\alpha$ avremo $\abs{\Phi'(x)} < 1$. Esiste quindi un intervallo $I = [\alpha-\rho,\alpha+\rho]$, con $\rho\leq \hat{\rho}$, in cui la $\Phi(x)$ esiste e $\abs{\Phi'(x)} < 1$ per ogni $x\in I$. In questo intervallo possiamo applicare il teorema del punto fisso e quindi ottenere la tesi.
\end{proof}
Poiché $r = \Phi'(\alpha)=0$, il metodo di Newton ha convergenza superlineare.

\paragraph{Vantaggi e svantaggi del metodo di Newton}
Svantaggi:
\begin{itemize}
    \item Richiede di conoscere non solo $f$ ma anche $f'$: con Matlab, tipicamente dovremo passare due funzioni anziché una.
    \item Costo computazionale maggiore: ad ogni passo, dobbiamo valutare $f$ e $f'$ una volta.
    \item La convergenza è garantita solo localmente, come per il metodo di punto fisso.
\end{itemize}
Vantaggi:
\begin{itemize}
    \item Nella maggior parte dei casi, converge molto più velocemente degli altri metodi.
\end{itemize}

Il comportamento che si osserva tipicamente con il metodo di Newton è un certo numero di iterazioni iniziali in cui l'errore non scende per nulla o quasi, e poi una convergenza molto veloce; appena $x_n$ si avvicina a $\alpha$ e l'errore $e_n$ va sotto una certa soglia, esso comincia ad andare a zero molto velocemente.

\paragraph{Ordine di convergenza di un metodo iterativo}

Abbiamo visto che il metodo di Newton ha convergenza superlineare, cioè, il limite $\lim_{n \to \infty }\frac{e_{n+1}}{e_n}$ è uguale a zero: questo vuol dire che la successione degli errori $e_n$ va a zero più velocemente di una serie geometrica, qualunque sia la sua ragione $r$. In un grafico in scala logaritmica, la differenza di ordinata tra due punti successivi $\log e_{n+1} - \log e_n$ tende a $-\infty$. Fissato un qualunque $r>0$, abbiamo che da un certo punto in poi $\lim_{n \to \infty }\frac{e_{n+1}}{e_n} < r$, e  questo vuol dire che la successione degli errori $e_n$ sta al di sotto di una retta con coefficiente angolare $\log r$. Questo significa che un metodo con convergenza superlineare converge sempre (al limite) più velocemente di un metodo lineare.

Per valutare la velocità di convergenza di metodi superlineari in modo più preciso, introduciamo un'altra definizione: dato un $p > 1$, diciamo che un metodo iterativo ha \emph{ordine di convergenza $p$} se vale
\[
\lim_{n \to \infty }\frac{e_{n+1}}{e_n^p} = s \in (0,\infty).
\]
Notare che non richiediamo che $s<1$, a differenza della convergenza lineare: basta che $s$ sia un limite finito, per ottenere un metodo con convergenza superlineare. Difatti, se un metodo ha ordine di convergenza $p>1$ allora per qualunque $s<\infty$ vale
\begin{equation} \label{almeno}
\lim_{n \to \infty }\frac{e_{n+1}}{e_n} = \lim_{n \to \infty }\frac{e_{n+1}}{e_n^p} \cdot \lim_{n \to \infty } e_n^{p-1} = s \cdot 0 = 0.
\end{equation}

\paragraph{Esempio} La successione $x_n = 3\cdot 10^{-2^n}$ converge a $0$ con ordine di convergenza $2$: difatti si ha
\[
\frac{e_{n+1}}{e_n^2} = \frac{3\cdot 10^{-2^{n+1}}-0}{(3\cdot 10^{-2^n} - 0)^2} = \frac{3\cdot 10^{-2^{n+1}}}{9\cdot 10^{-2^{n+1}}} = \frac13.
\]
I primi elementi della successione sono $x_0 = 3\cdot 10^{-1}$, $x_1 = 3\cdot 10^{-2}$, $x_2 = 3\cdot 10^{-4}$, $x_3 = 3\cdot 10^{-8}$, $x_4 = 3\cdot 10^{-16}$, cioè $x_n = 0,00\dots03$, dove prima del $3$ ci sono $2^n$ zeri in totale (incluso quello prima della virgola). Il numero di zeri raddoppia ad ogni passo, e questo fa sì che la successione converga molto più velocemente che non una successione che converge linearmente. In un grafico in scala logaritmica, gli errori tendono a scendere come un'esponenziale, e la distanza (in verticale) tra due punti successivi $\log e_{n+1} - \log e_n$ raddoppia ad ogni passo.

Diciamo che un metodo numerico converge con ordine \emph{almeno $p$} se vale
\[
\lim_{n \to \infty }\frac{e_{n+1}}{e_n^p} = s \in [0,\infty).
\]
Questa volta abbiamo incluso lo zero tra i possibili valori ammessi per $s$. Si può mostrare che questo concetto di ``convergenza di ordine almeno $k$'' si comporta come ci aspettiamo dall'uso della parola ``almeno'': se un metodo converge con ordine $k$, allora converge anche di ordine almeno $h$ per ogni $h\leq k$. (La dimostrazione di questo fatto, che non vediamo, è analoga alla~\eqref{almeno}.)

\paragraph{Convergenza quadratica} \begin{theorem}[Convergenza almeno quadratica del metodo di Newton]\label{thm:convnewton}
Supponiamo $f \in \mathcal{C}^2([a,b])$. Se il metodo di Newton converge a $\alpha \in (a,b)$ e se $f'(\alpha) \neq 0$ (cioè se $\alpha$ è uno \emph{zero semplice}), allora l'errore $e_n = \abs{x_n - \alpha}$ soddisfa
\[
\lim_{n\to \infty} \frac{e_{n+1}}{e_n^2} = s \in [0,\infty).
\]
(cioè questo limite esiste ed è finito.)
\end{theorem}

\begin{proof}
Usiamo uno sviluppo di Taylor (con resto di Lagrange) in $x_n$ per scrivere l'uguaglianza
\begin{equation} \label{sviluppo Taylor per dimostrazione conv. quadratica Newton}
    0 = f(\alpha) = f(x_n) + f'(x_n)(\alpha-x_n) + \frac{f''(\xi_n)}{2}(\alpha-x_n)^2    
\end{equation}
che vale per uno $\xi_n$ compreso tra $\alpha$ e $x_n$.

Dividiamo per $f'(x_n)$ per ottenere
\[
\frac{f''(\xi_n)}{2f'(x_n)}(\alpha-x_n)^2 = - \frac{f(x_n)}{f'(x_n)} - \alpha + x_n   =  x_{n+1} - \alpha.
\]
Allora
\[
\frac{x_{n+1} - \alpha}{(x_n-\alpha)^2} = \frac{f''(\xi_n)}{2f'(x_n)}.
\]
Questa uguaglianza può essere scritta per ogni $n$ (con un valore diverso di $\xi_n$). Vogliamo ora passare al limite per $n \to \infty$. Come già detto sopra, sappiamo che $0 \leq \abs{\xi_n - \alpha} \leq \abs{x_n - \alpha}$, da cui per il teorema dei carabinieri concludiamo che $\abs{\xi_n - \alpha} \to 0$ e quindi $\xi_n \to \alpha$. Allora, per la continuità di queste funzioni, $f''(\xi_n) \to f''(\alpha)$ e $f'(x_n) \to f'(\alpha)$ (che è diverso da zero); quindi
\[
\lim_{n\to\infty} \frac{x_{n+1} - \alpha}{(x_n-\alpha)^2} = \lim \frac{f''(\xi_n)}{2f'(x_n)} = \frac{f''(\alpha)}{2f'(\alpha)} = s \in [0,\infty).
\]
\end{proof}

\paragraph{Criterio di arresto} Come per il metodo di bisezione, un criterio di arresto euristico per il metodo di Newton è: fermiamoci quando $\abs*{\frac{f(x_n)}{f'(x_n)}} \leq \varepsilon$; ci aspettiamo (senza garanzie!) che questo avvenga quando $\abs{x_n - \alpha} \leq \varepsilon$. Per come è definito il metodo, questo equivale a $\abs{x_n - x_{n+1}} \leq \varepsilon$, cioè, ci fermiamo quando due iterate successive sono abbastanza vicine: questo è il criterio di arresto che avevamo visto anche per il metodo del punto fisso. Avevamo visto che questo criterio funziona male se $r\approx 1$, ma nel caso del metodo di Newton $r=0$, quindi non abbiamo questo problema.

\begin{conditional}[inf]
\paragraph{Convergenza su intervalli}
C'è un risultato che ci permette di concludere la convergenza del metodo di Newton su un intero intervallo, senza la condizione scomoda da verificare che il punto iniziale sia ``abbastanza vicino''. Questa volta per applicare il teorema dobbiamo usare un intervallo in cui lo zero $\alpha$ sia un estremo della funzione.
\begin{theorem}[Convergenza su intervalli del metodo di Newton]
    Sia $f$ una funzione di classe $\mathcal{C}^2$ su un intervallo $I = [a,b]$. Supponiamo che:
    \begin{itemize}
        \item $f$ abbia un solo zero $\alpha$ in un estremo dell'intervallo ($\alpha=a$ o $\alpha=b$).
        \item $f(x)f''(x) \geq 0$ su tutti i punti dell'intervallo.
    \end{itemize}
    Allora, a partire da qualunque $x_0 \in [a,b]$ si ha $x_k \in I$ e $\lim_{k\to\infty} x_k = \alpha$.
\end{theorem}
\begin{proof}
Visto che $f$ è continua e non ha altri zeri all'interno di $I$, dev'essere sempre positiva o sempre negativa. Quindi ci sono quattro situazioni possibili:
\begin{enumerate}
    \item $\alpha=a$, $f(x)>0, f''(x) \geq 0$ in tutti i punti di $(\alpha,b]$;
    \item $\alpha=a$, $f(x)<0, f''(x) \leq 0$ in tutti i punti di $(\alpha,b]$;
    \item $\alpha=b$, $f(x)>0, f''(x) \geq 0$ in tutti i punti di $[a,\alpha)$;
    \item $\alpha=b$, $f(x)<0, f''(x) \leq 0$ in tutti i punti di $[a,\alpha)$.
\end{enumerate}
Trattiamo solo il primo: gli altri sono analoghi, anche perché si ottengono dal primo riflettendo il grafico rispetto all'asse $x$ 
e/o all'asse $y$.

Innanzitutto, dimostriamo per induzione che per ogni $n=0,1,2,\dots$ si ha $x_n \in I$. Il caso base $x_0 \in I$ è vero per ipotesi; quindi assumiamo $x_n\in I$ e dimostriamo $x_{n+1}\in I$. Consideriamo l'equazione che definisce la retta tangente in $x_n$,
\[
y = T(x) = f(x_n) + f'(x_n)(x-x_n).
\]
Ricordiamo lo sviluppo di Taylor~\eqref{sviluppo Taylor per dimostrazione conv. quadratica Newton}
\[
0 = f(\alpha) = f(x_n) + f'(x_n)(\alpha-x_n) + \frac{f''(\xi_n)}{2}(\alpha-x_n)^2,
\]
che vale uno $\xi_n$ compreso tra $\alpha$ e $x_n$. Per le nostre ipotesi, $\frac{f''(\xi_n)}{2}(\alpha-x_n)^2 \geq 0$, quindi $f(x_n) + f'(x_n)(\alpha-x_n) = T(\alpha) \leq 0$. Poiché invece $T(x_n) = f(x_n) \geq 0$, il punto $x_{n+1}$ in cui la retta incrocia l'asse delle ascisse è compreso tra $\alpha$ e $x_n$; quindi in particolare $x_{n+1} \in I$. Questo completa la dimostrazione per induzione.

Quello che abbiamo scritto dimostra anche qualcosa di più forte: $x_{n+1} \leq x_n$ per ogni $n$. Ciò significa che la successione $x_n$ è decrescente; in particolare quindi converge, e il suo limite è necessariamente $\alpha$ perché è l'unico zero in $I$.
\end{proof}
\end{conditional}


\paragraph{Zeri di molteplicità superiore a 1} Cosa succede al metodo di Newton se la funzione a cui lo applichiamo ha $f'(\alpha) = 0$? Introduciamo innanzitutto una definizione: data una funzione $f\in\mathcal{C}^m$, diciamo che \emph{$f$ ha uno zero di molteplicità $m$ in $\alpha$} se vale
\[
f(\alpha) = f'(\alpha) = f''(\alpha) = \dots = f^{(m-1)}(\alpha) = 0, \quad \text{ ma } f^{(m)}(\alpha) \neq 0.
\]

Esempio: la funzione $f(x)=x^2$ ha uno zero in $\alpha=0$ di molteplicità $m=2$.

Esempio: la funzione $f(x) = \sin(2x) - 2\sin(x)$ ha uno zero di molteplicità $3$ in $x=2\pi$. Difatti,
\begin{align*}
    f(\alpha) &= \sin(2\alpha) - 2\sin(\alpha) = 0 - 0 = 0,\\
    f'(\alpha) &= 2\cos(2\alpha) - 2\cos(\alpha) = 2 - 2 = 0,\\
    f''(\alpha) &= -4\sin(2\alpha) +2\sin(\alpha) = -0 + 0 = 0,\\
    f'''(\alpha) &= -8\cos(2\alpha) +2\cos(\alpha) = -8 + 2 \neq 0.
\end{align*}

È possibile dimostrare che questa definizione di molteplicità restituisce lo stesso risultato di quella che già conoscete per i polinomi: se un polinomio si fattorizza come
\[
    p(x) = (x-\alpha)^m g(x),
\]
dove $g(x)$ è il prodotto di tutti gli altri fattori di grado $1$ diversi da $(x-\alpha)$, allora $\alpha$ è uno zero di molteplicità $m$. Però la nostra definizione è più generale, in quanto si applica anche a funzioni che non sono polinomi.

È possibile anche dimostrare una fattorizzazione simile a quella che si ha per i polinomi.
\begin{lemma}
Se $f\in\mathcal{C}^m([a,b])$ ha uno zero di molteplicità $m$ in $\alpha \in (a,b)$, allora si ha $f(x) = (x-\alpha)^m g(x)$, dove $g(x)$ è una funzione continua in $[a,b]$ con $g(\alpha) \neq 0$.
\end{lemma}
\begin{proof}
Definiamo $g(x) = \frac{f(x)}{(x-\alpha)^m}$. Questa funzione è definita su tutto $[a,b]$ tranne che in $x=\alpha$, dove si annulla il denominatore. Possiamo però estenderla per continuità. Per farlo, dobbiamo mostrare che esiste ed è finito il limite
\[
\lim_{x\to \alpha} \frac{f(x)}{(x-\alpha)^m}.
\]
Per calcolare questo limite, utilizziamo $m$ volte il teorema di De l'Hopital: 
\begin{align} \label{hop1}
\lim_{x\to \alpha} \frac{f(x)}{(x-\alpha)^m} &= \lim_{x\to \alpha} \frac{f'(x)}{m(x-\alpha)^{m-1}} = \lim_{x\to \alpha} \frac{f''(x)}{m(m-1)(x-\alpha)^{m-2}} = \dots \\
&= \lim_{x\to \alpha} \frac{f^{(m)}(x)}{m!\cdot 1} = \frac{f^{(m)}(\alpha)}{m!} = C\neq 0.
\end{align}
(Tutti i limiti tranne l'ultimo sono della forma $\frac{0}{0}$.)
Quindi possiamo definire
\[
    g(x) = \begin{cases}
        \frac{f(x)}{(x-\alpha)^m} & x\neq \alpha,\\
        C & x=\alpha.
    \end{cases}
\]
In questo modo la funzione $g(x)$ è continua su tutto $[a,b]$, ha $g(\alpha)\neq 0$, e soddisfa $f(x) = (x-\alpha)^m g(x)$, come richiesto.
\end{proof}
Dalla riga~\eqref{hop1} segue anche che
\begin{equation} \label{limnotevoli}
\lim_{x\to\alpha} \frac{f(x)}{(x-\alpha)^{m}} = C, \quad \lim_{x\to\alpha} \frac{f'(x)}{(x-\alpha)^{m-1}} = Cm, \quad \lim_{x\to\alpha} \frac{f''(x)}{(x-\alpha)^{m-2}} = Cm(m-1).    
\end{equation}
Usando questi tre limiti, possiamo dimostrare che se $\alpha$ è uno zero di molteplicità $m>1$, la convergenza del metodo di Newton è più lenta.
\begin{theorem}
    Sia $f(x) \in \mathcal{C}^m([a,b])$ una funzione con uno zero $\alpha \in (a,b)$ di molteplicità $m>1$.
    Allora, il metodo di Newton converge localmente ad $\alpha$, e la sua velocità di convergenza è lineare con tasso $\frac{m-1}{m}$.
\end{theorem}
\begin{proof}
Vogliamo applicare di nuovo i risultati di convergenza locale del metodo di punto fisso; questa volta però ci scontriamo con il problema che la funzione $\Phi(x) = x - \frac{f(x)}{f'(x)}$ non è definita in $x=\alpha$, perché il denominatore si annulla.

Possiamo però estendere anche questa funzione per continuità, cioè definire
\[
\Phi(x) = \begin{cases}
    x - \frac{f(x)}{f'(x)} & x\neq \alpha,\\
    \alpha & x=\alpha,
\end{cases}
\]
in modo appunto che $\alpha$ sia un punto fisso. Ci serve però che $\Phi$ sia di classe $\mathcal{C}^1$, quindi dobbiamo verificare due cose:
\begin{itemize}
    \item che $\Phi$ sia derivabile in $x=\alpha$, cioè che esiste il limite
    \[
        \lim_{x\to\alpha} \frac{\Phi(x)-\alpha}{x-\alpha};
    \]
    questo assicura automaticamente anche che $\Phi$ è continua in $\alpha$;
    \item che la derivata $\Phi'$ sia una funzione continua, cioè
    \[
        \lim_{x\to\alpha} \Phi'(x) = \Phi'(\alpha).
    \]
\end{itemize}
Partiamo dalla prima. Vogliamo utilizzare i primi due limiti calcolati in~\eqref{limnotevoli}, quindi dividiamo numeratore e denominatore per $(x-\alpha)^m$:
\begin{align*}
    \Phi'(\alpha) = \lim_{x\to\alpha} \frac{\Phi(x)-\alpha}{x-\alpha} &= \lim_{x\to\alpha} \frac{x - \frac{f(x)}{f'(x)}-\alpha}{x-\alpha}\\
    &= \lim_{x\to\alpha} 1 - \frac{f(x)}{f'(x)(x-\alpha)}\\
    &= 1 - \lim_{x\to\alpha}  \frac{\frac{f(x)}{(x-\alpha)^m}}{\frac{f'(x)(x-\alpha)}{(x-\alpha)^m}}\\
    & = 1 - \frac{C}{Cm} = \frac{m-1}{m}.
\end{align*}
Usando questa derivata e la~\eqref{Phiprime}, otteniamo 
\begin{align*}
    \lim_{x\to\alpha} \Phi'(x) &= \lim_{x\to\alpha} \frac{f(x)f''(x)}{(f'(x))^2}\\
    &= \lim_{x\to\alpha} \frac{\frac{f(x)}{(x-\alpha)^m}\cdot \frac{f''(x)}{(x-\alpha)^{m-2}}}{\left(\frac{f'(x)}{(x-\alpha)^{m-1}}\right)^2}\\
    &= \frac{C \cdot Cm(m-1)}{(Cm)^2} = \frac{m-1}{m} = \Phi'(\alpha).
\end{align*}
Nei passaggi, abbiamo diviso numeratore e denominatore per $(x-\alpha)^{2m-2}$.

Quindi è possibile estendere $\Phi(x)$ a una funzione di classe $\mathcal{C}^1$ con $\Phi(\alpha)=\alpha$ e $\Phi'(\alpha) = \frac{m-1}{m} < 1$. Allora, per il teorema del punto fisso, il metodo di Newton converge (localmente) linearmente con tasso $\frac{m-1}{m}$.
\end{proof}

\paragraph{Metodo di Newton modificato} Data una funzione $f$ che ha uno zero di molteplicità $m$ in $\alpha$, abbiamo visto che la funzione
\[
    \Phi(x) = x - \frac{f(x)}{f'(x)},
\]
una volta estesa per continuità, soddisfa
\[
    \Phi'(\alpha) = 1 - \frac{1}{m}.
\]
%%%
% definire in generale un metodo di Newton con un parametro in più, e dire che se è uguale alla molteplicità viene superlineare?
%%%
Questo suggerisce di fare una modifica al metodo: se definiamo
\[
    \Phi_m(x) = x - m \frac{f(x)}{f'(x)}
\]
allora avremo
\[
    \Phi_m'(\alpha) = 1 - m\frac{1}{m} = 0.
\]

Quindi se il valore della molteplicità $m$ è noto a priori possiamo utilizzare il seguente (\emph{metodo di Newton modificato}):
\begin{equation} \label{newtonmod}
    x_{n+1} = \underbrace{x_n - m\frac{f(x_n)}{f'(x_n)}}_{:=\Phi_m(x_n)} \quad n = 0,1,2,\dots    
\end{equation}
Si può dimostrare, con passaggi simili a quelli precedenti, che questo metodo converge (localmente) con ordine almeno 2, quando viene applicato a una funzione che ha uno zero di molteplicità $m$.

\paragraph{Esercizi}

Esempio: metodo di Newton su una funzione lineare $f(x) = a x + b$: ha convergenza in un passo.

Esempio: metodo di Newton su $f(x) = x^2-a$: è anche un metodo per calcolare radici quadrate a mano. Per esempio, calcolando $\sqrt{17}$ con $x_0 = 4$, già $x_2$ ha 5 cifre significative esatte.

Esempio: metodo di Newton su $f(x) = x^2$: lo zero è di ordine 2, e la convergenza diventa lineare con ragione $\frac12$.

Esempio: metodo di Newton modificato su $f(x) = x^2$ per recuperare convergenza quadratica (converge di nuovo in un passo).

\section{Varianti del metodo di Newton} Non sempre si ha a disposizione (in modo facile da calcolare) la derivata della funzione $f$. Per questo esistono alcune varianti del metodo di Newton che cercano di evitare di calcolare derivate.
\begin{description}
    \item[Metodo delle corde] Si ottiene rimpiazzando la derivata $f'(x_n)$ con un valore costante fissato $c$:
        \[
            \begin{cases}
                \text{$x_0$ dato},\\
                x_{n+1} = x_n - \frac{f(x_n)}{c}, \quad n=0,1,2,\dots.
            \end{cases}
        \]    
    Per esempio, si può prendere $c = f'(x_0)$, se lo si conosce; questo richiede di calcolare la $f'$ una volta sola anziché una volta per passo come nel metodo di Newton. Geometricamente, questo metodo corrisponde a rimpiazzare le rette tangenti che si usano nel metodo di Newton con rette che hanno coefficiente angolare costante $c$. Un esempio di questo metodo è l'iterazione di punto fisso che abbiamo già studiato $x_{k+1} = x_{k} - \frac14 (x_k^3-2)$, dove la $c$ vale $4$. 
    
    Anche il metodo delle corde è un metodo di punto fisso, con $\Phi(x) = x - \frac{1}{c}f(x)$, quindi possiamo studiarne la convergenza locale con le tecniche che abbiamo visto: $\Phi'(x) = 1 - \frac{1}{c}f'(x)$, e per avere $\abs{\Phi'(\alpha)} < 1$ dobbiamo scegliere $c$ in modo che $f'(\alpha) \in (0,2c)$.
    \item[Metodo delle secanti] È l'iterazione che si ottiene rimpiazzando, nel metodo di Newton, $f'(x_n)$ con il rapporto incrementale calcolato sugli ultimi due punti,
    \[
    \frac{f(x_n) - f(x_{n-1})}{x_n - x_{n-1}}.
    \]
    In questo modo si rimpiazza la derivata con una sua approssimazione più economica da calcolare: abbiamo già calcolato $f(x_n)$ e $f(x_{n-1})$ nei passi precedenti del metodo, quindi dobbiamo fare solo due sottrazioni e una divisione (che in realtà diventa una moltiplicazione, quando si va a scrivere il metodo per esteso). 
    
    Per applicare il metodo delle secanti, serve partire da \emph{due} punti iniziali $x_0$ e $x_1$:
    \[
    \begin{cases}
        \text{$x_0$, $x_1$ dati},\\
        x_{n+1} = x_n - \frac{f(x_n) (x_n - x_{n-1})}{f(x_n) - f(x_{n-1})}, \quad n=1,2,\dots.
    \end{cases}
    \]
    Anche questo metodo converge localmente, e il suo ordine di convergenza (sotto opportune ipotesi sulla funzione) è $p = \frac{1+\sqrt{5}}{2} \approx 1.618$. Non dimostriamo quest'ultimo risultato, che è più complesso: difatti questo non è un metodo del tipo $x_{n+1} = \Phi(x_n)$, perché ogni valore dipende dalle \emph{due} iterate precedenti. 
    

\end{description}

% [Note per lezione Matlab:
% \begin{itemize}
%     \item Descrizione sintassi vettori e matrici: \lstinline{A = [1 2;3 4]}
%     \item Accesso elementi con \lstinline{A(1,2)}. Accesso elementi oltre i limiti.
%     \item \lstinline{size(), length()} 
%     \item Plot: esempio con plot della funzione quadrato.
%     \item Remark che esiste \lstinline{1:n} già fatto.
%     \item Funzioni già pronte per bisezione, punto fisso, Newton. Provarle su $f(x) = x^2 - 2$.
%     \item Calcolo dell'errore come \lstinline{abs(xs - sqrt(2))}.
%     \item Grafici in scala logaritmica.
% \end{itemize}
% ]

% \section{Condizionamento del problema della ricerca di zeri}

% Studiare il condizionamento di questo problema ci richiede di cambiare un po' le nostre definizioni, perché il suo ``input'' non è un numero ma una funzione $f$. Supponiamo qui che invece di ricevere in ``ingresso'' $f$ riceviamo una funzione $g$ che soddisfa $\max |g-f| \leq \delta$ (disegno). Può darsi che una piccola perturbazione sia sufficiente a trasformare un problema risolubile in uno non risolubile; per esempio se $f(x) = x^2$ e $g(x) = x^2 + \varepsilon$.

% Sia $\alpha$ uno zero di $f$. Supponiamo che $f$ sia derivabile con $f'(\alpha) \neq 0$, quindi ``taglia'' l'asse delle ascisse trasversalmente (ed è invertibile in un intorno di $\alpha$).

% Uno zero $\tilde{x}$ di $g$ (se c'è) deve stare per forza tra $f^{-1}(-\delta)$ e $f^{-1}(\delta)$. Sviluppando al primo ordine (e ricordando la derivata della funzione inversa),
% \[
% f^{-1}(\alpha + \delta) = f^{-1}(\alpha) + \delta\frac{1}{f'(\alpha)} + \mathcal{O}(\delta^2)
% \]
% Quindi $f^{-1}(\delta) - \alpha \doteq \frac{1}{f'(\alpha)}\delta$. Rifacendo lo stesso ragionamento su $-\delta$, si ha $f^{-1}(-\delta) - \alpha \doteq -\frac{1}{f'(\alpha)}\delta$, quindi
% \[
% \abs{\tilde{x} - \alpha} \stackrel{.}{\leq} \frac{1}{\abs{f'(\alpha)}} \delta.
% \]

% Per parlare di ``numero di condizionamento'' nello stesso senso usato sopra, ci serve parlare di errori \emph{relativi} sia sulla $\alpha$ che sulla $f$. Un modo di farlo è questo: scriviamo $M = \max_{[a,b]} |f|$, consideriamo una perturbazione $g$ tale che $\abs{f-g} \leq \varepsilon M$ (il nostro input), e chiamiamo $\tilde{x}$ uno zero della $f$ (il nostro output). Allora,
% \[
% \abs*{\frac{\tilde{x} - \alpha}{\alpha}}  \stackrel{.}{\leq} \frac{M}{\abs{\alpha f'(\alpha)}}.
% \]

\chapter{Aritmetica di macchina}

Se provate a implementare i metodi precedenti su un computer con Matlab, noterete in molti casi un comportamento abbastanza particolare: i metodi spesso smettono di convergere attorno a $10^{-15}$ o $10^{-16}$, come accade nella Figura~\ref{fig:stagnazione}. Per comprendere cosa sta succedendo, dobbiamo studiare come i numeri reali vengono rappresentati in un computer.

\begin{figure}
    \begin{center}
        \begin{tikzpicture}
        \begin{axis}[width=\textwidth, ymode = log, xlabel={iterazione}, ylabel={errore (in scala logaritmica)}, legend style={at={(0.5,-0.15)},anchor=north}]
            \addplot+[x=it, y=e] table{
                it e

                1.0000e+00   2.5992e-01
                2.0000e+00   4.9008e-01
                3.0000e+00   2.3298e-01
                4.0000e+00   3.0730e-02
                5.0000e+00   2.8083e-02
                6.0000e+00   2.0157e-02
                7.0000e+00   1.7687e-02
                8.0000e+00   1.3288e-02
                9.0000e+00   1.1349e-02
                1.0000e+01   8.7614e-03
                1.1000e+01   7.3487e-03
                1.2000e+01   5.7697e-03
                1.3000e+01   4.7814e-03
                1.4000e+01   3.7945e-03
                1.5000e+01   3.1195e-03
                1.6000e+01   2.4928e-03
                1.7000e+01   2.0385e-03
                1.8000e+01   1.6362e-03
                1.9000e+01   1.3334e-03
                2.0000e+01   1.0734e-03
                2.1000e+01   8.7269e-04
                2.2000e+01   7.0387e-04
                2.3000e+01   5.7139e-04
                2.4000e+01   4.6143e-04
                2.5000e+01   3.7421e-04
                2.6000e+01   3.0244e-04
                2.7000e+01   2.4511e-04
                2.8000e+01   1.9821e-04
                2.9000e+01   1.6057e-04
                3.0000e+01   1.2989e-04
                3.1000e+01   1.0519e-04
                3.2000e+01   8.5111e-05
                3.3000e+01   6.8917e-05
                3.4000e+01   5.5769e-05
                3.5000e+01   4.5153e-05
                3.6000e+01   3.6542e-05
                3.7000e+01   2.9583e-05
                3.8000e+01   2.3943e-05
                3.9000e+01   1.9383e-05
                4.0000e+01   1.5688e-05
                4.1000e+01   1.2700e-05
                4.2000e+01   1.0279e-05
                4.3000e+01   8.3208e-06
                4.4000e+01   6.7350e-06
                4.5000e+01   5.4518e-06
                4.6000e+01   4.4129e-06
                4.7000e+01   3.5721e-06
                4.8000e+01   2.8914e-06
                4.9000e+01   2.3404e-06
                5.0000e+01   1.8944e-06
                5.1000e+01   1.5335e-06
                5.2000e+01   1.2413e-06
                5.3000e+01   1.0047e-06
                5.4000e+01   8.1328e-07
                5.5000e+01   6.5831e-07
                5.6000e+01   5.3287e-07
                5.7000e+01   4.3133e-07
                5.8000e+01   3.4914e-07
                5.9000e+01   2.8261e-07
                6.0000e+01   2.2876e-07
                6.1000e+01   1.8517e-07
                6.2000e+01   1.4989e-07
                6.3000e+01   1.2132e-07
                6.4000e+01   9.8206e-08
                6.5000e+01   7.9493e-08
                6.6000e+01   6.4345e-08
                6.7000e+01   5.2084e-08
                6.8000e+01   4.2160e-08
                6.9000e+01   3.4126e-08
                7.0000e+01   2.7623e-08
                7.1000e+01   2.2360e-08
                7.2000e+01   1.8099e-08
                7.3000e+01   1.4650e-08
                7.4000e+01   1.1859e-08
                7.5000e+01   9.5990e-09
                7.6000e+01   7.7699e-09
                7.7000e+01   6.2893e-09
                7.8000e+01   5.0909e-09
                7.9000e+01   4.1208e-09
                8.0000e+01   3.3356e-09
                8.1000e+01   2.7000e-09
                8.2000e+01   2.1855e-09
                8.3000e+01   1.7691e-09
                8.4000e+01   1.4320e-09
                8.5000e+01   1.1591e-09
                8.6000e+01   9.3823e-10
                8.7000e+01   7.5945e-10
                8.8000e+01   6.1474e-10
                8.9000e+01   4.9760e-10
                9.0000e+01   4.0278e-10
                9.1000e+01   3.2603e-10
                9.2000e+01   2.6390e-10
                9.3000e+01   2.1362e-10
                9.4000e+01   1.7291e-10
                9.5000e+01   1.3996e-10
                9.6000e+01   1.1329e-10
                9.7000e+01   9.1706e-11
                9.8000e+01   7.4231e-11
                9.9000e+01   6.0086e-11
                1.0000e+02   4.8637e-11
                1.0100e+02   3.9369e-11
                1.0200e+02   3.1867e-11
                1.0300e+02   2.5795e-11
                1.0400e+02   2.0880e-11
                1.0500e+02   1.6901e-11
                1.0600e+02   1.3681e-11
                1.0700e+02   1.1074e-11
                1.0800e+02   8.9637e-12
                1.0900e+02   7.2558e-12
                1.1000e+02   5.8733e-12
                1.1100e+02   4.7542e-12
                1.1200e+02   3.8483e-12
                1.1300e+02   3.1151e-12
                1.1400e+02   2.5218e-12
                1.1500e+02   2.0413e-12
                1.1600e+02   1.6525e-12
                1.1700e+02   1.3376e-12
                1.1800e+02   1.0827e-12
                1.1900e+02   8.7641e-13
                1.2000e+02   7.0965e-13
                1.2100e+02   5.7443e-13
                1.2200e+02   4.6518e-13
                1.2300e+02   3.7637e-13
                1.2400e+02   3.0465e-13
                1.2500e+02   2.4647e-13
                1.2600e+02   1.9962e-13
                1.2700e+02   1.6165e-13
                1.2800e+02   1.3078e-13
                1.2900e+02   1.0569e-13
                1.3000e+02   8.5487e-14
                1.3100e+02   6.9056e-14
                1.3200e+02   5.5733e-14
                1.3300e+02   4.5075e-14
                1.3400e+02   3.6415e-14
                1.3500e+02   2.9310e-14
                1.3600e+02   2.3759e-14
                1.3700e+02   1.9318e-14
                1.3800e+02   1.5765e-14
                1.3900e+02   1.2657e-14
                1.4000e+02   1.0214e-14
                1.4100e+02   8.2157e-15
                1.4200e+02   6.6613e-15
                1.4300e+02   5.5511e-15
                1.4400e+02   4.6629e-15
                1.4500e+02   3.7748e-15
                1.4600e+02   3.3307e-15
                1.4700e+02   2.6645e-15
                1.4800e+02   1.9984e-15
                1.4900e+02   1.5543e-15
                1.5000e+02   1.1102e-15
                1.5100e+02   8.8818e-16
                1.5200e+02   6.6613e-16
                1.5300e+02   6.6613e-16
                1.5400e+02   6.6613e-16
                1.5500e+02   6.6613e-16
                1.5600e+02   6.6613e-16
                1.5700e+02   6.6613e-16
                1.5800e+02   6.6613e-16
                1.5900e+02   6.6613e-16
                1.6000e+02   6.6613e-16
                1.6100e+02   6.6613e-16
                1.6200e+02   6.6613e-16
                1.6300e+02   6.6613e-16
                1.6400e+02   6.6613e-16
                1.6500e+02   6.6613e-16
                1.6600e+02   6.6613e-16
                1.6700e+02   6.6613e-16
                1.6800e+02   6.6613e-16
                1.6900e+02   6.6613e-16
                1.7000e+02   6.6613e-16
                1.7100e+02   6.6613e-16
                1.7200e+02   6.6613e-16
                1.7300e+02   6.6613e-16
                1.7400e+02   6.6613e-16
                1.7500e+02   6.6613e-16
                1.7600e+02   6.6613e-16
                1.7700e+02   6.6613e-16
                1.7800e+02   6.6613e-16
                1.7900e+02   6.6613e-16
                1.8000e+02   6.6613e-16
                1.8100e+02   6.6613e-16
                1.8200e+02   6.6613e-16
                1.8300e+02   6.6613e-16
                1.8400e+02   6.6613e-16
                1.8500e+02   6.6613e-16
                1.8600e+02   6.6613e-16
                1.8700e+02   6.6613e-16
                1.8800e+02   6.6613e-16
                1.8900e+02   6.6613e-16
                1.9000e+02   6.6613e-16
                1.9100e+02   6.6613e-16
                1.9200e+02   6.6613e-16
                1.9300e+02   6.6613e-16
                1.9400e+02   6.6613e-16
                1.9500e+02   6.6613e-16
                1.9600e+02   6.6613e-16
                1.9700e+02   6.6613e-16
                1.9800e+02   6.6613e-16
                1.9900e+02   6.6613e-16
                2.0000e+02   6.6613e-16            
        }; \addlegendentry{Punto fisso su $\Phi(x) = 2/x^2 + (x^3-2)/4$};
        \end{axis}
        \end{tikzpicture}
        \end{center}
    \caption{Stagnazione di un metodo iterativo attorno alla precisione di macchina.} \label{fig:stagnazione}
    \end{figure}    

\paragraph{Rappresentazione in base}

Scegliamo un intero $\beta > 1$ che sarà la \emph{base} della nostra rappresentazione. Questo teorema descrive la notazione scientifica che già conoscete:
\begin{theorem}[rappresentazione scientifica in base $\beta$]
Fissato un intero $\beta > 1$ (la \emph{base}), ogni numero reale $x\neq 0$ si può scrivere come
\begin{equation} \label{rapprbase}
    x = \pm \beta^p \sum_{i=0}^\infty c_i \beta^{-i},
\end{equation}
dove i $c_i$ (\emph{cifre}) sono interi $0 \leq c_i < \beta$.

Questa scrittura è unica se aggiungiamo le condizioni che $c_1 \neq 0$, e che $c_i$ non sono tutti uguali a $\beta-1$ da un certo punto in poi.
\end{theorem}
Per esempio, $x = -764.88888\dots$ (periodico) si scrive in base $\beta=10$ come
\[
x = - 10^2 (7\cdot 10^{0} + 6\cdot 10^{-1} + 4\cdot 10^{-2} + 8 \cdot 10^{-3} + 8 \cdot 10^{-4} + 8 \cdot 10^{-5} + \dots)
\]
Questo è un modo più prolisso di scrivere la notazione scientifica che già conosciamo: $x= -7.6488888\ldots \cdot 10^{2}$.

Terminologia: $p$ si chiama \emph{esponente} di $x$, la quantità nella sommatoria in~\eqref{rapprbase} si chiama \emph{mantissa}.

Non ci interessa qui dimostrare questo teorema: ``sappiamo che è vero'' fin dalla scuola primaria, e più si va verso fatti base e più bisogna essere puntigliosi e formali nelle dimostrazioni. Però ci soffermiamo un attimo sulle condizioni di unicità.

La prima condizione $c_1 \neq 0$ serve a escludere scritture alternative con zeri iniziali, per esempio
\[
-764.88888 = - 10^4 (0 \cdot 10^0 + 0 \cdot 10^{-1} + 7\cdot 10^{-2} + 6\cdot 10^{-3} + 4\cdot 10^{-4} + \dots) = -10^4 \cdot 0.07648\dots
\]
La rappresentazione senza zeri iniziali si chiama \emph{normalizzata}.

La seconda condizione esclude scritture come $0.999999\dots$ (periodico): se vi ricordate come si sommano le serie, $9\cdot 10^{-1}+9\cdot 10^{-2} + 9\cdot 10^{-3}+\dots$ è uguale a 1; quindi $0.999999\dots$ è un modo diverso di scrivere il numero 1 che vogliamo escludere.

\paragraph{Numeri di macchina}
Su un computer, possiamo rappresentare solo una quantità finita di numeri.
\begin{definition}
    L'insieme dei \emph{numeri di macchina (o floating-point) normalizzati}, $\mathbb{F}(\beta, t, m, M)$ è l'insieme dei numeri della forma
    \[
        \pm \beta^p \sum_{i=0}^{t-1} c_i \beta^{-i}, \quad p \in \{m, m+1, \dots, M\}  
    \]
\end{definition}
Ci sono due grossi cambiamenti rispetto alla~\eqref{rapprbase}: abbiamo $t$ cifre (anziché infinite) nella mantissa, e un insieme finito per gli esponenti, da $m$ a $M$.

\paragraph{Esempio} Prendiamo i numeri di macchina costruiti con $\beta=10$, $t=3$, $m=-2$, $M=3$.

Il numero di macchina positivo più piccolo è $10^{-2}(1 \cdot 10^{0} + 0 \cdot 10^{-1} + 0 \cdot 10^{-2}) = 0.0100$. I numeri di macchina successivi si ottengono incrementando le cifre: $0.0101, 0.0102, \dots, 0.0999$. Altri numeri compresi tra due di questi, ad esempio $0.01005$, non si possono scrivere con sole $t=3$ cifre significative. A questo punto abbiamo elencato tutti i numeri con esponente $-2$; il numero di macchina ancora successivo è un numero con esponente $-1$: precisamente, $10^{-1}(1 \cdot 10^{0} + \cdot 10^{-1} + 0 \cdot 10^{-2}) = 0.100$. Si prosegue in questo modo, ottenendo
\begin{align*}
    &0.0100, 0.0101, 0.0102 \dots, 0.0999 & & \text{esponente $p=-2$}\\
    &0.100, 0.101, 0.102 \dots, 0.999 & & \text{esponente $p=-1$}\\
    &1.00, 1.01, 1.02, \dots, 9.99 & & \text{esponente $p=0$}\\
    &10.0., 10.1, 10.2, \dots, 99.9 & & \text{esponente $p=1$}\\
    &100, 101, 102, \dots, 999 & & \text{esponente $p=2$}\\
    &1000, 1010, 1020, \dots, 9990 & & \text{esponente $p=3$}\\
\end{align*}
L'elenco che abbiamo fatto qui sopra contiene tutti i numeri di macchina normalizzati positivi dell'insieme $\mathbb{F}(10, 3, -2, 3)$. A questi vanno aggiunti quelli negativi, che sono gli stessi ma con un segno meno davanti.

Notiamo che i numeri con esponente $-2$ hanno distanza $10^{-4}$ l'uno dal successivo; i numeri con esponente $-1$ hanno distanza $10^{-3}$ l'uno dal successivo, fino ai numeri con esponente $3$ che hanno distanza $10$.

\begin{esercizio}
    Qual è il più piccolo intero positivo che \emph{non} appartiene all'insieme $\mathbb{F}(10, 3, -2, 3)$ riportato qui sopra?
\end{esercizio}

Quindi i numeri di macchina non sono equispaziati: i numeri più vicini allo zero (con $p$ piccolo) hanno una spaziatura minore tra l'uno e l'altro. Vedremo che queste spaziature variabili sono proprio quello che consente un'approssimazione con un errore \emph{relativo} basso.

\paragraph{Numero di macchina più piccolo, più grande, successivo}  
Il numero positivo più piccolo rappresentabile, che chiamiamo $\omega$, si ottiene scegliendo $p=m$ e mantissa $1000\dots 0$. Il numero più grande rappresentabile, $\Omega$, si ottiene scegliendo $p=M$ e mantissa con tutte cifre $\beta-1$.

Dato un numero di macchina normalizzato positivo 
\[
x = \beta^p \left(c_0 \beta^0 + c_1 \beta^1 + \ldots + c_{t-1} \beta^{-(t-1)} \right),
\]
il numero di macchina immediatamente successivo è quello che si ottiene aggiungendo $1$ all'ultima cifra $c_{t-1}$, cioè $x + \beta^{p-(t-1)}$. Questo è chiaro se l'ultima cifra è diversa da $\beta-1$; se l'ultima cifra è $\beta-1$, aggiungendo 1 all'ultima cifra ci sono dei riporti: ad esempio, aggiungendo $0.0001$ a $0.0999$ otteniamo $0.1000$. Quando si hanno questi riporti, però, l'ultima cifra è sempre $0$, quindi siamo sempre in grado di scrivere questo numero $x + \beta^{p-(t-1)}$ come un numero di macchina, eventualmente cambiando esponente.

\paragraph{Approssimazione con numeri di macchina}

\begin{theorem} \label{th:precmacchina} Dato un numero reale $x \in [-\Omega, -\omega] \cup [\omega, \Omega]$, esiste un numero di macchina $\tilde{x}$ tale che
\begin{equation} \label{roundingerror}
    \frac{\abs{\tilde{x}-x}}{\abs{x}} < \beta^{1-t}.    
\end{equation}
\end{theorem}
\begin{proof}
Possiamo assumere che $x$ sia positivo (il caso negativo è analogo), e che non sia esso stesso un numero di macchina (altrimenti il risultato è ovvio, basta prendere $\tilde{x}=x$). Allora $x$ è compreso tra due numeri di macchina successivi, chiamiamoli $\underline{x}$ e $\overline{x}$. In particolare, $\underline{x}$ si ottiene troncando la rappresentazione~\eqref{rapprbase}, cioè arrestando la sommatoria a $t$ anziché a $\infty$, e ha lo stesso esponente $p$ del numero $x$: per esempio, il troncamento di $10^{-1} \cdot 7.648888\dots$ è $10^{-1} 7.64$.

Possiamo scegliere se prendere $\tilde{x} = \underline{x}$ (troncamento o arrotondamento verso $0$), $\tilde{x} = \overline{x}$ (arrotondamento verso infinito), o quello dei due che ha un errore minore (arrotondamento al più vicino); tutti questi forniscono arrotondamenti che soddisfano la~\eqref{roundingerror}. In ogni caso, visto che $x$ e $\tilde{x}$ sono entrambi compresi nell'intervallo $(\underline{x}, \overline{x})$, si ha 
\begin{equation}
    \abs{\tilde{x}-x} < \overline{x} - \underline{x} = \beta^{p-(t-1)}.
\end{equation}
Inoltre, visto che la prima cifra di $x$ è almeno $1$ e le altre sono positive o nulle,
\begin{equation}
    x \geq \beta^{p}.
\end{equation}
Dividendo membro a membro queste due disuguaglianze (notare che i versi sono quelli giusti per farlo!) si ha la tesi.
\end{proof}

\paragraph{Errore relativo}
Data un'approssimazione $\tilde{x}$ di un numero reale $x \neq 0$, il suo \emph{errore relativo} è
\begin{equation} \label{relerr}
    \varepsilon = \frac{\tilde{x}-x}{x}.    
\end{equation}
È un tipo di errore naturale da considerare: l'errore assoluto $\tilde{x}-x$ da solo non dice nulla: possiamo fare degli esempi dalla vita reale di errori su lunghezze e prezzi. Per esempio, aver misurato una lunghezza con un errore di $0.5 \text{ cm}$ da solo non vuol dire nulla: è molto diverso se questa lunghezza è la distanza dalla terra alla luna, o una tolleranza di fabbricazione sulla cover del vostro cellulare.

Possiamo riscrivere la~\eqref{relerr} come $\tilde{x} = x(1+\varepsilon)$. Quindi la~\eqref{roundingerror} dice che per ogni $x$ in quegli intervalli esiste un numero di macchina $\tilde{x} = x(1+\varepsilon)$ che lo approssima con un errore relativo che soddisfa $\abs{\varepsilon} \leq \beta^{1-t}$. La quantità $\mathsf{u} = \beta^{1-t}$ (detta \emph{precisione di macchina}) non dipende da $x$, ma solo dall'insieme di numeri di macchina scelto.

\paragraph{Valori non normalizzati}
Su un computer, una variabile può assumere anche alcuni valori speciali, oltre ai numeri di macchina visti sopra:
\begin{itemize}
    \item Lo zero: difficile fare senza, e non è un numero normalizzato!
    \item $+\infty, -\infty, -0$: vengono aggiunti, con regole aritmetiche ispirate dall'analisi come $1/-\infty = -0$, per far sì che gli algoritmi possano funzionare anche in alcuni casi limite.
    \item \texttt{NaN}, che viene restituito come una sorta di codice d'errore da alcune operazioni non valide come $0/0$ e $\infty-\infty$.
    \item Alcuni numeri in più compresi tra $0$ e $\omega$, chiamati \emph{numeri denormalizzati}; non ci interessano qui.
\end{itemize}

\paragraph{Numeri a doppia precisione}
Esiste uno standard (IEEE 754) per l'aritmetica di macchina; praticamente tutti i computer e i linguaggi di programmazione si conformano a quello. Lo standard specifica quali parametri $\beta,t,m,M$ scegliere e il risultato di ogni operazione. Il formato più comune è quello noto come \texttt{double}, \texttt{float64} o \texttt{binary64}; esso corrisponde a scegliere $\beta = 2, t=53, m=-1022, M = 1023$. Ogni numero viene memorizzato in 64 bit (=valori~0 oppure~1).


\begin{conditional}[inf]
\[
\begin{tabular}{|c|c|c|}
    \hline
$s$ & $eeee\dots e$ & $d_1 d_2 d_3 \dots d_{52}$\\
\hline
\end{tabular}
\]
Il primo bit codifica il segno, i successivi 11 bit l'esponente, e i successivi 52 sono le cifre della mantissa ($d_0$ è sempre uguale a 1 e non serve memorizzarla).
\end{conditional}


Con questi valori, il Teorema~\ref{th:precmacchina} ci dice che ogni numero con valore assoluto compreso tra $\omega \approx 2.2 \cdot 10^{-308}$ e $\Omega \approx 1.8 \cdot 10^{308}$ può venire approssimato con precisione di maccchina $\mathsf{u} \approx 2.2 \cdot 10^{-16}$. Matlab (che useremo per programmare in questo corso) usa questo formato.

C'è anche un altro formato comune, chiamato \texttt{single} o \texttt{float32}, che ha precisione di macchina $\mathsf{u}\approx 10^{-8}$. Con questo formato gli errori relativi sono maggiori, ma è possibile memorizzare più numeri nello stesso spazio di memoria (32 bit l'uno).

Quando scriviamo (per esempio) \texttt{x = 0.3} in Matlab, questo numero non viene memorizzato esattamente: non appartiene a $\mathbb{F}(2, 53, -1022, 1023)$, ma anzi in base 2 è il numero periodico $0.0\overline{1001}$. Questo numero periodico viene troncato a $t=53$ cifre binarie. Quindi il numero con cui il computer lavora non è \emph{esattamente} $0.3$, bensì il numero in base 2
\begin{align*}
    \tilde{x} &= 0.010011001100110011001100110011001100110011001100110011    \\
    &= 2^{-2} \cdot \underbrace{1.0011001100110011001100110011001100110011001100110011}_{\text{53 cifre binarie nella mantissa}}
\end{align*}

cioè, in base 10,
\[
\tilde{x} = 0.2\underbrace{999999999999999}_{\text{15 volte 9}}88897769753748434595763683319091796875,
\]
che ha un errore relativo $\abs{\tilde{x}- 0.3} / 0.3$ minore di $\mathsf{u} = 
2.2 \cdot 10^{-16}$, come promesso dal Teorema~\ref{th:precmacchina}.

Un buon sito che potete usare per visualizzare lo sviluppo in base 2 dei numeri e fare qualche esperimento è \url{https://www.exploringbinary.com/floating-point-converter/}.

\paragraph{Operazioni di macchina}

Una volta memorizzati due numeri, possiamo chiedere al computer di calcolarne la somma: per esempio se scriviamo in Matlab
\texttt{x = 0.3; y = 0.4; x + y} viene visualizzato il risultato.

Sappiamo già che il computer memorizza approssimazioni $\tilde{x}$ e $\tilde{y}$ di 0.3 e 0.4, che soddisfano $\tilde{x} = 0.3(1+\varepsilon_1), \tilde{y} = 0.4(1+\varepsilon_2)$, con $\abs{\varepsilon_i} \leq \mathsf{u}$. Ma c'è una terza fonte di errore: anche se $\tilde{x}$ e $\tilde{y}$ sono numeri di macchina, la loro somma $\tilde{x} + \tilde{y}$ potrebbe non esserlo; quindi va approssimata anche lei con un numero di macchina. L'operazione ``calcola la somma di $\tilde{x}$ e $\tilde{y}$ e rimpiazzala con il numero di macchina più vicino'' viene indicata con $\tilde{x} \oplus \tilde{y}$. Analogamente definiamo $\ominus, \odot, \oslash$. Quindi $ \tilde{x} \oplus \tilde{y} = (\tilde{x}+\tilde{y})(1+\varepsilon)$, per un opportuno errore $\varepsilon$ che soddisfa $\abs{\varepsilon} \leq \mathsf{u}$, e analogamente per le altre operazioni.

\paragraph{Underflow/overflow} Ci sono due casi particolari da citare: eseguendo operazioni con numeri di macchina, si può ottenere come risultato un numero più grande di $\Omega$ in valore assoluto. In questo caso, viene restituito $+\infty$ o $-\infty$. Questo fenomeno si chiama \emph{overflow}. Similmente, quando un'operazione produce un numero più piccolo di $\omega$ in valore assoluto, viene restituito $0$ (\emph{underflow}).

Vediamo qui sotto alcuni esempi interessanti del risultato di operazioni di macchina.
\begin{esempio} \label{ese: miscellanea numeri di macchina}
Consideriamo di nuovo il sistema di numerazione con $\beta=10, t=3, m=-2, M=3$. Qual è il risultato delle seguenti operazioni (arrotondando sempre al numero di macchina più vicino)? 
\begin{itemize}
    \item $100 \ominus 0.01$;
    \item $1.01 \ominus 1.01$;
    \item $(7.24 \oplus 0.04) \oplus 10$;
    \item $7.24 \oplus (0.04 \oplus 10)$;
    \item $(1 \oslash 3) \oplus (1 \oslash 3) \oplus (1 \oslash 3)$;
    \item $5000 \oplus 5000$; 
    \item $0.01 \odot 0.01$;
    \item $50 \oplus 0.01$.
\end{itemize}
\end{esempio}
Le risposte sono queste:
\begin{itemize}
    \item $100 \ominus 0.01$ è il numero di macchina più vicino al risultato esatto $99.99$, cioè $100$ stesso.
    \item $1.01 \ominus 1.01$: poiché $1.01-1.01 = 0$, viene restituito $0$.
    \item Il risultato di $7.24 \oplus 0.04$ è il numero di macchina più vicino a $7.24+0.04 = 7.28$, cioè $7.28$. Il risultato di $ 7.28\oplus 10$ è il numero di macchina più vicino a $17.28$, cioè $17.3$.
    \item Ora dobbiamo fare le operazioni in ordine diverso. Il risultato di $10 \oplus 0.04$ è il numero di macchina più vicino a $10.04$, cioè $10$. Il risultato di $7.24\oplus 10$ è il numero di macchina più vicino a $17.24$, cioè $17.2$. È interessante notare che l'ordine diverso produce risultati diversi: per l'operazione $\oplus$ non vale sempre la proprietà associativa!
    \item $(1 \oslash 3) \oplus (1 \oslash 3) \oplus (1 \oslash 3) = 0.333 \oplus 0.333 \oplus 0.333 = 0.999$, che è diverso dal risultato esatto $1/3 + 1/3 + 1/3 = 1$.
    \item $5000 \oplus 5000 = +\infty$, visto che il risultato esatto $10000$ supera il più grande numero di macchina $\Omega = 9990$ (un esempio di overflow).
    \item $0.01 \odot 0.01 = 0$, visto che il risultato esatto $0.01 \cdot 0.01 = 10^{-4}$ è più piccolo del più piccolo numero di macchina positivo $\omega = 0.01$ (un esempio di underflow).
\end{itemize}



\paragraph{Commenti} Perché è stato scelto questo sistema per rappresentare i numeri reali sul computer? Esistono alternative, come rappresentare i numeri tramite razionali, cioè rapporti di interi (ma i denominatori diventano spesso \emph{molto} grandi anche quando si fanno operazioni semplici) o tenere traccia degli errori calcolando esplicitamente degli intervalli di inclusione per ogni quantità calcolata (ma gli intervalli diventano spesso \emph{molto} grandi anche quando si fanno operazioni semplici). Il sistema dei numeri di macchina è quello che si è affermato come il più comodo nelle applicazioni, ed è diventato lo standard. È un sistema che richiede di effettuare continuamente delle approssimazioni; per questo è importante comprendere teoricamente il loro impatto.

\chapter{Analisi dell'errore}

\paragraph{Errore analitico ed errore di macchina} Siamo ora in grado di studiare nel dettaglio l'errore commesso nella soluzione di problemi numerici. Supponiamo di dover calcolare una quantità $\alpha \neq 0$ tramite una successione $x_n$ che converge ad $\alpha$. Il primo errore che commettiamo è il cosiddetto \emph{errore analitico}, che commettiamo quando rimpiazziamo $\alpha$ con $x_n$. In generale, rimpiazzeremo la quantità desiderata $\alpha$ con una quantità effettivamente calcolata $\gamma$, per esempio se decidiamo di fare cinque passi del metodo di Newton avremo $\gamma=x_5$. Possiamo definire l'errore analitico come
\begin{equation} \label{ean}
    e_{an} = \frac{\gamma - \alpha}{\alpha}.    
\end{equation}
Il secondo errore che commettiamo è il cosiddetto \emph{errore di macchina}, dovuto al fatto che nel calcolare $\gamma$ usiamo non numeri e operazioni esatte, ma le loro approssimazioni ottenute con numeri in virgola mobile. Per esempio, se vogliamo applicare il metodo di Newton alla funzione $f(x) = x^2 - 2$, su un computer otterremo la successione
\[
\begin{cases}
    \tilde{x}_0 = \text{approssimazione con numeri di macchina di $x_0$},\\
    \tilde{x}_{n+1} = \tilde{x}_n \ominus (\tilde{x}_n\odot \tilde{x}_n \ominus 2) \oslash (2\odot \tilde{x}_n).
\end{cases}
\]
Questo processo produce un risultato $\tilde{\gamma}$ che è, solitamente, diverso da $\gamma$. (Come già fatto nel capitolo precedente, usiamo la tilde per indicare un'approssimazione ottenuta tramite aritmetica di macchina.) È importante notare che questo $\tilde{\gamma}$ \emph{non} è necessariamente il numero di macchina più vicino a $\gamma$, ma può essere più grande a causa dell'accumulo di molti errori successivi (come in uno degli esempi precedenti: $1\oslash 3 \oplus 1\oslash 3 \oplus 1\oslash 3 \neq 1$). 

Definiamo l'errore di macchina come
\[
e_{mac} = \frac{\tilde{\gamma} - \gamma}{\gamma}.
\]
L'effetto combinato dei due errori è il cosiddetto \emph{errore totale}
\[
e_{tot} = \frac{\tilde{\gamma} - \alpha}{\alpha}.
\]
Vediamo ora un teorema che consente di darne un'espressione approssimata. Essa è approssimata perché assumiamo che tutti questi errori siano piccoli, e ignoriamo termini che contengono il prodotto di due errori: un po' come quando approssimiamo $\exp(x) \approx 1 + x$ per valori di $x$ piccoli, ignorando i termini di grado superiore $x^2, x^3, \dots$ perché, essendo il prodotto di più copie di $x$, sono molto più piccoli di $x$.

Nel seguito, usiamo il simbolo $a \doteq b$ per indicare che $a$ e $b$ sono uguali a patto di ignorare ``termini di ordine superiore''. Cosa siano esattamente questi termini di ordine superiore dipende dal contesto: in questo caso, termini che sono il prodotto di due o più errori.
\begin{theorem}
\[
e_{tot} \doteq e_{an} + e_{mac}.
\]
\end{theorem}
\begin{proof} Notiamo innanzitutto che riarrangiando la~\eqref{ean} si ottiene
\[
\gamma = \alpha(1+e_{an}).
\]
Ora possiamo scrivere
\begin{align*}
e_{tot} &= \frac{\tilde{\gamma} - \alpha}{\alpha} = \frac{\tilde{\gamma} - \gamma}{\alpha} + \frac{\gamma - \alpha}{\alpha}\\
&= e_{mac}\frac{\gamma}{\alpha} + e_{an} = e_{mac}(1+e_{an}) + e_{an}\\
&= e_{mac} + e_{mac}e_{an} + e_{an} \doteq e_{mac} + e_{an}. \qedhere
\end{align*}
\end{proof}
In questa dimostrazione abbiamo usato solo il fatto che abbiamo fatto due approssimazioni successive una dopo l'altra: prima abbiamo rimpiazzato $\alpha$ con $\gamma$, poi $\gamma$ con $\tilde{\gamma}$. Questo quindi è un risultato generale che ci dice che gli errori relativi commessi successivamente si sommano (al prim'ordine).

Questo risultato è già sufficiente a spiegare qualitativamente il comportamento che osserviamo nella figura~\ref{fig:stagnazione}. Nell'analizzare i metodi abbiamo già stimato l'errore analitico $e_{an} = \abs{x_n - \alpha}$, e sappiamo che si comporta come $cr^k$, dove $k$ è il numero di passi, quindi scende come una retta su un grafico in scala semi-logaritmica. Nelle prime 150 iterazioni l'errore analitico è più grande di $10^{-16}$, ed è la quantità dominante nella somma degli errori; più avanti, l'errore analitico è minore, e quello dominante è l'errore di macchina, che è dell'ordine di $10^{-16}$ e cresce solo molto lentamente con il numero di iterazioni.

\paragraph{Approssimazione al prim'ordine dell'errore di macchina}
In realtà l'errore di macchina $\varepsilon_{mac}$ non è sempre dell'ordine di $10^{-16}$: l'accumulo di errori successivi può far sì che esso diventi molto più grande. Vediamo ora come analizzare questo errore su un esempio semplice. 

Supponiamo di avere dati due numeri reali $x,y$ (non necessariamente dei numeri di macchina), e di voler calcolare la quantità $\gamma = f(x,y) = x^2 - y^2$. Per farlo, calcoliamo in quest'ordine
\[
A = x \cdot x, \quad B = y \cdot y, \quad \gamma = A - B.
\]
Il primo errore che commettiamo è quello che facciamo approssimando $x$ e $y$ con dei numeri di macchina: otteniamo $\tilde{x} = x(1+\varepsilon_x)$, $\tilde{y} = y(1+\varepsilon_y)$, con $\abs{\varepsilon_x},\abs{\varepsilon_y} \leq \mathsf{u}$. Successivamente, effettuiamo le tre operazioni (due moltiplicazioni e una sottrazione) con i numeri di macchina:
\[
\tilde{A} = \tilde{x} \odot \tilde{x}, \quad \tilde{B} = \tilde{y} \odot \tilde{y}, \quad \tilde{\gamma} = \tilde{A} \ominus \tilde{B}.
\]
Nel calcolare $\tilde{A}$, si combinano un nuovo errore di macchina $\varepsilon_1$, ottenuto quando approssimiamo il risultato esatto $\tilde{x}^2$ con un numero di macchina, e gli errori precedenti che hanno modificato $x$ in $\tilde{x}$:
\begin{align*}
    \tilde{A} &= \tilde{x} \odot \tilde{x} = \tilde{x}^2 (1+\varepsilon_1) = x^2(1+\varepsilon_x)^2 (1+\varepsilon_1)\\
    &= x^2 (1+2\varepsilon_x + \underbrace{\varepsilon_x^2}_{\mathcal{O}(\mathsf{u}^2)})(1+\varepsilon_1)\\
    &= x^2(1+2\varepsilon_x + \varepsilon_1 + \underbrace{2\varepsilon_x\varepsilon_1}_{\mathcal{O}(\mathsf{u}^2)} + \mathcal{O}(\mathsf{u}^2)).
\end{align*}
Possiamo evitare di calcolare nel dettaglio i termini che contengono il prodotto di due o più errori; ci basta dire che sono dell'ordine di $\mathcal{O}(\mathsf{u}^2)$ per avere una stima dell'errore al primo ordine. Questo ci dice che l'errore relativo su $A$ è
\[
\varepsilon_A = \frac{\tilde{A}-A}{A} = 2\varepsilon_x + \varepsilon_1 + \mathcal{O}(\mathsf{u}^2):
\]
ricordiamo difatti che $\varepsilon_A = \frac{\tilde{A}-A}{A}$ con qualche manipolazione algebrica diventa $\tilde{A}=A(1+\varepsilon_A)$.

In modo analogo si ha
\[
\tilde{B} = \tilde{y} \odot \tilde{y} = B(1+\varepsilon_B), \quad \varepsilon_B = 2\varepsilon_y + \varepsilon_2 + \mathcal{O}(\mathsf{u}^2),
\]
dove abbiamo chiamato $\varepsilon_2$ l'errore che facciamo rimpiazzando il risultato del secondo prodotto $\tilde{y} \odot \tilde{y}$ con un numero di macchina. Già questi errori $\varepsilon_A$ e $\varepsilon_B$ possono essere leggermente più grandi della precisione di macchina, fino a $3\mathsf{u}$. Ma l'errore maggiore si verifica quando consideriamo anche la sottrazione finale. Abbiamo
\[
\tilde{\gamma} = \tilde{A} \ominus \tilde{B} = (\tilde{A}-\tilde{B})(1+\varepsilon_3).
\]
Con un po' di manipolazioni, possiamo scrivere anche questo risultato in una forma simile a quella sopra: il risultato esatto $\gamma=x^2-y^2$, moltiplicato per un fattore $(1+e_{mac})$:
\begin{align*}
    \tilde{\gamma}&= (\tilde{A}-\tilde{B})(1+\varepsilon_3)\\
    &= \frac{\gamma}{x^2-y^2}\biggl(x^2(1+\varepsilon_A) - y^2(1+\varepsilon_B)\biggr)(1+\varepsilon_3)\\
    &= \gamma \biggl(\underbrace{\frac{x^2-y^2}{x^2-y^2}}_{=1} + \frac{x^2}{x^2-y^2}\varepsilon_A - \frac{y^2}{x^2-y^2}\varepsilon_B\biggr)(1+\varepsilon_3)\\
    &= \gamma \biggl(1 + \frac{x^2}{x^2-y^2}\varepsilon_A - \frac{y^2}{x^2-y^2}\varepsilon_B +\varepsilon_3 + \mathcal{O}(\mathsf{u}^2)\biggr)\\
    &= \gamma \biggl(1 + \frac{x^2}{x^2-y^2}(2\varepsilon_x + \varepsilon_1) - \frac{y^2}{x^2-y^2}(2\varepsilon_y + \varepsilon_2) +\varepsilon_3 + \mathcal{O}(\mathsf{u}^2)\biggr)\\
    &= \gamma \biggl(1 + \frac{2x^2}{x^2-y^2}\varepsilon_x + \frac{2x^2}{x^2-y^2}\varepsilon_1 - \frac{2y^2}{x^2-y^2}\varepsilon_y - \frac{y^2}{x^2-y^2}\varepsilon_2 +\varepsilon_3 + \mathcal{O}(\mathsf{u}^2)\biggr).
\end{align*}
Questo ci dice che l'errore di macchina è
\[
e_{mac} = \frac{\tilde{\gamma} - \gamma}{\gamma} = \frac{2x^2}{x^2-y^2}\varepsilon_x + \frac{x^2}{x^2-y^2}\varepsilon_1 - \frac{2y^2}{x^2-y^2}\varepsilon_y - \frac{y^2}{x^2-y^2}\varepsilon_2 +\varepsilon_3 + \mathcal{O}(\mathsf{u}^2).
\]
Usando solo il fatto che $\abs{\varepsilon_i} \leq \mathsf{u}$ per $i=x,y,1,2,3$, la stima migliore che possiamo dare è quella che otteniamo usando la disuguaglianza triangolare: dividendo tutto per $\gamma$, abbiamo
\begin{align}
    \frac{\abs{\tilde{\gamma}-\gamma}}{\abs{\gamma}} &\stackrel{.}{\leq} \frac{2x^2}{\abs{x^2-y^2}} \abs{\varepsilon_x} + \frac{x^2}{\abs{x^2-y^2}}\abs{\varepsilon_1} + \frac{2y^2}{\abs{x^2-y^2}} \abs{\varepsilon_y} + \frac{y^2}{\abs{x^2-y^2}} \abs{\varepsilon_2} + \abs{\varepsilon_3} \nonumber\\
    &\leq \frac{2x^2}{\abs{x^2-y^2}} \mathsf{u} + \frac{x^2}{\abs{x^2-y^2}} \mathsf{u} + \frac{2y^2}{\abs{x^2-y^2}} \mathsf{u} + \frac{y^2}{\abs{x^2-y^2}} \mathsf{u} + \mathsf{u}. \label{esempiox2y2}
\end{align}
Questo calcolo ci permette di individuare per quali valori di $x$ e $y$ l'errore di macchina diventa molto grande: in particolare, quando $x^2$ e $y^2$ sono molto vicini tra loro, il denominatore $x^2-y^2$ è molto più piccolo del numeratore, e quindi $e_{mac}$ diventa molto grande. Questo è un fenomeno comune: l'errore di macchina tipicamente diventa molto alto quando facciamo sottrazioni tra due numeri molto vicini tra loro.

Questo calcolo è stato lungo e macchinoso anche per un'espressione semplice come $x^2-y^2$; potete immaginare come le cose si complichino ancora di più quando eseguiamo sequenze più lunghe di operazioni. C'è però almeno una parte di questo calcolo che possiamo effettuare facilmente: quella dei coefficienti di fronte a $\varepsilon_x$ e $\varepsilon_y$.

\paragraph{Numero di condizionamento} Concentriamoci sull'errore $\varepsilon_x$, e supponiamo per un attimo di ignorare gli errori $\varepsilon_y, \varepsilon_1,\varepsilon_2,\varepsilon_3$, ponendoli uguali a zero. Allora, possiamo notare che quello che stiamo calcolando è $\tilde{\gamma} = f(\tilde{x},y)$: l'unico errore che commettiamo è quello dovuto a rimpiazzare il valore iniziale $x$ con $\tilde{x}$, e tutte le altre operazioni sono esatte. Abbiamo a disposizione uno strumento dell'analisi per dare un'espressione approssimata di questo errore: lo sviluppo di Taylor. Consideriamo la funzione $g(x) = f(x,y)$, dove nascondiamo la dipendenza dalla $y$ perché la stiamo considerando costante. Se questa funzione è di classe $\mathcal{C}^1$, possiamo farne uno sviluppo di Taylor in $x$ per ottenere
\[
g(\tilde{x}) \doteq g(x) + \frac{\partial g(x)}{\partial x} (\tilde{x}-x).
\]
La differenza $\tilde{x}-x$ è uguale a $x(1+\varepsilon_x)-x = x\varepsilon_x$, e abbiamo ignorato (con la notazione $\doteq$) il termine che dipende da $(\tilde{x}-x)^2$, perché contiene il termine $\varepsilon_x^2$ e quindi è molto più piccolo. Allora otteniamo
\begin{equation} \label{ampliferrore}
    \frac{\tilde{\gamma} - \gamma}{\gamma} = \frac{g(\tilde{x})-g(x)}{g(x)} \doteq \frac{\frac{\partial g(x)}{\partial x} x\varepsilon_x}{g(x)}    
\end{equation}
Questa formula ci dice che quando calcoliamo una funzione $g(x)$ nel punto $\tilde{x}$ anziché $x$, l'errore relativo sul risultato $\frac{\tilde{\gamma}-\gamma}{\gamma}$ è uguale (al prim'ordine) a quello sul dato in ingresso
\[
\varepsilon_x = \frac{\tilde{x}-x}{x}
\]
moltiplicato per un fattore
\[
\frac{\partial g}{\partial x}\frac{x}{g(x)}.
\]
Il valore assoluto di questa quantità, cioè
\[
\kappa_{g,x} = \abs*{\frac{\partial g}{\partial x}\frac{x}{g(x)}}
\]
viene detto \emph{numero di condizionamento} della funzione $g$ nel punto $x$. Esso è una sorta di `fattore di amplificazione' dell'errore, che ci dice di quanto un errore cresce (o decresce) quando effettuiamo operazioni.

\paragraph{Esempio} La funzione $f(x) = \frac{x}{1-x}$ ha numero di condizionamento
\[
\kappa_{f,x} = \abs*{\frac{f'(x)x}{f(x)}} = \abs*{\frac{\frac{1}{(1-x)^2}x}{\frac{x}{1-x}}} = \frac{1}{\abs{1-x}}.
\]
Questa quantità è grande quando $x\approx 1$. Un errore relativo piccolo sull'argomento $x$, per esempio $x=0.9991$, $\tilde{x} = 0.999$, causa un errore relativo grande sul risultato della funzione $\frac{f(\tilde{x})-f(x)}{f(x)}$.

Una funzione che ha un numero di condizionamento grande viene detta \emph{mal condizionata}.

Possiamo riconoscere nel nostro esempio~\eqref{esempiox2y2}, con $g(x) = f(x,y) = x^2-y^2$, che il coefficiente davanti a $\varepsilon_x$ è proprio
\[
\kappa_{g,x} = \abs*{\frac{\partial g}{\partial x}}\frac{\abs{x}}{\abs{g(x)}} = \abs{2x} \frac{\abs{x}}{\abs{x^2-y^2}}.
\]
Analogamente, il coefficiente davanti a $\varepsilon_y$ è uguale a 
\[
    \abs*{\frac{\partial (x^2-y^2)}{\partial y}}\frac{\abs{y}}{\abs{x^2-y^2}} = \abs{-2y} \frac{\abs{y}}{\abs{x^2-y^2}}.
\]

\paragraph{Errore inerente, algoritmico, e stabilità (*)}
Notare che l'errore di macchina dipende non dalla funzione che vogliamo calcolare, ma dalla sequenza di operazioni che usiamo per calcolarla: per esempio $\gamma = f(x,y) = x^2-y^2 = (x+y)(x-y)$ è la stessa funzione scritta in due modi diversi, ma se usiamo la seconda espressione su un calcolatore possiamo ottenere un risultato $\tilde{\gamma}$ diverso:
\[
    \tilde{\gamma} = \tilde{f}(\tilde{x},\tilde{y}) = (\tilde{x}\oplus\tilde{y})\odot(\tilde{x}\ominus\tilde{y}).
\]
non è per forza uguale alla quantità che avevamo chiamato $\tilde{\gamma}$ in precedenza: abbiamo visto nell'Esercizio~\ref{ese: 
miscellanea numeri di macchina} che anche solo facendo operazioni di macchina in ordine diverso possiamo ottenere risultati diversi. Lavorando nello stesso modo, possiamo ottenere in questo caso la disuguaglianza sull'errore
\begin{align}
    \frac{\abs{\tilde{\gamma}-\gamma}}{\abs{\gamma}} &\stackrel{.}{\leq} \frac{2x^2}{\abs{x^2-y^2}} \abs{\varepsilon_x} 
    + \frac{2y^2}{\abs{x^2-y^2}} \abs{\varepsilon_y}
    + \abs{\varepsilon_1}+\abs{\varepsilon_2}+\abs{\varepsilon_3} \nonumber\\
    &\leq \frac{2x^2}{\abs{x^2-y^2}} \mathsf{u} + \frac{2y^2}{\abs{x^2-y^2}} \mathsf{u} + 3\mathsf{u}. \label{esempiox2y2bis}
\end{align}
Abbiamo ottenuto un risultato diverso da quello in~\eqref{esempiox2y2}: i due algoritmi non eseguono le stesse operazioni sul calcolatore, e quindi sono soggetti a errori diversi. Tuttavia, una parte del risultato è la stessa: i coefficienti di fronte a $\varepsilon_x$ e $\varepsilon_y$. Come abbiamo visto sopra, questi coefficienti sono uguali al numero di condizionamento della $f(x,y)$ rispetto alla $x$ e rispetto alla $y$. Questi numeri di condizionamento dipendono solo dalla funzione che vogliamo calcolare, non dalla sequenza di operazioni (\emph{algoritmo}) che stiamo usando per farlo. Quindi all'interno dell'errore di macchina ci sono degli addendi che sono inevitabili, anche se usiamo l'algoritmo migliore del mondo per calcolare il risultato: sono quelli dovuti all'errore sull'approssimazione con numeri di macchina dei dati in ingresso. Questo errore si chiama \emph{errore inerente}, e si può stimare come il numero di condizionamento della funzione che stiamo calcolando moltiplicato per $\mathsf{u}$. Se abbiamo una funzione che dipende da più di un valore in ingresso, come la nostra $f(x,y)$ che dipende sia dalla $x$ che dalla $y$, abbiamo un numero di condizionamento diverso rispetto a ognuna delle variabili, e l'errore inerente è la somma di questi errori $\left(\kappa_{f,x}+\kappa_{f,y}\right)\mathsf{u}$.

I termini rimanenti, che dipendono dall'algoritmo che stiamo utilizzando, compongono l'\emph{errore algoritmico}. Nella~\eqref{esempiox2y2bis}, l'errore algoritmico è minore o uguale di $3\mathsf{u}$, quindi è sempre dello stesso ordine di grandezza della precisione di macchina, a parte un piccolo fattore moltiplicativo; questo è quanto di meglio possiamo sperare per un algoritmo. Nella~\eqref{esempiox2y2} invece l'errore algoritmico $\frac{x^2}{\abs{x^2-y^2}}\abs{\varepsilon_1} + \frac{y^2}{\abs{x^2-y^2}} \abs{\varepsilon_2} + \abs{\varepsilon_3}$ può essere molto più grande della precisione di macchina. Comunque, anche in questo caso però l'errore algoritmico non può mai essere molto più grande dell'errore inerente: la quantità
$
\frac{x^2}{\abs{x^2-y^2}}\mathsf{u}
$
è sempre minore di 
$
\frac{2x^2}{\abs{x^2-y^2}}\mathsf{u}
$, e la quantità 
$
\frac{y^2}{\abs{x^2-y^2}}\mathsf{u}
$
è sempre minore di 
$
\frac{2y^2}{\abs{x^2-y^2}}\mathsf{u},
$
Un algoritmo in cui l'errore algoritmico è sempre al più dello stesso ordine di grandezza dell'errore inerente si dice \emph{stabile}. Quindi entrambi gli algoritmi che abbiamo visto per calcolare $f(x,y) = x^2-y^2$ sono stabili. La stabilità è una proprietà che cerchiamo sempre di avere nei nostri algoritmi: ci dice che l'algoritmo non fa mai un errore molto più grande di quello inerente che è inevitabile. Quindi un algoritmo stabile (informalmente) restituisce il minore errore possibile, come ordine di grandezza.

\paragraph{Esempio di un algoritmo instabile (*)}
Consideriamo la funzione $f(x) = 2x+x^2 = (1+x)^2-1$. Queste due espressioni equivalenti portano a due algoritmi per calcolare il valore della funzione:
\[
\tilde{f}_A(\tilde{x}) = 2\odot \tilde{x} \oplus \tilde{x}\odot \tilde{x}, \quad \tilde{f}_B(\tilde{x}) = (1\oplus \tilde{x}) \odot (1\oplus \tilde{x}) \ominus 1.
\]
Studiamo l'errore di macchina del secondo algoritmo, che scriviamo per comodità con delle quantità intermedie:\
\[
A = 1+x \quad B = A \cdot A, \quad \gamma = B-1.
\]
Abbiamo innanzitutto
\begin{align*}
    \tilde{A} &= 1\oplus\tilde{x} = (1+x(1+\varepsilon_x))(1+\varepsilon_1)\\
    &= (1+x) \left(\frac{1}{1+x} \right)
&= 1 + x + x\varepsilon_x + (1+x)\varepsilon_1 + \mathcal{O}(\mathsf{u}^2),
\end{align*}
poiché il termine $x\varepsilon_x\varepsilon_1$ contiene due fattori minori di $\mathsf{u}$. Calcoliamo anche l'espansione al primo ordine di $\tilde{z}^2$, che ci servirà più avanti:
\begin{align*}
    \tilde{z}^2 &= \biggl(1 + x + x\varepsilon_x + (1+x)\varepsilon_1 + \mathcal{O}(\mathsf{u}^2)\biggr)\biggl(1 + x + x\varepsilon_x + (1+x)\varepsilon_1 + \mathcal{O}(\mathsf{u}^2)\biggr)\\
    &= (1+x)^2 + 2(1+x)(x\varepsilon_x + (1+x)\varepsilon_1) + \mathcal{O}(\mathsf{u}^2)\\
    &= (1+x)^2 + 2x(1+x)\varepsilon_x + 2(1+x)^2\varepsilon_1 + \mathcal{O}(\mathsf{u}^2)\\
\end{align*}
Poi continuiamo con
\begin{align*}
    \tilde{\gamma} &= \tilde{z}\odot \tilde{z} \ominus 1 \\
    &= \tilde{z}^2 (1+\varepsilon_2) \ominus 1 \\
    &= \biggl(\tilde{z}^2 (1+\varepsilon_2) - 1\biggr)(1+\varepsilon_3)\\
    &= \tilde{z}^2 (1+\varepsilon_2)(1+\varepsilon_3) - 1 -\varepsilon_3\\
    &= \tilde{z}^2 (1+\varepsilon_2 + \varepsilon_3 + \mathcal{O}(\mathsf{u}^2)) - 1 -\varepsilon_3\\
    &=  \biggl((1+x)^2 + 2x(1+x)\varepsilon_x + 2(1+x)^2\varepsilon_1 + \mathcal{O}(\mathsf{u}^2)\biggr)(1+\varepsilon_2 + \varepsilon_3 + \mathcal{O}(\mathsf{u}^2)) - 1 -\varepsilon_3\\
    &= (1+x)^2 + (1+x)^2(\varepsilon_2 + \varepsilon_3) + 2x(1+x)\varepsilon_x + 2(1+x)^2\varepsilon_1 + \mathcal{O}(\mathsf{u}^2)- 1 -\varepsilon_3\\
    &= \gamma + (2x+2x^2)\varepsilon_x + 2(1+x)^2\varepsilon_1 + (1+x)^2\varepsilon_2 + ((1+x)^2-1)\varepsilon_3 + \mathcal{O}(\mathsf{u}^2).
\end{align*}
Quindi
\begin{align*}
    \abs*{\frac{\tilde{\gamma}-\gamma}{\gamma}} &= \abs*{\frac{2x+2x^2}{2x+x^2}\varepsilon_x + \frac{2(1+2x+x^2)}{2x+x^2}\varepsilon_1  + \frac{1+2x+x^2}{2x+x^2}\varepsilon_2 + \frac{2x+x^2}{2x+x^2}\varepsilon_3 + \mathcal{O}(\mathsf{u}^2)} \\
    &\stackrel{.}{\leq} \abs*{\frac{2x+2x^2}{2x+x^2}}\mathsf{u} + \abs*{3\frac{1+2x+x^2}{2x+x^2}}\mathsf{u} + \mathsf{u}.
\end{align*}
Come già sappiamo, il coefficiente davanti a $\varepsilon_x$ è uguale al numero di condizionamento della funzione:
\[
\kappa_{f,x} = \abs*{\frac{f'(x) x}{f(x)}} = \abs*{\frac{(2+2x)x}{2x+x^2}} = \abs*{\frac{2+2x}{2+x}};
\]
questo numero di condizionamento diventa molto grande quando $x\approx -2$; quindi la funzione è mal condizionata intorno a questo punto. Però l'errore di macchina diventa molto grande anche quando $x\approx 0$, per colpa del termine $\frac{1+2x+x^2}{2x+x^2}$ che diverge; mentre il numero di condizionamento resta limitato attorno a questo valore. Quindi quando $x\approx 0$ l'errore algoritmico è molto più grande dell'errore inerente, e quindi l'algoritmo dato da $\tilde{f}_B$ è instabile. (Si noti che quando abbiamo esattamente $x=0$ si ha $f(x)=0$, quindi non è ben definito il concetto di errore relativo perché ci richiederebbe di dividere per $0$.)

\begin{conditional}[inf]
\paragraph{Esempio: attacchi avversari} Alcune reti neurali sono usate in informatica per classificare immagini, ad esempio di segnali stradali: il modello restituisce come output dei numeri reali che sono probabilità (secondo il modello) che l'immagine contenga un determinato oggetto: per esempio, un certo segnale può essere riconosciuto con una probabilità dell'87\% di essere un divieto di transito, 7\% di essere divieto di sosta, 6\% di essere un limite di velocità. Alcuni ricercatori hanno osservato che queste probabilità possono essere funzioni mal condizionate dei pixel dell'immagine, e specialmente di alcuni pixel in posizione chiave. Facendo piccole modifiche mirate ai segnali, come quelle rappresentate nell'immagine qui sotto (\href{https://arxiv.org/abs/1707.08945}{fonte}), è possibile fare sì che l'immagine venga riconosciuta dalla rete neurale come un segnale stradale diverso, per esempio un limite di velocità. Questo mal condizionamento può avere conseguenze catastrofiche, per esempio, per i sistemi di guida automatica.
\begin{center}
    % public domain: https://picryl.com/media/trouble-at-the-halt-4d8cc6
    \includegraphics[width=0.5\textwidth]{trouble-at-the-halt-4d8cc6.jpg}
\end{center}
\end{conditional}

\begin{conditional}[inf]
\section{Grafi computazionali per l'analisi dell'errore}
Mostriamo ora una tecnica per calcolare l'approssimazione al primo ordine dell'errore algoritmico basata sulla rappresentazione delle operazioni eseguite come un grafo. Rappresentiamo innanzitutto le operazioni da fare come un grafo in cui le frecce collegano gli \emph{input} di un'operazione ai suoi \emph{output}; per esempio qui sotto vediamo il grafo che rappresenta il calcolo della quantità $\frac{y}{x+y}$ a partire dai due input $x$, $y$.

\begin{center}
\begin{tikzpicture}[node distance=2cm, auto]
  % Nodes
  \node[draw, rectangle] (x) {$x$};
  \node[draw, rectangle, below of=x] (y) {$y$};
  \node[draw, rectangle, right of=x, node distance=3.5cm] (sum) {$x + y$};
  \node[draw, rectangle, below of=sum] (divide) {$\frac{y}{x+y}$};
  
  % Edges
  \draw[->] (x) -- (sum);
  \draw[->] (y) -- (sum);
  \draw[->] (y) -- (divide);
  \draw[->] (sum) -- (divide);
\end{tikzpicture}
\end{center}

Quando memorizziamo i due input $x,y$ come numeri di macchina, commettiamo errori $\varepsilon_x, \varepsilon_y$, come visto sopra. Inoltre, i risultati delle due operazioni (somma e divisione) sono affetti da errori $\varepsilon_1,\varepsilon_2$. Disegniamo di nuovo il grafo, ma questa volta mettiamo in ogni nodo gli errori in cui incorriamo.
\begin{center}
\begin{tikzpicture}[node distance=2cm, auto]
  % Nodes
  \node[draw, rectangle] (x) {$x$};
  \node[draw, rectangle, below of=x] (y) {$y$};
  \node[draw, rectangle, right of=x, node distance=3.5cm] (sum) {$x + y$};
  \node[draw, rectangle, below of=sum] (divide) {$\frac{y}{x+y}$};

  \node[red, above=0mm] at (x.north) {$\varepsilon_x$};
  \node[red, above=0mm] at (y.north) {$\varepsilon_y$};
  \node[red, above=0mm] at (sum.north) {$\varepsilon_1$};
  \node[red, above=0mm] at (divide.north) {$\phantom{asd}\varepsilon_2$};

  % Edges
  \draw[->] (x) -- (sum);
  \draw[->] (y) -- (sum);
  \draw[->] (y) -- (divide);
  \draw[->] (sum) -- (divide);
\end{tikzpicture}
\end{center}
Il punto chiave ora è capire come gli errori si propagano da un nodo all'altro del grafo. Concentriamoci sulla prima addizione. Essa ha come input $x$ e $y$, e come output $x+y$. La formula~\eqref{ampliferrore} ci dice che l'errore sull'input $x$  $\varepsilon_x$ causa un errore sul risultato della somma di
\[
    \frac{\partial (x+y)}{\partial x} \frac{x}{x+y} \varepsilon_x = 1 \cdot \frac{x}{x+y} \varepsilon_x.
\]
Similmente,
\[
    \frac{\partial (x+y)}{\partial y} \frac{y}{x+y} \varepsilon_y = 1 \cdot \frac{y}{x+y} \varepsilon_y.
\]
Scriviamo i due coefficienti di amplificazione dell'errore $\frac{x}{x+y}$ e $\frac{y}{x+y}$ sui lati del grafo che collegano il risultato della somma (output) ai suoi due input $x$ e $y$:
\begin{center}
\begin{tikzpicture}[node distance=2cm, auto]
  % Nodes
  \node[draw, rectangle] (x) {$x$};
  \node[draw, rectangle, below of=x] (y) {$y$};
  \node[draw, rectangle, right of=x, node distance=3.5cm] (sum) {$x+y$};
  
  \node[red, above=0mm] at (x.north) {$\varepsilon_x$};
  \node[red, above=0mm] at (y.north) {$\varepsilon_y$};
  \node[red, above=0mm] at (sum.north) {$\varepsilon_1$};

  % Edges
  \draw[->] (x) -- (sum) node[midway, above] {$\frac{x}{x+y}$};
  \draw[->] (y) -- (sum) node[midway, above] {$\frac{y}{x+y}$};
\end{tikzpicture}
\end{center}
Questi due coefficienti rappresentano come l'errore si propaga lungo l'operazione da fare, in questo caso una somma. L'errore relativo totale sulla quantità calcolata $x+y$ quindi è dato dalla somma dell'errore effettuato sull'operazione stessa, $\varepsilon_1$, e dei due errori propagati dai due input, $\frac{x}{x+y}\varepsilon_x + \frac{y}{x+y}\varepsilon_y$. Scriviamo questi errori nel grafo, rimpiazzando i risultati delle operazioni in modo da non avere troppe formule.
\begin{center}
\begin{tikzpicture}[node distance=2cm, auto]
  % Nodes
  \node[draw, rectangle, blue] (x) {$\varepsilon_x$};
  \node[draw, rectangle, below of=x, blue] (y) {$\varepsilon_y$};
  \node[draw, rectangle, right of=x, node distance=3.5cm, blue] (sum) {$\frac{x}{x+y}\varepsilon_x + \frac{y}{x+y}\varepsilon_y+\varepsilon_1$};
  
  \node[red, above=0mm] at (x.north) {$\varepsilon_x$};
  \node[red, above=0mm] at (y.north) {$\varepsilon_y$};
  \node[red, above=0mm] at (sum.north) {$\varepsilon_1$};

  % Edges
  \draw[->] (x) -- (sum) node[midway, above] {$\frac{x}{x+y}$};
  \draw[->] (y) -- (sum) node[midway, above] {$\frac{y}{x+y}$};
\end{tikzpicture}
\end{center}
Procediamo in modo simile per ogni operazione contenuta nel grafo. Tutte le volte che nel grafo computazionale c'è una somma tra due quantità $a$ e $b$, sui lati corrispondenti scriveremo $\frac{a}{a+b}$ e $\frac{b}{a+b}$. Analogamente, quando abbiamo una sottrazione $g(a,b) = a-b$ (tra due numeri $a$ e $b$) i due coefficienti di amplificazione sono
\[
\frac{\partial g(a,b)}{\partial a} \frac{a}{g(a,b)} = 1\frac{a}{a-b} = \frac{a}{a-b}, \quad \frac{\partial g(a,b)}{\partial b} \frac{b}{g(a,b)} = -1\frac{b}{a-b} = \frac{-b}{a-b},
\]
e quindi andremo a scrivere
\begin{center}
\begin{tikzpicture}[node distance=2cm, auto]
  % Nodes
  \node[draw, rectangle] (x) {$a$};
  \node[draw, rectangle, below of=x] (y) {$b$};
  \node[draw, rectangle, right of=x, node distance=3.5cm] (sum) {$a-b$};
  
  % Edges
  \draw[->] (x) -- (sum) node[midway, above] {$\frac{a}{a-b}$};
  \draw[->] (y) -- (sum) node[midway, above] {$\frac{-b}{a-b}$};
\end{tikzpicture}
\end{center}
Per un prodotto $g(a,b) = ab$ invece si ha
\[
\frac{\partial g(a,b)}{\partial a} \frac{a}{g(a,b)} = b\frac{a}{ab} = 1, \quad \frac{\partial g(a,b)}{\partial b} \frac{b}{g(a,b)} = a\frac{b}{ab} = 1
\]
e quindi
\begin{center}
\begin{tikzpicture}[node distance=2cm, auto]
  % Nodes
  \node[draw, rectangle] (x) {$a$};
  \node[draw, rectangle, below of=x] (y) {$b$};
  \node[draw, rectangle, right of=x, node distance=3.5cm] (sum) {$ab$};
  
  % Edges
  \draw[->] (x) -- (sum) node[midway, above] {$1$};
  \draw[->] (y) -- (sum) node[midway, above] {$1$};
\end{tikzpicture}
\end{center}
e infine per una divisione $g(a,b) = a/b$
\[
\frac{\partial g(a,b)}{\partial a} \frac{a}{g(a,b)} = \frac{1}{b}\frac{a}{a/b} = 1, \quad \frac{\partial c}{\partial b} \frac{b}{a/b} = -\frac{a}{b^2}\frac{b}{a/b} = -1
\]
quindi
\begin{center}
\begin{tikzpicture}[node distance=2cm, auto]
  % Nodes
  \node[draw, rectangle] (x) {$a$};
  \node[draw, rectangle, below of=x] (y) {$b$};
  \node[draw, rectangle, right of=x, node distance=3.5cm] (sum) {$a/b$};
  
  % Edges
  \draw[->] (x) -- (sum) node[midway, above] {$1$};
  \draw[->] (y) -- (sum) node[midway, above] {$-1$};
\end{tikzpicture}
\end{center}
Questi calcoli ci dicono che coefficienti scrivere su ogni arco del nostro grafo, a seconda di a quale operazione elementare esso corrisponde. Se sugli archi del nostro grafo ci fossero avere operazioni più complesse che il computer è in grado di eseguire, per esempio un elevamento a potenza o un logaritmo, a ognuna di esse possiamo associare dei coefficienti di amplificazione in base alla formula~\eqref{ampliferrore}. Completiamo quindi il calcolo per il nostro esempio: i coefficienti di amplificazione lungo i due lati rimanenti sono $1$ e $-1$, quindi
\begin{center}
\begin{tikzpicture}[node distance=2cm, auto]
  % Nodes
  \node[draw, rectangle] (x) {$x$};
  \node[draw, rectangle, below of=x] (y) {$y$};
  \node[draw, rectangle, right of=x, node distance=3.5cm] (sum) {$x + y$};
  \node[draw, rectangle, below of=sum] (divide) {$\frac{y}{x+y}$};

  \node[red, above=0mm] at (x.north) {$\varepsilon_x$};
  \node[red, above=0mm] at (y.north) {$\varepsilon_y$};
  \node[red, above=0mm] at (sum.north) {$\varepsilon_1$};
  \node[red, above=0mm] at (divide.north) {$\phantom{asd}\varepsilon_2$};

  % Edges
  \draw[->] (x) -- (sum) node[midway, above] {$\frac{x}{x+y}$};
  \draw[->] (y) -- (sum) node[midway, above] {$\frac{y}{x+y}$};
  \draw[->] (y) -- (divide) node[midway, above] {$1$};
  \draw[->] (sum) -- (divide) node[midway, above] {$\phantom{asd}-1$};
\end{tikzpicture}
\end{center}
Quindi scrivendo in ogni nodo l'errore totale corrispondente si ha
\begin{center}
\begin{tikzpicture}[node distance=2cm, auto]
  % Nodes
  \node[draw, rectangle, blue] (x) {$\varepsilon_x$};
  \node[draw, rectangle, below of=x, blue] (y) {$\varepsilon_y$};
  \node[draw, rectangle, right of=x, node distance=6.5cm, blue] (sum) {$\frac{x}{x+y}\varepsilon_x + \frac{y}{x+y}\varepsilon_y+\varepsilon_1$};
  \node[draw, rectangle, below of=sum, blue] (divide) {$1\cdot \varepsilon_y - 1\cdot\left(\frac{x}{x+y}\varepsilon_x + \frac{y}{x+y}\varepsilon_y+\varepsilon_1\right) + \varepsilon_2$};

  \node[red, above=0mm] at (x.north) {$\varepsilon_x$};
  \node[red, above=0mm] at (y.north) {$\varepsilon_y$};
  \node[red, above=0mm] at (sum.north) {$\varepsilon_1$};
  \node[red, above=0mm] at (divide.north) {$\phantom{asd}\varepsilon_2$};

  % Edges
  \draw[->] (x) -- (sum) node[midway, above] {$\frac{x}{x+y}$};
  \draw[->] (y) -- (sum) node[midway, above] {$\frac{y}{x+y}$};
  \draw[->] (y) -- (divide) node[midway, above] {$1$};
  \draw[->] (sum) -- (divide) node[midway, above] {$\phantom{asd}-1$};
\end{tikzpicture}
\end{center}
Facciamo attenzione a moltiplicare i coefficienti di propagazione per l'errore ``totale'' (in blu) e non quello ``parziale'' (in rosso).

Possiamo ottenere lo stesso risultato anche eseguendo le operazioni in un ordine diverso. Per determinare il coefficiente davanti a $\varepsilon_x$ nel risultato finale, moltiplichiamo tra loro tutti i coefficienti di amplificazione che compaiono lungo i lati del percorso che lo collega al risultato: $-1 \cdot \frac{x}{x+y} \cdot \varepsilon_x$, andando a ritroso. Analogamente per $\varepsilon_1$: il prodotto (questa volta con un solo coefficiente di amplificazione) è $-1 \cdot \varepsilon_1$. Nel caso di $\varepsilon_y$, i percorsi sono due, e dobbiamo sommare i loro contributi:
\[
1 \cdot \varepsilon_y + (-1) \cdot \frac{y}{x+y} \cdot \varepsilon_y.
\]
In altre parole, l'algoritmo che possiamo seguire per calcolare l'errore di macchina lungo una sequenza di operazioni è questo:
\begin{itemize}
    \item Rappresentiamo in un grafo la sequenza di operazioni da svolgere, collegando ogni input con il suo output;
    \item Scriviamo sopra ogni nodo un errore $\varepsilon_k$ che rappresenta l'errore ``parziale'' in cui si incorre nell'operazione del nodo.
    \item Scriviamo sopra ogni arco del grafo il coefficiente di propagazione corrispondente, che dice come il valore nel nodo di arrivo dipende da quello nel nodo di partenza.
    \item Per ogni errore parziale, calcoliamo il prodotto dei coefficienti lungo il percorso che lo collega al risultato finale ( o lungo ognuno dei percorsi, se sono più di uno); esso rappresenta un addendo dell'errore di macchina $\frac{\tilde{\gamma}-\gamma}{\gamma}$.
\end{itemize}
\begin{remark}
    Con un algoritmo simile a questo possiamo calcolare gli errori \emph{assoluti}, anziché relativi, cioè essenzialmente le derivate. Questa è una variante del famoso algoritmo di \emph{backpropagation} che viene utilizzato per calcolare derivate quando si allenano modelli di intelligenza artificiale.
\end{remark}

\end{conditional}

\chapter{Equazioni lineari e autovalori}

\section{Richiami di algebra lineare}

Ricordiamo che il prodotto matrice-vettore $A \mathbf{x}$ è definito come $(Ax)_i = \sum_{j=1}^n A_{ij}x_j$ (riga per colonna). Più geometricamente, crea una combinazione lineare $\mathbf{v}_1 x_1 + \mathbf{v}_2 x_2 + \dots + \mathbf{v}_n x_n$ delle colonne $\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_n$ di $A$. 

% Prodotto matrice-matrice: $AB$ definito come $(AB)_{ij} = \sum_{k=1}^{n} A_{ik}B_{kj}$, prodotti scalari nello stesso modo. Ben definito solo quando $A\in\mathbb{C}^{m\times n}$ e $B\in\mathbb{C}^{n\times p}$ hanno la dimensione ``interna'' uguale, e produce una matrice $AB\in\mathbb{C}^{m\times p}$. L'ordine dei fattori conta! $AB \neq BA$ (e può anche darsi che uno sia ben definito e l'altro no).

% A parte questo, valgono le ``normali'' proprietà di addizione e moltiplicazione: $(A+B)C = AC+BC$, $A(BC)=(AB)C$. Un'altra che non vale è l'annullamento del prodotto: $AB=0$ può verificarsi anche se $A,B\neq 0$. (Esempio: $\begin{bmatrix}
%     -1 & 1\\
%     1 & -1
% \end{bmatrix}\begin{bmatrix}
%     1 & 1\\
%     1 & 1
% \end{bmatrix} = 0_{2\times 2}$.)

% Possiamo moltiplicare matrici e vettori anche per degli \emph{scalari} (cioè dei numeri $\in\mathbb{C}$). In questo caso, l'ordine non conta e possiamo ``portare fuori'' scalari da un prodotto, $A(\alpha B) = \alpha (AB)$.

Un \emph{sistema lineare} è il problema inverso del prodotto: data $A\in\mathbb{R}^{n\times n}$ e $\mathbf{b} \in \mathbb{R}^n$, trovare il vettore di coefficienti $\mathbf{x}$ che servono per scrivere $\mathbf{b}$ come combinazione lineare delle colonne di $A$.

Partiamo studiando sistemi quadrati, cioè $A \in \mathbb{R}^{n\times n}$ (o $\mathbb{C}^{n\times n}$). Un sistema ha \emph{una e una sola} soluzione quando le righe/colonne di $A$ formano una base di $\mathbb{R}^n$ (in particolare, quando sono linearmente indipendenti). Ci concentriamo su sistemi che soddisfano questa ipotesi. Dall'algebra lineare, sappiamo che se $A$ è invertibile esiste una matrice $A^{-1}\in\mathbb{R}^{n\times n}$ tale che la soluzione si scrive come prodotto $\mathbf{x} = A^{-1}\mathbf{b}$. Questa matrice è unica e soddisfa $A^{-1}A=AA^{-1}= I$, la matrice con uni sulla diagonale e zeri altrove.

\emph{Non} possiamo scrivere $\mathbf{x} = \mathbf{b}A^{-1}$ (dimensioni non compatibili per il prodotto; l'ordine dei fattori conta!), né $\mathbf{x} = \frac{\mathbf{b}}{A}$ (non vuol dire nulla, e non mi specifica l'ordine!).

In Matlab, esiste una funzione \lstinline{inv(A)} che calcola la matrice inversa, quindi potremmo scrivere \lstinline{inv(A) * b}; però questo metodo di risolvere un sistema lineare è più costoso (e spesso anche più inaccurato) di altri algoritmi. C'è una notazione diversa per risolvere un sistema, \lstinline{x = A \ b}. Occhio: la barra è la ``backslash'' \lstinline!\!, non \lstinline{/}. Per non confondere le barre, pensate a questa operazione come a una sorta di ``divisione da un lato'': c'è una barra di frazione, e la \lstinline{A} sta al di sotto.

Detto informalmente, per calcolare le colonne della matrice inversa dobbiamo risolvere gli $n$ sistemi lineari $A^{-1}\mathbf{e}_1, A^{-1}\mathbf{e}_2,\dots A^{-1}\mathbf{e}_n$; quando poi calcoliamo \texttt{x = inv(A)*b} facciamo una combinazione lineare di queste soluzioni. Per questo l'errore rischia di essere maggiore di quello fatto risolvendo un solo sistema lineare.

\paragraph{Determinanti} Altri algoritmi da evitare per risolvere sistemi lineari su un computer sono quelli basati su determinanti, come il \emph{metodo di Cramer}. Tipicamente i determinanti sono più lenti da calcolare, e per matrici grandi vanno spesso in overflow/underflow; per esempio, $\det(0.1\, I_{400\times 400})$ restituisce $0$ su Matlab. Quindi i determinanti sono inaffidabili anche solo per dire se una matrice è singolare o no. 

Nelle prossime sezioni vedremo invece gli algoritmi che Matlab utilizza per risolvere sistemi lineari. Ma prima di farlo, studiamo il condizionamento di questo problema.

\section{Condizionamento della soluzione di sistemi lineari}

Partiamo studiando il condizionamento della soluzione di sistemi lineari. Per farlo, introduciamo alcuni strumenti teorici.

\paragraph{Norme vettoriali} L'analisi dell'errore che abbiamo fatto nei capitoli precedenti assumeva di avere funzioni $f: \mathbb{R} \to \mathbb{R}$, funzioni $x=f(a)$ di un reale $a$. La soluzione di un sistema lineare invece è una funzione $\mathbf{x} = f(A,\mathbf{b})$ che prende una matrice e un vettore e restituisce un vettore. Potremmo studiare separatamente il condizionamento di ogni componente rispetto a ogni componente dell'input, ma si preferisce un approccio diverso che passa attraverso il misurare ``distanze'' tra vettori e matrici.

Lo strumento teorico che ci serve è una \emph{norma vettoriale}, cioè una funzione che ``assomiglia al valore assoluto'' per vettori.

Si definisce \emph{norma vettoriale} una funzione $f: \mathbb{C}^n \to \mathbb{R}$ che ha queste proprietà.
\begin{enumerate}
    \item $f(\mathbf{v}) \geq 0$ per ogni vettore $\mathbf{v}\in\mathbb{C}^n$, e l'uguaglianza vale solo per il vettore zero.
    \item $f(\alpha \mathbf{v}) = \abs{\alpha} f(\mathbf{v})$ per ogni vettore $\mathbf{v}\in\mathbb{C}^n$ e scalare $\alpha \in \mathbb{C}$.
    \item $f(\mathbf{v}+\mathbf{w}) \leq f(\mathbf{v}) + f(\mathbf{w})$ per ogni $\mathbf{v},\mathbf{w}\in\mathbb{C}^n$.
\end{enumerate}
Notate che queste proprietà sono analoghe a quelle del valore assoluto; per esempio l'ultima è la disuguaglianza triangolare. Difatti non è complicato verificare che il valore assoluto è una norma per $n=1$.

Una norma di solito non si indica con $f(\mathbf{v})$, ma con $\norm{\mathbf{v}}$ (due stanghette).

Le norme più usate sono le seguenti.

\begin{itemize}
    \item Norma-1: $\norm{\mathbf{v}}_1 = \sum_{i=1}^n \abs{v_i}$.
    \item Norma-2 (o Euclidea): $\norm{\mathbf{v}}_2 = \sqrt{\sum_{i=1}^n \abs{v_i}^2} = \sqrt{\mathbf{v}^*\mathbf{v}}$.
    \item Norma infinito: $\norm{\mathbf{v}}_\infty = \max_{i\in \{1,2,\dots,n\}} \abs{v_i}$.
\end{itemize}
Si dimostra che tutte e tre soddisfano le proprietà qui sopra. L'unica un po' più difficile è la disuguaglianza triangolare per la norma-2; le altre potete provare a farle come esercizio.

Esempio: calcola le tre norme di $\begin{bmatrix}
    2\\-3\\-1
\end{bmatrix}$.

Data una norma vettoriale, $\norm{\mathbf{v}-\mathbf{w}}$ fornisce un modo di misurare la distanza tra $\mathbf{v}$ e $\mathbf{w}$. Ogni norma fornisce valori diversi, che danno modi leggermente diversi di definire questa distanza. In generale, si dimostra (noi non lo vediamo) che date due norme qualunque queste non possono restituire valori troppo diversi l'una dall'altra: per ogni coppia di norme $\norm{\cdot}_p,\norm{\cdot}_q$ esistono due reali $c_1,c_2 > 0$ tali che
\[
c_1\norm{\mathbf{v}}_p \leq \norm{\mathbf{v}}_q \leq c_2 \norm{\mathbf{v}}_p \quad \text{per ogni $\mathbf{v}\in\mathbb{C}^n$}.
\]
Queste costanti spesso sono una funzione della dimensione; per esempio, per ogni $\mathbf{v}\in\mathbb{C}^n$ si ha
\[
\norm{\mathbf{v}}_0 \leq \norm{\mathbf{v}}_2 \leq \sqrt{n}\norm{\mathbf{v}}_0.
\]
(esercizio: dimostrarlo.)

Esempio: disegnare le ``sfere'' $\norm{\mathbf{v}}=1$ in $\mathbb{R}^2$ nelle tre norme viste.

\paragraph{Norme matriciali}

Similmente ai vettori, possiamo definire norme su matrici. Si dice \emph{norma matriciale} una funzione $f: \mathbb{C}^{n\times n} \to \mathbb{R}$ che soddisfa queste proprietà:
\begin{enumerate}
    \item $f(A) \geq 0$ per ogni matrice $A\in\mathbb{C}^{n\times n}$, e l'uguaglianza vale solo per la matrice zero.
    \item $f(\alpha A) = \abs{\alpha} f(A)$ per ogni $A\in\mathbb{C}^{n\times n}$ e scalare $\alpha \in \mathbb{C}$.
    \item $f(A+B) \leq f(A) + f(B)$ per ogni $A,B\in\mathbb{C}^{n\times n}$.
    \item $f(AB) \leq f(A)f(B)$ per ogni $A,B\in\mathbb{C}^{n\times n}$.
\end{enumerate}
Rispetto al caso dei vettori, abbiamo aggiunto una proprietà che lega la norma al prodotto di matrici. Notate stavolta una differenza rispetto al valore assoluto; non abbiamo $\norm{AB} = \norm{A}\norm{B}$. Sarebbe impossibile ottenere norme con questa proprietà più forte.

\paragraph{Norme matriciali indotte}

È possibile costruire una norma matriciale a partire da ogni norma vettoriale in questo modo. Fissata una norma vettoriale $\norm{\cdot}_p$ (per esempio quelle con $p = 1,2,\infty$ viste sopra) definiamo
\begin{equation} \label{normamatriciale}
    \norm{A}_p = \max_{\substack{\mathbf{u}\in\mathbb{R}^n \\ \norm{\mathbf{u}}_p=1}} \norm{A\mathbf{u}}_p.
\end{equation}
In generale la matrice $A$ manderà gli infiniti vettori con norma uguale a $1$ in vettori di lunghezza diversa; prendiamo il più lungo, e definiamolo come la norma. Si può dimostrare (non lo faremo) che questa definizione soddisfa tutte le proprietà di una norma matriciale.

La definizione fatta in questo modo serve per assicurare un'ulteriore proprietà.
\begin{theorem}[compatibilità della norma matriciale indotta] \label{thm:compatibilita}
La norma matriciale $\norm{A}_p$ definita qui sopra soddisfa $\norm{A\mathbf{v}}_p \leq \norm{A}_p\norm{\mathbf{v}}_p$ per ogni matrice $A\in\mathbb{C}^{n\times n}$ e vettore $\mathbf{v}\in\mathbb{C}^n$.
\end{theorem}
Notare che mi serve usare \emph{la stessa} norma: per esempio se misuro i vettori in una norma $p$ con $p\in\{1,2,\infty\}$, dovrò usare la norma matriciale costruita usando la norma $p$ nella~\eqref{normamatriciale}.
\begin{proof}
Prima un caso particolare: se $\mathbf{v}=0$, allora anche $A\mathbf{v}=0$ e sia il membro di sinistra che quello di destra si annullano. Possiamo quindi proseguire considerando il caso $\mathbf{v}\neq 0$, e quindi $\norm{\mathbf{v}}_p \neq 0$.

Mi basta considerare il vettore $\mathbf{u} = \mathbf{v} \frac{1}{\norm{\mathbf{v}}_p}$. Questo vettore ha norma uguale a 1, per le proprietà delle norme vettoriali (considerandolo come il prodotto dello scalare $\frac{1}{\norm{\mathbf{v}}_p}$ e del vettore $\mathbf{v}$); quindi
\[
\frac{1}{\norm{\mathbf{v}}}_p \norm{A\mathbf{v}}_p  = \norm{A\mathbf{u}}_p \leq \norm{A}_p,
\]
ed eliminando il denominatore otteniamo la tesi.
\end{proof}

\paragraph{Norma di Frobenius}

Non tutte le norme matriciali si ottengono da questa costruzione. Un altro esempio è la \emph{norma di Frobenius},
\[
\norm{A}_F = \sqrt{\sum_{i,j=1}^n \abs{A_{ij}}^2}.
\]
Questa funzione soddisfa tutte le proprietà di una norma matriciale, ma non è una norma matriciale \emph{indotta}. Un modo veloce di vederlo è considerando la norma della matrice identità: $\norm{I}_F = \sqrt{n}$, ma per una norma matriciale indotta segue dalla definizione che $\norm{I}_p = 1$.

\paragraph{Norme, autovalori e raggio spettrale}

Data una matrice quadrata $A$, ricordiamo che quando $A\mathbf{v} = \mathbf{v}\lambda$ per un qualche vettore $\mathbf{v}\in\mathbb{C}^n$ (diverso dal vettore nullo!) e scalare $\lambda \in \mathbb{C}$ si dice che $\lambda$ è un \emph{autovalore} e $\mathbf{v}$ è un \emph{autovettore} di $A$. Avete visto ad algebra lineare diverse proprietà degli autovalori. Prendendo norme, abbiamo che
\[
\norm{\mathbf{v}}_p \abs{\lambda} = \norm{\mathbf{v}\lambda}_p = \norm{A\mathbf{v}}_p \leq \norm{A}_p \norm{\mathbf{v}}_p.
\]
Possiamo semplificare $\norm{\mathbf{v}}_p \neq 0$, quindi $\abs{\lambda} \leq \norm{A}$ per ogni autovalore.

Data una matrice $A \in \mathbb{C}^{n\times n}$ (quindi gli autovalori esistono sempre), si chiama \emph{spettro} l'insieme dei suoi autovalori, e \emph{raggio spettrale} (e si indica $\rho(A)$) il valore assoluto più grande degli autovalori, $\rho(A) = \max_{\lambda \text{ autoval.}} \abs{\lambda}$. Notate che il raggio spettrale non è per forza un autovalore: per esempio potremmo avere $A$ con autovalori $\{-2, i, -i\}$, e quindi $\rho(A)=2$ non è un autovalore.

In ogni caso, dalla formula qui sopra segue
\[
\rho(A) \leq \norm{A}_p
\]
per ogni norma matriciale indotta.

\paragraph{Formule per le norme matriciali $1,2,\infty$}
È abbastanza complicato calcolare le norme matriciali indotte usando la loro definizione: c'è da fare un massimo su un insieme infinito di vettori\dots. Per le norme $1,2,\infty$ ci sono delle formule più semplici. Le enunciamo senza dimostrazione.
\begin{align*}
\norm{A}_{\infty} &= \max_{i=1}^n \sum_{j=1}^n \abs{A_{ij}},\\
\norm{A}_{1} &= \max_{j=1}^n \sum_{i=1}^n \abs{A_{ij}},\\
\norm{A}_2 &= \rho(A^TA)^{1/2}.
\end{align*}
(Qui $\rho(\cdot)$ è di nuovo il raggio spettrale.)

Esempio: calcolare queste tre norme (e anche la norma di Frobenius) sulla matrice
\[
A = \begin{bmatrix}
    -2 & -1\\
    -2 & 1
\end{bmatrix},
\]
e verificare (aiutandosi eventualmente con Matlab) che $\rho(A)\leq \norm{A}_p$ per $p=1,2,\infty$. (La disuguaglianza è vera anche per $\norm{A}_F$, ma la dimostrazione che abbiamo fatto funziona solo per norme matriciali indotte.)

\paragraph{Condizionamento della soluzione di sistemi lineari} Prima ancora di parlare di algoritmi risolutivi, andiamo a studiare il condizionamento della soluzione di sistemi lineari, che ci dice quanto vale l'errore inerente. La soluzione di sistemi lineari è un problema che ha come ``input'' $A,\b$ e come ``output'' $\x$. Ha senso chiederci come cambia $\x$ se perturbiamo $A$ oppure $\b$, o anche tutti e due insieme. Possiamo definire degli errori relativi su queste quantità vettoriali e matriciali rimpiazzando i valori assoluti con delle norme: $\frac{\norm{\tilde{\x}-\x}}{\norm{\x}}$, $\frac{\norm{\tilde{A}-A}}{\norm{A}}$, $\frac{\norm{\tilde{\b}-\b}}{\norm{\b}}$ (occhio che $\norm{\frac{\tilde{\b}-\b}{\b}}$ non vuol dire niente, non possiamo dividere per vettori!)

Qui vediamo cosa succede quando perturbiamo il vettore dei termini noti $\b$. 
\begin{theorem}
    Sia $A\in \mathbb{C}^{n\times n}$ una matrice invertibile, e $\b,\tilde{\b} \in \mathbb{C}^n$ due vettori, con $\b\neq \mathbf{0}$. Siano $\x$ e $\tilde{\x}$ le soluzioni dei due sistemi lineari $A\x=\b$, $A\tilde{\x}=\tilde{\b}$. Allora, per una qualunque norma vettoriale $\norm{\cdot}_p$ si ha
    \begin{equation} \label{conditionbound}
        \frac{\norm{\tilde{\x}-\x}_p}{\norm{\x}_p} \leq \norm{A}_p\norm{A^{-1}}_p \frac{\norm{\tilde{\b}-\b}_p}{\norm{\b}_p}.    
    \end{equation}
\end{theorem}
In questa disuguaglianza, nei termini $\norm{A}_p$, $\norm{A^{-1}}_p$ si intende che utilizzano la norma matriciale indotta dalla norma vettoriale $\norm{\cdot}_p$.
\begin{proof}
Possiamo calcolare
\[
\norm{\tilde{\x}-\x}_p = \norm{A^{-1}\tilde{\b} - A^{-1}\b}_p = \norm{A^{-1}(\tilde{\b}-\b)}_p \leq  \norm{A^{-1}}_p\norm{\tilde{\b}-\b}_p,
\]
utilizzando la proprietà di compatibilità della norma matriciale indotta (Teorema~\ref{thm:compatibilita}). Per la stessa proprietà abbiamo
\[
\norm{\b}_p = \norm{A \x}_p \leq \norm{A}\norm{\x}_p.
\]
Possiamo dividere membro a membro le due disuguaglianze (i versi sono quelli corretti per farlo!), ottenendo la~\eqref{conditionbound}.
\end{proof}

Questa disuguaglianza è valida non solo al prim'ordine, ma per tutti gli $A,\x,\b$. La quantità $\kappa_p(A) = \norm{A}_p\norm{A^{-1}}_p$ si definisce ``numero di condizionamento'' (in norma-$p$) della matrice $A$ (con un piccolo abuso di notazione, visto che finora abbiamo definito il condizionamento di un \emph{problema} o di una \emph{funzione}).

La quantità $\kappa(A)$ è sempre maggiore di $1$, perché per ogni norma matriciale indotta $1 = \norm{I}_p = \norm{AA^{-1}}_p \leq \norm{A}_p\norm{A^{-1}}_p$. Una matrice si dice ``ben condizionata'' se questa quantità è vicina a 1, e ``mal condizionata'' se è molto maggiore di 1 (qualche migliaio almeno, di solito; non c'è una soglia precisa).

Non vediamo la dimostrazione, ma si può dimostrare che $\kappa(A)$ è anche il numero di condizionamneto rispetto a perturbazioni della matrice $A$: se $\tilde{\x}$ e $\x$ sono le soluzioni rispettivamente di $\tilde{A}\tilde{\x}=\b$ e $A\x=\b$, allora
\[
\frac{\norm{\tilde{\x}-\x}_p}{\norm{\x}_p} \mathrel{\stackrel{.}{\leq}} \norm{A}_p\norm{A^{-1}}_p \frac{\norm{\tilde{A}-A}_p}{\norm{A}_p}.
\]
Occhio al punto sopra il $\leq$: a differenza del precedente, in questo caso si tratta di un risultato che vale solo a meno di termini dell'ordine del quadrato di $\frac{\norm{\tilde{A}-A}_p}{\norm{A}_p}$: se $\frac{\norm{\tilde{A}-A}_p}{\norm{A}_p}$ è grande, questa disuguaglianza può essere ben lontana dall'essere verificata.

\paragraph{Esempio} Con Matlab, è problematico mostrare gli errori facendo esempi di perturbazioni dell'ordine della precisione di macchina $\mathsf{u}\approx 2.2\times 10^{-16}$, visto che i calcoli stessi che facciamo sono affetti da un errore dello stesso ordine di grandezza. Possiamo però vedere cosa succede con perturbazioni molto più grandi.
\begin{lstlisting}
>> A = [1 2; 3 4]
A =
        1     2
        3     4
>> b = [3;7];
>> x = A \ b
x =
    1.0000e+00
    1.0000e+00
>> btilde = [3.0001; 6.9999];
>> xtilde = A \ btilde
xtilde =
    9.9970e-01
    1.0002e+00
>> norm(btilde - b, inf) / norm(b, inf) % errore relativo
ans =
    1.4286e-05
>> norm(xtilde - x, inf) / norm(x, inf)
ans =
    3.0000e-04
>> norm(A, inf) * norm(inv(A), inf) % numero di condizionamento
ans =
    2.1000e+01
>> cond(A, inf)  % funzione Matlab per calcolarlo direttamente
ans =
    2.1000e+01
\end{lstlisting}
La matrice $A$ ha numero di condizionamento 21. Quindi l'errore relativo sulla soluzione $\x$ calcolata è pari ad al più 21 volte l'errore relativo sul dato in ingresso $\b$. Visto che questo fattore 21 è tutto sommato piccolo, diciamo che la matrice $A$ è \emph{ben condizionata}.
\begin{lstlisting}
>> A = [1 2; 2.0001 4]
A =
    1.0000e+00   2.0000e+00
    2.0001e+00   4.0000e+00
>> b = A*[1;1]
b =
    3.0000e+00
    6.0001e+00
>> btilde = [2.9999; 6.0002]
btilde =
    2.9999e+00
    6.0002e+00
>> x = A \ b
x =
    1.0000e+00
    1.0000e+00
>> xtilde = A \ btilde
xtilde =
    4.0000e+00
    -5.0005e-01
>> norm(btilde - b, inf) / norm(b, inf)
ans =
    1.6666e-05
>> norm(xtilde - x, inf) / norm(x, inf)
ans =
    3.0000e+00
>> norm(A, inf) * norm(inv(A), inf)
ans =
    1.8000e+05
>> cond(A, inf)
ans =
    1.8000e+05        
\end{lstlisting}
Questa nuova matrice $A$ ha un numero di condizionamento molto più grande, $1.8\times 10^{-5}$. Diciamo che è \emph{mal condizionata}. L'errore relativo sul termine noto $b$ pari a $1.66 \times 10^{-5}$ produce un errore relativo sulla soluzione $x$ pari a $3$; cioè la soluzione ottenuta è completamente sbagliata. La disuguaglianza~\eqref{conditionbound} comunque è rispettata anche in questo caso.


\section{Condizionamento del calcolo di autovalori (**)}
Un altro problema classico dell'algebra lineare è il calcolo di autovalori e autovettori. Non vediamo nel dettaglio algoritmi per farlo, perché sono molto più complicati; ci fideremo di \texttt{eig(A)} di Matlab. Però, almeno per studiare il problema teoricamente, è importante vedere quale è il condizionamento di questa operazione, in modo da sapere quando anche Matlab rischia di calcolare un risultato errato.

Ci limitiamo a un caso più facile, quello di \emph{autovalori semplici}: un autovalore si dice \emph{semplice} se la sua molteplicità geometrica e algebrica è uguale a 1, cioè, se è uno zero semplice del polinomio caratteristico $\det(\lambda I - A)$. In questo caso, esistono e sono unici (a meno di multipli) un autovalore destro $\mathbf{x}$ e uno sinistro $\mathbf{y}^*$ associati a $\lambda$; cioè, $A\mathbf{x} = \mathbf{x}\lambda$ e $\mathbf{y}^* A = \lambda \mathbf{y}^*$. Si può dimostrare che per un autovalore semplice $\mathbf{x}$ e $\mathbf{y}^*$ non sono mai ortogonali. Il risultato di perturbazione che enunciamo dipende dal coseno dell'angolo che essi formano, cioè
\[
\cos \theta = \frac{\abs{\mathbf{y}^* \mathbf{x}}}{\norm{\mathbf{y}}_2 \norm{\mathbf{x}}_2}.
\]
\begin{theorem}[Perturbazione di autovalori (*)]
Sia $\lambda$ un autovalore \emph{semplice} della matrice $A \in \mathbb{C}^{n\times n}$. Sia $\tilde{A}$ una perturbazione di $A$; allora esiste un autovalore $\tilde{\lambda}$ di $\tilde{A}$ tale che
\[
\abs{\tilde{\lambda} - \lambda} \stackrel{.}{\leq} \frac{1}{\cos \theta}\norm{\tilde{A}-A}_2,
\]
dove $\theta$ è l'angolo tra l'autovettore destro $\mathbf{x}$ e quello sinistro $\mathbf{y}^*$ associati a $\lambda$.
\end{theorem}
Occhio al punto sopra il $\leq$: anche in questo caso il risultato è valido solo al prim'ordine, cioè ignorando termini dell'ordine di $\norm{\tilde{A}-A}_2^2$.

In particolare, quando $A$ è una matrice simmetrica gli autovalori destri e sinistri coincidono, cioè $\mathbf{x}=\mathbf{y}$; quindi il coseno è uguale a 1 e il calcolo degli autovalori di una matrice simmetrica è sempre un'operazione ben condizionata.

\begin{proof}
Scriviamo $\tilde{A} - A = \varepsilon E$, dove $\norm{E}_2 = 1$ e $\varepsilon = \norm{\tilde{A}-A}_2$. Consideriamo la funzione $A(t) = A + t E$. È possibile dimostrare usando il teorema della funzione implicita che esistono funzioni differenziabili $\lambda(t), \mathbf{x}(t)$ tali che $\lambda(t)$ è un autovalore di $A(t)$ e $\mathbf{x}(t)$ è il suo autovettore, e tali che $\lambda(0)=\lambda$, $\mathbf{x}(0) = \mathbf{x}$. Quindi, in particolare, vale la relazione
\[
A(t)\mathbf{x}(t) = \mathbf{x}(t) \lambda(t).
\]
Possiamo derivare entrambi i termini rispetto a $t$, per ottenere
\[
\underbrace{\dot{A}(t)}_{=E} \mathbf{x}(t) + A(t)\dot{\mathbf{x}}(t) = \dot{\mathbf{x}}(t) \lambda(t) + \mathbf{x}(t) \dot{\lambda}(t).
\]
Valutiamo in $t=0$, e otteniamo
\[
E \mathbf{x} + A \dot{\mathbf{x}}(0) = \dot{\mathbf{x}}(0) \lambda + \mathbf{x} \dot{\lambda}(0)
\]
Moltiplichiamo a sinistra per $\mathbf{y}^*$, e usiamo il fatto che $\mathbf{y}^* A = \lambda \mathbf{y}^*$ per semplificare due termini della relazione
\[
\mathbf{y}^* E \mathbf{x} +  \mathbf{y}^*A \dot{\mathbf{x}}(0) = \lambda\mathbf{y}^* \dot{\mathbf{x}}(0)  + \mathbf{y}^* \mathbf{x} \dot{\lambda}(0).
\]
Quindi otteniamo
\[
\dot{\lambda}(0) = \frac{1}{\mathbf{y}^*\mathbf{x}} \mathbf{y}^* E \mathbf{x}.
\]
Possiamo scrivere, a meno di termini di ordine superiore in $\varepsilon$, lo sviluppo di Taylor
\begin{equation} \label{eigperturb}
\tilde{\lambda} = \lambda(\varepsilon) \stackrel{.}{=} \lambda + \varepsilon \dot{\lambda}(0) = \lambda + \varepsilon \frac{1}{\mathbf{y}^*\mathbf{x}} \mathbf{y}^* E \mathbf{x}
\end{equation}
da cui
\[
\abs{\tilde{\lambda} - \lambda} \stackrel{.}{=} \varepsilon \frac{1}{\mathbf{y}^*\mathbf{x}} \mathbf{y}^* E \mathbf{x}
\]

Per concludere dimostriamo che $\abs{\mathbf{y}^* E \mathbf{x}} \leq \norm{\mathbf{y}}_2\norm{\mathbf{x}}_2$. Poiché $\mathbf{y}^* E \mathbf{x}$ è il prodotto scalare tra $\mathbf{y}$ e $E \mathbf{x}$, chiamando $\alpha$ l'angolo che formano abbiamo
\[
    \abs{\mathbf{y}^* E \mathbf{x}} = \norm{\mathbf{y}}_2 \norm{E \mathbf{x}}_2 \cos\alpha \leq \norm{\mathbf{y}}_2 \norm{E \mathbf{x}}_2
\]
Infine, poiché $\norm{E}_2 = 1$, dalle proprietà delle norme matriciali abbiamo $\norm{E\mathbf{x}}_2 \leq \norm{E}_2\norm{\mathbf{x}}_2$. Combinando le disuguaglianze e ricordando che $\varepsilon = \norm{\tilde{A}-A}_2$, otteniamo la tesi.
\end{proof}
Nel caso di autovalori non semplici, le perturbazioni agli autovalori possono essere molto più grandi. Per esempio, consideriamo la matrice $n\times n$ che ha uni sulla sopradiagonale, $\varepsilon$ in posizione $(n,1)$, e zero in tutte le altre posizioni
\[
A(\varepsilon) = \begin{bmatrix}
    0 & 1\\
    & 0 & \ddots\\
    & & \ddots & 1\\
    \varepsilon & & &  0\\
\end{bmatrix}.
\]
Se $\varepsilon=0$, chiaramente tutti gli autovalori sono zero, perché la matrice è triangolare superiore. Per $\varepsilon \neq 0$, è possibile dimostrare che gli autovalori di $A(\varepsilon)$ sono le radici $n$-esime complesse di $\varepsilon$, che hanno tutte modulo $\varepsilon^{1/n}$. Quindi
\[
\abs{\tilde{\lambda} - \lambda} = \varepsilon^{1/n},
\]
che è molto più grande di $\varepsilon$. Per esempio, se $\varepsilon=10^{-16}$, $n=8$, abbiamo $\varepsilon^{1/n} = 10^{-2}$: una perturbazione alla matrice $A(0)$ di norma $10^{-16}$ fa spostare gli autovalori di una distanza $10^{-2}$.

\section{Teorema dei cerchi di Gershgorin (*)}

Vediamo ora un risultato teorico che ci dice in quali regioni del piano complesso si possono trovare gli autovalori di una matrice. Per introdurlo, definiamo i \emph{cerchi di Gershgorin} di una matrice $A\in\mathbb{C}^{n\times n}$ come gli insiemi
\[
K_i = \left\{z\in \mathbb{C} \colon \abs{z - A_{ii}} \leq \sum_{\substack{j=1\\ j \neq i}}^n \abs{A_{ij}} \right\}, \quad i=1,2,\dots,n.
\]
Le equazioni definiscono l'interno di $n$ cerchi, che hanno centro negli elementi diagonali di $A$ e raggio uguale alla somma dei moduli degli elementi al di fuori della riga.

\begin{theorem}[Teorema dei cerchi di Gershgorin]
Sia $A\in\mathbb{C}^{n\times n}$, e $\lambda$ un suo autovalore. Allora $\lambda$ appartiene all'unione dei cerchi $K_i$ definiti sopra (al variare di $i=1,2,\dots,n$).
\end{theorem}
\begin{proof}
Prendiamo un autovettore $\mathbf{x}$ associato a $\lambda$. Scrivendo componente per componente la relazione $A\mathbf{x} = \mathbf{x}\lambda$ otteniamo
\[
\sum_{j=1}^n A_{ij}x_j = x_i \lambda, \quad i=1,2,\dots,n.
\]
Riarrangiando termini e prendendo i moduli otteniamo
\[
\abs{\lambda - A_{ii}}\abs{x_i} = \abs{x_i\lambda - A_{ii}x_i} = \abs*{\sum_{\substack{j=1\\ j \neq i}}^n A_{ij}x_j} \leq \sum_{\substack{j=1\\ j \neq i}}^n \abs{A_{ij}}\abs{x_j}.
\]
Questa uguaglianza è valida per ogni $i=1,2,\dots,n$. Scegliamo ora come $i$ l'indice $p$ (o uno degli indici) tale che il modulo $\abs{x_p}$ sia massimo. Poiché $\mathbf{x}\neq 0$, avremo $\abs{x_p} \neq 0$. Possiamo quindi riscrivere l'uguaglianza precedente per $i=p$ e dividere per $\abs{x_p}$ entrambi i lati, ottenendo
\[
\abs{\lambda - A_{pp}} \leq \sum_{\substack{j=1\\ j \neq p}}^n \abs{A_{pj}}\frac{\abs{x_j}}{\abs{x_p}} \leq \sum_{\substack{j=1\\ j \neq i}}^n \abs{A_{pj}}.
\]
L'ultima disuguaglianza segue dal fatto che $\abs{x_p}$ è massimo. Questa catena di disuguaglianze dimostra che $\lambda$ sta all'interno del cerchio $K_p$. Poiché $\lambda$ sta all'interno di almeno un cerchio, sta anche all'interno della loro unione.
\end{proof}


\section{Soluzione di equazioni lineari: casi speciali}

\paragraph{Sistemi diagonali}

Il caso più semplice è quello di $A$ \emph{diagonale}, vale a dire
\[  
A = \begin{bmatrix}
    A_{11} \\
    & A_{22}\\
    && \ddots\\
    &&& A_{nn}
\end{bmatrix} \in \mathbb{R}^{n \times n}
\]
(ricordiamo la convenzione che gli elementi che non scriviamo sono zeri).

In questo caso i prodotti sono semplici da fare, e $Ax=b$ implica
\begin{align*}
x_i = \frac{b_i}{A_{ii}}, \quad i=1,2,\dots,n.
\end{align*}
Il costo chiaramente è di $n$ operazioni aritmetiche.

\paragraph{Sistemi triangolari}

Un caso particolare  è quello in cui la matrice è \emph{triangolare inferiore}, cioè contiene zeri al di sopra della diagonale ($A_{ij} =0$ se $i<j$), oppure è \emph{triangolare superiore} ($A_{ij}=0$ se $i>j$).

(Una matrice può essere al tempo stesso \emph{triangolare} e \emph{quadrata}!)

Ricordiamo che una matrice triangolare è invertibile se gli elementi sulla sua diagonale sono tutti diversi da zero. Per dimostrarlo, per esempio notiamo che una matrice è invertibile se tutti i suoi autovalori sono diversi da zero, e che gli autovalori di una matrice triangolare sono uguali agli elementi sulla diagonale.

Se la matrice è triangolare inferiore, possiamo risolvere il sistema per \emph{sostituzione in avanti} partendo dalla prima equazione, che contiene solo la prima incognita:
\begin{align*}
 x_1 &= \frac{b_1}{A_{11}},\\
 x_2 &= \frac{b_2 - A_{21}x_1}{A_{22}},\\
 \vdots & \quad \quad \quad \vdots\\
 % x_i &= \frac{b_i - A_{i1}x_1 - \dots -A_{i,i-1}x_{i-1}}{A_{ii}},\\
 % \vdots & \vdots\\
 x_n &= \frac{b_n - A_{n1}x_1 - A_{n2}x_2 - \dots -A_{n,n-1}x_{n-1}}{A_{nn}}.\\
 \end{align*} 
Notare che ad ogni passo compaiono a destra dell'uguale solo valori $x_i$ che abbiamo già calcolato nei passi precedenti.
Possiamo contare il numero di operazioni in ogni riga, ottenendo
\[
1 + 3 + 5 + \dots + (2n-1) = n^2
\]
(questa ultima uguaglianza si può dimostrare per induzione).

Diciamo che la complessità del metodo è di $n^2$ operazioni aritmetiche. Notare che in questo caso non ci sono funzioni sconosciute da valutare, quindi questa è davvero tutta la complessità. Inoltre queste operazioni calcolano esattamente la soluzione, quindi quello che abbiamo chiamato ``errore analitico'' è zero.

Spesso quando si parla di complessità ci interessa solo l'ordine di grandezza, e quindi si scrive $\mathcal{O}(n^2)$. Come in analisi, questa è una notazione che include complessità come $2n^2$, $\frac{1}{3}n^2 + 2n - 5$, ecc. Si intende che lavoriamo nel limite $n\to \infty$, quindi ignoriamo potenze \emph{inferiori} della $n$ che crescono più lentamente di $n^2$. 

Per una matrice triangolare superiore, la tecnica è analoga, ma dobbiamo partire dall'ultima equazione e risolvere ``andando al contrario'' (\emph{sostituzione all'indietro}):
\begin{align*}
x_n &= \frac{b_n}{A_{nn}},\\
x_{n-1} &= \frac{b_{n-1} - A_{n-1,n}x_n}{A_{n-1,n-1}},\\
\vdots & \quad \quad \quad \vdots\\
x_1 &= \frac{b_1 - A_{1,n}x_n - A_{1,n-1}x_{n-1} - \dots -A_{1,2}x_{2}}{A_{11}}.\\
\end{align*}

La complessità è di nuovo $n^2$ operazioni.

Se una matrice triangolare ha molti elementi uguali a zero (si dice che è \emph{sparsa}), e sappiamo da principio questo fatto, possiamo scrivere del codice specializzato che salta le operazioni che coinvolgono degli elementi $A_{ij}$ che sappiamo essere zero. In questo modo si utilizzano $\mathcal{O}(2\texttt{nnz})$ operazioni, dove \texttt{nnz} è il \emph{numero di nonzeri} della matrice.

\paragraph{Stabilità della soluzione di sistemi lineari speciali} Abbiamo visto che l'errore commesso nella soluzione numerica di un problema è $e_{tot} \doteq e_{an} + e_{mac}$. In questi algoritmi, la quantità $\gamma$ che calcoliamo è \emph{esattamente} uguale alla soluzione $\alpha$ del problema: non abbiamo processi di limite, o successioni che convergono alla soluzione $\alpha$ e che dobbiamo troncare. Quindi $e_{an} = 0$. Abbiamo visto ulteriormente che 
$e_{mac} \doteq e_{in} + e_{alg},$ e che $e_{alg} \leq \kappa_{\x,A}\mathsf{u} + \kappa_{\x,\b} \mathsf{u} \doteq 2\kappa(A)\mathsf{u}$. È possibile dimostrare (qui non lo vediamo) che gli algoritmi di soluzione di sistemi diagonali e sostituzione in avanti e all'indietro sono \emph{stabili}, cioè $e_{alg}$ non è mai molto più grande di $e_{in}$.

\section{Eliminazione di Gauss e fattorizzazione LU}

Si chiama \emph{fattorizzazione LU} di $A$ una decomposizione di una matrice $A\in\mathbb{C}^{n\times n}$ come prodotto $A=LU$, dove $L$ è una matrice triangolare inferiore con elementi tutti uguali a $1$ sulla diagonale, e $U$ è una matrice triangolare superiore. Vediamo ora un metodo che permette di calcolare una fattorizzazione LU di una matrice $A \in \mathbb{C}^{n\times n}$; questo algoritmo è sostanzialmente una variante dell'eliminazione di Gauss che avete già visto ad algebra lineare.

\paragraph{Ripasso: l'eliminazione di Gauss} Ricordiamo come funziona l'eliminazione di Gauss. Ce ne sono diverse varianti che si vedono ad algebra lineare, qui in particolare ci concentriamo su una di esse:
\begin{itemize}
    \item Lavoriamo solo sulla matrice quadrata $A\in\mathbb{C}^{n\times n}$, \emph{non} sulla cosiddetta ``matrice estesa'' $\begin{bmatrix}
    A & \b
\end{bmatrix}$;
    \item Puntiamo a fare combinazioni lineari delle \emph{righe} (non colonne) per trasformare $A$ in forma \emph{triangolare superiore}; non vogliamo eliminare anche gli elementi sopra il pivot per trasformare $A$ in una matrice diagonale, come talvolta si fa (eliminazione di Gauss--Jordan).
    \item Non facciamo (per ora) scambi di righe, e assumiamo (per ora) che tutti i pivot siano diversi da zero; in questo modo otterremo una matrice triangolare superiore con elementi diversi da zero sulla triangolare principale.
\end{itemize}
Partiamo definendo $U_1 = A$, e vogliamo applicare ripetutamente delle trasformazioni in modo da generare una sequenza di matrici $U_2, U_3, \dots, U_n$, dove l'ultima matrice $U_n$ è triangolare superiore. Supponiamo di aver già fatto $k-1$ passi ed essere al $k$-esimo. Abbiamo generato a partire da $A$ una matrice $A_k \in\mathbb{C}^{n\times n}$ che è parzialmente in forma triangolare superiore: in ogni colonna $j<k$, gli elementi sotto la diagonale sono nulli. 
\[
U_k = \begin{bmatrix}
    \ast & \dots & \ast & \ast & \ast & \dots & \ast\\
    0 & \ddots & \ast& \ast & \ast& \dots & \ast\\
    \vdots & \ddots & \ast & \ast& \ast & \dots & \ast\\
    0& 0  &0 & (U_k)_{kk} & \ast & \dots & \ast\\
    0& 0  &0 & (U_k)_{k+1,k} & \ast & \dots & \ast\\
    0& 0  &0 & \vdots & \ast & \dots & \ast\\
    0& 0  &0 & (U_k)_{n,k} & \ast & \dots & \ast\\
\end{bmatrix}
\]
(abbiamo chiamato $(A_k)_{ij}$ gli elementi della matrice $A_k$).
Nel $k$-esimo passo, andiamo a introdurre zeri anche nella $k$-esima colonna, costruendo una nuova matrice 
\[
U_{k+1} = \begin{bmatrix}
    \ast & \dots & \ast & \ast & \ast & \dots & \ast\\
    0 & \ddots & \ast& \ast & \ast& \dots & \ast\\
    \vdots & \ddots & \ast & \ast& \ast & \dots & \ast\\
    0& 0  &0 & (U_k)_{kk} & \ast & \dots & \ast\\
    0& 0  &0 & 0 & \ast & \dots & \ast\\
    0& 0  &0 & \vdots & \ast & \dots & \ast\\
    0& 0  &0 & 0 & \ast & \dots & \ast\\
\end{bmatrix}.
\]
Per ottenere $U_{k+1}$, sottraiamo da ogni riga $i>k$ di $U_k$ un opportuno multiplo (\emph{moltiplicatore}) della $k$-esima riga; visto che vogliamo eliminare l'elemento in posizione $(i,k)$, questo multiplo dev'essere scelto pari a $L_{ik} = \frac{(U_k)_{ik}}{(U_k)_{kk}}$. Le prime $k$ righe di $U_k$ rimangono invariate.

\paragraph{Moltiplicatori}
In aggiunta all'eliminazione di Gauss, vogliamo tenere traccia dei moltiplicatori usati ad ogni passo, andando a scriverli separatamente in una seconda matrice. Al primo passo, partiamo da una matrice $L_1 = I$ (vedremo poi perché partiamo dalla matrice identità); poi, ad ogni passo di eliminazione di Gauss, andiamo a scrivere il moltiplicatore $L_{ik} = \frac{(U_k)_{ik}}{(U_k)_{kk}}$ nella posizione $i,k$ di questa matrice. In questo modo, per esempio per una matrice $4\times 4$,  ad ogni passo la struttura delle matrici ottenute è (indicando con $*$ gli elementi diversi da zero)
\[
    \begin{array}{ll}
    L_1 = \begin{bmatrix}
        1 & 0 & 0 & 0\\
        0 & 1 & 0 & 0\\
        0 & 0 & 1 & 0\\        
        0 & 0 & 0 & 1\\
    \end{bmatrix} 
    & U_1 = \begin{bmatrix}
        * & * & * & *\\
        * & * & * & *\\
        * & * & * & *\\
        * & * & * & *\\
    \end{bmatrix},\\[6ex]
    L_2 = \begin{bmatrix}
        1 & 0 & 0 & 0\\
        * & 1 & 0 & 0\\
        * & 0 & 1 & 0\\        
        * & 0 & 0 & 1\\
    \end{bmatrix} & U_2 = \begin{bmatrix}
        * & * & * & *\\
        0 & * & * & *\\
        0 & * & * & *\\
        0 & * & * & *\\
    \end{bmatrix},\\[6ex]
    L_3 = \begin{bmatrix}
        1 & 0 & 0 & 0\\
        * & 1 & 0 & 0\\
        * & * & 1 & 0\\        
        * & * & 0 & 1\\
    \end{bmatrix} & U_3 = \begin{bmatrix}
        * & * & * & *\\
        0 & * & * & *\\
        0 & 0 & * & *\\
        0 & 0 & * & *\\
    \end{bmatrix},\\[6ex]
    L_4 = \begin{bmatrix}
        1 & 0 & 0 & 0\\
        * & 1 & 0 & 0\\
        * & * & 1 & 0\\        
        * & * & * & 1\\
    \end{bmatrix} & U_4 = \begin{bmatrix}
        * & * & * & *\\
        0 & * & * & *\\
        0 & 0 & * & *\\
        0 & 0 & 0 & *\\
    \end{bmatrix}.
    \end{array}
\]
Dimostreremo più avanti che ad ogni passo si ha $L_k U_k = A$, cioè il prodotto di queste due matrici è uguale alla matrice di partenza $A$. Questo è il motivo per cui siamo partiti con $L_1 = I$, anziché, per esempio, da $L_1 = 0$: gli uni sulla diagonale sono necessari per far valere l'uguaglianza $L_k U_k = A$. Notiamo in particolare due casi di questa uguaglianza: quando $k=1$, abbiamo l'uguaglianza (ovvia) $I \cdot A = A$; e all'ultimo passo abbiamo $L_n U_n = A$, che è esattamente la fattorizzazione LU che stiamo cercando: $L_n=L$ è triangolare inferiore con 1 sulla diagonale, $U_n=U$ è triangolare superiore.

% Quindi dopo il passo $k$ abbiamo
% \begin{equation} \label{fattLU}
% A = 
% \underbrace{
% \begin{bmatrix}
%     1\\
%     \ell_{21} & \ddots\\
%     \vdots & \vdots & 1\\
%     \vdots & \vdots & \ell_{k+1,k} & 1\\
%     \vdots & \vdots & \ell_{k+2,k} & 0 & 1\\
%     \vdots & \vdots & \vdots & 0 & 0 & \ddots\\
%     \ell_{n1} & \dots & \ell_{n,k} & 0 & \dots & \dots & 1\\
% \end{bmatrix}
% }_{L_{k+1} = E_1^{-1}E_2^{-1}\dots E_k^{-1}}
% \underbrace{
% \begin{bmatrix}
%     U_{11} & U_{12} & \dots & & & &U_{1,n} \\
%     0 & \ddots  & \dots & \dots & \dots &\dots & \vdots\\
%     0 & & U_{kk} & \dots & \dots & \dots & \vdots\\
%     0 & \dots & 0 & U_{k+1,k+1} & \dots & \dots & U_{k+1,n}\\
%     0 & \dots & 0 & U_{k+2,k+1} & & &\vdots\\
%     0 & \dots & 0 & \vdots & & & \vdots\\
%     0 & \dots & 0 & U_{n,k+1} & \dots & \dots & U_{n,n}\\
% \end{bmatrix}.
% }_{U_{k+1}}
% \end{equation}
% In particolare, dopo $n-1$ passi, abbiamo ottenuto matrici $L=L_n$ e $U=U_n$ tali che
% \[
% A = L U,
% \]
% $U = U_n$ è una matrice triangolare superiore, e 
% \[
% L = E_1^{-1}E_2^{-1}\dots E_{n-1}^{-1} = \begin{bmatrix}
%     1\\
%     \ell_{21} & 1\\
%     \ell_{31} & \ell_{32} & 1\\
%     \ell_{41} & \ell_{42} & \ell_{43} & 1\\
%     \vdots & \vdots & \vdots & \ddots & \ddots\\
%     \ell_{n1} & \ell_{n2} & \ell_3 & \dots & \ell_{n,n-1} & 1
% \end{bmatrix},
% \]
% è una matrice triangolare inferiore con $1$ sulla diagonale.

\paragraph{Esempio} Vediamo innanzitutto un esempio.
% >> rng(0)
\begin{lstlisting}
>> A = rand(4, 4)
A =
    0.8147    0.6324    0.9575    0.9572
    0.9058    0.0975    0.9649    0.4854
    0.1270    0.2785    0.1576    0.8003
    0.9134    0.5469    0.9706    0.1419
>> U1 = A;
>> E1 = eye(4); E1(2:4, 1) = -U1(2:4, 1) / U1(1, 1)
E1 =
    1.0000         0         0         0
   -1.1118    1.0000         0         0
   -0.1559         0    1.0000         0
   -1.1211         0         0    1.0000
>> U2 = E1 * U1
U2 =
    0.8147    0.6324    0.9575    0.9572
         0   -0.6055   -0.0996   -0.5788
         0    0.1799    0.0084    0.6511
         0   -0.1620   -0.1029   -0.9312
>> E2 = eye(4); E2(3:4, 2) = -U2(3:4, 2) / U2(2, 2)
E2 =
    1.0000         0         0         0
         0    1.0000         0         0
         0    0.2972    1.0000         0
         0   -0.2676         0    1.0000
>> U3 = E2 * U2
U3 =
    0.8147    0.6324    0.9575    0.9572
         0   -0.6055   -0.0996   -0.5788
         0         0   -0.0212    0.4791
         0         0   -0.0762   -0.7763
>> E3 = eye(4); E3(4:4, 3) = -U3(4:4, 3) / U3(3, 3)
E3 =
    1.0000         0         0         0
         0    1.0000         0         0
         0         0    1.0000         0
         0         0   -3.5869    1.0000
>> U4 = E3 * U3
U4 =
    0.8147    0.6324    0.9575    0.9572
         0   -0.6055   -0.0996   -0.5788
         0         0   -0.0212    0.4791
         0         0         0   -2.4948
\end{lstlisting}
Basandoci sull'esempio, andiamo ora a scrivere in una funzione una versione generale dell'algoritmo. Vogliamo utilizzare due sole variabili: una che chiamiamo $U$ e che contiene $U_k$ ad ogni passo, e una che chiamiamo $L$, che inizialmente è uguale alla matrice identità, e in cui scriviamo di volta in volta i moltiplicatori usati.
\begin{lstlisting}
function [L, U] = fattorizzazioneLU(A)

[m, n] = size(A);
if not(m == n)
    error('A dev''essere quadrata');
end

L = eye(n); % qui scriveremo i moltiplicatori
U = A;      % qui scriveremo U1, U2, ... Un
for k = 1:n-1
    % ad ogni passo di questo ciclo vale L*U = A

    if U(k,k) == 0
        error('Pivot nullo');
    end
    L(k+1:n, k) = U(k+1:n, k) / U(k, k);
    % sappiamo che questi elementi devono diventare zero
    U(k+1:n, k) = 0;
    % aggiorniamo le righe di U una ad una
    for i = k+1:n
        U(i, k+1:n) = U(i, k+1:n) - L(i,k)*U(k,k+1:n);
    end
end
\end{lstlisting}

\paragraph{Costo computazionale dell'eliminazione di Gauss}

Il grosso del costo è dato dall'aggiornamento del blocco $U_{k+1:n, k+1:n}$ ad ogni passo del ciclo for; questo richiede $2(n-1)^2$ operazioni al primo passo, $2(n-2)^2$ al secondo, \dots $2\cdot 1^2$ al $n-2$-esimo passo, $2\cdot 0^2$ al $n-1$-esimo passo. Un'identità algebrica (che possiamo dimostrare per induzione) ci dice che
\[
0^2+1^2 + 2^2 + \dots + (n-1)^2 = \frac{1}{6}(n-1)n(2n-1) = \frac13n^3 + \mathcal{O}(n^2).
\]
I termini che abbiamo omesso e indicato con $\mathcal{O}(n^2)$ sono \emph{di ordine inferiore} a $\frac13 n^3$, cioè contengono potenze più basse della $n$. Se teniamo traccia delle operazioni nelle altre righe (ad esempio, il calcolo degli $L_{ij}$) otteniamo termini di ordine inferiore. Quindi il costo della fattorizzazione LU (così come quello dell'eliminazione di Gauss) è $\frac23 n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche.

Notiamo che nel codice non abbiamo mai scritto esplicitamente moltiplicazioni di matrici \lstinline{Ek*Uk}, ma abbiamo invece usato del codice che ne calcola il risultato usando la struttura particolare di queste matrici $E_k$. Se invece lo avessimo scritto come prodotto, per esempio \lstinline{U2 = E1*U1}, Matlab avrebbe usato ad ogni passo l'algoritmo generale per calcolare un prodotto matrice-matrice, che è molto più costoso. Solo effettuare il prodotto $U_2 = E_1 U_1$ al primo passo avrebbe richiesto $2n^3 + \mathcal{O}(n^2)$ operazioni in aritmetiche: più di quello che abbiamo speso per tutto l'algoritmo!

\paragraph{Soluzione di sistemi lineari tramite la fattorizzazione LU} 
Una volta calcolata $A = LU$, abbiamo decomposto $A$ in un prodotto di matrici più semplici, e possiamo usare questa decomposizione per risolvere sistemi lineari. 


Notiamo inoltre che la matrice $L$ è sempre invertibile (perché ha 1 sulla diagonale), e in più abbiamo $\det(A) = \det(LU) = \det(L) \det(U)$, quindi $U$ è invertibile se e solo se $A$ lo è. Quindi possiamo risolvere sistemi lineari con matrici $L$ e $U$. Abbiamo $\b = A\x = LU\x$.
L'algoritmo è composto di tre passi:
\begin{enumerate}
    \item Calcolo la fattorizzazione $A=LU$.
    \item Calcolo il vettore $\mathbf{y}=U\x$ risolvendo il sistema lineare $\b=L\mathbf{y}$ (sostituzione in avanti).
    \item Calcolo il vettore $\x$ risolvendo il sistema lineare $\mathbf{y}=U\x$ (sostituzione all'indietro).
\end{enumerate}
Il costo del primo passo è di $\frac23 n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche. Il secondo e il terzo costano $n^2$ operazioni aritmetiche, quindi sono molto più economici e possono venire inclusi dentro il termine $\mathcal{O}(n^2)$. In totale quindi la soluzione di un sistema lineare tramite la fattorizzazione LU richiede $\frac23 n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche.

Un'altra osservazione interessante è che se dobbiamo risolvere molti sistemi lineari con vettori $\b$ diversi ma la stessa matrice $A$, possiamo riutilizzare la stessa fattorizzazione LU più volte, e quindi effettuare il passo più costoso una volta sola.

\paragraph{Matrici elementari di Gauss} Ci concentriamo ora sul dimostrare la proprietà che $L_k U_k = A$ in ogni passo $k=1,2,\dots,n$ della fattorizzazione. Per farlo, ci serve introdurre una famiglia di matrici che permette di vedere l'eliminazione di Gauss come una sequenza di moltiplicazioni.

Possiamo notare che effettuare un passo di eliminazione di Gauss si può vedere come una moltiplicazione a sinistra per una matrice: $U_{k+1} = E_k U_k$. La matrice $E_k$ è
\begin{equation} \label{Ekgauss}
E_k = \begin{bmatrix}
    1 \\
    & 1\\
    && \ddots\\
    & & & 1\\
    & & & -L_{k+1,k} & 1\\
    & & & -L_{k+2,k} & & 1\\
    & & & \vdots & & & \ddots \\
    & & & -L_{n,k} & & & & 1
\end{bmatrix}
\end{equation}
(ricordiamo la convenzione: gli elementi che non scriviamo sono zero). Una matrice della forma~\eqref{Ekgauss} è detta \emph{matrice elementare di Gauss}. Difatti, se calcoliamo il prodotto di $E_k$ per un vettore generico $\mathbf{x}$, otteniamo
\[
E_k \mathbf{x} = \begin{bmatrix}
    1 \\
    & 1\\
    && \ddots\\
    & & & 1\\
    & & & -L_{k+1,k} & 1\\
    & & & -L_{k+2,k} & & 1\\
    & & & \vdots & & & \ddots \\
    & & & -L_{n,k} & & & & 1
\end{bmatrix}
\begin{bmatrix}
    x_1\\
    x_2\\
    \vdots\\
    x_k\\
    x_{k+1}\\
    \vdots\\
    x_n
\end{bmatrix} = \begin{bmatrix}
    x_1\\
    x_2\\
    \vdots\\
    x_k\\
    x_{k+1} - L_{k+1,k}x_k\\
    \vdots\\
    x_n - L_{n,k}x_k
\end{bmatrix}.
\]
Quindi in ogni riga $i>k$ sottraiamo all'elemento presente sulla riga un multiplo dell'elemento sulla $k$-esima riga, con moltiplicatore $L_{i,k}$. Se immaginiamo di farlo su tutte le colonne di una matrice, questo è esattamente un passo di eliminazione di Gauss.

Possiamo anche scrivere $E_k$ come
\[
E_k = I - \boldsymbol{\ell}_k \mathbf{e}_k^T,
\]
dove $\boldsymbol{\ell}_k$ è il vettore tale che 
\[
(\boldsymbol{\ell}_k)_i = L_{i,k} = \begin{cases}
0 & i \leq k,\\
\frac{(U_k)_{ik}}{(U_k)_{kk}} & i>k,
\end{cases}
\]
e $\mathbf{e}_k$ è il $k$-esimo vettore della base canonica.

Difatti, è semplice verificare che per ogni vettore $\x\in\mathbb{R}^n$ 
\[
E_k \begin{bmatrix}
    x_1\\x_2\\ \vdots \\ x_n
\end{bmatrix}
=
\begin{bmatrix}
    x_1 \\ x_2\\ \vdots \\ x_k \\ x_{k+1} - L_{k+1,k}x_k\\
    \vdots \\
    x_n - L_{n,k}x_k
\end{bmatrix},
\]
quindi l'effetto della matrice $E_k$ è proprio di sommare a ogni riga dalla $k+1$-esima in poi un multiplo della $k$-esima, per la precisione alla $i$-esima riga viene sommata $L_{i,k}$ volte la $k$-esima riga, per ogni $i=k+1,\dots,n$.

Dimostriamo innanzitutto alcune proprietà di queste matrici.
\begin{lemma}[Proprietà delle matrici elementari di Gauss] Valgono le seguenti due proprietà:
\begin{enumerate}
    \item $E_k^{-1} = I + \boldsymbol{\ell}_k \mathbf{e}_k^T$.
    \item $E_1^{-1}E_2^{-1}\dots E_k^{-1} = I + \boldsymbol{\ell}_1 \mathbf{e}_1^T + \boldsymbol{\ell}_2 \mathbf{e}_2^T + \dots + \boldsymbol{\ell}_k \mathbf{e}_k^T$.
\end{enumerate}
\end{lemma}
\begin{proof}
\begin{enumerate}
    \item Basta verificare che
    \[
    E_k(I+\boldsymbol{\ell}_k \mathbf{e}_k^T) = (I-\boldsymbol{\ell}_k\mathbf{e}_k^T)(I+\boldsymbol{\ell}_k \mathbf{e}_k^T) = I - \boldsymbol{\ell}_k \mathbf{e}_k^T + \boldsymbol{\ell}_k \mathbf{e}_k^T - \boldsymbol{\ell}_k\underbrace{\mathbf{e}_k^T\boldsymbol{\ell}_k}_{=0}\mathbf{e}_k^T = I.
    \]
    Difatti il prodotto scalare $\mathbf{e}_k^T\boldsymbol{\ell}_k$ fa zero perché $\boldsymbol{\ell}_k$ ha uno zero in posizione~$k$.
    \item Possiamo verificarlo per induzione: il caso $k=1$ l'abbiamo dimostrato al passo precedente. Supponendo che sia vero per un certo $k-1$, si ha
    \begin{align*}
    E_1^{-1}E_2^{-1}\dots E_k^{-1} = (I + \boldsymbol{\ell}_1 \mathbf{e}_1^T + \boldsymbol{\ell}_2 \mathbf{e}_2^T + \dots + \boldsymbol{\ell}_{k-1} \mathbf{e}_{k-1}^T)(I+\ell_k \mathbf{e}_k^T).
    \end{align*}
    Ora espandiamo le parentesi e utilizziamo il fatto che $\mathbf{e}_i^T\boldsymbol{\ell}_k=0$ per $i<k$, vero perché $\boldsymbol{\ell}_k$ ha le prime componenti uguali a zero.
\end{enumerate}
\end{proof}
Notiamo che la matrice $E_1^{-1}E_2^{-1}\dots E_k^{-1} = I + \boldsymbol{\ell}_1 \mathbf{e}_1^T + \boldsymbol{\ell}_2 \mathbf{e}_2^T + \dots + \boldsymbol{\ell}_k \mathbf{e}_k^T$ è esattamente la matrice che abbiamo chiamato $L_{k+1}$ più sopra:
\[
    L_{k+1} = \begin{bmatrix}
        1\\
        L_{21} & \ddots\\
        \vdots & \ddots & 1\\
        \vdots & \vdots & L_{k+1,k} & 1\\
        \vdots & \vdots & L_{k+2,k} & 0 & 1\\
        \vdots & \vdots & \vdots & \vdots & \ddots & \ddots\\
        L_{n1} & \dots & L_{n,k} & 0 & \dots & 0 & 1\\
    \end{bmatrix}.
\]

Possiamo ora enunciare il risultato promesso.

\begin{theorem}
    Sia data una matrice $A\in\mathbb{R}^{n\times n}$, supponiamo di non incontrare mai pivot $(U_k)_{kk}$ nulli durante l'eliminazione di Gauss. Allora, dopo ogni passo dell'eliminazione si ha $L_k U_k = A$. In particolare, dopo $n-1$ passi, otteniamo la \emph{fattorizzazione LU} $A = LU = L_{n}U_{n}$, in cui $L$ è una matrice triangolare inferiore con tutti $1$ sulla diagonale, e $U$ è una matrice triangolare superiore.
\end{theorem}
\begin{proof}
    All'inizio, abbiamo $L_1 U_1 = I \cdot A = A$, quindi la proprietà è vera per $k=1$. Otteniamo la matrice $U_{k+1}$ moltiplicando $A$ successivamente per le matrici elementari $E_1, E_2,\dots, E_k$, quindi (attenzione all'ordine dei fattori!)
    \[
        U_{k+1} = E_k E_{k-1} \dots E_2 E_1 A.
    \]
    Abbiamo già osservato al termine della dimostrazione del lemma che $L_{k+1} = E_1^{-1} E_2^{-1} \dots E_{k-1}^{-1} E_k^{-1}$, quindi il prodotto di queste due matrici fa $A$.
\end{proof}

\paragraph{Esistenza della fattorizzazione LU}

Cosa può andare storto durante la fattorizzazione LU? Una sola cosa: quando dobbiamo dividere per $(U_k)_{kk}$ (elemento \emph{pivot}), questo potrebbe essere zero. Possiamo dimostrare un criterio che mostra quando questo succede.

Definiamo le \emph{sottomatrici principali di testa} di una matrice $A$ come $A_{1:k,1:k}$. Questa notazione (che ci è familiare da Matlab) significa prendere gli elementi della matrice $A$ che stanno nelle righe dalla $1$ alla $k$ e nelle colonne dalla $1$ alla $k$, ottenendo una sottomatrice quadrata $k\times k$.

\begin{theorem}[Esistenza della fattorizzazione LU]
Data una matrice $A\in\mathbb{C}^{n\times n}$, supponiamo che le sottomatrici principali di testa $A_{1:k,1:k}$ di $A$, per $k=1,\dots,n-1$, siano tutte invertibili. Allora, è possibile portare a termine l'algoritmo di fattorizzazione LU senza mai incontrare pivot nulli, e quindi esiste una fattorizzazione LU di $A$.
\end{theorem}
\begin{proof}
Partiamo dall'equazione
\begin{equation} \label{fattLU}
A = 
\underbrace{
\begin{bmatrix}
    1\\
    \ell_{21} & \ddots\\
    \vdots & \vdots & 1\\
    \vdots & \vdots & \ell_{k+1,k} & 1\\
    \vdots & \vdots & \ell_{k+2,k} & 0 & 1\\
    \vdots & \vdots & \vdots & 0 & 0 & \ddots\\
    \ell_{n1} & \dots & \ell_{n,k} & 0 & \dots & \dots & 1\\
\end{bmatrix}
}_{L_{k+1} = E_1^{-1}E_2^{-1}\dots E_k^{-1}}
\underbrace{
\begin{bmatrix}
    U_{11} & U_{12} & \dots & & & &U_{1,n} \\
    0 & \ddots  & \dots & \dots & \dots &\dots & \vdots\\
    0 & & U_{kk} & \dots & \dots & \dots & \vdots\\
    0 & \dots & 0 & U_{k+1,k+1} & \dots & \dots & U_{k+1,n}\\
    0 & \dots & 0 & U_{k+2,k+1} & & &\vdots\\
    0 & \dots & 0 & \vdots & & & \vdots\\
    0 & \dots & 0 & U_{n,k+1} & \dots & \dots & U_{n,n}\\
\end{bmatrix}.
}_{U_{k+1}}
\end{equation}
che mostra le matrici ottenute dopo i primi $k$ passi della fattorizzazione. Siamo quindi pronti per fare il passo $k+1$, e vogliamo controllare se il pivot $(U_{k+1})_{k+1,k+1}$ è zero.

La matrice $A_{1:k+1,1:k+1}$ è uguale al prodotto tra le prime $k+1$ righe di $L_{k+1}$ e le prime $k+1$ colonne di $U_{k+1}$. In realtà, per come sono messi gli zeri nella matrice di destra, ci basta considerare le due matrici $(k+1)\times(k+1)$ ottenute prendendo le prime $k+1$ righe e $k+1$ colonne delle matrici al membro di destra, che chiameremo $\hat{L}$ e $\hat{U}$. Difatti tutti gli elementi a destra di $\hat{L}$ sono zeri, quindi quando facciamo il prodotto con gli elementi sotto $\hat{U}$ (che pure \emph{non} sono tutti zeri!) non contano.

Per questo abbiamo
\[
A_{1:k+1,1:k+1} = \hat{L}\hat{U}.
\]
Questa è una fattorizzazione LU della matrice $A_{1:k+1,1:k+1}$. In particolare, abbiamo
\[
\det A_{1:k+1,1:k+1} = (\det \hat{L}) (\det \hat{U}) = (1\cdot 1 \cdot \dots \cdot 1) (U_{11}U_{22}\cdots U_{k+1,k+1}).
\]
Quindi se $\det A_{1:k+1,1:k+1} \neq 0$, allora anche l'elemento $U_{k+1,k+1}$ è diverso da zero e possiamo effettuare il passo $k$-esimo dell'eliminazione di Gauss. Visto che ci sono $n-1$ passi nel metodo, mi basta guardare fino a $A_{1:n-1,1:n-1}$: la matrice $A$ stessa potrebbe essere singolare, e quindi potremmo avere $U_{nn}=0$, ma non importa: non ci sono passi successivi in cui dobbiamo dividere per esso.
\end{proof}
Notiamo che quello che abbiamo dimostrato qui sopra in realtà è un ``se e solo se'': se $A_{1:k+1,1:k+1}$ è la \emph{prima} sottomatrice principale di testa non invertibile, allora possiamo effettuare i primi $k$ passi, e $U_{11},\dots,U_{k,k}$ sono diversi da zero, ma arrivati al passo $k+1$ si ha $U_{k+1,k+1}=0$ e quindi l'eliminazione di Gauss fallisce.

\paragraph{Matrici dominanti diagonali}

Ci sono alcune famiglie di matrici particolari per cui si può dimostrare che esiste sempre la fattorizzazione LU. Una di esse sono le matrici \emph{dominanti diagonali}. Una matrice $A\in\mathbb{C}^{n\times n}$ si dice \emph{dominante diagonale per righe} se
\[
\abs{A_{ii}} > \sum_{j\neq i} \abs{A_{ij}}, \quad i=1,2,\dots,n
\]
vale a dire, in ogni riga il valore assoluto dell'elemento sulla diagonale è maggiore della somma di tutti gli altri.
\begin{theorem}
Una matrice dominante diagonale è invertibile.
\end{theorem}
\begin{proof}
Supponiamo invece (per assurdo) che $A\mathbf{x}=0$ per un qualche vettore $\mathbf{x}\neq 0$. Allora, $\mathbf{x}$ è un autovettore con autovalore $\lambda=0$. Per il teorema dei cerchi di Gershgorin, dovrà esistere un indice $p\in \{1,2,\dots,n\}$ tale che $0 \in K_p$. Ma questa relazione vuol dire che
\[
\abs{A_{pp}} = \abs{0 - A_{pp}} \leq \sum_{j\neq i} \abs{A_{ij}},
\]
e quindi contraddice la dominanza diagonale.
\end{proof}
Osserviamo che se $A$ è dominante diagonale, allora lo sono anche tutte le sue sottomatrici principali di testa: le disuguaglianze diventano più forti perché stiamo omettendo dei termini. Quindi se $A$ è dominante diagonale allora ammette fattorizzazione LU.

Analogamente, possiamo definire matrici dominanti diagonali per colonne, quando
\[
\abs{A_{jj}} > \sum_{i\neq j} \abs{A_{ij}}, \quad j=1,2,\dots,n.
\]
Una matrice $A$ è dominante diagonale per colonne se $A^T$ è dominante diagonale per righe, quindi valgono gli stessi risultati.

Esempio: la matrice
\[
\begin{bmatrix}
    -5 & 2 & 2\\
    1 & 3 & -1\\
    1 & 1 & 3
\end{bmatrix}
\]
è dominante diagonale per righe, ma non per colonne (valgono uguaglianze). Le sue sottomatrici principali di testa sono di nuovo pred. diag. per righe (e questa volta anche per colonne).



\paragraph{Stabilità e necessità del pivoting}

Su un computer, difficilmente gli ``zeri'' vengono calcolati esattamente come zero! L'eliminazione di Gauss tecnicamente fallisce solo se c'è un pivot \emph{esattamente} uguale a zero, ma un pivot molto vicino a zero è comunque problematico. Non facciamo un'analisi dettagliata dell'errore algoritmico, ma vediamo direttamente un esempio in cui le cose vanno storte. Supponiamo di avere (per un $\varepsilon>0$ molto piccolo) la matrice
\[
A = \begin{bmatrix}
    \varepsilon & 1 & 1\\
    1 & 1 & 1\\
    1 & 1 & -1
\end{bmatrix}.
\]
Questa matrice è ben condizionata (in tutte e tre le norme che abbiamo visto, il suo condizionamento è minore di 10), ma dopo il primo passo di eliminazione di Gauss otteniamo
\[
U_2 = \begin{bmatrix}
    \varepsilon & 1 & 1\\
    0 & 1-\frac{1}{\varepsilon} & 1-\frac{1}{\varepsilon}\\
    0 & 1-\frac{1}{\varepsilon} & -1-\frac{1}{\varepsilon}
\end{bmatrix}.
\]
Se $\varepsilon$ è molto piccolo, $\frac{1}{\varepsilon}$ è molto grande. In particolare, se per esempio $\varepsilon = 2^{-60}$, il numero di macchina più vicino sia a $1-\frac{1}{\varepsilon}$ che a $-1-\frac{1}{\varepsilon}$ è $\frac{1}{\varepsilon}$, e quindi quando andiamo a scrivere quei numeri su un calcolatore la matrice che viene memorizzata è
\[
\tilde{U}_2 = 
\begin{bmatrix}  
    \varepsilon & 1 & 1\\
    0 & -\frac{1}{\varepsilon} & -\frac{1}{\varepsilon}\\
    0 & -\frac{1}{\varepsilon} & -\frac{1}{\varepsilon}
\end{bmatrix}.
\]
In particolare, le ultime due righe sono identiche. Pertanto al passo successivo l'algoritmo di fattorizzazione LU si blocca affermando (erroneamente) che la matrice è singolare. Ma in realtà la matrice di partenza $A$ è molto lontana dall'essere singolare, anzi, è una matrice ben condizionata e quindi non dovremmo avere problemi numerici con un algoritmo stabile. Anche in un esempio senza valori così estremi, possiamo vedere che quando $A_{11}$ è molto più piccolo degli altri valori presenti nella matrice dobbiamo sommare un numero molto grande a tutti gli elementi della sottomatrice $A_{2:3,2:3}$, e poi successivamente dobbiamo fare una sottrazione tra due valori molto grandi e molto vicini tra loro, al passo successivo dell'eliminazione. Questo causa perdita di precisione e problemi numerici.

La soluzione per eliminare questi problemi è introdurre la possibilità di scambiare tra loro le righe durante la fattorizzazione. In particolare, ad ogni passo scambieremo le righe in modo da portare, ad ogni passo $k$, in posizione pivot $(k,k)$ il numero \emph{più grande} in valore assoluto tra quelli della sottomatrice $(U_k)_{k:n,k}$. Questo scambio lo faremo sempre, non solo quando $(U_k)_{k,k}$ è molto piccolo.

Notare che questo è il contrario rispetto a quello che facevate ad algebra lineare facendo i conti a mano: se per esempio i numeri della prima colonna erano $2,-4,-3,1$, tipicamente volevate $1$ come pivot in modo da non avere denominatori. Questa volta invece l'obiettivo è diverso: vogliamo pivot più grandi possibili (in valore assoluto), quindi scegliamo $-4$ come pivot.

Scambiando righe, possiamo completare l'eliminazione di Gauss, esattamente come abbiamo visto nel corso di algebra lineare. Tutte le volte che la matrice $A$ è invertibile, otterremo $n$ pivot, quindi una matrice $U$ triangolare superiore, con elementi non nulli sulla diagonale. Però per continuare il nostro algoritmo vogliamo interpretare questo processo di nuovo come una fattorizzazione; nelle prossime sezioni vediamo come farlo.

\paragraph{Matrici di permutazione}
La soluzione che vedremo per questo problema corrisponde essenzialmente a calcolare la fattorizzazione LU di una matrice ottenuta dalla $A$ permutando le righe in un ordine opportuno: quindi per esempio
\[
A = \begin{bmatrix}
    \begin{array}{c}
    \phantom{AS}A_{1,:}\phantom{AS} \\
    \hline
    A_{2,:} \\
    \hline
    A_{3,:} \\
    \hline
    A_{4,:}    
    \end{array}
\end{bmatrix}, \quad
PA = \begin{bmatrix}
    \begin{array}{c}
    \phantom{AS}A_{4,:}\phantom{AS}\\
    \hline
    A_{2,:}\\
    \hline
    A_{1,:}\\
    \hline
    A_{3,:}
    \end{array}
\end{bmatrix}.
\]
Abbiamo indicato la matrice di destra con $PA$ perché effettivamente si verifica che si può ottenere moltiplicando la matrice $A$ a sinistra per una matrice $P\in\mathbb{R}^{n\times n}$: la matrice ottenuta dalla matrice identità applicando alcuni scambi di righe (gli stessi applicati in $A$); ad esempio,
\[
P = 
\begin{bmatrix}
    \begin{array}{c}
    \phantom{AS}\mathbf{e}_4^T\phantom{AS}\\
    \hline
    \mathbf{e}_2^T\\
    \hline
    \mathbf{e}_1^T\\
    \hline
    \mathbf{e}_3^T        
    \end{array}
\end{bmatrix}
=
\begin{bmatrix}
    0 & 0 & 0 & 1\\
    0 & 1 & 0 & 0\\
    1 & 0 & 0 & 0\\
    0 & 0 & 1 & 0
\end{bmatrix}.
\]
Una matrice di questo tipo è detta \emph{matrice di permutazione}, perché il suo effetto su vettori e matrici è quello di permutarne le entrate:
\[
P\mathbf{x}
=
\begin{bmatrix}
    0 & 0 & 0 & 1\\
    0 & 1 & 0 & 0\\
    1 & 0 & 0 & 0\\
    0 & 0 & 1 & 0
\end{bmatrix}
\begin{bmatrix}
    x_1\\x_2\\x_3\\x_4
\end{bmatrix} = \begin{bmatrix}
    x_4\\x_2\\x_1\\x_3
\end{bmatrix}.
\]
La stessa cosa succede quando effettuiamo il prodotto $PA$; la stessa permutazione viene applicata calcolando ogni colonna separatamente, quindi l'effetto netto è quello di permutare le righe di $A$.

L'algoritmo che vedremo non suppone di conoscere a priori la matrice $P$, ma la costruisce passo per passo scambiando le righe di $A$.

\paragraph{Eliminazione di Gauss con pivoting (parziale)}

Partiamo da una matrice $P_1 = I$. Al primo passo dell'eliminazione di Gauss, una volta individuata la riga $p$ dove sta l'elemento con $\abs{A_{p1}} = \max \abs{A_{i1}}$, scambiamo la riga $p$ e la riga $1$ in $A$. Questo corrisponde a rimpiazzare la matrice $A$ con una matrice $P_2A$, dove $P_2$ è la matrice che differisce dall'identità solo per lo scambio delle righe $1$ e $p$.

Similmente, prima di ogni passo $k$, individuiamo la riga dove sta il pivot $\abs{(U_k)_{pk}} = \max \abs{(U_k)_{k:n,k}}$, e scambiamo la riga $k$ con la riga $p$ nella matrice $P_k A$. Quella che otteniamo quindi è un'altra matrice ottenuta permutando le righe della matrice $A$, che possiamo quindi scrivere come $P_{k+1} A$, dove $P_k$ è un'opportuna matrice di permutazione.

Notiamo che fino a questo punto l'algoritmo di fattorizzazione LU ha lavorato indipendentemente sulle righe da $k:n$: se queste righe fossero state in un altro ordine nella matrice $A$, avremmo ottenuto le stesse matrici $L_k$ e $U_k$, solo con gli elementi calcolati nelle ultime righe in ordine diverso. Quindi per ottenere il risultato dei primi $k$ passi di fattorizzazione LU su questa matrice $P_{k+1} A$, dobbiamo semplicemente prendere le matrici $L_k$ e $U_k$ che abbiamo già calcolato, e scambiare gli elementi calcolati nelle righe $p$ e $k$. (Occhio: sulla matrice $L_k$, questo scambio si limita alle prime $k-1$ colonne, quelle contenenti gli elementi che abbiamo calcolato: gli elementi uguali a $1$ sulla diagonale restano al loro posto.)

A questo punto, effettuiamo normalmente un passo di eliminazione di Gauss sulle matrici ottenute, ottenendo due nuove matrici $L_{k+1}$ e $U_{k+1}$. Per come abbiamo lavorato, vale ad ogni passo la relazione $P_k A = L_k U_k$.

Vediamo insieme il codice Matlab di questo algoritmo.
\begin{lstlisting}
function [L, U, P] = fattorizzazioneLU_pivoting(A)
% fattorizzazione LU con pivoting
% restituisce matrici tali che L*U = P*A
[m, n] = size(A);
if not(m == n)
    error('A deve essere quadrata');
end

L = eye(n);
U = A;
P = eye(n);
for k = 1:n-1
    % ad ogni iterazione, abbiamo L*U == P*A

    % calcola riga p del pivot
    [valore, posizione] = max(abs(U(k:n,k)));
    % converte una posizione in k:n in un indice di riga
    p = posizione + k-1;
    if valore == 0
        error('matrice esattamente singolare');
    end

    % esegue gli scambi
    L([p k], 1:k-1) = L([k p], 1:k-1);
    U([p k], k:n) = U([k p], k:n);
    P([p k], 1:n) = P([k p], 1:n);

    % prosegue con l'eliminazione di Gauss
    L(k+1:n, k) = U(k+1:n, k) / U(k, k);
    U(k+1:n, k) = 0;
    for i = k+1:n
        U(i, k+1:n) = U(i, k+1:n) - L(i,k)*U(k,k+1:n);
    end
end    
\end{lstlisting}
Il secondo argomento di output della funzione \lstinline{max}, che abbiamo salvato nella variabile \lstinline{posizione}, restituisce un indice all'interno del vettore di $n-k+1$ elementi $U_{k:n,n}$: se per esempio l'elemento di modulo massimo fosse il primo, \lstinline{posizione = 1}, però questa posizione 1 corrisponde alla riga $k$ della matrice $U$. Per convertire questa posizione in un indice di riga, dobbiamo sommare $k-1$.

Qual è il costo computazionale di questo algoritmo? Le uniche operazioni che abbiamo aggiunto sono la ricerca del massimo e gli scambi di righe. Queste sono operazioni che richiedono tempo per essere effettuate sul computer, però non sono operazioni aritmetiche, strettamente parlando. Se misuriamo il costo in termini di numero di operazioni aritmetiche necessarie, come abbiamo fatto finora, quindi il costo dell'eliminazione di Gauss con pivoting è sempre  $\frac23 n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche, come nel caso senza pivoting.

In Matlab esiste già una funzione che calcola la fattorizzazione LU con pivoting, come la nostra \lstinline{fattLU}, con un nome diverso: \lstinline{[L, U, P] = lu(A)}.


\paragraph{Soluzione di sistemi lineari tramite fattorizzazione LU con pivoting}

La fattorizzazione LU con pivoting restituisce quindi tre matrici $L,U,P$ (le prime due triangolari, la terza matrice di permutazione) tali che $LU = PA$. Possiamo usare questa fattorizzazione per risolvere un sistema lineare $A\x=\b$, in questo modo.

Il sistema $A\x = \b$ ha la stessa soluzione di $PA\x = P\b$; difatti, moltiplicare per $P$ ha il solo effetto di riordinare le equazioni del sistema. Possiamo quindi risolvere $LU\x=P\b$, e per farlo procediamo come nel caso della fattorizzazione LU: chiamiamo $\mathbf{y}=U\x$, e risolviamo nell'ordine
\[
L\mathbf{y} = P\b, \quad U\x = \mathbf{y}
\]
per sostituzione in avanti e all'indietro rispettivamente.

La fattorizzazione LU con pivoting è l'algoritmo normalmente usato per risolvere sistemi lineari su un computer; in Matlab 
anche \lstinline{A \ b} utilizza questo algoritmo. Questo algoritmo è più stabile ed efficiente di tutti gli altri che avete visto ad algebra lineare: quelli basati sull'inversa $A^{-1}$, quelli basati su varianti diverse dell'eliminazione di Gauss che comportano di eliminare elementi sopra i pivot, quelli basati su determinanti come il metodo di Cramer, \dots

\paragraph{Errore algoritmico nella soluzione di sistemi lineari}
Non vediamo un'analisi completa dell'errore algoritmico della soluzione di sistemi lineari con la fattorizzazione LU, poiché è abbastanza complessa; ma si può dimostrare che l'errore algoritmico (sia con che senza pivoting) è dell'ordine di $\norm{L}\norm{U} \norm{A^{-1}} \mathsf{u}$. In particolare, visto che l'errore inerente è invece dell'ordine di $\kappa(A)\mathsf{u} = \norm{A}\norm{A^{-1}}\mathsf{u}$  l'algoritmo è stabile a patto che l'algoritmo produca matrici $L$ e $U$ tali che $\norm{L}\norm{U}$ non sia molto più grande di $\norm{A}$.

Il pivoting assicura che gli elementi della $L$ siano tutti minori o uguali a $1$ in valore assoluto, quindi la norma di $L$ non è mai troppo grande. Però, anche con il pivoting, esistono matrici particolarmente sfortunate in cui $\norm{U}/\norm{A}$ cresce come $2^n$, dove $n$ è il numero di righe e colonne della matrice $A$. Nella maggior parte dei casi, però, questo non succede e l'eliminazione di Gauss con pivoting è un algoritmo stabile: cioè l'errore algoritmico $e_{alg}$ è dello stesso ordine di grandezza di quello inerente $e_{in}$. L'errore analitico, di nuovo, è $0$, visto che l'algoritmo calcola la soluzione esatta di $A\x=\b$, non una successione convergente ad essa.

\paragraph{Calcolo del determinante mediante fattorizzazione LU con pivoting} Abbiamo visto nell'introduzione del corso che usare le formule classiche dell'algebra lineare (espansione di Laplace, formule ricorsive sui minori, \dots) non è un modo efficiente di calcolare il determinante: il loro costo computazionale cresce troppo velocemente. Vediamo qui invece un metodo basato sulla fattorizzazione LU per calcolarlo.

\begin{theorem}
Sia $PA = LU$ una fattorizzazione LU con pivoting della matrice $A \in \mathbb{C}^{n \times n}$. Allora,
\[
\det(A) = (-1)^s U_{11} U_{22} \dots U_{nn},
\]
dove $s$ è il numero di scambi di riga effettuati durante il calcolo della fattorizzazione.
\end{theorem}
\begin{proof}
Usando il teorema di Binet, abbiamo
\begin{equation} \label{detconti}
    \det P \det A = \det PA = \det LU = \det L \det U.    
\end{equation}
Poiché $L$ e $U$ sono triangolari, i loro determinanti sono i prodotti degli elementi lungo la diagonale:
\begin{align*}
\det L = 1 \cdot 1 \cdot 1 \cdot \dots \cdot 1 = 1; \quad
\det U = U_{11} U_{22} \dots U_{nn}.
\end{align*}
La matrice di permutazione $P$ è ottenuta applicando alla matrice identità gli scambi di riga effettuati lungo la fattorizzazione; sappiamo dall'algebra lineare che ogni scambio di riga fa cambiare il segno del determinante, quindi abbiamo
\[
\det P = (-1)^s \det I = (-1)^s.
\]
Possiamo quindi ricavare $\det A$ dalla~\eqref{detconti}, ottenendo la tesi.
\end{proof}

\paragraph{Esercizio} Dato un parametro $\alpha \in \mathbb{C}$, consideriamo la matrice
\[
A_\alpha =
\begin{bmatrix}
    1  & & & & -\alpha\\
    -\alpha & 1 & & & \\
    & -\alpha & 1 & & \\
    & & \ddots & \ddots\\
    & & & -\alpha & 1
\end{bmatrix} \in \mathbb{C}^{n\times n}.
\]
\begin{enumerate}
    \item Per quali valori di $\alpha$ il teorema dei cerchi di Gershgorin ci permette di concludere che la matrice è invertibile?
    \item Per quali valori di $\alpha$ è soddisfatta la condizione di esistenza della fattorizzazione LU?
    \item Sapreste trovare la fattorizzazione LU di $A$?
    \item Per quali valori di $\alpha$ la matrice è invertibile?
\end{enumerate}
Soluzione:
\begin{enumerate}
    \item I cerchi di Gershgorin hanno tutti centro $1$ e raggio $\abs{\alpha}$. Se $\abs{\alpha} < 1$, allora $0$ non appartiene all'unione dei cerchi di Gershgorin, quindi non è un autovalore della matrice $A_\alpha$; pertanto $A_\alpha$ è invertibile. Se invece $\abs{\alpha} \geq 1$, allora $1$ sta all'interno dell'unione dei cerchi, quindi il teorema non ci permette di concludere nulla: $0$ potrebbe essere autovalore oppure no.
    \item Le sottomatrici di testa fino all'ordine $n-1$ sono tutte triangolare inferiori con $1$ sulla diagonale; quindi sono invertibili per ogni valore di $\alpha\in\mathbb{C}$.
    \item Eseguiamo l'eliminazione di Gauss: al primo passo, l'unico elemento da eliminare è quello in posizione $(2,1)$, e per farlo dobbiamo sottrarre $-\alpha$ volte la riga 1 dalla riga 2 (occhio al doppio segno $-$).
    \[
        U_1 = A; \, U_2 = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& -\alpha & 1 & \dots  & 0 & 0\\
            & & \alpha & 1\\
            & & & \ddots & \ddots & \\
            & & &  &-\alpha & 1      
        \end{bmatrix}
    \]
    Continuando nello stesso modo, al passo successivo dobbiamo eliminare l'elemento in posizione $(3,2)$, di nuovo con moltiplicatore $-\alpha$, ottenendo
    \[
        U_3 = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& 0 & 1 & \dots  & 0 & 0\\
            & & \alpha & 1\\
            & & & \ddots & \ddots & \\
            & & &  &-\alpha & 1      
        \end{bmatrix}.
    \]
    L'unico passo leggermente diverso è l'ultimo, in cui abbiamo
    \[
        U_{n-1} = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& 0 & 1 & \dots  & 0 & 0\\
            & & \ddots & \ddots\\
            & & & 0 & 1 & -\alpha^{n-1}\\
            & & &  &-\alpha & 1      
        \end{bmatrix},
        \quad
        U_n = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& 0 & 1 & \dots  & 0 & 0\\
            & & \ddots & \ddots\\
            & & & -\alpha & 1 & -\alpha^{n-1}\\
            & & &  & 0 & 1-\alpha_n
        \end{bmatrix}.
    \]
    Quindi otteniamo la fattorizzazione $A=LU$ con
    \[
        L = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  0\\
            -\alpha & 1 & 0 & \dots & 0 & 0\\
            0& -\alpha & 1 & \dots  & 0 & 0\\
            & & \alpha & 1\\
            & & & \ddots & \ddots & \\
            & & &  &-\alpha & 1      
        \end{bmatrix}, \quad U = \begin{bmatrix}
            1  & 0 &  0& \dots  & 0 &  -\alpha\\
            0 & 1 & 0 & \dots & 0 & -\alpha^2\\
            0& 0 & 1 & \dots  & 0 & 0\\
            & & \ddots & \ddots\\
            & & & 0 & 1 & -\alpha^{n-1}\\
            & & &  & 0 & 1-\alpha_n
        \end{bmatrix}.
    \]
    Ricordiamo che la matrice $L$ è ottenuta a partire dalla matrice identità inserendo sotto la diagonale tutti i moltiplicatori utilizzati nell'eliminazione.
    \item Dalla fattorizzazione LU calcolata, abbiamo $\det A_\alpha = \det U = 1\cdot 1 \cdot \dots \cdot 1 \cdot (1-\alpha^n) = 1-\alpha^n$. Quindi il determinante si annulla se e solo se $\alpha$ è una radice $n$-esima complessa dell'unità. Notiamo che questo risultato è coerente con quanto visto sopra con il teorema dei cerchi di Gershgorin.
\end{enumerate}

\begin{conditional}[ich]

\section{Fattorizzazioni per matrici simmetriche}

\paragraph{Fattorizzazione $LDL^T$}

Supponiamo di effettuare l'eliminazione di Gauss su una matrice simmetrica, cioè $A = A^T$. Non è difficile vedere che già dopo il primo passo la matrice $U_2$ ottenuta non è più simmetrica; la struttura della matrice viene persa. Esiste però una variante dell'eliminazione di Gauss che evita questo problema e lavora unicamente con matrici simmetriche. L'idea è la seguente: ad ogni passo, anziché definire $U_{2} = E_1 U_1$, definiamo $U_{2} = E_1 U_1 E_1^T$ (moltiplicando a destra e a sinistra). Questa matrice è simmetrica, difatti $(E_1 U_1 E_1^T)^T = (E_1^T)^T (U_1)^T E_1^T = E_1 U_1 E_1^T$.

L'effetto della moltiplicazione per $E_1^T$ è quello di sommare ad ogni colonna un multiplo della prima; quindi gli unici elementi che cambiano rispetto a $E_1 U_1$ sono quelli della prima riga successivi al primo, che diventano zero: quindi $U_2 = E_1 U_1 E_1^T$ ha la forma
\[
U_2 = \begin{bmatrix}
    A_{11} & 0 & 0 & 0\\
    0 & \star & \star & \star\\
    0 & \star & \star & \star\\
    0 & \star & \star & \star\\
\end{bmatrix}.  
\]
Il blocco di elementi indicati con $\star$ è simmetrico, e possiamo continuare nello stesso modo, definendo $U_3 = E_2 U_2 E_2^T$, e così via. Alla fine della procedura, otteniamo una matrice diagonale, che possiamo chiamare $D$. Più nel dettaglio, abbiamo
\[
D = E_{n-1}E_{n-2}\dots E_2 E_1 A E_1^T E_2^T\dots E_{n-2}^T E_{n-1}^T.
\]
Moltiplicando per le inverse delle $E_k$ (che esistono) dai lati opportuni, abbiamo
\[
A = \underbrace{(E_1^{-1}E_2^{-1}\dots E_{n-1}^{-1}) }_{=L}D \underbrace{(E_{n-1}^T)^{-1}  (E_{n-2}^T)^{-1} \dots (E_{2}^T)^{-1} (E_{1}^T)^{-1}}_{=L^T} = LDL^T.
\]
Quella che abbiamo ottenuto, quindi, è una particolare fattorizzazione LU in cui la matrice $U$ è uguale a $DL^T$, il prodotto di $L$ per una matrice diagonale. Si chiama \emph{fattorizzazione $LDL^T$}.

\paragraph{Costo computazionale della fattorizzazione $LDL^T$}

Possiamo impostare un'analisi del costo computazionale analoga a quella che abbiamo fatto per la fattorizzazione LU. Di nuovo, la parte più consistente del costo viene dall'aggiornamento delle righe, 
\[
U_{i,k+1:n} \gets U_{i,k+1:n} - L_{i,k}U_{k,k+1:n}.
\]
Questa volta le matrici coinvolte sono simmetriche. Quindi non è necessario calcolare tutti gli elementi: basta calcolare quelli della parte triangolare superiore (inclusa la diagonale), e ignorare la parte triangolare inferiore che può essere ricavata per simmetria. Questo riduce il costo computazionale alla metà: da $\frac23 n^3 + \mathcal{O}(n^2)$ a $\frac13n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche.

Vediamo del codice per effettuarla, utilizzando questo accorgimento.
\begin{lstlisting}
function [L, D] = fattorizzazioneLDL(A)
% fattorizzazione A = L*D*L^T di una matrice simmetrica, senza pivoting
[m, n] = size(A);
if not(m == n)
    error('A deve essere quadrata');
end
if not(isequal(A, A'))
    % controlla che tutti gli elementi di A e A' siano uguali
    error('A deve essere simmetrica');
end

L = eye(n);
U = A;     
for k = 1:n-1
    if U(k,k) == 0
        error('Pivot nullo');
    end
    L(k+1:n, k) = U(k+1:n, k) / U(k, k);
    for i = k+1:n
        % aggiorniamo la parte triangolare superiore della riga i...
        U(i, i:n) = U(i, i:n) - L(i,k)*U(k,i:n);
        % ...e copiamo gli elementi calcolati nella parte inferiore
        U(i+1:n, i) = U(i, i+1:n)';
    end
    % questi elementi sono 0, non serve calcolarli
    U(k+1:n, k) = 0;
    U(k, k+1:n) = 0;
end
D = U;        
\end{lstlisting}

\paragraph{Pivoting nella fattorizzazione $LDL^T$}

In una fattorizzazione $LDL^T$, il pivoting diventa più complicato: difatti, scambiando righe si perde la simmetria. Per mantenerla, è necessario scambiare non solo le righe, ma anche le colonne corrispondenti, cioè considerare $PAP^T$. Questo, però, non è sufficiente per ottenere un algoritmo stabile.
In Matlab, la funzione \lstinline{[L,D,P] = ldl(A)} produce una fattorizzazione $LDL^T = P^TAP$, però (per avere una versione più stabile) la matrice $D$ non è diagonale, ma è diagonale a blocchi con blocchi $1\times 1$ o $2\times 2$, per esempio come questa:
\[
    D = \begin{bmatrix}
        *\\
        & * & *\\
        & * & *\\
        & & & *\\
        && & & *\\
        & & & & & * & *\\
        & & & & & * & *\\
        & & & & & & & *\\
        & & & & & & & &*
    \end{bmatrix}.
\]
Anche per questa fattorizzazione, però, c'è una categoria particolare di matrici per cui possiamo dimostrare che la fattorizzazione funziona sempre senza bisogno di ricorrere al pivoting.

\paragraph{Matrici SPD (simmetriche e positive definite)}

Una matrice $A\in\mathbb{R}^{n\times n}$ (serve che sia reale, questa volta!) si definisce \emph{simmetrica e positiva definita} (SPD) se:
\begin{enumerate}
    \item è simmetrica, cioè $A=A^T$;
    \item è positiva definita, cioè $\mathbf{x}^TA\mathbf{x} > 0$ per ogni vettore $\mathbf{x}\in \mathbb{R}^n$ tale che $\mathbf{x}\neq 0$.
\end{enumerate}
Spesso si dice solo ``positiva definita'' sottintendendo ``simmetrica''. Si può dimostrare il seguente risultato (non vediamo qui la dimostrazione; talvolta si fa nei corsi di algebra lineare):
\begin{theorem}
Una matrice simmetrica $A$ è definita positiva se e solo se tutti i suoi autovalori sono reali (strettamente) positivi. 
\end{theorem}
Valgono le seguenti proprietà.
\begin{enumerate}
    \item Una matrice definita positiva ha tutti gli elementi sulla diagonale (strettamente) positivi; difatti $A_{kk} = \mathbf{e}_k^T A \mathbf{e}_k > 0$. (Notare che questo \emph{non} è un ``se e solo se'': esistono matrici simmetriche che hanno tutti gli elementi sulla diagonale positivi, ma non sono positive definite! Per esempio, $A = \begin{bsmallmatrix}
        1 & 2\\ 2 & 1
    \end{bsmallmatrix}$).
    \item Se $A$ è positiva definita e $M$ è una qualunque invertibile, allora anche $MAM^T$ è definita positiva: difatti $MAM^T$ è simmetrica, e $\mathbf{x}^T MAM^T \mathbf{x} = (M^T\mathbf{x})^T A (M^T\mathbf{x}) > 0$.
\end{enumerate}
Utilizzando queste due proprietà, è facile dimostrare che ad ogni passo della fattorizzazione $LDL^T$ la matrice $U_k$ è positiva definita, e quindi il pivot $U_{kk}$ è (strettamente!) positivo. Quindi una matrice SPD ammette sempre fattorizzazione $LDL^T$, e gli elementi diagonali $d_{kk}$ sono tutti (strettamente) positivi. In più, è possibile dimostrare (noi non lo facciamo) che questa fattorizzazione è stabile senza bisogno di fare pivoting; gli elementi della matrice $D$ non crescono mai troppo rispetto agli elementi di $A$.

\paragraph{Fattorizzazione di Cholesky}
Per una matrice definita positiva, possiamo riscrivere la fattorizzazione LDL in un formato leggermente diverso. Visto che tutti gli elementi di $D$ sono positivi, possiamo scrivere $D = D^{1/2} D^{1/2}$, dove $D^{1/2}$ è la matrice diagonale che ha elementi diagonali $\sqrt{d_{11}}, \sqrt{d_{22}}, \dots, \sqrt{d_{nn}}$. Quindi
\[
A = LDL^T = (LD^{1/2})(D^{1/2}L^T) = R^TR,
\]
dove $R$ è una matrice triangolare superiore. Abbiamo quindi scritto $A$ come il prodotto di una matrice triangolare inferiore e di una triangolare superiore, che sono una la trasposta dell'altra. Questa fattorizzazione si chiama \emph{fattorizzazione di Cholesky}. 

Il costo computazionale di questa fattorizzazione è di nuovo di $\frac13n^3 + \mathcal{O}(n^2)$ operazioni aritmetiche, come per la $LDL^T$, con il dettaglio che tra le operazioni da fare ci sono anche $n$ radici quadrate. In Matlab, questa fattorizzazione si può calcolare con il comando \lstinline{R = chol(A)}.

\end{conditional}

% \section{Laboratorio su LDL ed esistenza LU}

% Esercizio: scriviamo una \lstinline{function s = somma_fuori_diagonale(A, i)} che, data in input una matrice $A$, calcola $\sum_{\substack{j=1\\ j\neq i}}^n \abs{A_{ij}}$. Mostrare soluzioni fatte sia con \lstinline{for j=1:n; if j ~= i} che con\\ \lstinline{sum(abs(A(i,1:i-1))) + sum(abs(A(i,i+1:n)))}.

% Poi usiamola per scrivere una 
% funzione che controlla se una matrice è predominante diagonale per righe. Come facciamo a restituire valori vero/falso?
% \begin{lstlisting}
% function result = isdominant(A)
%   % cicli, condizioni, eccetera
%   result = true;
%   return

%   result = false;
%   % "return" non serve alla fine
% \end{lstlisting}

% Altro esercizio: scriviamo una funzione che controlla se una matrice è predominante diagonale per colonne. Facile se riutilizziamo il codice dell'altra funzione!

% Buona norma di programmazione: se potete, meglio riutilizzare che riscrivere! E meglio usare funzioni corte che fanno una cosa sola, come stiamo facendo qua. Sono più facili da testare.

% Altro esercizio: proviamo a scrivere una \lstinline{function result = issymmetric(A)} che testa se la matrice $A$ è simmetrica.

% Come facciamo a farlo? Occhio che \lstinline{A == A'} non fa quello che volete: in Matlab, \lstinline{A == B} restituisce una matrice $n\times n$ di valori vero/falso (o 0/1) che ci dice quali elementi $A_{ij}$ sono uguali a quali elementi $B_{ij}$. Ci servono due cicli for, oppure \lstinline{isequal(A, A')}.

% Altro esercizio: calcoliamo la fattorizzazione LDL di una matrice simmetrica $A$ (senza pivoting).

% Il punto delicato è come calcolare l'update $A_{k+1:n,k+1:n} \gets A_{k+1:n,k+1:n} - L_{k+1:n,k}A_{k,k+1:n}$ facendo operazioni solo per parte triangolare inferiore. Per questo, andiamo a scrivere questo update come
% \[
% A_{ij} \gets A_{ij} - L_{ik}A_{kj}, \quad i,j=k+1,k+2,\dots,n
% \]
% ed usiamo dei cicli for che effettuano il calcolo solo su una delle due parti. Definiamo una funzione ausiliaria \lstinline{symmetric_update(A, l, u)}.

% Possibile errore: un ciclo del tipo
% \begin{lstlisting}
% for i = k+1:n
%   for j = k+1:n
%     if j>i
%       A(i,j) = A(j,i);
%     else
%       A(i,j) = ... ;
%     end
%   end
% end
% \end{lstlisting}
% rischia di copiare un valore dalla parte triangolare inferiore prima che questo venga assegnato; quindi copia solo uno zero!

% Domanda aperta: come fareste a controllare se una matrice è positiva definita, oltre che simmetrica? Impossibile testare che $x^T A x > 0$ su un numero infinito di vettori! Un modo è testare solo su alcuni vettori casuali. Oppure calcolare gli autovalori di $A$ e controllare se sono strettamente maggiori di zero. In alternativa: è vero che se portiamo a termine la fattorizzazione LDL (e otteniamo solo valori positivi sulla diagonale) allora $A$ è SPD? Abbiamo (brevemente) dimostrato l'altra implicazione a lezione; ora vediamo che anche questa è un ``se e solo se''. 

% Esercizio extra se avanza tempo: fattorizzazione LU di una matrice di Hessenberg superiore.

\section{Metodi iterativi per sistemi lineari}

\paragraph{Matrici sparse} Spesso nelle applicazioni compaiono matrici che hanno molti elementi uguali a zero. Per esempio, alcuni metodi di soluzione di equazioni differenziali conducono a matrici \emph{tridiagonali}, oppure a matrici che hanno elementi diversi da zero solo lungo alcune diagonali (non per forza vicine a quella principale). In una matrice $n\times n$ di questo tipo, il numero di elementi diversi da zero (``non-zeri'') è proporzionale a $n$, (possiamo scriverlo come $\mathcal{O}(n)$), quindi molti meno degli $n^2$ elementi.

Alcune operazioni su matrici sparse si possono effettuare più velocemente. Per esempio, per calcolare il prodotto con un vettore, $Av$, mi basta considerare nella somma gli elementi di $A$ diversi da zero. Il costo computazionale di questo prodotto quindi è di $2nnz$ operazioni, dove con $nnz$ indichiamo il ``numero di non-zeri'' della matrice $A$.

In Matlab, abbiamo alcuni comandi per gestire matrici sparse. Per esempio, \lstinline{sparse(A)} restituisce una copia della matrice $A$, memorizzata in un formato diverso che elenca i soli ``non-zeri''. Similmente, \lstinline{sparse(m, n)} e \lstinline{speye(m)} creano, in questo formato, rispettivamente una matrice nulla e l'identità. Lavorare con questo formato comincia a diventare conveniente solo quando la $A$ ha una densità di non-zeri molto bassa, $10\%$ o meno: se una matrice triangolare ha semplicemente zeri nella parte triangolare inferiore, o superiore, ma a parte questo è densa, allora i non-zeri sono circa il $50\%$, e i costi collegati alla gestione delle matrici sparse sono maggiori dei risparmi ottenuti usando questo formato. Ve lo dico solo per conoscenza, ma non vediamo dettagli su come gestire matrici sparse in questo corso.

I metodi che abbiamo visto finora per risolvere sistemi lineari non sono l'ideale per matrici sparse, perché spesso l'eliminazione di Gauss elimina anche la sparsità, introducendo molti elementi diversi da zero. Per esempio, data una matrice della forma
\[
\begin{bmatrix}
    * & * & * & * & * & *\\
    * & * \\
    * & & *\\
    * & & &*\\
    * & & & & *\\
    * & & & & & *\\
\end{bmatrix}
\]
già dopo il primo passaggio otteniamo una matrice con molti più non-zeri di quella di partenza:
\[
\begin{bmatrix}
    * & * & * & * & * & *\\
    0 & * & * & * & * & *\\
    0 & * & * & * & * & *\\
    0 & * & * & * & * & *\\
    0 & * & * & * & * & *\\
    0 & * & * & * & * & *\\
\end{bmatrix}.
\]
Esistono metodi per risolvere sistemi lineari che riescono a sfruttare il fatto che $A$ sia una matrice sparsa, ottenendo un minore costo computazionale rispetto a $\mathcal{O}(n^3)$. Questi metodi sono molto simili a quelli che abbiamo visto nella prima sezione: producono, passo dopo passo, una successione di vettori, $\x^{(1)}, \x^{(2)}, \x^{(3)},\dots,\x^{(3)}, \dots$ (ogni $\x^{(i)}$ è un vettore; mettiamo l'indice in alto per non confonderci con gli elementi). Sotto condizioni opportune (che vedremo), questa successione converge alla soluzione $\x$ di $A\x=\b$.

\paragraph{Metodi iterativi basati su splitting} Descriviamo ora un modo per ottenere un metodo iterativo a partire da uno \emph{splitting} della matrice $A$, cioè una scrittura del tipo $A = M - N$, dove $M\in\mathbb{C}^{n\times n}$ è una matrice invertibile. La soluzione $\x\in\mathbb{C}^{n\times n}$ del sistema lineare soddisfa
\begin{equation} \label{solsistema}
    A\x = \b \iff (M-N)\x=\b \iff M\x = \b + N\x  \iff \x = M^{-1}(\b + N\x)
%    \underbrace{M^{-1}N}_{=H}x + \underbrace{M^{-1}b}_{=c}.
\end{equation}
Questo suggerisce di impostare un'iterazione di punto fisso
\begin{equation} \label{iterlin}
    \begin{cases}
    \x^{(0)} \in \mathbb{C}^n & \text{fissato};\\
    \x^{(k+1)} = M^{-1}(N\x^{(k)} + \mathbf{b}) & k=0,1,2,\dots
    \end{cases}
\end{equation}
Notiamo che questa iterazione si può implementare in modo efficiente se abbiamo un modo efficiente di risolvere il sistema lineare $M\x^{(k+1)} = \b + N\x^{(k)}$: per esempio, se $M$ è triangolare possiamo usare un processo di sostituzione. Tipicamente \emph{non} vogliamo calcolare $M^{-1}$, né tantomeno $M^{-1}N$, perché questo sarebbe troppo costoso.

La~\eqref{iterlin} è una versione ``multidimensionale'' del metodo di punto fisso $x_{k+1} = \Phi(x_k)$ che abbiamo già visto per equazioni non lineari. Parlando di quel metodo, avevamo visto che spesso la convergenza avviene solo quando $\x^{(1)}$ è sufficientemente vicino alla soluzione esatta $\x$. Per questi metodi, invece, la convergenza solitamente \emph{non} dipende dal punto iniziale, come vedremo. Questa è una conseguenza della linearità.

\paragraph{Metodi di Jacobi e Gauss--Seidel} Due metodi iterativi sono particolarmente comuni per la loro semplicità. Il \emph{metodo di Jacobi} si ottiene scegliendo come $M$ una matrice diagonale che ha elementi diagonali uguali a quelli di $A$, cioè
\[
M = \begin{bmatrix}
    A_{11}\\
    & A_{22}\\
    & & \ddots \\
    & & & A_{nn}
\end{bmatrix}, \quad N = -\begin{bmatrix}
    0 & A_{12} & \dots & A_{1n}\\
    A_{21} & 0 & \dots & A_{2n}\\
    \vdots & \vdots & \ddots & \vdots\\
    A_{n1} & A_{n2} & \dots & 0
\end{bmatrix}.
\]
(Notiamo che, una volta scelta la $M$, la matrice $N = M-A$ è determinata univocamente.) Con questa scelta, la soluzione di sistemi lineari con $M$ è molto veloce perché $M$ è diagonale. Questo metodo è applicabile tutte le volte che gli elementi sulla diagonale di $A$ sono diversi da zero, visto che ci serve che $M$ sia invertibile.

Il \emph{metodo di Gauss--Seidel} si ottiene scegliendo come $M$ una matrice triangolare inferiore che ha entrate uguali a quelle di $A$ nella parte triangolare inferiore, cioè
\[
M = \begin{bmatrix}
    A_{11}\\
    A_{21} & A_{22}\\
    A_{31}& \ddots & \ddots \\
    A_{n1}& A_{n2} &\dots & A_{nn}
\end{bmatrix}
, \quad N =-\begin{bmatrix}
    0& A_{12} & \dots & A_{1n}\\
    & 0 & \ddots & \vdots\\
    &  & \ddots & A_{n-1,n}\\
    & &  & 0
\end{bmatrix}.
\]
La soluzione di sistemi lineari con $M$ è veloce perché $M$ è triangolare. Anche questo metodo è applicabile se e solo se $A_{ii} \neq 0$ per ogni $i$. 

\paragraph{Implementazione del metodo di Jacobi}
Per ottenere una formula più esplicita, partiamo scrivendo la relazione $M\x^{(k+1)} = \b + N\x^{(k)}$:
\[
\begin{bmatrix}
    A_{11}\\
    & A_{22}\\
    & & \ddots \\
    & & & A_{nn}
\end{bmatrix}
\begin{bmatrix}
    x_1^{(k+1)}\\
    x_2^{(k+1)}\\
    \vdots\\
    x_n^{(k+1)}\\
\end{bmatrix}
=
\begin{bmatrix}
    b_1\\
    b_2\\
    \vdots\\
    b_n\\
\end{bmatrix}
-
\begin{bmatrix}
    0 & A_{12} & \dots & A_{1n}\\
    A_{21} & 0 & \dots & A_{2n}\\
    \vdots & \vdots & \ddots & \vdots\\
    A_{n1} & A_{n2} & \dots & 0
\end{bmatrix}
\begin{bmatrix}
    x_1^{(k)}\\
    x_2^{(k)}\\
    \vdots \\
    x_n^{(k)}\\
\end{bmatrix}
\]
La $i$-esima riga corrisponde a
\[
A_{ii}x_i^{(k+1)} = b_i - \sum_{\substack{j=1\\ j \neq i}}^n A_{ij}x_j^{(k)}
\]
da cui possiamo ricavare $x_i^{(k+1)}$ ottenendo
\[
x_i^{(k+1)} = \frac{b_i - \sum_{\substack{j=1\\ j \neq i}}^n A_{ij}x_j^{(k)}}{A_{ii}} = \frac{b_i - \sum_{j=1}^{i-1} A_{ij}x_j^{(k)} - \sum_{j=i+1}^n A_{ij}x_j^{(k)} }{A_{ii}}, \quad i=1,2,\dots,n.
\]
Con queste formule possiamo calcolare uno ad uno gli elementi di $\x^{(k+1)}$ a partire da quelli $\x^{(k)}$. Questo costituisce un'iterazione del metodo.

Il costo computazionale è di $2n$ operazioni aritmetiche per ogni $i$, quindi in totale $2n^2$ per ogni iterazione (il numero di iterazioni che servono per ottenere convergenza non è noto a priori, anzi, il metodo potrebbe non convergere del tutto). Inoltre, se
 sappiamo a priori che alcuni elementi $A_{ij}$ sono zero, possiamo restringere la somma agli elementi non-nulli; questo modifica il costo totale in $2nnz(A)$.

\paragraph{Implementazione del metodo di Gauss--Seidel}

Di nuovo, partiamo scrivendo la relazione $M\x^{(k+1)} = \b + N\x^{(k)}$:
\[
\begin{bmatrix}
    A_{11}\\
    A_{21} & A_{22}\\
    A_{31}& \ddots & \ddots \\
    A_{n1}& A_{n2} &\dots & A_{nn}
\end{bmatrix}
\begin{bmatrix}
    x_1^{(k+1)}\\
    x_2^{(k+1)}\\
    \vdots\\
    x_n^{(k+1)}\\
\end{bmatrix}
=
\begin{bmatrix}
    b_1\\
    b_2\\
    \vdots\\
    b_n\\
\end{bmatrix}
-
\begin{bmatrix}
     0& A_{12} & \dots & A_{1n}\\
     & 0 & \ddots & \vdots\\
     &  & \ddots & A_{n-1,n}\\
     & &  & 0
\end{bmatrix}
\begin{bmatrix}
    x_1^{(k)}\\
    x_2^{(k)}\\
    \vdots \\
    x_n^{(k)}\\
\end{bmatrix}.
\]
L'equazione corrispondente alla riga $i$-esima è
\[
\sum_{j=1}^i A_{ij}x_j^{(k+1)} = b_i - \sum_{j=i+1}^n A_{ij}x_j^{(k)}. 
\]
Risolvendola per $x_{i}^{(k+1)}$ otteniamo
\begin{equation} \label{GS}
    x_{i}^{(k+1)} = \frac{b_i - \sum_{j=1}^{i-1} A_{ij}x_j^{(k+1)} - \sum_{j=i+1}^n A_{ij}x_j^{(k)} }{A_{ii}}, \quad i=1,2,\dots,n.
\end{equation}
Possiamo risolvere queste equazioni una dopo l'altra per $i=1,2,\dots,n$ (in quest'ordine!) per calcolare tutti gli elementi di $\x^{(k+1)}$. Questo corrisponde a risolvere il sistema lineare $M\x^{(k+1)} = \b + N\x^{(k)}$ per sostituzione in avanti; il sistema è triangolare inferiore, quindi non ci stupisce che questo sia possibile!

La~\eqref{GS} differisce dalla corrispondente formula per il metodo di Jacobi solo per il fatto che abbiamo $x_j^{(k+1)}$ anziché $x_j^{(k)}$ nella prima sommatoria. Questo corrisponde ad usare immediatamente gli elementi più nuovi $x_j^{(k+1)}$ appena li abbiamo calcolati, invece di aspettare l'iterazione successiva del metodo. Intuitivamente, questo metodo fornisce un'approssimazione migliore della soluzione, perché usiamo approssimazioni più accurate ad ogni passo. Questa intuizione non sempre corrisponde a realtà: esistono matrici per cui il metodo di Jacobi converge più velocemente di quello di Gauss--Seidel. (Lo vedremo in laboratorio.)

Un'osservazione interessante è che il metodo di Gauss--Seidel può essere implementato in Matlab usando \emph{una sola} variabile (vettore) $\x$ che contiene ad ogni passo le approssimazioni più recenti degli elementi di $\x$; ad ogni passo $i=1,2,\dots,n$ rimpiazziamo un elemento $x_i^{(k)}$ con $x_i^{(k+1)}$:
\[
\x^{(k)} = \begin{bmatrix}
    x^{(k)}_1\\ 
    x^{(k)}_2\\ 
    \vdots \\
    x^{(k)}_{n-1}\\ 
    x^{(k)}_n\\ 
\end{bmatrix} \stackrel{i=1}{\to}
\begin{bmatrix}
    x^{(k+1)}_1\\ 
    x^{(k)}_2\\ 
    \vdots \\
    x^{(k)}_{n-1}\\ 
    x^{(k)}_n\\ 
\end{bmatrix} \stackrel{i=2}{\to}
\begin{bmatrix}
    x^{(k+1)}_1\\ 
    x^{(k+1)}_2\\ 
    \vdots \\
    x^{(k)}_{n-1}\\ 
    x^{(k)}_n\\ 
\end{bmatrix} \stackrel{i=3}{\to}
\dots
\stackrel{i=n-1}{\to}
\begin{bmatrix}
    x^{(k+1)}_1\\ 
    x^{(k)}_2\\ 
    x^{(k)}_3\\ 
    \vdots \\
    x^{(k+1)}_{n-1}\\ 
    x^{(k)}_n\\ 
\end{bmatrix} \stackrel{i=n}{\to}
\begin{bmatrix}
    x^{(k+1)}_1\\ 
    x^{(k)}_2\\ 
    x^{(k)}_3\\ 
    \vdots \\
    x^{(k+1)}_{n-1}\\ 
    x^{(k+1)}_n\\ 
\end{bmatrix} = \x^{(k+1)}.
\]
Lavorando in questo modo, in ogni passo abbiamo a disposizione tutti gli elementi che ci servono per calcolare l'elemento successivo.

Lo stesso trucco non funziona per il metodo di Jacobi: non possiamo cancellare $x_1^{(k)}$ rimpiazzandolo con $x_1^{(k+1)}$, perché quell'elemento ci serve anche successivamente quando calcoliamo $x_2^{(k+1)}, \dots, x_n^{(k+1)}$.

\paragraph{Convergenza dei metodi iterativi} Dimostriamo ora dei risultati che ci dicono quando un metodo iterativo converge. Partiamo introducendo una definizione. Diciamo che il metodo iterativo è \emph{convergente} se \emph{per ogni scelta} del punto iniziale $\x^{(0)}\in\mathbb{C}^n$ la successione generata dal metodo converge alla soluzione $\x$ del sistema lineare.

Per studiare la convergenza, definiamo $\e^{(k)} = \x^{(k)} - \x$ l'errore (assoluto) al passo $k$. Usando la~\eqref{solsistema} e la~\eqref{iterlin} abbiamo per ogni $k=1,2,\dots$
\begin{equation} \label{ekiter}
    \e^{(k+1)} = \x^{(k+1)} - \x = M^{-1}(N\x^{(k)} + \b) - M^{-1}(N\x + \b) = M^{-1}(N\x^{(k)}-N \x) = M^{-1}N \e^{(k)}.    
\end{equation}
Definiamo la \emph{matrice di iterazione} del metodo come $H = M^{-1}N$.

\begin{theorem}
Il metodo iterativo~\eqref{iterlin} è convergente se e solo se $\rho(H) < 1$.
\end{theorem}
\begin{proof}
In questo corso dimostriamo il teorema solo nel caso particolare in cui $H$ è diagonalizzabile (ma in realtà è vero sempre).

Usando ripetutamente la~\eqref{ekiter} si ha
\begin{align*}
  \e^{(1)} &= H \e^{(0)},\\
  \e^{(2)} &= H \e^{(1)} = H^2 \e^{(0)},\\
  \vdots\\
  \e^{(k)} &= H^k \e^{(0)}.
\end{align*}
Supponiamo che la matrice $H$ sia diagonalizzabile, cioè che esistano una matrice $V$ invertibile e $D$ diagonale tali che $H = VDV^{-1}$; sappiamo dall'algebra lineare che gli elementi diagonali di $D$ sono proprio gli autovalori di $H$. Possiamo scrivere
\[
H^k = \underbrace{(VDV^{-1})(VDV^{-1}) \dots (VDV^{-1})}_{\text{$k$ volte}} = VD^kV^{-1},
\]
semplificando le coppie $V^{-1}V=I$ che compaiono. Se $\rho(H) < 1$, allora $\abs{D_{ii}} < 1$ per ogni $i=1,2,\dots,n$, e quindi $\lim_{k\to\infty} D^k = 0$. Allora anche
\[
\lim_{k\to\infty} \mathbf{e}^{(k)} = \lim H^k \mathbf{e}^{(0)} = \lim VD^k V^{-1} \mathbf{e}^{(0)} = 0.
\]
Questo conclude (con l'ipotesi aggiuntiva che $k$ sia diagonalizzabile) la dimostrazione che se $\rho(H)<1$ allora il metodo è convergente. Visto che questo è un ``se e solo se'', vogliamo però dimostrare anche l'implicazione opposta: se $\rho(H)\geq 1$, allora il metodo non converge (per ogni scelta del punto iniziale $\x^{(0)}$). Per fare questo, ci basta dimostrare che se $H$ ha un autovalore e un autovettore $H\mathbf{v} = \mathbf{v} \lambda$, con $\abs{\lambda} \geq 1$, allora esiste \emph{almeno una} scelta di $\x^{(0)}$ per cui l'errore $\e^{(k)}$ non converge a zero. Prendiamo $\x^{(0)} = \x + \mathbf{v}$. Allora abbiamo $\e^{(0)} = \x^{(0)} - \x = \mathbf{v}$, e 
\begin{align*} \label{nonconverge}
    \e^{(1)} &= He^{(0)} = H\mathbf{v} = \mathbf{v}\lambda,\\
    \e^{(2)} &= He^{(1)} = H\mathbf{v}\lambda = \mathbf{v}\lambda^2,\\
    \vdots\\
    \e^{(k)} &= H e^{(k-1)} = \mathbf{v} \lambda^k.
\end{align*}
(Ogni volta che facciamo un prodotto $H\mathbf{v}$ otteniamo il vettore $\mathbf{v}\lambda$.)

Se $\abs{\lambda} \geq 1$ (e $\mathbf{v}\neq 0$, visto  che $\mathbf{v}$ è un autovettore), allora la quantità $\mathbf{v} \lambda^k$ non converge a zero, che era quello che volevamo dimostrare.
\end{proof}
Visto che $\rho(H) \leq \norm{H}_p$ per ogni norma matriciale indotta, abbiamo anche il seguente risultato.
\begin{corollary}
Se $\norm{H}_p \leq 1$ per una qualunque norma matriciale indotta, allora il metodo iterativo~\eqref{iterlin} è convergente.
\end{corollary}
Questo \emph{non} è un ``se e solo se''! In particolare, possiamo anche avere situazioni in cui alcune norme matriciali indotte sono minori di 1 e altre maggiori di 1.

È possibile dimostrare anche che per ogni norma vettoriale vale
\[
\lim_{k\to\infty} \frac{\norm{\e^{(k+1)}}}{\norm{\e^{(k)}}} \leq \rho(H),
\]
con uguaglianza per quasi tutti i vettori di partenza $\x^{(0)}$. Pertanto il metodo converge linearmente. La convergenza è tanto più veloce (pendenza della retta in scala logaritmica più vicina a $-\infty$) quanto più $\rho(H)$ è piccolo.

\paragraph{Criteri di arresto per metodi iterativi per sistemi lineari}
Abbiamo due scelte naturali come criteri di arresto per il metodo:
\begin{enumerate}
    \item Ci fermiamo quando $\norm{\x^{(k)} - \x^{(k+1)}} \leq \varepsilon$, per una certa norma e un valore $\varepsilon > 0$ fissato.
    \item Ci fermiamo quando $\norm{A \x^{(k+1)} - \b} \leq \varepsilon$.
\end{enumerate}
Il primo criterio è facile da implementare, ma (esattamente come abbiamo visto per il metodo del punto fisso nel caso scalare), quando la convergenza è lenta, $\norm{\x^{(k)} - \x^{(k+1)}}$ può essere molto più piccolo di $\norm{\x^{(k+1)} - \x}$, quindi rischiamo di sottostimare l'errore.

\paragraph{Residuo e stabilità all'indietro (*)}  Se $\x$ è la soluzione esatta del sistema lineare $A\x = \b$, allora chiaramente $\norm{A\x-\b} = 0$. Ma se per un vettore $\tilde{\x} \in \mathbb{C}^n$ il \emph{residuo} $\mathbf{r} = A\tilde{\x}-\b$ è piccolo, questo implica che $\tilde{\x}$ e $\x$ sono vicini? Intuitivamente sì, ma vediamo un risultato quantitativo che dice cosa succede.

\begin{theorem}[Stima del residuo]
Siano $A \in \mathbb{C}^{n\times n}$, $\b\in\mathbb{C}^n$. Sia $\x$ la soluzione del sistema lineare $A\x=\b$, sia $\tilde{\x}\in\mathbb{R}^n$ un altro vettore, e sia $\mathbf{r} = A\tilde{\x}-\b$. Allora,
\[
\frac{\norm{\tilde{\x}-\x}}{\norm{\x}} \leq \kappa(A) \frac{\norm{\mathbf{r}}}{\norm{\b}}.
\]
\end{theorem}
\begin{proof}
Abbiamo $A\tilde{\x} = \b + \mathbf{r}$. Allora, $\tilde{\x}$ è la soluzione del sistema lineare $A\tilde{\x} = \widehat{\b}$, in cui abbiamo perturbato il termine noto in $\widehat{\b} = \b + \mathbf{r}$. Pertanto possiamo applicare la disuguaglianza~\eqref{conditionbound}, che ci dà la tesi.
\end{proof}
Questo risultato non si applica solo all'iterata $\x^{(k+1)}$ prodotta da un metodo iterativo, ma a una qualunque soluzione approssimata di un sistema lineare, non importa come l'abbiamo ottenuta. È quindi particolarmente interessante perché ci permette di ottenere una stima esplicita sull'errore relativo nella $\tilde{\x}$ calcolata, sulla base di quantità calcolabili al computer.

\paragraph{Convergenza di Jacobi e Gauss--Seidel per matrici $A$ dominanti diagonali}
\begin{theorem}
Se $A$ è dominante diagonale, i metodi di Jacobi e Gauss--Seidel sono applicabili e convergenti.
\end{theorem}
\begin{proof}
Innanzitutto notiamo che i metodi sono applicabili; difatti $A_{ii} \neq 0$:
\[
\abs{A_{ii}} > \sum_{\substack{j=1\\j\neq i}}^n \abs{A_{ij}} \geq 0, \quad i=1,2,\dots,n.
\]
Vogliamo dimostrare che $\rho(H)<1$, in modo da avere la convergenza. Scriviamo il polinomio caratteristico
\[
\det (H - \lambda I) = \det (M^{-1}(N-\lambda M)) = \det M^{-1} \det (N-\lambda M).
\]
Poiché $\det M^{-1} \neq 0$, il polinomio caratteristico si annulla solo quando $\det (N-\lambda M) = 0$, cioè $N-\lambda M$ è singolare. Quindi ci basta mostrare che $N-\lambda M$ è invertibile quando $\abs{\lambda} \geq 1$.

La matrice $N-\lambda M$ ha elementi
\[
N-\lambda M = -
\begin{bmatrix}
    \lambda A_{11} & A_{12} & \dots & A_{1n}\\
    A_{21} & \lambda A_{22} & \dots & A_{2n}\\
    \vdots & \vdots & \ddots & \vdots\\
    A_{n1} & A_{n2} & \dots & \lambda A_{nn}
\end{bmatrix}
\]
nel caso del metodo di Jacobi (rispetto a $-A$, la diagonale è moltiplicata per $\lambda$), e 
\[
N-\lambda M = -
\begin{bmatrix}
    \lambda A_{11} & A_{12} & \dots & A_{1n}\\
    \lambda A_{21} & \lambda A_{22} & \dots & A_{2n}\\
    \vdots & \vdots & \ddots & \vdots\\
    \lambda A_{n1} & \lambda A_{n2} & \dots & \lambda A_{nn}
\end{bmatrix}
\]
nel caso del metodo di Gauss--Seidel (la parte triangolare inferiore è moltiplicata per $\lambda$). In entrambi i casi, questa matrice è predominante diagonale: difatti, la predominanza diagonale di $A$ assicura che
\[
\abs{\lambda A_{ii}} = \abs{\lambda}\abs{ A_{ii}} > \sum_{j\neq i} \abs{\lambda} \abs{A_{ij}}
\]
e il membro di destra (quando $\abs{\lambda} \geq 1$) è più grande del termine corrispondente agli elementi fuori dalla diagonale di $N-\lambda M$.
\end{proof}

\section{Sistemi di equazioni non lineari}

\paragraph{Introduzione} Facciamo qualche accenno anche a metodi per risolvere sistemi di equazioni \emph{non} lineari: data una $F: D \subseteq \mathbb{R}^n \to \mathbb{R}^n$, come possiamo trovare \emph{una} soluzione del sistema?

Ad esempio, supponiamo di voler risolvere $F(\mathbf{x})=0$, dove
\begin{equation} \label{esempiosistemanonlin}
    F\left(\begin{bmatrix}
        x_1\\ x_2
    \end{bmatrix}\right) = \begin{bmatrix}
        2x_1 + \cos(x_2)\\
        \sin(x_1) + 2x_2 - \pi
    \end{bmatrix}.
\end{equation}
Questo è un sistema (\emph{non} lineare) di due equazioni in due incognite; una soluzione del sistema per esempio è $(x_1, x_2) = (0,\pi/2)$.

Un sistema di questo tipo è un problema molto più complicato che non un sistema lineare; tanto per cominciare, in generale si possono avere zero soluzioni, una, più di una, o anche infinite, e non c'è un criterio generale per capire quando questi casi si verificano.

 Non c'è un modo facile di estendere a sistemi di più equazioni il metodo di bisezione, più che altro perché non abbiamo un analogo facile del teorema di Weierstrass in più dimensioni: anche se $F(\mathbf{a})$ ha tutte le componenti $<0$ e $F(\mathbf{b})$ ha tutte le componenti $>0$, non è detto che ci sia una soluzione simultanea di tutte le equazioni né nella retta che congiunge $(a_1,a_2)$ e $(b_1,b_2)$ né nel ``rettangolo'' che li comprende. I metodi di punto fisso invece si riescono a generalizzare facilmente, come abbiamo già visto: possiamo calcolare la successione $\x_{k+1} = \Phi(\x_k)$ anche per una funzione in più variabili $\Phi: \mathbb{R}^n \to \mathbb{R}^n$. In particolare ci concentriamo su un metodo del punto fisso particolarmente efficiente, il metodo di Newton.

\paragraph{Metodo di Newton multivariato}
Possiamo definire, generalizzando la derivata prima di una funzione, la \emph{matrice Jacobiana}
\[
J_F(\x) = 
\begin{bmatrix}
    \frac{\partial F_1}{\partial x_1}(x) & \frac{\partial F_1}{\partial x_2}(x) & \dots & \frac{\partial F_1}{\partial x_n}(x)\\
    \frac{\partial F_2}{\partial x_1}(x) & \frac{\partial F_2}{\partial x_2}(x) & \dots & \frac{\partial F_2}{\partial x_n}(x)\\
    \vdots & \vdots & \ddots & \vdots\\
    \frac{\partial F_n}{\partial x_1}(x) & \frac{\partial F_n}{\partial x_2}(x) & \dots & \frac{\partial F_n}{\partial x_n}(x)\\
\end{bmatrix} \in \mathbb{R}^{n\times n}
\]
Per evitare di confondere $J_F$ con la sua trasposta, possiamo usare questa tecnica mnemonica per ricordarci la posizione degli indici: le diverse componenti di $F(\x)$ sono elementi di un vettore colonna, e anche nello Jacobiano vediamo che le diverse componenti di ogni derivata parziale stanno nella stessa colonna. 

Per esempio per la~\eqref{esempiosistemanonlin} abbiamo
\[
J_F(\x) = \begin{bmatrix}
    2 & -\sin(x_2)\\
    \cos(x_1) & 2
\end{bmatrix}.
\]
Per funzioni sufficientemente regolari vale una generalizzazione dello sviluppo di Taylor:
\begin{equation} \label{taylormulti}
    F(\x+\mathbf{h}) = F(\x) + J_F(\x) \mathbf{h} + \mathcal{O}(\norm{\mathbf{h}}^2),
\end{equation}
con $\x,\mathbf{h} \in\mathbb{R}^n$, e un termine di resto che abbiamo indicato con $\mathcal{O}(\norm{\mathbf{h}}^2)$ e che va a zero ogni volta che il vettore $\mathbf{h}$ tende a zero. Notiamo in particolare che nel membro di destra compare un prodotto matrice-vettore $J_F(\x) \mathbf{h}$. Ragionando come nel metodo di Newton in una sola variabile, possiamo trascurare il termine di resto $\mathcal{O}(\norm{\mathbf{h}}^2)$ e cercare una nuova approssimazione $\x_{k+1} = \x_k+\mathbf{h}$ imponendo che
\[
    \mathbf{0} = F(\x_k+\mathbf{h}) = F(\x_k) + J_F(\x_k) \mathbf{h}.
\]
Questo produce il metodo
\[
\begin{cases}
\x^{(0)} \in \mathbb{R}^n & \text{assegnato}\\
\x^{(k+1)} = \x^{(k)} - \left(J_F(\x^{(k)})\right)^{-1} F(\x^{(k)}), & k=0,1,2,\dots.
\end{cases}
\]
Si possono dimostrare (noi qui non lo facciamo) risultati analoghi a quelli del caso scalare: su funzioni sufficientemente regolari, il metodo converge a patto di prendere $\x^{(0)}$ sufficientemente vicino a una soluzione $\x$, e la convergenza è quadratica se la matrice $J_F(\x)$ è invertibile. 

Ad ogni passo, dobbiamo risolvere un sistema lineare con matrice $J_F(\x^{(k)})$. Nella pratica, possiamo evitare di calcolare esplicitamente la matrice inversa: calcoliamo la matrice $J_F(\x^{(k)})$, e poi risolviamo il sistema lineare
\[
    J_F(\x^{(k)}) \mathbf{h} = F(\x^{(k)}), \quad \mathbf{h} = \x^{(k)} - \x^{(k+1)}
\]
con una fattorizzazione LU o altri metodi. Abbiamo visto, difatti, che quando dobbiamo effettuare il calcolo $\x = A^{-1}\b$, calcolare esplicitamente l'inversa $A^{-1}$ non è una buona idea, visto che costa di più e ha proprietà di stabilità peggiori rispetto a risolvere il sistema lineare con la fattorizzazione LU.

I passi del metodo di Newton multivariato quindi sono, nell'ordine
\begin{enumerate}
    \item calcolare $F(\x^{(k)})$;
    \item calcolare $J_F(\x^{(k)})$;
    \item risolvere il sistema lineare $J_F(\x^{(k)}) \mathbf{h} = F(\x^{(k)})$ per trovare $\mathbf{h}$;
    \item calcolare $\x^{(k+1)} = \x^{(k)} - \mathbf{h}$.
\end{enumerate}
È impossibile dire qualcosa in generale su come si confrontano i costi dei vari passi senza sapere quanto costa calcolare $F$ e $J_F$. In molti casi, però, calcolare gli $n$ elementi di $F$ e gli $n^2$ elementi di $J_F$ costa in tutto $\mathcal{O}(n^2)$ operazioni aritmetiche. Se per risolvere il sistema lineare utilizziamo una fattorizzazione LU, il costo del terzo passo è invece $\mathcal{O}(n^3)$: quindi spesso questo passo risulta essere quello più costoso. Per questo, spesso vengono utilizzate varianti del metodo di Newton che cercano di ridurre il costo di questo passo. Una di esse è il metodo delle corde, in cui al posto della matrice $J_F(\x^{(k)})$ viene utilizzata una matrice fissata $A$, per esempio lo Jacobiano calcolato al primo passo $A = J_F(\x^{(0)})$. In questo modo, è possibile calcolare una volta sola la fattorizzazione LU della matrice $A$ (con il costo di $\mathcal{O}(n^3)$ da ``pagare'' una volta all'inizio del metodo), e poi riutilizzarla ad ogni passo per risolvere il sistema lineare (con il costo di $\mathcal{O}(n^2)$ per ogni passo).

\paragraph{Una strategia ibrida} Un altro metodo utilizzato abbastanza spesso cerca di combinare i benefici del metodo delle corde e di quello di Newton. L'idea è che la matrice $J_F$ viene ricalcolata solo in alcune iterazioni del metodo; in altre, viene riutilizzata la matrice calcolata ai passi precedenti.

Nel dettaglio, per ogni $k=0,1,2,\dots$:
\begin{enumerate}
    \item Calcolo $F(\x^{(k)})$;
    \item Faccio una di queste due cose: \begin{enumerate}
        \item valuto $A = J_F(\x^{(k)})$ e calcolo una sua fattorizzazione $PA = LU$; oppure
        \item prendo le matrici $A,L,U,P$ calcolate in un passo precedente del metodo.
    \end{enumerate}
    \item Utilizzo la fattorizzazione per risolvere il sistema lineare $ A \mathbf{h} = F(\x^{(k)})$;
    \item Calcolo $\x^{(k+1)} = \x^{(k)} - \mathbf{h}$.
\end{enumerate}
Per esempio, posso fissare un intero $m>1$ e scegliere di fare il passo (2a) ogni $m$ passi: al passo $1$, $m+1$, $2m+1$, \dots.

Con questa strategia, riduciamo il costo computazionale per passo: possiamo vedere che il costo è $\mathcal{O}(n^3)$ nei passi in cui ricalcoliamo lo Jacobiano, ma solo $\mathcal{O}(n^2)$ nei passi in cui riutilizziamo quello precedente.

Come nel caso scalare, la convergenza è garantita solo se partiamo all'interno di un certo intorno della soluzione (che può essere anche molto piccolo!).

La convergenza di questo metodo è quadratica, sotto le stesse condizioni del metodo di Newton. Nella pratica, il grafico dell'errore si comporta come una spezzata: nelle iterazioni in cui teniamo la matrice $A$ costante osserviamo dei segmenti di retta, visto che se $A$ è costante si ha convergenza lineare; ma nelle iterazioni in cui aggiorniamo la matrice $A$ la pendenza di questa retta cambia e diventa più ripida, come ci aspettiamo da un metodo a convergenza quadratica. Un esempio di questo comportamento è raffigurato in Figura~\ref{fig:newtonibrido}.
\begin{figure}
    \begin{center}
        \begin{tikzpicture}
        \begin{axis}[width=0.7\textwidth, ymode = log, xlabel={iterazione $k$}, ylabel={errore $\|\x^{(k)} - \x_*\|$}, legend style={at={(0.5,-0.15)},anchor=north}]
            \addplot+[x=it, y=e] table{
                it e
                0   2.8284e-01
                1.0000e+00   1.0859e-01
                2.0000e+00   7.6739e-02
                3.0000e+00   6.3122e-02
                4.0000e+00   5.5023e-02
                5.0000e+00   1.3399e-02
                6.0000e+00   6.1339e-03
                7.0000e+00   2.8688e-03
                8.0000e+00   1.4247e-03
                9.0000e+00   1.5944e-05
                1.0000e+01   3.6558e-07
                1.1000e+01   8.3809e-09
                1.2000e+01   1.9239e-10
                1.3000e+01   1.9626e-17
        }; %\addlegendentry{Punto fisso su $\Phi(x) = 2/x^2 + (x^3-2)/4$};
        \end{axis}
        \end{tikzpicture}
        \end{center}
    \caption{Convergenza della variante del metodo di Newton in un esempio con $m=4$.} \label{fig:newtonibrido}
    \end{figure}    

\section{Sistemi lineari sovradeterminati (minimi quadrati)}

Supponiamo di avere un sistema del tipo
\[
A\x = \b, \quad A \in \mathbb{R}^{m\times n}, \, \b\in\mathbb{R}^m, \, \x\in\mathbb{R}^n
\]
in cui $A$ non è quadrata, bensì alta e stretta ($m>n$).

In un sistema di questo tipo, la soluzione spesso non esiste: abbiamo più equazioni che incognite, ed esse tipicamente non sono soddisfatte contemporaneamente. 

\paragraph{Esempio} Consideriamo il sistema di tre equazioni
\begin{equation} \label{esminquadrati}
\begin{cases}
    x_1 + x_2 = 2,\\
    x_1 - x_2 = 1,\\
    x_2 = 1,
\end{cases} \quad \text{quindi } A = \begin{bmatrix}
    1 & 1\\
    1 & -1\\
    0 & 1
\end{bmatrix}, \quad \b = \begin{bmatrix}
    2\\1\\1
\end{bmatrix}.
\end{equation}
Visto che ho più equazioni che incognite, non è garantito che esista un vettore $\x$ che soddisfa tutte e tre le equazioni. Per esempio, il vettore che soddisfa le prime due equazioni è $\x_1 = \begin{bsmallmatrix}1.5\\0.5\end{bsmallmatrix}$, ma la terza equazione non è soddisfatta, e si ha $A\x_1 - \b = \begin{bsmallmatrix}0\\0\\-0.5\end{bsmallmatrix}$.

Similmente, se prendiamo il vettore $\x_2$ che soddisfa la seconda e la terza equazione, abbiamo $\x_2 = \begin{bsmallmatrix}2\\1\end{bsmallmatrix}$; questa volta la prima equazione non è soddisfatta e si ha $A\x_1 - \b = \begin{bsmallmatrix}1\\0\\0\end{bsmallmatrix}$.

In un certo senso però $\x_1$ è ``meno sbagliato'' di $\x_2$, visto che $A\x_1$ è più vicino a $\b$ che non $A\x_2$: difatti $\norm{A\x_1-\b} = 0.5$, $\norm{A\x_2 - \b} = 1$, per tutte e tre le norme che abbiamo visto. Da questo punto di vista, ha senso chiedersi qual è il vettore $\x$ per cui $A\x$ è più vicino a $\b$.

\paragraph{Interpretazione geometrica} Dall'algebra lineare, sappiamo che il vettore $A\x$ è una combinazione lineare delle colonne di $A$, e al variare del vettore $\x$ queste combinazioni lineari stanno tutte all'interno dell'immagine $\operatorname{Im} A$, che è un sottospazio di $\mathbb{R}^m$.
\begin{center}

    
    \begin{tikzpicture}[scale=1.5]

    \draw[thick, blue, opacity=0.5] (-1, 0, 0) -- (1, 0, 0) -- (1, 0, 1) -- (-1, 0, 1) -- cycle;
    
    \node at (1.4, 0, 0.5) {Im A};

    \draw[thick, ->, red] (0, 0, 0.5) -- (1, 1, 1) node[midway, right] {$\mathbf{b}$};
\end{tikzpicture}
\end{center}

\paragraph{Problema dei minimi quadrati} Possiamo quindi risolvere questo problema: di calcolare la combinazione lineare delle colonne di $A$, cioè il vettore $A\x$, che va più vicino al vettore $\b$:
\begin{equation} \label{minresiduo}
    \min_{\x\in\mathbb{R}^n} \norm{A\x-\b}.    
\end{equation}
In altre parole, stiamo cercando il vettore $\x$ che rende più piccola possibile la norma del \emph{residuo} $\mathbf{r}(\x) = A \x - \b$, cioè la differenza tra il termine di sinistra e quello di destra delle equazioni che stiamo considerando. Attenzione: in questo problema, anche quando lo calcoliamo nel punto di minimo $\x$, il residuo non vale $\mathbf{0}$, perché le equazioni non ammettono una soluzione comune!

Vogliamo concentrarci sul risolvere il problema~\eqref{minresiduo} nel caso della norma-2; difatti, vedremo che in questo caso ha una soluzione particolarmente semplice; non succede altrettanto per le altre norme. Minimizzare la norma-2 di $\mathbf{r}(\x)$ equivale a minimizzare il suo quadrato $\sum r_i^2  = \mathbf{r}(\x)^T\mathbf{r}(\x)$, ovvero
\begin{equation} \label{minimiquadrati}
    \min_{\x\in\mathbb{R}^n} \norm{\mathbf{r}(\x)}_2^2 = \min_{\x\in\mathbb{R}^n} \norm{A\x-\b}_2^2.
\end{equation}
Il problema~\eqref{minimiquadrati} è detto \emph{problema dei minimi quadrati}, visto che se espandiamo $\norm{\mathbf{r}(\x)}_2^2 = \mathbf{r}(\x)^T\mathbf{r}(\x) = \sum r_i^2$ otteniamo la somma dei quadrati delle componenti di $\mathbf{r}(\x)$. Per esempio, nell'esempio~\eqref{esminquadrati} si ha la somma di quadrati
\[
\min_{\x = \begin{bsmallmatrix}x_1\\x_2\end{bsmallmatrix} \in \mathbb{R}^2}\,\, (x_1 + x_2 - 2)^2 + (x_1 - x_2 - 1)^2 + (x_2 - 1)^2.
\]

\paragraph{Equazioni normali}  Dimostriamo il seguente risultato.
\begin{theorem}
Sia $\x\in\mathbb{R}^n$ un vettore tale che $A^T \mathbf{r}(\x) = A^T(A\x-\b) = \mathbf{0}$. Allora, $\x$ risolve il problema di minimo~\eqref{minimiquadrati}.
\end{theorem}
\begin{proof}
Prendiamo un qualunque vettore diverso da $\x$: possiamo scriverlo come $\x+\mathbf{z}$, con $\mathbf{z}\in\mathbb{R}^n, \mathbf{z} \neq \mathbf{0}$; il suo residuo vale
\[
\mathbf{r}(\x+\mathbf{z}) =  A(\x+\mathbf{z})-\b = \underbrace{A\x-\b}_{=\mathbf{r}} + \underbrace{A\mathbf{z}}_{=\mathbf{s}} = \mathbf{r}+\mathbf{s}.
\]
(Abbiamo usato la sola lettera $\mathbf{r}$ per indicare il residuo $\mathbf{r}(\x)$, per avere una notazione più semplice.)

Vogliamo dimostrare che la norma di questo residuo è maggiore o uguale a quella di $\mathbf{r}$; questo ci permette di concludere che $\x$ è la soluzione del problema. Il quadrato di questa norma vale
\[
\norm{\mathbf{r}(\x+\mathbf{z})}_2^2 = \norm{A(\x+\mathbf{z})-\b}_2^2 = (\mathbf{r}+\mathbf{s})^T(\mathbf{r}+\mathbf{s}) = \mathbf{s}^T \mathbf{s} + \mathbf{s}^T\mathbf{r} + \mathbf{r}^T \mathbf{s} + \mathbf{r}^T \mathbf{r}.
\]
Notiamo però che il prodotto scalare $\mathbf{r}^T\mathbf{s} = \mathbf{s}^T\mathbf{r}$ è uguale a zero: difatti,
\[
\mathbf{s}^T \mathbf{r} = (A\mathbf{z})^T \mathbf{r} = \mathbf{z}^T A^T \mathbf{r} = 0,
\]
visto che $A^T\mathbf{r} = A^T(A\x-\b) = \mathbf{0}$ per ipotesi.

Allora si ha
\[
\norm{A(\x+\mathbf{z})-\b}_2^2 = \mathbf{s}^T \mathbf{s} + \mathbf{r}^T \mathbf{r} \geq \mathbf{r}^T\mathbf{r}.
\]
Difatti $\mathbf{s}^T\mathbf{s} = s_1^2 + s_2^2 + \dots + s_m^2 \geq 0$ è positivo. Questo dimostra che $\mathbf{r}(\x +\mathbf{z})$ ha norma maggiore o uguale a quella di $\mathbf{r}(\x)$ per ogni scelta del vettore $\z$.
\end{proof}
Quindi per trovare la soluzione $\x$ di questo problema ci basta risolvere il sistema di equazioni
\begin{equation} \label{eqnormali}
    A^T A \x = A^T \b,    
\end{equation}
che si ottiene moltiplicando per $A^T$ il sistema originale (che era rettangolare e quindi potenzialmente senza soluzione) $A \x= \b$. La~\eqref{eqnormali} si chiama \emph{metodo delle equazioni normali}, perché le equazioni corrispondenti dicono (in termini geometrici) che il residuo $\mathbf{r}=A \x-\b$ è ortogonale (prodotto scalare nullo) alle colonne di $A$.

È semplice vedere che $A^T A$ è quadrata e simmetrica; inoltre, si può dimostrare che è positiva definita (quindi invertibile!) tutte le volte che le colonne di $A$ sono linearmente indipendenti. Possiamo allora risolvere il sistema lineare~\eqref{eqnormali} usando la fattorizzazione di Cholesky. 

Per risolvere questo problema quindi possiamo usare il seguente algoritmo.
\begin{enumerate}
    \item Calcoliamo la matrice $A^TA$ (costo computazionale: $O(mn^2)$);
    \item Calcoliamo il vettore $A^T \b$ (costo computazionale: $O(mn)$);
    \item Risolviamo il sistema lineare $(A^TA)\x = A^T\b$, utilizzando la fattorizzazione di Cholesky (costo computazionale: $O(n^3)$).
\end{enumerate}
Poiché $m>n$, il maggiore di questi costi è $O(mn^2)$.

Questo metodo basato sul sistema~\eqref{eqnormali} però in alcuni casi risulta instabile: il condizionamento del sistema lineare~\eqref{eqnormali} $\kappa(A^TA)$ può essere molto grande, e in particolare essere più alto di quello del problema di minimo originale. Esiste un altro metodo più costoso ma più stabile.

\paragraph{Fattorizzazione QR}

Si può dimostrare (noi qui non lo facciamo) il seguente risultato.
\begin{theorem}
    Per ogni $A \in \mathbb{R}^{m\times n}$, esistono una matrice $Q\in\mathbb{R}^{m\times m}$ \emph{ortogonale} (cioè che soddisfa $Q^TQ=I$) e una matrice $R \in \mathbb{R}^{m\times n}$ triangolare superiore tali che $A = QR$.
\end{theorem}
La matrice $R$ è rettangolare: quando scriviamo ``triangolare'' intendiamo che
\[
R = \begin{bmatrix}
    R_1\\ O
\end{bmatrix},
\]
dove $R_1 \in \mathbb{R}^{n\times n}$ è una normale matrice quadrata triangolare, e $O\in\mathbb{R}^{(m-n)\times n}$ è un blocco di zeri. Se suddividiamo in blocchi anche
\[
Q = \begin{bmatrix}
    Q_1 & Q_2
\end{bmatrix}, \quad Q_1 \in \mathbb{R}^{m\times n}, \, Q_2 \in \mathbb{R}^{m\times (m-n)},
\]
vediamo che gli elementi di $Q_2$ si ``scontrano'' con il blocco di zeri quando facciamo il prodotto, quindi $A = QR = Q_1 R_1$.

Con alcune manipolazioni algebriche (che non vediamo nel dettaglio) si può vedere che la soluzione $x$ delle~\eqref{eqnormali} è una soluzione anche del sistema lineare triangolare
\begin{equation} \label{qrsystem}
    R_1 x = Q_1^T b.    
\end{equation}
Questo ci suggerisce un altro algoritmo per la soluzione del problema dei minimi quadrati:
\begin{itemize}
    \item Calcoliamo la fattorizzazione $A=QR$ (o anche solo i blocchi $A = Q_1 R_1$).
    \item Risolviamo per sostituzione all'indietro il sistema~\eqref{qrsystem}.
\end{itemize}
Questo metodo è più costoso del precedente: facendo un'analisi più accurata, è possibile dimostrare che quando $m\gg n$ richiede $2mn^2$ operazioni più termini di ordine inferiore, contro $mn^2$ per il metodo delle equazioni normali. Però, il metodo è più stabile in alcuni problemi in cui $A^TA$ è mal condizionata.

\paragraph{Soluzione tramite Matlab} In Matlab, risolvere un problema ai minimi quadrati~\eqref{minimiquadrati} è semplice: basta il comando \lstinline{A \ b}, lo stesso che avreste usato per risolvere il sistema lineare se $A$ fosse quadrata. Matlab usa il metodo più stabile basato sulla fattorizzazione QR.

\chapter{Interpolazione e approssimazione}

\section{Approssimazione e interpolazione}

In diversi problemi applicativi, abbiamo una serie di misurazioni che corrispondono a punti del piano $(x_1, y_1), \dots, (x_n, y_n) \in \mathbb{R}^2$, e siamo interessati a determinare una funzione che passa (esattamente o approssimativamente) per questi punti.

Ad esempio: supponiamo di avere un impianto industriale in cui stiamo eseguendo una reazione chimica, e di averne misurato la temperatura in $4$ tempi distinti, alle 0:00, alle 1:00, alle 2:00, e alle 3:00. In che modo possiamo trovare una stima della temperatura a un'altra ora, ad esempio alle 2:45? O anche in un'ora al di fuori dell'intervallo di misurazione, per esempio alle 4:00? (In questo caso a volte si usa il termine \emph{estrapolazione}.)

Magari abbiamo dei modelli che ci dicono che la temperatura decresce linearmente o esponenzialmente, ma questi modelli dipendono da parametri che dobbiamo calcolare. Oppure qualche volta non abbiamo proprio un modello e stiamo genericamente cercando una funzione `semplice' che approssima i valori trovati. Studieremo due problemi:
\begin{itemize}
    \item Si chiama \emph{interpolazione} il problema di trovare una funzione $\phi$ (all'interno di una certa classe) tale che $\phi(x_i) = y_i$ per ogni $i=1,2,\dots, n$. In altre parole, il grafico della funzione nel piano cartesiano deve passare esattamente per i punti $(x_i, y_i)$.
    \item Si chiama \emph{approssimazione} (o, dall'inglese, \emph{fit}) il problema di trovare una funzione $\phi$ tale che $\phi(x_i) \approx y_i$, minimizzando un qualche tipo di errore (vedremo poi esattamente quale).
\end{itemize}

\begin{center}
\begin{tikzpicture}[scale=1.1]
  % Axes
  \draw[->] (-0.5,0) -- (4.5,0) node[right] {$x$};
  \draw[->] (0,-1.2) -- (0,3.5) node[above] {$y$};

  % Data points (chosen to match y = -0.3x^3 + 1.3x^2 - 0.2x + 1)
  \fill[blue] (0,1) circle (2pt);
  \fill[blue] (1,1.8) circle (2pt);
  \fill[blue] (2,3.4) circle (2pt);
  \fill[blue] (3,4) circle (2pt);

  \node[anchor=south east] at (0,1) {$(x_1,\,y_1)$};
  \node[anchor=south east] at (1,1.8) {$(x_2,\,y_2)$};
  \node[anchor=west] at (2,3.4) {$(x_3,\,y_3)$};
  \node[anchor=west] at (3,4) {$(x_4,\,y_4)$};

  % Interpolating polynomial curve: y = -0.3x^3 + 1.3x^2 - 0.2x + 1
  \draw[domain=0:3.5,smooth,thick,red,samples=100] 
    plot (\x,{ -0.3*\x*\x*\x + 1.3*\x*\x - 0.2*\x + 1 });

  % Optional: equation label
  % \node[red] at (2.7,3) {$y = -0.3x^3 + 1.3x^2 - 0.2x + 1$};

  % Legend (shifted 2 units to the right)
  \draw[blue,fill=blue] (5.7,3.2) circle (2pt);
  \node[right] at (5.8,3.2) {Valori osservati};
  \draw[thick,red] (5.7,2.9) -- (6.1,2.9);
  \node[right] at (6.1,2.9) {Polinomio di interpolazione};
\end{tikzpicture}
\end{center}


\section{Interpolazione polinomiale}

Vediamo più nel dettaglio il problema dell'\emph{interpolazione polinomiale}. Fissiamo un grado massimo $d$; si usa questa lettera dall'inglese \emph{degree}. Supponiamo di avere $d+1$ punti dati nel piano $(x_0, y_0), (x_1, y_1), \dots, (x_{d}, y_{d})$ (attenzione: per comodità con gli indici partiamo da $0$ questa volta) e di voler trovare un polinomio di grado minore o uguale a $d$ il cui grafico passa esattamente per questi punti; cioè, stiamo cercando coefficienti incogniti $\alpha_0, \alpha_1, \dots, \alpha_d$ tali che il polinomio
\[
p(x) = \alpha_0 + \alpha_1 x + \alpha_2 x^2 + \dots + \alpha_d x^d
\]
soddisfa le relazioni
\begin{equation} \label{interpolazione_polinomiale}
p(x_i) = y_i, \quad i=0,1,\dots,d.
\end{equation}
I punti $x_i$ qui sono detti \emph{nodi} dell'interpolazione, e i punti $y_i$ \emph{valori} da interpolare. Possiamo immaginare che questi punti $y_i$ siano calcolati come $y_i = f(x_i)$ a partire da una funzione $f$ più complicata da calcolare (perché è data da una formula più complicata, o perché è il risultato di misurazioni che non possiamo ripetere); in questo modo costruiamo un polinomio che fa da `modello' più semplice di questa funzione.

Possiamo osservare che le relazioni~\eqref{interpolazione_polinomiale} sono equivalenti a un sistema lineare di $d+1$ equazioni nelle $d+1$ incognite $\alpha_0,\dots,\alpha_d$:
\[
\underbrace{
\begin{bmatrix}
    1 & x_0 & x_0^2 & \dots & x_0^{d}\\
    1 & x_1 & x_1^2 & \dots & x_1^{d}\\
    1 & x_2 & x_2^2 & \dots & x_2^{d}\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    1 & x_d & x_d^2 & \dots & x_d^{d}\\
\end{bmatrix}
}_{=X}
\begin{bmatrix}
    \alpha_0 \\ \alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_d
\end{bmatrix}=
\begin{bmatrix}
    y_0 \\ y_1 \\ y_2 \\ \vdots \\ y_d
\end{bmatrix}.
\]
Attenzione: non ci facciamo ingannare dalle lettere usate: le $x_i$ e le $y_i$ non sono incognite: qui sono note, e sono i dati del problema.

La matrice associata a questo sistema, che abbiamo indicato con $X$, si chiama \emph{matrice di Vandermonde}.

\paragraph{Risolubilità} È possibile dimostrare il seguente risultato.
\begin{theorem}
Per ogni scelta di $x_0,x_1,\dots, x_d$ \emph{distinti}, la matrice di Vandermonde è invertibile.
\end{theorem}
\begin{proof} (*)
Sia
\[
\mathbf{a} = \begin{bmatrix}
    a_0\\
    a_1\\
    \vdots\\
    a_d
\end{bmatrix}
\]
un vettore nel kernel della matrice $X$, cioè tale che $X\mathbf{a} = \mathbf{0}$. Vogliamo dimostrare che dev'essere $\mathbf{a} = \mathbf{0}$; questo implica che la matrice $X$ è invertibile.

Se scriviamo l'uguaglianza $X\mathbf{a} = \mathbf{0}$ riga per riga, vediamo che essa corrisponde a
\[
1\cdot a_0 + x_i \cdot a_1 + x_i^2 \cdot a_2 + \dots + x_i^d \cdot a_d = 0, \quad i=0,1,\dots,d;
\]
Queste uguaglianze ci dicono che il polinomio $a(x) = a_0 + a_1 x + a_2 x^2 + \dots + a_d x^d$ si annulla nei punti $x_0, x_1, \dots, x_d$. Ma dalle proprietà dei polinomi sappiamo che un polinomio di grado al più $d$ che si annulla in $d+1$ punti dev'essere necessariamente il polinomio nullo\footnote{Per il teorema di Ruffini, un polinomio che si annulla in $x_0,x_1,\dots,x_d$ è un multiplo del polinomio $(x-x_0)(x-x_1)\dots (x-x_d)$; quindi o è il polinomio nullo, oppure ha grado almeno $d+1$.}. Questo quindi dimostra che $\mathbf{a}=\mathbf{0}$ e quindi che $X$ è invertibile.
\end{proof}
Dall'invertibilità di questa matrice segue che il problema dell'interpolazione polinomiale è sempre risolubile, cioè vale questo risultato.
\begin{theorem}[esistenza e unicità del polinomio di interpolazione]
Date $n+1$ coppie $(x_0,y_0),\dots,(x_d,y_d)$, con gli $x_i$ tutti diversi tra loro, esiste uno e un solo polinomio $p(x)$ di grado minore o uguale a $d$ tale che $p(x_i)=y_i$ per ogni $i=0,1,\dots,d$.
\end{theorem}

\paragraph{Esempio} Cerchiamo il polinomio di grado minore o uguale a $d=2$ che passa per i tre punti $(x_0,y_0) = (1,2)$, $(x_1,y_1) = (2,5)$, $(x_2,y_2) = (3,7)$. Questo equivale a trovare il polinomio $p(x) = \alpha_0 + \alpha_1 x + \alpha_2 x^2$ che risolve il sistema $X\mathbf{\alpha} = \mathbf{y}$
\[
    \begin{bmatrix}
    1 & 1 & 1\\
    1 & 2 & 4\\
    1 & 3 & 9
    \end{bmatrix}\begin{bmatrix}
        \alpha_0\\
        \alpha_1\\
        \alpha_2
    \end{bmatrix} = \begin{bmatrix}
        2\\5\\7
    \end{bmatrix}.
\]
Risolvendo il sistema (per esempio con \lstinline{X \ y} in Matlab, dopo aver definito $X$ e $\mathbf{y}$) si ottengono i coefficienti del polinomio $p(x) = -2 + 4.5 x = 0.5x^2$, che effettivamente soddisfa le tre condizioni cercate. Questo è l'unico polinomio di grado minore o uguale a due che soddisfa le tre condizioni; ne esistono altri di grado maggiore: si può mostrare (qui non lo vediamo nel dettaglio) che sono tutti i polinomi della forma $p(x) = -2 + 4.5 x = 0.5x^2 + (x-1)(x-2)(x-3)q(x)$, dove $q(x)$ è un qualunque altro polinomio; difatti vediamo che l'ultimo addendo si annulla per $x=1,x=2$, e $x=3$. 

Notare che sul grado abbiamo solo una disuguaglianza: nulla vieta che il coefficiente $\alpha_d$ (o anche quelli precedenti) sia uguale a zero per una particolare scelta dei punti $(x_i,y_i)$. Per esempio, se modifichiamo i dati in $(1,3), (2,5), (3,7)$ (che sono tre punti allineati), allora il polinomio di grado $\leq 2$ che passa esattamente per questi punti è $p(x)=1+2x+0x^2 = 1+2x$, che ha grado $1$ perché $\alpha_2 = 0$. 

Solitamente l'interpolazione polinomiale si usa con pochi nodi; $d \leq 10$ per esempio. Questo perché per valori grandi di $d$ in molti casi la matrice di Vandermonde, seppure invertibile, risulta mal condizionata. Ad esempio, la matrice di Vandermonde costruita con i 10 nodi $x_0 = 0,x_1=1,\dots,x_9=9$ ha condizionamento in norma-2 $\kappa(V) \approx 9\cdot 10^{10}$, un numero altissimo! Ricordiamo il significato del numero di condizionamento: questo significa che a piccolissime variazioni dei dati $x_i$ o $y_i$ possono corrispondere grandi variazioni nei coefficienti del polinomio. 

Un problema collegato è che spesso quando $d$ è grande succede che il polinomio passa sì per i punti dati, ma ha forti oscillazioni al di fuori di essi. come nell'esempio qui sotto.
\begin{center}
    
\begin{tikzpicture}
\begin{axis}[
    width=0.8\textwidth,
    axis lines=middle,
    ymin = -1,
    ymax = 2,
]
\addplot[
    color=red,
    thick,
    mark=none,
]
table{

  -5.0000e+00   3.8462e-02
  -4.9750e+00  -2.5449e+01
  -4.9500e+00  -4.2471e+01
  -4.9250e+00  -5.2888e+01
  -4.9000e+00  -5.8238e+01
  -4.8750e+00  -5.9782e+01
  -4.8500e+00  -5.8545e+01
  -4.8250e+00  -5.5353e+01
  -4.8000e+00  -5.0864e+01
  -4.7750e+00  -4.5597e+01
  -4.7500e+00  -3.9952e+01
  -4.7250e+00  -3.4233e+01
  -4.7000e+00  -2.8663e+01
  -4.6750e+00  -2.3401e+01
  -4.6500e+00  -1.8554e+01
  -4.6250e+00  -1.4188e+01
  -4.6000e+00  -1.0335e+01
  -4.5750e+00  -7.0021e+00
  -4.5500e+00  -4.1792e+00
  -4.5250e+00  -1.8410e+00
  -4.5000e+00   4.7059e-02
  -4.4750e+00   1.5254e+00
  -4.4500e+00   2.6378e+00
  -4.4250e+00   3.4294e+00
  -4.4000e+00   3.9451e+00
  -4.3750e+00   4.2278e+00
  -4.3500e+00   4.3183e+00
  -4.3250e+00   4.2541e+00
  -4.3000e+00   4.0691e+00
  -4.2750e+00   3.7939e+00
  -4.2500e+00   3.4550e+00
  -4.2250e+00   3.0753e+00
  -4.2000e+00   2.6744e+00
  -4.1750e+00   2.2682e+00
  -4.1500e+00   1.8699e+00
  -4.1250e+00   1.4897e+00
  -4.1000e+00   1.1353e+00
  -4.0750e+00   8.1222e-01
  -4.0500e+00   5.2404e-01
  -4.0250e+00   2.7272e-01
  -4.0000e+00   5.8824e-02
  -3.9750e+00  -1.1819e-01
  -3.9500e+00  -2.5980e-01
  -3.9250e+00  -3.6813e-01
  -3.9000e+00  -4.4587e-01
  -3.8750e+00  -4.9602e-01
  -3.8500e+00  -5.2181e-01
  -3.8250e+00  -5.2655e-01
  -3.8000e+00  -5.1355e-01
  -3.7750e+00  -4.8603e-01
  -3.7500e+00  -4.4705e-01
  -3.7250e+00  -3.9946e-01
  -3.7000e+00  -3.4588e-01
  -3.6750e+00  -2.8865e-01
  -3.6500e+00  -2.2984e-01
  -3.6250e+00  -1.7124e-01
  -3.6000e+00  -1.1435e-01
  -3.5750e+00  -6.0384e-02
  -3.5500e+00  -1.0316e-02
  -3.5250e+00   3.5135e-02
  -3.5000e+00   7.5472e-02
  -3.4750e+00   1.1040e-01
  -3.4500e+00   1.3979e-01
  -3.4250e+00   1.6370e-01
  -3.4000e+00   1.8228e-01
  -3.3750e+00   1.9582e-01
  -3.3500e+00   2.0467e-01
  -3.3250e+00   2.0927e-01
  -3.3000e+00   2.1009e-01
  -3.2750e+00   2.0764e-01
  -3.2500e+00   2.0242e-01
  -3.2250e+00   1.9497e-01
  -3.2000e+00   1.8578e-01
  -3.1750e+00   1.7533e-01
  -3.1500e+00   1.6408e-01
  -3.1250e+00   1.5245e-01
  -3.1000e+00   1.4080e-01
  -3.0750e+00   1.2948e-01
  -3.0500e+00   1.1875e-01
  -3.0250e+00   1.0886e-01
  -3.0000e+00   1.0000e-01
  -2.9750e+00   9.2306e-02
  -2.9500e+00   8.5883e-02
  -2.9250e+00   8.0790e-02
  -2.9000e+00   7.7050e-02
  -2.8750e+00   7.4653e-02
  -2.8500e+00   7.3561e-02
  -2.8250e+00   7.3709e-02
  -2.8000e+00   7.5011e-02
  -2.7750e+00   7.7366e-02
  -2.7500e+00   8.0660e-02
  -2.7250e+00   8.4769e-02
  -2.7000e+00   8.9564e-02
  -2.6750e+00   9.4916e-02
  -2.6500e+00   1.0070e-01
  -2.6250e+00   1.0678e-01
  -2.6000e+00   1.1305e-01
  -2.5750e+00   1.1939e-01
  -2.5500e+00   1.2571e-01
  -2.5250e+00   1.3192e-01
  -2.5000e+00   1.3793e-01
  -2.4750e+00   1.4369e-01
  -2.4500e+00   1.4915e-01
  -2.4250e+00   1.5426e-01
  -2.4000e+00   1.5901e-01
  -2.3750e+00   1.6337e-01
  -2.3500e+00   1.6735e-01
  -2.3250e+00   1.7096e-01
  -2.3000e+00   1.7421e-01
  -2.2750e+00   1.7713e-01
  -2.2500e+00   1.7976e-01
  -2.2250e+00   1.8214e-01
  -2.2000e+00   1.8430e-01
  -2.1750e+00   1.8630e-01
  -2.1500e+00   1.8819e-01
  -2.1250e+00   1.9002e-01
  -2.1000e+00   1.9184e-01
  -2.0750e+00   1.9370e-01
  -2.0500e+00   1.9565e-01
  -2.0250e+00   1.9774e-01
  -2.0000e+00   2.0000e-01
  -1.9750e+00   2.0248e-01
  -1.9500e+00   2.0521e-01
  -1.9250e+00   2.0822e-01
  -1.9000e+00   2.1153e-01
  -1.8750e+00   2.1516e-01
  -1.8500e+00   2.1913e-01
  -1.8250e+00   2.2344e-01
  -1.8000e+00   2.2810e-01
  -1.7750e+00   2.3310e-01
  -1.7500e+00   2.3845e-01
  -1.7250e+00   2.4412e-01
  -1.7000e+00   2.5012e-01
  -1.6750e+00   2.5643e-01
  -1.6500e+00   2.6303e-01
  -1.6250e+00   2.6990e-01
  -1.6000e+00   2.7702e-01
  -1.5750e+00   2.8438e-01
  -1.5500e+00   2.9196e-01
  -1.5250e+00   2.9974e-01
  -1.5000e+00   3.0769e-01
  -1.4750e+00   3.1582e-01
  -1.4500e+00   3.2409e-01
  -1.4250e+00   3.3251e-01
  -1.4000e+00   3.4106e-01
  -1.3750e+00   3.4974e-01
  -1.3500e+00   3.5855e-01
  -1.3250e+00   3.6748e-01
  -1.3000e+00   3.7655e-01
  -1.2750e+00   3.8575e-01
  -1.2500e+00   3.9509e-01
  -1.2250e+00   4.0460e-01
  -1.2000e+00   4.1427e-01
  -1.1750e+00   4.2413e-01
  -1.1500e+00   4.3420e-01
  -1.1250e+00   4.4449e-01
  -1.1000e+00   4.5503e-01
  -1.0750e+00   4.6583e-01
  -1.0500e+00   4.7691e-01
  -1.0250e+00   4.8829e-01
  -1.0000e+00   5.0000e-01
  -9.7500e-01   5.1204e-01
  -9.5000e-01   5.2444e-01
  -9.2500e-01   5.3719e-01
  -9.0000e-01   5.5031e-01
  -8.7500e-01   5.6381e-01
  -8.5000e-01   5.7768e-01
  -8.2500e-01   5.9192e-01
  -8.0000e-01   6.0653e-01
  -7.7500e-01   6.2148e-01
  -7.5000e-01   6.3676e-01
  -7.2500e-01   6.5234e-01
  -7.0000e-01   6.6820e-01
  -6.7500e-01   6.8431e-01
  -6.5000e-01   7.0062e-01
  -6.2500e-01   7.1709e-01
  -6.0000e-01   7.3367e-01
  -5.7500e-01   7.5031e-01
  -5.5000e-01   7.6696e-01
  -5.2500e-01   7.8354e-01
  -5.0000e-01   8.0000e-01
  -4.7500e-01   8.1627e-01
  -4.5000e-01   8.3228e-01
  -4.2500e-01   8.4796e-01
  -4.0000e-01   8.6324e-01
  -3.7500e-01   8.7805e-01
  -3.5000e-01   8.9231e-01
  -3.2500e-01   9.0595e-01
  -3.0000e-01   9.1891e-01
  -2.7500e-01   9.3111e-01
  -2.5000e-01   9.4249e-01
  -2.2500e-01   9.5299e-01
  -2.0000e-01   9.6255e-01
  -1.7500e-01   9.7112e-01
  -1.5000e-01   9.7865e-01
  -1.2500e-01   9.8509e-01
  -1.0000e-01   9.9042e-01
  -7.5000e-02   9.9459e-01
  -5.0000e-02   9.9759e-01
  -2.5000e-02   9.9940e-01
            0   1.0000e+00
   2.5000e-02   9.9940e-01
   5.0000e-02   9.9759e-01
   7.5000e-02   9.9459e-01
   1.0000e-01   9.9042e-01
   1.2500e-01   9.8509e-01
   1.5000e-01   9.7865e-01
   1.7500e-01   9.7112e-01
   2.0000e-01   9.6255e-01
   2.2500e-01   9.5299e-01
   2.5000e-01   9.4249e-01
   2.7500e-01   9.3111e-01
   3.0000e-01   9.1891e-01
   3.2500e-01   9.0595e-01
   3.5000e-01   8.9231e-01
   3.7500e-01   8.7805e-01
   4.0000e-01   8.6324e-01
   4.2500e-01   8.4796e-01
   4.5000e-01   8.3228e-01
   4.7500e-01   8.1627e-01
   5.0000e-01   8.0000e-01
   5.2500e-01   7.8354e-01
   5.5000e-01   7.6696e-01
   5.7500e-01   7.5031e-01
   6.0000e-01   7.3367e-01
   6.2500e-01   7.1709e-01
   6.5000e-01   7.0062e-01
   6.7500e-01   6.8431e-01
   7.0000e-01   6.6820e-01
   7.2500e-01   6.5234e-01
   7.5000e-01   6.3676e-01
   7.7500e-01   6.2148e-01
   8.0000e-01   6.0653e-01
   8.2500e-01   5.9192e-01
   8.5000e-01   5.7768e-01
   8.7500e-01   5.6381e-01
   9.0000e-01   5.5031e-01
   9.2500e-01   5.3719e-01
   9.5000e-01   5.2444e-01
   9.7500e-01   5.1204e-01
   1.0000e+00   5.0000e-01
   1.0250e+00   4.8829e-01
   1.0500e+00   4.7691e-01
   1.0750e+00   4.6583e-01
   1.1000e+00   4.5503e-01
   1.1250e+00   4.4449e-01
   1.1500e+00   4.3420e-01
   1.1750e+00   4.2413e-01
   1.2000e+00   4.1427e-01
   1.2250e+00   4.0460e-01
   1.2500e+00   3.9509e-01
   1.2750e+00   3.8575e-01
   1.3000e+00   3.7655e-01
   1.3250e+00   3.6748e-01
   1.3500e+00   3.5855e-01
   1.3750e+00   3.4974e-01
   1.4000e+00   3.4106e-01
   1.4250e+00   3.3251e-01
   1.4500e+00   3.2409e-01
   1.4750e+00   3.1582e-01
   1.5000e+00   3.0769e-01
   1.5250e+00   2.9974e-01
   1.5500e+00   2.9196e-01
   1.5750e+00   2.8438e-01
   1.6000e+00   2.7702e-01
   1.6250e+00   2.6990e-01
   1.6500e+00   2.6303e-01
   1.6750e+00   2.5643e-01
   1.7000e+00   2.5012e-01
   1.7250e+00   2.4412e-01
   1.7500e+00   2.3845e-01
   1.7750e+00   2.3310e-01
   1.8000e+00   2.2810e-01
   1.8250e+00   2.2344e-01
   1.8500e+00   2.1913e-01
   1.8750e+00   2.1516e-01
   1.9000e+00   2.1153e-01
   1.9250e+00   2.0822e-01
   1.9500e+00   2.0521e-01
   1.9750e+00   2.0248e-01
   2.0000e+00   2.0000e-01
   2.0250e+00   1.9774e-01
   2.0500e+00   1.9565e-01
   2.0750e+00   1.9370e-01
   2.1000e+00   1.9184e-01
   2.1250e+00   1.9002e-01
   2.1500e+00   1.8819e-01
   2.1750e+00   1.8630e-01
   2.2000e+00   1.8430e-01
   2.2250e+00   1.8214e-01
   2.2500e+00   1.7976e-01
   2.2750e+00   1.7713e-01
   2.3000e+00   1.7421e-01
   2.3250e+00   1.7096e-01
   2.3500e+00   1.6735e-01
   2.3750e+00   1.6337e-01
   2.4000e+00   1.5901e-01
   2.4250e+00   1.5426e-01
   2.4500e+00   1.4915e-01
   2.4750e+00   1.4369e-01
   2.5000e+00   1.3793e-01
   2.5250e+00   1.3192e-01
   2.5500e+00   1.2571e-01
   2.5750e+00   1.1939e-01
   2.6000e+00   1.1305e-01
   2.6250e+00   1.0678e-01
   2.6500e+00   1.0070e-01
   2.6750e+00   9.4916e-02
   2.7000e+00   8.9564e-02
   2.7250e+00   8.4769e-02
   2.7500e+00   8.0660e-02
   2.7750e+00   7.7366e-02
   2.8000e+00   7.5011e-02
   2.8250e+00   7.3709e-02
   2.8500e+00   7.3561e-02
   2.8750e+00   7.4653e-02
   2.9000e+00   7.7050e-02
   2.9250e+00   8.0790e-02
   2.9500e+00   8.5883e-02
   2.9750e+00   9.2306e-02
   3.0000e+00   1.0000e-01
   3.0250e+00   1.0886e-01
   3.0500e+00   1.1875e-01
   3.0750e+00   1.2948e-01
   3.1000e+00   1.4080e-01
   3.1250e+00   1.5245e-01
   3.1500e+00   1.6408e-01
   3.1750e+00   1.7533e-01
   3.2000e+00   1.8578e-01
   3.2250e+00   1.9497e-01
   3.2500e+00   2.0242e-01
   3.2750e+00   2.0764e-01
   3.3000e+00   2.1009e-01
   3.3250e+00   2.0927e-01
   3.3500e+00   2.0467e-01
   3.3750e+00   1.9582e-01
   3.4000e+00   1.8228e-01
   3.4250e+00   1.6370e-01
   3.4500e+00   1.3979e-01
   3.4750e+00   1.1040e-01
   3.5000e+00   7.5472e-02
   3.5250e+00   3.5135e-02
   3.5500e+00  -1.0316e-02
   3.5750e+00  -6.0384e-02
   3.6000e+00  -1.1435e-01
   3.6250e+00  -1.7124e-01
   3.6500e+00  -2.2984e-01
   3.6750e+00  -2.8865e-01
   3.7000e+00  -3.4588e-01
   3.7250e+00  -3.9946e-01
   3.7500e+00  -4.4705e-01
   3.7750e+00  -4.8603e-01
   3.8000e+00  -5.1355e-01
   3.8250e+00  -5.2655e-01
   3.8500e+00  -5.2181e-01
   3.8750e+00  -4.9602e-01
   3.9000e+00  -4.4587e-01
   3.9250e+00  -3.6813e-01
   3.9500e+00  -2.5980e-01
   3.9750e+00  -1.1819e-01
   4.0000e+00   5.8824e-02
   4.0250e+00   2.7272e-01
   4.0500e+00   5.2404e-01
   4.0750e+00   8.1222e-01
   4.1000e+00   1.1353e+00
   4.1250e+00   1.4897e+00
   4.1500e+00   1.8699e+00
   4.1750e+00   2.2682e+00
   4.2000e+00   2.6744e+00
   4.2250e+00   3.0753e+00
   4.2500e+00   3.4550e+00
   4.2750e+00   3.7939e+00
   4.3000e+00   4.0691e+00
   4.3250e+00   4.2541e+00
   4.3500e+00   4.3183e+00
   4.3750e+00   4.2278e+00
   4.4000e+00   3.9451e+00
   4.4250e+00   3.4294e+00
   4.4500e+00   2.6378e+00
   4.4750e+00   1.5254e+00
   4.5000e+00   4.7059e-02
   4.5250e+00  -1.8410e+00
   4.5500e+00  -4.1792e+00
   4.5750e+00  -7.0021e+00
   4.6000e+00  -1.0335e+01
   4.6250e+00  -1.4188e+01
   4.6500e+00  -1.8554e+01
   4.6750e+00  -2.3401e+01
   4.7000e+00  -2.8663e+01
   4.7250e+00  -3.4233e+01
   4.7500e+00  -3.9952e+01
   4.7750e+00  -4.5597e+01
   4.8000e+00  -5.0864e+01
   4.8250e+00  -5.5353e+01
   4.8500e+00  -5.8545e+01
   4.8750e+00  -5.9782e+01
   4.9000e+00  -5.8238e+01
   4.9250e+00  -5.2888e+01
   4.9500e+00  -4.2471e+01
   4.9750e+00  -2.5449e+01
   5.0000e+00   3.8462e-02
};
\addplot[
    color=blue,
    thick,
    only marks,
    mark=o,
]
table{
  -5.0000e+00   3.8462e-02
  -4.5000e+00   4.7059e-02
  -4.0000e+00   5.8824e-02
  -3.5000e+00   7.5472e-02
  -3.0000e+00   1.0000e-01
  -2.5000e+00   1.3793e-01
  -2.0000e+00   2.0000e-01
  -1.5000e+00   3.0769e-01
  -1.0000e+00   5.0000e-01
  -5.0000e-01   8.0000e-01
            0   1.0000e+00
   5.0000e-01   8.0000e-01
   1.0000e+00   5.0000e-01
   1.5000e+00   3.0769e-01
   2.0000e+00   2.0000e-01
   2.5000e+00   1.3793e-01
   3.0000e+00   1.0000e-01
   3.5000e+00   7.5472e-02
   4.0000e+00   5.8824e-02
   4.5000e+00   4.7059e-02
   5.0000e+00   3.8462e-02
};

\end{axis}
\end{tikzpicture}
\end{center}
Questo non è il comportamento che ci aspettiamo da una funzione ``semplice'' che passi per i punti marcati in blu!

% In molti casi, approssimare i dati utilizzando un polinomio di grado basso che passa \emph{vicino}, ma non esattamente per i punti dati (come vedremo più avanti) fornisce risultati graficamente migliori che non un polinomio di interpolazione.

\paragraph{Polinomi di Lagrange}

Possiamo dare una formula esplicita per la soluzione del problema dell'interpolazione polinomiale. Fissati i nodi distinti $x_0,x_1,\dots,x_d$, definiamo i \emph{polinomi di Lagrange}
\[
L_k(x) = \frac{\prod_{j\neq k}(x - x_j)}{\prod_{j\neq k}(x_k - x_j)}, \quad k=1,2,\dots,d.
\]
Ad esempio, se i nodi sono $x_0 = 1, x_1 = 2, x_2 = 4$, abbiamo
\[
L_0(x) = \frac{(x-2)(x-4)}{(1-2)(1-4)}, \quad L_1(x) = \frac{(x-1)(x-4)}{(2-1)(2-4)}, \quad L_2(x) = \frac{(x-1)(x-2)}{(4-1)(4-2)}.
\]
Notare che il denominatore non si annulla mai se i nodi sono distinti, e che sono tutti polinomi di grado $d$, visto che il numeratore è il prodotto di $d$ fattori di grado $1$. Inoltre, vale il seguente risultato.
\begin{lemma} \label{lem:polylagrange}
Si ha
\[
L_k(x_i) = \begin{cases}
1 & i=k,\\
0 & \text{altrimenti}.
\end{cases}
\]
\end{lemma}
\begin{proof}
Sostituendo $x = x_k$, numeratore e denominatore diventano identici, quindi il polinomio vale $1$. Sostituendo $x = x_i$ con $i\neq k$, uno dei fattori nella produttoria al numeratore diventa $(x_i-x_i)$, quindi $L_k(x_i) = 0$.
\end{proof}
Quindi il $k$-esimo polinomio di Lagrange fornisce la soluzione al problema di interpolazione con $\mathbf{y} = \e_k$ ($k$-esimo vettore della base canonica). Facendo una combinazione lineare di queste soluzioni, possiamo ottenere la soluzione a un problema di interpolazione polinomiale con un vettore $\mathbf{y}$ generico.
\begin{theorem}
Siano $(x_0,y_0),\dots,(x_d,y_d)$ dati. La soluzione del problema di interpolazione polinomiale (cioè l'unico polinomio $p$ di grado $\leq d$ tale che $p(x_i)=y_i$ per ogni $i=0,1,\dots,d$) è data da
\[
p(x) = \sum_{k=0}^d y_k L_k(x).
\]
\end{theorem}
\begin{proof}
Sappiamo già che la soluzione del problema è unica. Basta verificare che $p(x_i) = y_i$ per ogni $i$ (cosa che segue dal Lemma~\ref{lem:polylagrange}) e che $p(x)$ ha grado minore o uguale a $d$ (perché è una combinazione lineare dei polinomi di Lagrange, che hanno tutti grado $d$). 
\end{proof}

%%% TODO: inserire un esempio %%%

\paragraph{Resto dell'interpolazione}
In alcuni casi, sappiamo che i punti da interpolare $(x_i,y_i)$ appartengono esattamente al grafico di una certa funzione $f$, cioè, $y_i = f(x_i)$ per ogni $i=0,\dots,d$. Si parla in questo caso di ``polinomio di interpolazione della funzione $f$''. Questa $f$ tipicamente non è un polinomio, ma potrebbe essere una funzione definita da una formula più complicata. Ha senso quindi cercare di ``rimpiazzarla'' con un polinomio più semplice, se possiamo assicurarci che l'errore commesso nell'interpolazione è piccolo. Il risultato seguente ci dà un modo di stimare questo errore, in funzione delle derivate della funzione $f$.
\begin{theorem}[Resto dell'interpolazione]
Sia $f\in \mathcal{C}^{d+1}([a,b])$, $x_0,x_1,\dots,x_d$ nodi distinti in $[a,b]$, e $p(x)$ il polinomio di interpolazione (di grado al più $d$) di $f$ sui nodi dati. Allora per ogni $x\in [a,b]$ esiste un punto $\xi \in (a,b)$ tale che
\begin{equation} \label{resto dell'interpolazione}
    f(x) - p(x) = \frac{f^{(d+1)}(\xi)}{(d+1)!} (x-x_0)(x-x_1) \dots (x-x_d).    
\end{equation}
\end{theorem}
Non lo dimostriamo ma facciamo qualche commento.
\begin{itemize}
    \item Questo risultato assomiglia a uno sviluppo di Taylor con resto di Lagrange: abbiamo che $f(x)$ è uguale a un polinomio $p(x)$ (che arriva ad avere potenze fino al grado $d$) più un resto che dipende dalla derivata $d+1$-esima. Qui abbiamo $d+1$ punti, anziché un ``centro'' solo dello sviluppo di Taylor, e nella formula per il resto $\frac{f^{(d+1)}(\xi)}{(d+1)!}(x-x_0)^{d+1}$, il termine $(x-x_0)^{d+1}$ viene rimpiazzato da $\prod_{j=0}^d (x-x_i)$. (Questo è un ottimo modo per ricordarsi la formula.)
    \item Non ci stupisce che ci siano dei fattori $(x-x_i)$ nel membro di destra: difatti, se sostituiamo $x=x_i$, per un qualche $i=0,1,\dots,d$, il termine di sinistra si annulla, quindi deve annullarsi anche quello di destra.
    \item Un caso speciale in cui possiamo verificare il risultato direttamente è quello in cui $f(x)$ è essa stessa un polinomio di grado minore o uguale a $d$. In questo caso il polinomio di interpolazione coincide con $f(x)$ stessa, quindi il termine di sinistra è nullo per ogni $x$; e anche il termine di destra si annulla perché per un polinomio di grado al più $d$ abbiamo $f^{(d+1)} \equiv 0$.
\end{itemize}






\paragraph{Errore dell'interpolazione} Dal teorema del resto dell'interpolazione segue una stima per l'errore massimo (differenza tra $f(x)$ e $p(x)$), cioè
\[
\abs{f(x) - p(x)} \leq \frac{C_{d+1}}{(d+1)!}(b-a)^{d+1},
\]
dove $C_{d+1} = \max_{x\in [a,b]} \abs{f^{(d+1)}(x)}$.

%% TODO: esempio
\section{Altri problemi di interpolazione e approssimazione}

\paragraph{Approssimazione / fit} Come abbiamo visto, quando il grado $d$ è alto, il polinomio di interpolazione può avere forti oscillazioni, e la matrice di Vandermonde $V$ può essere mal condizionata. In molti casi, anche se abbiamo tanti punti $(x_0,y_0), \dots, (x_m,y_m)$, conviene fissare un grado $d<m$ e prendere il polinomio di grado minore o uguale a $d$ che più si avvicina ai punti dati. Questo corrisponde a risolvere un sistema lineare sovradeterminato nel senso dei minimi quadrati: difatti, si ha
\begin{align*}
&\min_{\alpha \in \mathbb{R}^{d+1}} \, \abs{p(x_0)-y_0}^2 + \abs{p(x_1)-y_1}^2 + \dots + \abs{p(x_m)-y_m}^2\\
&= 
\min_{\alpha \in \mathbb{R}^{d+1}}\, \norm*{\begin{bmatrix}
    1 & x_0 & x_0^2 & \dots & x_0^d\\
    1 & x_1 & x_1^2 & \dots & x_1^d\\
    1 & x_2 & x_2^2 & \dots & x_2^d\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    1 & x_m & x_m^2 & \dots & x_m^d\\
\end{bmatrix}
\begin{bmatrix}
    \alpha_0\\
    \alpha_1\\
    \alpha_2\\
    \vdots\\
    \alpha_d
\end{bmatrix} - \begin{bmatrix}
    y_0\\
    y_1\\
    y_2\\
    \vdots\\
    y_m
\end{bmatrix}
}_2^2.    
\end{align*}
Vediamo in figura un esempio con quattro punti e un polinomio di grado $d=1$. La retta non passa esattamente per i punti dati, ma vicino ad essi, in modo da minimizzare (al variare di tutte le possibili rette) la somma dei segmenti verticali disegnati in verde, i residui.
\begin{center}
\begin{tikzpicture}[scale=1.1]
  % Axes
  \draw[->] (-0.5,0) -- (4.5,0) node[right] {$x$};
  \draw[->] (0,-0.5) -- (0,4.5) node[above] {$y$};

  % Data points
  \fill[blue] (0,1.3) circle (2pt);
  \fill[blue] (1,1.7) circle (2pt);
  \fill[blue] (2,3.4) circle (2pt);
  \fill[blue] (3,4.2) circle (2pt);

  \node[anchor=south east] at (0,1.3) {$(x_1,\,y_1)$};
  \node[anchor=north west] at (1,1.7) {$(x_2,\,y_2)$};
  \node[anchor=south east] at (2,3.4) {$(x_3,\,y_3)$};
  \node[anchor=south east] at (3,4.2) {$(x_4,\,y_4)$};

  % Best-fit line (approximate linear regression)
  % Example: y = 1.0 + 1.0x
  \draw[thick,red,domain=0:3.5,samples=2] plot(\x,{1 + 1.0*\x});
  % \node[red,anchor=west] at (3.6,4.2) {$y = a + bx$};

  % Vertical residuals (distances between points and the line)
  \foreach \x/\y in {0/1.3, 1/1.7, 2/3.4, 3/4.2} {
    \draw[very thick,green!50!black] (\x,\y) -- (\x,{1 + 1.0*\x});
  }

  % Small labels for residuals
%   \foreach \x/\y/\i in {0/1/1, 1/1.8/2, 2/3.4/3, 3/4/4} {
%     \node[gray,anchor=west] at (\x+0.05,{(\y + (1 + 1.0*\x))/2}) {$r_{\i}$};
%   }

  % Legend
  \draw[blue,fill=blue] (5.7,3.2) circle (2pt);
  \node[right] at (5.8,3.2) {Valori osservati};
  \draw[thick,red] (5.7,2.9) -- (6.1,2.9);
  \node[right] at (6.1,2.9) {Retta di regressione};
  \draw[very thick,green!50!black] (5.7,2.6) -- (6.1,2.6);
  \node[right] at (6.1,2.6) {Residui};
\end{tikzpicture}
\end{center}
Questo problema si chiama \emph{approssimazione} di funzioni, o, dall'inglese, \emph{fitting}.  Il problema risultante è un problema ai minimi quadrati, e si può risolvere con gli algoritmi che abbiamo già visto: equazioni normali, fattorizzazione QR, funzione ``backslash'' di Matlab.

\paragraph{Retta dei minimi quadrati} Vediamo come esempio il caso particolare $d=1$, in cui il polinomio è una retta, detta a volte \emph{retta dei minimi quadrati} o \emph{retta di regressione}. A differenza del problema dell'interpolazione, i punti sono più di due, quindi non esiste una retta che passa esattamente per tutti questi punti. Abbiamo
\[
X = \begin{bmatrix}
    1 & x_0\\
    1 & x_1\\
    1 & x_2\\
    \vdots & \vdots\\
    1 & x_m
\end{bmatrix}, \quad \mathbf{y} = \begin{bmatrix}
y_0\\
y_1\\
y_2\\
\vdots\\
y_m
\end{bmatrix}, \quad \boldsymbol{\alpha} = \begin{bmatrix}
\alpha_1\\
\alpha_2
\end{bmatrix} = (X^TX)^{-1} X^T \mathbf{y},
\]
dove l'ultima formula corrisponde ad usare le equazioni normali per risolvere questo problema. Possiamo ottenere una formula più esplicita espandendo i conti e usando la formula per l'inversa di una matrice $2\times 2$. Potreste aver visto queste formule se avete già incontrato la retta di regressione lineare in altri corsi, per esempio parlando di statistica; per noi rifare questo conto non è particolarmente interessante.

%%% TODO: inserire un esempio %%%

\paragraph{Approfondimento: interpolazione con funzioni più generali} Quello dell'interpolazione polinomiale è un problema apparentemente non-lineare, ma che sorprendentemente si riduce a un sistema di equazioni lineari: anche se nella formulazione del problema compaiono polinomi di grado più alto di 1, la dipendenza dai coefficienti incogniti $\alpha_0,\dots, \alpha_d$ è lineare. 

Possiamo risolvere nello stesso modo anche un problema più generale: fissiamo $n$ funzioni $\phi_1(x), \dots, \phi_n(x)$, e cerchiamo coefficienti incogniti $\alpha_1,\dots,\alpha_n$ in modo da ottenere una funzione
\begin{equation} \label{phi}
    \phi(x) = \alpha_1 \phi_1(x) + \alpha_2 \phi_2(x) + \dots + \alpha_n \phi_n(x)    
\end{equation}
che passi per certi punti.

Più nel dettaglio, supponiamo di avere $m$ coppie di valori $(x_1,y_1), \dots, (x_m,y_m)$. Di nuovo, assumiamo che gli $x_i$ siano \emph{distinti}.

Se imponiamo le condizioni $\phi(x_i) = y_i$ per $i=1,2,\dots, m$, abbiamo il sistema lineare di $m$ equazioni in $n$ incognite
\[
\underbrace{
\begin{bmatrix}
    \phi_1(x_1) & \phi_2(x_1) & \dots & \phi_n(x_1)\\
    \phi_1(x_2) & \phi_2(x_2) & \dots & \phi_n(x_2)\\
    \vdots & \vdots & \ddots & \vdots\\
    \phi_1(x_m) & \phi_2(x_m) & \dots & \phi_n(x_m)
\end{bmatrix}}_{=X}
\underbrace{\begin{bmatrix}
    \alpha_1\\ \alpha_2 \\ \vdots \\ \alpha_n
\end{bmatrix}
}_{=\boldsymbol{\alpha}}
= \underbrace{\begin{bmatrix}
    y_1\\ y_2 \\ \vdots \\ y_m
\end{bmatrix}}_{=\mathbf{y}}.
\]
Se $m=n$, cioè se ho tanti punti quante funzioni incognite, questo è un sistema lineare quadrato e posso risolverlo esattamente (ammesso che la matrice $X$ sia invertibile) (\emph{interpolazione}). Se $m>n$, allora ho un sistema con più equazioni che incognite, e posso risolverlo nel senso dei minimi quadrati (\emph{approssimazione/fit}), calcolando $\min \norm{X\boldsymbol{\alpha}-\mathbf{y}}$. Vediamo un esempio.

\paragraph{Polinomi trigonometrici} Se desideriamo interpolare (o approssimare) una funzione che sappiamo essere periodica di periodo $2\pi$, viene naturale scegliere una base composta di funzioni che sono anch'esse periodiche, per esempio
\begin{align*}
\phi_1(x) &= 1,\\
\phi_2(x) &= \sin x, & \phi_3(x) &= \cos x,\\
\phi_4(x) &= \sin 2x, & \phi_5(x) &= \cos 2x,\\
\vdots & & \vdots &\\
\phi_{2k}(x) &= \sin kx, & \phi_{2k+1}(x) &= \cos kx.
\end{align*}
Queste sono, in un certo senso, le funzioni periodiche ``più semplici'' di periodo $2\pi$. Non vediamo i dettagli qui, ma è un approccio molto usato, e collegato alla cosiddetta \emph{trasformata di Fourier}, che forse avrete occasione di incontrare in futuro in altri corsi.

\begin{conditional}[ich]
    
\chapter{Integrazione numerica}
In questo capitolo consideriamo il problema di approssimare numericamente l'integrale di una funzione, $I = \int_a^b f(x) dx$. Questo problema si chiama \emph{integrazione numerica}, o \emph{quadratura}.

Sappiamo dall'analisi che il problema di calcolare il valore di un integrale è un problema difficile: a differenza delle derivate, non ci sono delle formule da applicare meccanicamente ma soltanto una serie di tecniche che a volte funzionano e a volte no. Per questo diventa prezioso avere dei metodi numerici per approssimare la soluzione.

Le formule che vedremo sono tutte del tipo
\[
I \approx \sum_{i=1}^n w_i f(x_i) = w_1 f(x_1) + w_2 f(x_2) + \dots + w_n f(x_n),
\]
dove $w_i$ sono detti \emph{pesi} e $x_i$ \emph{nodi} della formula, e sono scelti indipendentemente da $f$ (ma tipicamente dipendono dall'intervallo $[a,b]$).

Il costo computazionale di applicare una formula di quadratura con $n$ pesi e nodi è di $n$ valutazioni della funzione $f$, più poche altre operazioni ($2n-1$ per la precisione). Poiché il calcolo della funzione $f$ richiede un numero variabile di operazioni (e potenzialmente molto grande), esprimiamo il costo computazionale in termini di qaunte volte va valutata la funzione, esattamente come abbiamo fatto in passato per gli algoritmi per risolvere equazioni non lineari.

\paragraph{Suddivisione di un intervallo in sottointervalli uguali} Un'operazione che ci servirà fare diverse volte nel seguito sarà quella di suddividere un intervallo $[a,b]$ in un certo numero di sottointervalli uguali. Vediamo qui delle formule che permettono di dare un'espressione per i punti risultanti. Per aiutarci, mostriamo un esempio con $n=5$ sottointervalli.
\begin{center}
    \begin{tikzpicture}
    % Define points a and b
    \coordinate (a) at (0,0);
    \coordinate (b) at (10,0);

    % Draw the main segment a..b
    \draw[thick] (a) -- (b);
    
    % Number of subdivisions

    \def\d{5}

    % Calculate the length of each subdivision
    \pgfmathsetmacro{\subdivLength}{10/\d}

    % Draw the subdivisions
    \foreach \i in {1,...,\numexpr\d-1\relax}
    {
        \coordinate (subdiv\i) at (\i*\subdivLength,0);
        \fill (subdiv\i) circle (2pt);
        \node[below] at (subdiv\i) {$x_{\i}$};    
    }
    \fill (a) circle (2pt);
    \fill (b) circle (2pt);
    % Label the points a and b
    \node[below] at (a) {$a=x_0$};
    \node[below] at (b) {$b=x_5$};
\end{tikzpicture}
\end{center}

La prima osservazione è che quando suddividiamo un intervallo $[a,b]$ in $n$ sottointervalli uguali (con $n$ intero positivo), ogni sottointervallo è lungo $h = \frac{b-a}{n}$, cioè $\frac{1}{n}$ della lunghezza dell'intervallo di partenza. La seconda osservazione è che $n$ sottointervalli determinano $n+1$ punti (attenzione, non $n$) che sono i loro estremi; possiamo chiamarli $x_0, x_1,\dots, x_n$, partendo da $0$. Questi punti sono \emph{equispaziati}, cioè alla stessa distanza l'uno dall'altro. Più precisamente, ogni punto sta a una distanza $h$ da quello precedente, quindi abbiamo
\[
    x_0=a,\, x_1=a+h,\, x_2 = a+2h,\, \dots, \,x_n = a+nh = a + n\frac{b-a}{n} = b.
\]
o genericamente
\[
    x_k = a + kh, \quad k=0,1,2,\dots,n.
\]

\section{Metodi classici}

\paragraph{Somme di Riemann}
Nel definire l'integrale, probabilmente avete usato una strategia basata sul rimpiazzare l'area sotto la funzione con una somma di rettangoli, come nell'esempio seguente.
\begin{center}
\begin{tikzpicture}
  % Define nonlinear function
  \def\func{0.5*x^2 + 1}
  \def\nrect{12} % number of rectangles
  \def\xmin{0}
  \def\xmax{4}
  \def\deltax{(\xmax-\xmin)/\nrect}

  % Axis
  \begin{axis}[
    domain=0:4,
    samples=100,
    axis lines=middle,
    ymin=0, ymax=10,
    xmin=0, xmax=4.3,
    xtick={},
    ytick={},
    width=10cm,
    height=6cm,
    legend style={at={(0.98,0.98)},anchor=north east}
  ]
    % Plot the nonlinear function
    \addplot[thick,blue,domain=\xmin:\xmax] {\func};

    % Draw left Riemann rectangles
    \foreach \i in {0,...,11} {
      \pgfmathsetmacro{\xi}{\xmin + \i*\deltax}
      \pgfmathsetmacro{\width}{\deltax}
      \pgfmathsetmacro{\height}{0.5*\xi*\xi + 1}
      \addplot [
        fill=red!10,
        draw=red!80!black,
        area legend
      ] coordinates {(\xi,0) (\xi,\height) (\xi+\width,\height) (\xi+\width,0)} -- cycle;
    }

    % Add points for left endpoints
    \foreach \i in {0,...,11} {
      \pgfmathsetmacro{\xi}{\xmin + \i*\deltax}
      \pgfmathsetmacro{\yi}{0.5*\xi*\xi + 1}
      \addplot[only marks,mark=*,color=red] coordinates {(\xi,\yi)};
    }
  \end{axis}
\end{tikzpicture}
\end{center}
Nel dettaglio, suddividiamo l'intervallo $[a,b]$ in $n$ intervalli uguali, come descritto sopra; poi calcoliamo le aree dei rettangoli: il $k$-esimo rettangolo ha base $[x_{k},x_{k+1}]$, quindi con lunghezza $x_{k+1}-x_k=h$, e altezza $f(x_k)$: abbiamo scelto di prendere come altezza il valore della funzione nel punto a \emph{sinistra} dell'intervallo. Questo dobbiamo farlo per $k=0,1,2,\dots,n-1$, in modo che il primo intervallo sia $[x_0,x_1]$ e l'ultimo $[x_{n-1},x_n]$; la formula che dà la somma delle loro aree quindi è
\[
\tilde{I}_{L,n} = \sum_{k=0}^{n-1} hf(x_k) = \frac{b-a}{n} \biggl( f(x_0) + f(x_1) + \dots + f(x_{n-1}) \biggr).
\]
La somma contiene il valore della funzione su $n$ degli $n+1$ punti della suddivisione, tutti tranne l'ultimo.

Possiamo definire questa approssimazione dell'integrale anche quando $f(x)$ assume valori negativi, anche se la nostra intuizione basata sul disegno è meno chiara: sarebbe necessario parlare in qualche modo di rettangoli con area negativa\dots

Abbiamo usato l'indice $L$ per sinistra, dall'inglese \emph{left}. Analogamente possiamo definire un'approssimazione prendendo le somme sull'estremo destro di ogni rettangolo, 
\[
\tilde{I}_{R,n} = \sum_{k=0}^{n-1} hf(x_{k+1}) = \frac{b-a}{n} \biggl( f(x_1) + f(x_2) + \dots + f(x_{n}) \biggr).
\]

Un esempio semplice: consideriamo la funzione $f(x)=x^2$, e approssimiamo il suo integrale su $[0,1]$, suddividendo l'intervallo in $n=5$ sottointervalli uguali. Si ha $h=1/5$,
\[
x_0 = 0, \quad x_1 = 0.2, \quad x_2=0.4,\quad x_3=0.6,\quad x_4 = 0.8,\quad x_5=1
\]
e
\begin{align*}
    \tilde{I}_{L,5} &= h (x_0^2+x_1^2+x_2^2+x_3^2+x_4^2) = \frac{1}{5}\left(0^2+0.2^2+0.4^2+0.6^2+0.8^2\right) = 0.24,\\
    \tilde{I}_{R,5} &= h (x_1^2+x_2^2+x_3^2+x_4^2+x_5^2) = \frac{1}{5}\left(0.2^2+0.4^2+0.6^2+0.8^2+1^2\right) = 0.44.\\
\end{align*}
Queste non sono approssimazioni particolarmente accurate del valore esatto $I=\frac{1}{3}$, perché il numero di punti che abbiamo usato è molto basso. Però al crescere di $n$ l'errore scende. Possiamo dimostrare questo fatto.
\paragraph{Errore delle somme di Riemann}
\begin{theorem}
Sia $f$ una funzione di classe $\mathcal{C}^1$ su $[a,b]$, e definiamo $C_1 = \max_{x\in [a,b]} \abs{f'(x)}$. Allora,
\begin{equation} \label{Riemann sum error}
    \abs{I - \tilde{I}_{L,n}} \leq \frac{1}{2} (b-a) C_1 h
\end{equation}
\end{theorem}
\begin{proof}
    Riduciamo il problema a un singolo sottointervallo della nostra suddivisione. Per questo scriviamo l'integrale di $f$ come somma sui sottointervalli:
    \[
    I = \int_a^b f(x)\, dx = \sum_{k=0}^{n-1} \int_{x_k}^{x_{k+1}}f(x)\, dx.
    \]
    Per ogni sottointervallo vogliamo valutare l'errore $\int_{x_k}^{x_{k+1}}f(x)\, dx - f(x_k)(x_{k+1}-x_k)$. Usiamo uno sviluppo di Taylor di ordine 1 centrato in $x_k$:
    \begin{align*}
    \int_{x_k}^{x_{k+1}}f(x)\, dx &= \int_{x_k}^{x_{k+1}} \biggl(f(x_k) + f'(\xi_k)(x - x_k) \biggr)\, dx\\
    &= \underbrace{\int_{x_k}^{x_{k+1}} f(x_k) \, dx}_{=f(x_k)(x_{k+1}-x_k)} + \underbrace{\int_{x_k}^{x_{k+1}}f'(\xi_k)(x - x_k)\, dx}_{=R_k}.
    \end{align*}
    Il primo addendo è l'integrale di una funzione costante, ed è proprio l'area del rettangolo. Per il secondo, che abbiamo chiamato $R_k$ (da ``resto''), abbiamo
    \begin{align*}
        \abs{R_k} &= \abs*{\int_{x_k}^{x_{k+1}}f'(\xi_k)(x - x_k)\, dx}\\
        & \leq \int_{x_k}^{x_{k+1}}\abs{f'(\xi_k)(x - x_k)}\, dx\\
        & \leq \int_{x_k}^{x_{k+1}} C_1 (x - x_k)\, dx\\
        &= C_1\frac{1}{2}(x-x_k)^2\bigg|_{x_k}^{x_{k+1}} = \frac{C_1}{2} h^2.
    \end{align*}
    In questo calcolo abbiamo tolto il valore assoluto da $\abs{x-x_k}$, poiché questa espressione è maggiore o uguale a zero per ogni punto dell'intervallo $[x_k,x_{k+1}]$.

    Ora possiamo sommare gli errori su tutti i sottointervalli:
    \begin{align*}
        \abs{I - \tilde{I}_{L,n}} &= \abs*{\sum_{k=0}^{n-1} \int_{x_k}^{x_{k+1}}f(x)\, dx - f(x_k)(x_{k+1}-x_k)}\\
        & \leq \sum_{k=0}^{n-1} \abs{R_k}\\
        & \leq n \cdot \frac{C_1}{2} h^2,
    \end{align*}
    e ricordando che $h = \frac{b-a}{n}$ vediamo che questa espressione è uguale a quella nel testo del teorema.
\end{proof}
Per le somme destre $\tilde{I}_{R,n}$ vale la stessa disuguaglianza, che si dimostra in modo analogo.

Ci può venire qualche dubbio che la funzione $f'(\xi_k)(x - x_k)$ sia integrabile, visto che i teoremi sullo sviluppo di Taylor non ci dicono nulla su come è scelto $\xi_k$, ma possiamo notare che $f'(\xi_k)(x - x_k) = f(x) - f(x_k)$, e la funzione a destra dell'uguale è sicuramente continua in $x$.

La formula~\eqref{Riemann sum error} ci dice che quando usiamo valori più grandi di $n$ abbiamo valori di $h$ più piccoli, e $\tilde{I}_{L,n}$ converge al valore esstto dell'integrale $I$ quando $n\to \infty$. L'errore è proporzionale a $h$, quindi possiamo scriverlo cone $\mathcal{O}(h)$. Vediamo ora che una piccola modifica al metodo ci permette di ottenere una convergenza più veloce (e quindi un errore più piccolo).

\paragraph{Formula del punto medio}
In questo metodo, invece di prendere come altezza del rettangolo il valore della funzione nell'estremo sinistro o destro dell'intervallo, usiamo il valore nel punto medio:
\begin{equation} \label{formula del punto medio}
    \int_{x_k}^{x_{k+1}} f(x) \, dx \approx \underbrace{(x_{k+1}-x_k)}_{=h} f\left(\frac{x_k + x_{k+1}}{2}\right).    
\end{equation}
\begin{center}
\begin{tikzpicture}
    % Draw axes
    \draw[->] (-0.5,0) -- (5.5,0);
    \draw[->] (0,-0.5) -- (0,4);

    \draw[draw=red!80!black, fill=red!10] (1,0) -- (4,0) -- (4,3.0625) -- (1,3.0625) -- cycle;

    \draw[domain=1:4,smooth,variable=\x,blue,thick] plot ({\x},{3/2*\x*\x*\x - 23/2*\x*\x + 27*\x -16});
    
    % \fill [blue, opacity=0.2, domain=1:4, smooth, variable=\x]
    %   (1, 0)
    %   -- plot ({\x},{3/2*\x*\x*\x - 23/2*\x*\x + 27*\x -16})
    %   -- (4, 0)
    %   -- cycle;
    
    \node at (1,-0.3) {$x_k$};
    \node at (4,-0.3) {$x_{k+1}$};
    \node at (2.5,-0.3) {$\frac{x_k + x_{k+1}}{2}$};
%    \node at (\midpoint,0) {$c$};
    \fill[red] (2.5,3.0625) circle (2pt);
\end{tikzpicture}
\end{center}

Quindi, quando sommiamo su tutti gli intervalli $[x_k,x_{k+1}]$, otteniamo
\begin{align*}
\tilde{I}_{M,n} &= \sum_{k=0}^{n-1} (x_{k+1}-x_k) f\left(\frac{x_k + x_{k+1}}{2}\right) \\
&= h \left(f\left(\frac{x_0 + x_{1}}{2}\right) + f\left(\frac{x_1 + x_{2}}{2}\right) + \dots + f\left(\frac{x_{n-1} + x_{n}}{2}\right)\right).
\end{align*}

\begin{tikzpicture}
  % Define nonlinear function
  \def\func{0.5*x^2 + 1}
  \def\nrect{12} % number of rectangles
  \def\xmin{0}
  \def\xmax{4}
  \def\deltax{(\xmax-\xmin)/\nrect}

  % Axis
  \begin{axis}[
    domain=0:4,
    samples=100,
    axis lines=middle,
    ymin=0, ymax=10,
    xmin=0, xmax=4.3,
    xtick={},
    ytick={},
    width=10cm,
    height=6cm,
    legend style={at={(0.98,0.98)},anchor=north east}
  ]

    % Draw midpoint rectangles
    \foreach \i in {0,...,11} {
      \pgfmathsetmacro{\xi}{\xmin + \i*\deltax}
      \pgfmathsetmacro{\xmid}{\xi + 0.5*\deltax}
      \pgfmathsetmacro{\width}{\deltax}
      \pgfmathsetmacro{\height}{0.5*\xmid*\xmid + 1}
      \addplot [
        fill=red!10,
        draw=red!80!black,
        area legend
      ] coordinates {(\xi,0) (\xi,\height) (\xi+\width,\height) (\xi+\width,0)} -- cycle;
    }
    % Plot the nonlinear function
    \addplot[thick,blue,domain=\xmin:\xmax] {\func};

    % Add points for midpoints
    \foreach \i in {0,...,11} {
      \pgfmathsetmacro{\xi}{\xmin + \i*\deltax}
      \pgfmathsetmacro{\xmid}{\xi + 0.5*\deltax}
      \pgfmathsetmacro{\yi}{0.5*\xmid*\xmid + 1}
      \addplot[only marks,mark=*,color=red] coordinates {(\xmid,\yi)};
    }
  \end{axis}
\end{tikzpicture}



Riprendiamo l'esempio di sopra: approssimiamo l'integrale $I = \int_0^1 x^2\, dx$ con $n=5$ punti, e otteniamo
\[
I_{M,5} = \frac{1}{5}\left(0.1^2+0.3^2+0.5^2+0.7^2+0.9^2\right) = 0.33,
\]
che è un'approssimazione dell'integrale esatto $I=\frac{1}{3}$ molto migliore di quelle trovate in precedenza.

\paragraph{Errore della formula del punto medio}
\begin{theorem} \label{thm: errore metodo punto medio}
    Sia $f$ una funzione di classe $\mathcal{C}^2$ su $[a,b]$, e definiamo $C_2 = \max_{x\in [a,b]} \abs{f''(x)}$. Allora,
    \begin{equation} \label{midpoint method error}
        \abs{I - \tilde{I}_{M,n}} \leq \frac{1}{24} (b-a) C_2 h^2.
    \end{equation}
\end{theorem}
\begin{proof}
    Come nella dimostrazione precedente, consideriamo l'errore del metodo su un singolo sottointervallo; questa volta, facciamo uno sviluppo di Taylor di ordine 2, centrato nel punto medio $m = \frac{x_k+x_{k+1}}{2}$
    \begin{align*}
        \int_{x_k}^{x_{k+1}} f(x)\, dx &= \int_{x_k}^{x_{k+1}} \biggl(f(m)+f'(m)(x-m) +\frac{f''(\xi_k)}{2}(x-m)^2 \biggr)dx\\
        &= \underbrace{\int_{x_k}^{x_{k+1}} f(m)\, dx}_{=f(m)(x_{k+1}-x_k)} + \underbrace{\int_{x_k}^{x_{k+1}} f'(m)(x-m)\, dx}_{=0}
        + \underbrace{\int_{x_k}^{x_{k+1}} \frac{f''(\xi_k)}{2}(x-m)^2 \,dx}_{=R_k}.
    \end{align*}
    Di nuovo, il primo addendo è l'area del rettangolo che stiamo considerando. Il secondo addendo vale 0: lo vediamo dalla primitiva
    \[
    \int_{x_k}^{x_{k+1}} f'(m)(x-m)\, dx = f'(m)\frac{(x-m)^2}{2}\bigg|_{x_k}^{x_{k+1}} = f'(m)\frac{(x_{k+1}-m)^2}{2} - f'(m)\frac{(x_k-m)^2}{2}:
    \]
    poiché $m$ è il punto medio tra $x_k$ e $x_{k+1}$, si ha $x_{k+1}-m = m-x_k = \frac{h}{2}$. Oppure anche geometricamente: stiamo calcolando l'integrale della funzione raffigurata qui sotto.
\begin{center}
\begin{tikzpicture}
    % Draw axes
    \draw[->] (-0.5,0) -- (5.5,0);
    \draw[->] (0,-2) -- (0,2);

    \draw[draw=red!80!black, fill=red!10] (1,0) -- (4,0) -- (4,1.5) -- (1,-1.5) -- cycle;

    \draw[domain=1:4,smooth,variable=\x,blue,thick] plot ({\x},{\x-2.5});
    
    % \fill [blue, opacity=0.2, domain=1:4, smooth, variable=\x]
    %   (1, 0)
    %   -- plot ({\x},{3/2*\x*\x*\x - 23/2*\x*\x + 27*\x -16})
    %   -- (4, 0)
    %   -- cycle;
    
    \node at (1,-0.3) {$x_k$};
    \node at (4,-0.3) {$x_{k+1}$};
    \node at (2.5,-0.3) {$m$};
%    \node at (\midpoint,0) {$c$};
\end{tikzpicture}
\end{center}
L'integrale fa $0$ per simmetria: i due triangoli sono uguali; quello a sinistra ha area che va contata col segno meno perché è al di sotto dell'asse delle ascisse, e quello a destra ha area che va contata col segno più.

Di nuovo, diamo una limitazione per l'area del resto $R_k$:
\begin{align*}
    \abs{R_k} &= \abs*{\int_{x_k}^{x_{k+1}} \frac{f''(\xi_k)}{2}(x-m)^2 \,dx}\\
    &\leq \int_{x_k}^{x_{k+1}} \abs*{\frac{f''(\xi_k)}{2}(x-m)^2} \, dx\\
    &\leq \int_{x_k}^{x_{k+1}} \frac{C_2}{2} (x-m)^2 \\
    & = \frac{C_2}{6} (x-m)^3\bigg|_{x_k}^{x_{k+1}}\\
    &= \frac{C_2}{6} \left(\frac{h}{2}\right)^3 - \frac{C_2}{6}\left(-\frac{h}{2}\right)^3 = \frac{1}{24}C_2 h^3.
\end{align*}
Abbiamo usato di nuovo il fatto che $x_{k+1}-m = m-x_k = \frac{h}{2}$. Come nella dimostrazione precedente, sommiamo questi errori lungo tutti i sottointervalli per ottenere
\begin{align*}
    \abs{I - \tilde{I}_{M,n}} &= \abs*{\sum_{k=0}^{n-1} \int_{x_k}^{x_{k+1}} f(x)\, dx - f\left(\frac{x_k+x_{k+1}}{2}\right)(x_{k+1}-x_k) }\\
    &\leq \sum_{k=0}^{n-1} \abs{R_k} \leq n \cdot \frac{C_2}{24}h^3 = (b-a)\frac{C_2}{24}h^2. \qedhere
\end{align*}
\end{proof}
Questa volta l'errore è limitato da una costante (non dipendente da $n$) moltiplicata per $h^2$, cioè $\mathcal{O}(h^2)$. Quando $n\to\infty$, e quindi $h\to 0$, questo errore va a zero come il \emph{quadrato} di $h$, quindi più velocemente che non l'errore delle somme di Riemann~\eqref{Riemann sum error}, che era dell'ordine di $h$. 

\paragraph{Formula dei trapezi} Un altro metodo classico si ottiene con una variante di questa idea. Invece che con un rettangolo, approssimiamo l'integrale su ogni singolo sottointervallo con l'area del trapezio che si forma tracciando il segmento che unisce i punti $(x_{k}, f(x_k))$ e $(x_{k+1}, f(x_{k+1}))$.

\begin{center}
    \begin{tikzpicture}
        % Draw axes
        \draw[->] (-0.5,0) -- (5.5,0);
        \draw[->] (0,-0.5) -- (0,4);
        

        \draw[draw=red!80!black, fill=red!10] (1,0) -- (4,0) -- (4,4) -- (1,1) -- cycle;

        \draw[domain=1:4,smooth,variable=\x,blue] plot ({\x},{3/2*\x*\x*\x - 23/2*\x*\x + 27*\x -16});
        % \fill [blue, opacity=0.2, domain=1:4, smooth, variable=\x]
        %   (1, 0)
        %   -- plot ({\x},{3/2*\x*\x*\x - 23/2*\x*\x + 27*\x -16})
        %   -- (4, 0)
        %   -- cycle;
        
        
        \node at (1,-0.3) {$x_k$};
        \node at (4,-0.3) {$x_{k+1}$};
        \node[red!80!black] at (2.5,-0.3) {altezza};
        \node[rotate=90,red!80!black] at (0.7, 0.5) {base};
        \node[rotate=90,red!80!black] at (4.3, 2) {base};

        \fill[red] (1,1) circle (2pt);
        \fill[red] (4,4) circle (2pt);
    \end{tikzpicture}
    \end{center}
Girando la testa verso sinistra, vediamo che la figura in rosso è un trapezio rettangolo con due basi (in verticale) lunghe $f(x_k)$ e $f(x_{k+1})$, e altezza (in orizzontale) lunga $x_{k+1}-x_k = h$. Pertanto, usando la formula per l'area di un trapezio, l'approssimazione che abbiamo è
\begin{equation} \label{trapezi semplice}
    \int_{x_k}^{x_{k+1}} f(x)\, dx \approx \frac{f(x_k)+f(x_{k+1})}{2}h.
\end{equation}
Occhio alle differenze tra questa formula e la~\eqref{formula del punto medio}: in questa formula prima si applica la $f$ e poi si fa la media, nell'altra formula viceversa.

Sommando lungo tutti i sottointervalli quindi abbiamo l'approssimazione
\begin{align*}
    \tilde{I}_{T,n} &= \sum_{k=0}^{n-1 }\frac{h}{2}(f(x_k)+f(x_{k+1}))\\
    &= \frac{h}{2}\biggl(f(x_0)+f(x_1) + f(x_1)+f(x_2) + f(x_2)+f(x_3) + \dots + f(x_{n-1})+f(x_n)\biggr).    
\end{align*}

Nella figura qui sotto, vediamo che per una funzione che non ha grosse oscillazioni è difficile distinguere i lati obliqui dei trapezi dal grafico della funzione stessa.

\begin{tikzpicture}
  % Define nonlinear function
  \def\func{0.5*x^2 + 1}
  \def\nrect{12} % number of subintervals
  \def\xmin{0}
  \def\xmax{4}
  \def\deltax{(\xmax-\xmin)/\nrect}

  % Axis
  \begin{axis}[
    domain=0:4,
    samples=100,
    axis lines=middle,
    ymin=0, ymax=10,
    xmin=0, xmax=4.3,
    xtick={},
    ytick={},
    width=10cm,
    height=6cm,
    legend style={at={(0.98,0.98)},anchor=north east}
  ]

    % Draw trapezoids
    \foreach \i in {0,...,11} {
      \pgfmathsetmacro{\xi}{\xmin + \i*\deltax}
      \pgfmathsetmacro{\xnext}{\xi+\deltax}
      \pgfmathsetmacro{\yi}{0.5*\xi*\xi + 1}
      \pgfmathsetmacro{\ynext}{0.5*\xnext*\xnext + 1}
      \addplot [
        fill=red!10,
        draw=red!80!black,
        area legend
      ] coordinates {(\xi,0) (\xi,\yi) (\xnext,\ynext) (\xnext,0)} -- cycle;
    }

    % Plot the nonlinear function
    \addplot[thick,blue,domain=\xmin:\xmax] {\func};

    % Add points at trapezoid vertices (endpoints of function values)
    \foreach \i in {0,...,12} {
      \pgfmathsetmacro{\xi}{\xmin + \i*\deltax}
      \pgfmathsetmacro{\yi}{0.5*\xi*\xi + 1}
      \addplot[only marks,mark=*,color=red] coordinates {(\xi,\yi)};
    }
  \end{axis}
\end{tikzpicture}

A parte il primo e l'ultimo, ogni addendo della forma $f(x_i)$ compare due volte: prima come $f(x_{k+1})$, poi come $f(x_k)$ del termine successivo della sommatoria. Quindi possiamo riscrivere la formula come
\begin{align*}
    \tilde{I}_{T,n} = h\biggl(\frac{1}{2} f(x_0) + f(x_1) + f(x_2) + \dots + f(x_{n-1}) + \frac{1}{2}f(x_n)  \biggr),
\end{align*}
dove i coefficienti $\frac{1}{2}$ compaiono solo davanti al primo e all'ultimo termine. In questo modo la formula è molto simile a quelle per le somme di Riemann $\tilde{I}_{L,n}$ e $\tilde{I}_{R,n}$ che abbiamo visto più sopra.

In questo metodo abbiamo $n+1$ pesi e $n+1$ nodi nella formula, e ci serve valutare la funzione $f$ $n+1$ volte per calcolare $\tilde{I}_{T,n}$.

Riprendiamo l'esempio già visto: per $I = \int_0^1 x^2\, dx = 1/3$, con $n=5$ punti, l'approssimazione data da questa formula è
\begin{equation} \label{esempio trapezi composito}
    \tilde{I}_{T,n} = \frac{1}{5} \left(\frac{1}{2}0^2 + 0.2^2 + 0.4^2 + 0.6^2 + 0.8^2 + \frac{1}{2}1^2\right) = 0.34.    
\end{equation}
Di nuovo, anche con pochi punti siamo molto vicini al valore esatto dell'integrale. Possiamo di nuovo determinare una formula per l'errore.

\paragraph{Errore della formula dei trapezi} 
\begin{theorem}
    Sia $f$ una funzione di classe $\mathcal{C}^2$ su $[a,b]$, e definiamo $C_2 = \max_{x\in [a,b]} \abs{f''(x)}$. Allora,
    \begin{equation} \label{trapezoid formula error}
        \abs{I - \tilde{I}_{T,n}} \leq \frac{1}{12} (b-a) C_2 h^2.
    \end{equation}
\end{theorem}
Notiamo che il membro di destra è il doppio di quello che avevamo ottenuto per il metodo del punto medio, visto che al denominatore abbiamo $12$ anziché $24$.
\begin{proof}
    Di nuovo, iniziamo studiando l'errore del metodo su ogni singolo sottointervallo. Questa volta non è utile uno sviluppo di Taylor, visto che nella formula~\eqref{trapezi semplice} la funzione viene valutata in due punti. Però, osserviamo che l'approssimazione prodotta dal metodo è uguale all'integrale della funzione $p(x)$, dove $p(x)$ è il segmento di retta (polinomio di grado 1) che congiunge i due punti $(x_k, f(x_k))$ e $(x_{k+1},f(x_{k+1}))$. Con la terminologia del capitolo precedente, questa funzione $p(x)$ è il polinomio di approssimazione della funzione $f(x)$ nei due nodi $x_k$ e $x_{k+1}$. 
    
    Questa osservazione ci permette di usare la formula per il resto dell'interpolazione~\eqref{resto dell'interpolazione}. Applicando quella formula per $d=1$ e i due nodi $x_k,x_{k+1}$ abbiamo
    \begin{align*}
    \int_{x_k}^{x_{k+1}} f(x)\, dx &= \int_{x_k}^{x_{k+1}} \left(p(x) + \frac{f''(\xi)}{2}(x-x_k)(x-x_{k+1}) \right)\, dx\\
    &= \underbrace{\int_{x_k}^{x_{k+1}} p(x)\, dx}_{=h\frac{f(x_k)+f(x_{k+1})}{2}} +
    \underbrace{\int_{x_k}^{x_{k+1}} \frac{f''(\xi)}{2}(x-x_k)(x-x_{k+1}) \, dx}_{=R_k}.
    \end{align*}
    Dobbiamo quindi dare una limitazione al valore di
    \begin{align*}
        \abs{R_k} &= \abs*{\int_{x_k}^{x_{k+1}} \frac{f''(\xi)}{2}(x-x_k)(x-x_{k+1}) \, dx}\\
        & \leq \int_{x_k}^{x_{k+1}} \abs*{\frac{f''(\xi)}{2}(x-x_k)(x-x_{k+1})}\, dx\\
        & \leq \int_{x_k}^{x_{k+1}} \frac{C_2}{2} (x-x_k)(x_{k+1}-x)\, dx\\
        & = \frac{C_2}{12}h^3.
    \end{align*}
    Questa volta abbiamo tolto il valore assoluto cambiando segno a $x - x_{k+1}$: visto che $x$ sta nell'intervallo $[x_k,x_{k+1}]$, questa quantità è sempre minore o uguale a zero. L'ultimo passaggio è stato calcolare l'integrale di una funzione che è un polinomio di grado 2 in $x$: non abbiamo scritto tutti i dettagli, perché è un po' più macchinoso che nei casi precedenti trovare una primitiva e svolgere l'integrale, ma sono tutti passaggi che sappiamo fare. Da qui procediamo come nella dimostrazione dell'errore del metodo del punto medio.
\end{proof}

\paragraph{Formule semplici e composite}
Le formule di quadratura che abbiamo visto hanno una struttura comune:
\begin{itemize}
    \item troviamo una strategia, anche con un'approssimazione molto rozza, per approssimare l'integrale sull'intervallo $[x_k,x_{k+1}]$, per esempio rimpiazzandolo con l'area di un rettangolo o di un trapezio;
    \item suddividiamo $[a,b]$ in $n$ sottointervalli uguali e applichiamo la strategia su ogni sottointervallo.
\end{itemize}
Questa prima strategia a volte è definita la versione \emph{semplice} della formula di integrazione: per esempio, approssimare $\int_0^1 x^2$ con la \emph{formula dei trapezi semplice} significa usare la strategia senza suddividere $[0,1]$ in sottointervalli, ossia con un solo trapezio ($n=1$):
\[
\tilde{I}_{T,1} = (b-a)\frac{f(a)+f(b)}{2} = (1-0)\frac{0^2+1^2}{2} = \frac{1}{2}.
\]
Quando è necessario distinguerla dalla formula semplice corrispondente, la formula di integrazione ottenuta ripetendo questa strategia su ogni sottointervallo di una suddivisione è detta \emph{formula composita} (o anche \emph{metodo composito}); quindi per esempio la formula vista in~\eqref{esempio trapezi composito} è la formula dei trapezi composita con $n=5$ sottointervalli.

\paragraph{Ordine del metodo e convergenza a zero dell'errore}
Le formule che abbiamo visto per la stima dell'errore seguono tutte la stessa strategia di dimostrazione: prima mostriamo che la versione semplice del metodo, applicata su un intervallo di lunghezza $h$, ha un errore che si può limitare con un'espressione del tipo
\begin{equation} \label{ordine locale quadratura}
    \abs*{\int_{x_k}^{x_{k+1}} f(x)\, dx - (\text{formula semplice})} = \abs{R_k} \leq K C_p h^{p+1},    
\end{equation}
dove $C_p$ è il massimo della derivata $p$-esima (in valore assoluto) e $K$ è una costante opportuna; poi da questa disuguaglianza deduciamo che
\begin{equation} \label{ordine globale quadratura}
    \abs*{I - \tilde{I}} \leq K (b-a) C_p h^p.
\end{equation}
La costante $p$, che vale $1$ per le somme di Riemann e $2$ per la formula del punto medio e quella dei trapezi, è detta \emph{ordine del metodo}. Più precisamente, quando vale la~\eqref{ordine locale quadratura} diciamo che la formula ha \emph{errore locale di ordine $p$}, mentre quando vale la~\eqref{ordine globale quadratura} diciamo che ha \emph{errore globale di ordine $p$}. I termini ``locale'' e ``globale'' sono perché uno si riferisce a un singolo, piccolo sottointervallo, mentre l'altro si riferisce a tutto l'intervallo $[a,b]$. Il fatto che l'ordine locale e quello globale siano lo stesso è un fatto che reincontreremo anche più avanti, parlando di metodi per risolvere equazioni differenziali.

Nella~\eqref{ordine locale quadratura} compare $h^{p+1}$; è utile pensare a questo termine come $h \cdot h^p$, dove il primo $h$ è l'ampiezza dell'intervallo su cui lavoriamo, per analogia con il $b-a$ che compare nella~\eqref{ordine globale quadratura}.

Possiamo usare la notazione O-grande dell'analisi, e dire che per un metodo di ordine $p$ l'errore è della forma $\mathcal{O}(h^p)$ (per $n\to\infty$, o equivalentemente $h\to 0$).

\paragraph{Ordine e comportamento sperimentale del metodo}
L'ordine del metodo tipicamente rispecchia il comportamento dell'errore al variare di $n$, nella pratica. Vediamolo innanzitutto in un esempio: la tabella seguente rappresenta l'errore ottenuto approssimando $I=\int_0^1 x^4 \, dx$ con i metodi visti e diversi valori di $n$.
%
\begin{center}
\pgfplotstabletypeset[
    col sep=&, 
    row sep=\\, 
    sci zerofill,
    every head row/.style={before row=\toprule,after row=\midrule},
    every last row/.style={after row=\bottomrule},
    columns/n/.style={column name=$n$},
    columns/h/.style={column name=$h$},
    columns/EL/.style={column name=$\abs{\tilde{I}_{L,n}-I}$},
    columns/ER/.style={column name=$\abs{\tilde{I}_{R,n}-I}$},
    columns/EM/.style={column name=$\abs{\tilde{I}_{M,n}-I}$},
    columns/ET/.style={column name=$\abs{\tilde{I}_{T,n}-I}$},
    ]{
n & h & EL & ER & EM & ET\\
5 & 2.00e-01 & 8.67e-02 & 1.13e-01 & 6.62e-03 & 1.33e-02\\
10 & 1.00e-01 & 4.67e-02 & 5.33e-02 & 1.66e-03 & 3.33e-03\\
20 & 5.00e-02 & 2.42e-02 & 2.58e-02 & 4.16e-04 & 8.33e-04\\
40 & 2.50e-02 & 1.23e-02 & 1.27e-02 & 1.04e-04 & 2.08e-04\\
}
\end{center}
%
Ogni volta che $n$ raddoppia, la lunghezza $h$ di ogni sottointervallo dimezza. L'errore delle somme di Riemann (sinistre o destre) si riduce di circa la metà: $8.67\cdot 10^{-2} / 4.67 \cdot 10^{-2} \approx 1.8565$, mentre $2.42\cdot 10^{-2} / 1.23 \cdot 10^{-2} = 1.9675$. Questi rapporti si avvicinano sempre di più a 2 al crescere di $n$. Questo comportamento rispecchia le formule che abbiamo visto: quando $h$ dimezza, anche il membro di destra di~\eqref{Riemann sum error} si dimezza. Anche se quella che abbiamo dimostrato è solo una limitazione dall'alto all'errore, vediamo che l'errore vero $\abs{\tilde{I}-I}$ rispecchia il comportamento della formula~\eqref{Riemann sum error}.

Invece, per il metodo del punto medio e per quello dei trapezi, vediamo nella tabella che l'errore si riduce circa di un fattore 4 al raddoppiare di $n$. Di nuovo, questo rispecchia le formule che abbiamo visto: quando $h$ dimezza, il membro di destra di~\eqref{midpoint method error} e di~\eqref{trapezoid formula error} si divide per un fattore $4$, visto che compare $h^2$ anziché $h$: il termine $h^2$ va rimpiazzato con $\left(\frac{h}{2}\right)^2 = \frac{h^2}{4}$. Pertanto, questi due metodi convergono al valore esatto molto più velocemente di quelli basati su somme di Riemann destre e sinistre, come si vede anche dalla tabella.

Vedremo che metodi con ordine ancora più alto hanno un errore che converge a zero ancora più velocemente: in un metodo di ordine $p$, quando rimpiazziamo $n$ con $d n$, la stima dell'errore (e anche l'errore, sebbene solo approssimativamente) si riduce di un fattore $d^p$.

\paragraph{Diverse nozioni di ordine di convergenza}
Attenzione: è importante notare che questo concetto di ``ordine di convergenza'' è diverso da quello visto per i metodi iterativi. Nel caso dei metodi iterativi, la convergenza si riferiva a un numero di iterazioni $n$: convergenza di ordine $p$ significa che
\[
e_{n+1} = \mathcal{O}(e_n^p),
\]
cioè, l'errore al passo $n+1$ è dell'ordine della potenza $p$-esima di \emph{quello al passo precedente}.

Questi metodi, invece, sono basati sulla suddivisione di un intervallo. Non c'è un concetto di ``iterazioni successive'', e non ha molto senso confrontare $e_{n+1}$ con $e_n$: il risultato di una formula di integrazione con $n+1$ punti non si può calcolare facilmente a partire da quello con $n$ punti, visto che tutti i punti in cui è necessario valutare la funzione sono diversi.

Anche il comportamento dei due errori al crescere di $n$ è diverso. Ad esempio, supponiamo di avere un metodo iterativo con ordine di convergenza $1$; esso soddisfa
\[
\lim_{n\to\infty} \frac{e_{n+1}}{e_n} = r < 1,
\]
quindi $e_n \approx C r^n$. In particolare, passando dall'iterazione $n$ all'iterazione $2n$ l'erore si riduce di un fattore $r^n$, non di un fattore $2$.

\paragraph{Grado di esattezza} Nelle formule per l'errore locale (del tipo della~\eqref{ordine locale quadratura}) compare
\[
    C_p = \max_{x\in [a,b]} \abs{f^{(p)}(x)},
\]
il massimo della derivata $p$-esima (in valore assoluto). Quando $f$ è un polinomio di grado minore di $p$, la sua derivata $p$-esima vale $0$ su tutto l'intervallo; quindi per ogni formula di ordine $p$ si ha $R_k=0$ e quindi $\abs{I-\tilde{I}}=0$. Questo mostra il seguente risultato, che vale per come abbiamo definito l'ordine di una formula di quadratura.
\begin{theorem}
    Ogni formula di integrazione di ordine $p$ restituisce il valore esatto dell'integrale ($\tilde{I}=I$) quando la funzione $f$ è un polinomio di grado strettamente minore di $p$.
\end{theorem}
In particolare:
\begin{itemize}
    \item Quando la funzione $f$ è della forma $f(x) = mx+q$, sia il metodo dei trapezi che quello del punto medio (di ordine $p=2$) restituiscono il valore esatto $I$ dell'integrale.
    \item Quando la funzione $f$ è costante ($f(x)=q$), anche i due metodi basati sulle somme di Riemann (di ordine $p=1$) restituiscono il valore esatto $I$ dell'integrale.
\end{itemize}
Possiamo verificare questi fatti anche direttamente. Per la formula dei trapezi: se prendiamo $f(x) = mx+q$, il grafico della funzione coincide con il lato obliquo dei trapezi che consideriamo.
\begin{center}
    \begin{tikzpicture}
        % Draw axes
        \draw[->] (-0.5,0) -- (5.5,0);
        \draw[->] (0,-0.5) -- (0,4);
        

        \draw[draw=red!80!black, fill=red!10] (1,0) -- (4,0) -- (4,4) -- (1,1) -- cycle;
        \draw[draw=blue, thick] (1,1) -- (4,4);

        %\draw[domain=1:4,smooth,variable=\x,blue] plot ({\x},{3/2*\x*\x*\x - 23/2*\x*\x + 27*\x -16});
        % \fill [blue, opacity=0.2, domain=1:4, smooth, variable=\x]
        %   (1, 0)
        %   -- plot ({\x},{3/2*\x*\x*\x - 23/2*\x*\x + 27*\x -16})
        %   -- (4, 0)
        %   -- cycle;
        
        
        \node at (1,-0.3) {$x_k$};
        \node at (4,-0.3) {$x_{k+1}$};

        \fill[red] (1,1) circle (2pt);
        \fill[red] (4,4) circle (2pt);
    \end{tikzpicture}
    \end{center}
Quindi il trapezio in rosso ha area uguale all'integrale della funzione in blu. Per il metodo del punto medio, il ragionamento è simile a quello che abbiamo fatto nella dimostrazione del Teorema~\ref{thm: errore metodo punto medio}.
\begin{center}
    \begin{tikzpicture}
        % Draw axes
        \draw[->] (-0.5,0) -- (5.5,0);
        \draw[->] (0,-0.5) -- (0,4);
        

        \draw[draw=red!80!black, fill=red!10] (1,0) -- (4,0) -- (4,2.5) -- (1,2.5) -- cycle;
        \draw[draw=blue, thick] (1,1) -- (4,4);

        %\draw[domain=1:4,smooth,variable=\x,blue] plot ({\x},{3/2*\x*\x*\x - 23/2*\x*\x + 27*\x -16});
        % \fill [blue, opacity=0.2, domain=1:4, smooth, variable=\x]
        %   (1, 0)
        %   -- plot ({\x},{3/2*\x*\x*\x - 23/2*\x*\x + 27*\x -16})
        %   -- (4, 0)
        %   -- cycle;
        
        
        \node at (1,-0.3) {$x_k$};
        \node at (4,-0.3) {$x_{k+1}$};

        \fill[red] (2.5,2.5) circle (2pt);
%        \fill[red] (4,4) circle (2pt);

        \draw[black] (4,2.5) -- (4,4);

        \node at (1.5, 2) {A};
        \node at (3.5, 3) {B};

    \end{tikzpicture}
    \end{center}
I due triangoli che abbiamo indicato con le lettere A e B sono uguali, quindi l'area del rettangolo in rosso coincide con l'integrale della funzione il cui grafico è il segmento di retta in blu.

\section{Formule di Newton--Cotes}
Nella dimostrazione che abbiamo fatto per l'errore della formula dei trapezi, abbiamo interpretato il trapezio tracciato come un polinomio di interpolazione di $f$ di grado $d=1$. Questo suggerisce una generalizzazione: per approssimare un integrale, possiamo fare in questo modo:
\begin{itemize}
    \item Fissiamo un grado $d$;
    \item Suddividiamo l'intervallo $[a,b]$ in $d$ sottointervalli uguali, ottenendo punti $x_0,x_1,\dots,x_d$;
    \item Calcoliamo il polinomio di interpolazione $p(x)$ sui nodi $x_0,x_1,\dots,x_d$ risultanti da questa suddivisione;
    \item Approssimiamo $I = \int_a^b f(x) dx$ con $I_d = \int_a^b p(x) dx$. Questo è l'integrale di un polinomio, che è semplice da calcolare.
\end{itemize}
Possiamo pensare alla formula dei trapezi come al caso $d=1$ di questa formula: dividiamo $[a,b]$ in \emph{un} sottointervallo, otteniamo due punti $x_0=a$ e $x_1=b$, e calcoliamo il polinomio di interpolazione di grado $1$ su questi due punti, cioè la retta che passa per i punti $(a,f(a))$ e $(b,f(b))$.

Questo procedimento produce una formula di quadratura che ha grado di esattezza almeno $d$: difatti, se $f(x)$ è un polinomio di grado al più $d$, allora coincide con il suo polinomio di interpolazione, $f(x)=p(x)$.

Utilizzando la forma di Lagrange del polinomio di interpolazione, possiamo scrivere la formula di quadratura risultante come
\[
    \tilde{I}_d = \int_a^b p(x) dx = \int_a^b \sum_{k=0}^d L_k(x)f(x_k) dx = \sum_{k=0}^d f(x_k) \underbrace{\int_a^b L_k(x) dx}_{=w_k}.
\]

Calcoliamo per esempio i pesi che risultano per $[a,b]=[-1,1]$ e $d=2$ intervalli: i tre punti equispaziati sono $x_0=-1,x_1=0,x_2 = 1$, e 
\begin{align*}
L_0(x) &= \frac{(x-0)(x-1)}{(-1-0)(-1-1)} = \frac{x(x-1)}{2}, & w_0 = \int_{-1}^1 L_0(x) = \frac13, \\
L_1(x) &= \frac{(x+1)(x-1)}{(0+1)(0-1)} = 1-x^2, & w_1 = \int_{-1}^1 L_1(x) = \frac43, \\
L_2(x) &= \frac{(x+1)(x-0)}{(1+1)(1-0)}  = \frac{(x+1)x}{2}, & w_2 = \int_{-1}^1 L_2(x) = \frac13.
\end{align*}
Quindi la formula di Newton--Cotes di grado $d=2$ sull'intervallo $[-1,1]$ è data da 
\[
I \approx \tilde{I}_2 = \frac{1}{3}f(-1) + \frac{4}{3}f(0) + \frac{1}{3}f(1).
\]

\paragraph{Cambio di variabile} A priori, sembrerebbe che per ogni scelta dell'intervallo $[a,b]$ dobbiamo ricalcolare da capo i pesi di queste formule. È possibile però fare un cambio di variabile lineare che ci permette di ricondurre un generico intervallo $[a,b]$ all'intervallo $[-1,1]$. Definiamo come in precedenza $c=\frac{a+b}{2}$ il punto medio di $[a,b]$, e $x = c + \frac{b-a}{2}y$. È semplice verificare che $y=-1,y=1$ corrispondono a $x=a,x=b$ rispettivamente. Inoltre, se $y_0,y_1,\dots,y_d$ sono punti equispaziati tra $-1$ e $1$, allora
\[
    x_k = c + \frac{b-a}{2}y_k
\]
sono $k$ punti equispaziati tra $a$ e $b$.

Quindi abbiamo $dx = \frac{b-a}{2}dy$ e 
\[
\int_{a}^b L_k(x)dx = \frac{b-a}{2}\int_{-1}^1 \underbrace{L_k\left(c+\frac{b-a}{2}y\right)}_{:=M_k(y)} dy.
\]
Il polinomio $M_k(y)$ è il $k$-esimo polinomio di Lagrange su $[-1,1]$. Quindi, per ottenere i pesi sull'intervallo $[a,b]$, ci basta prendere quelli per l'intervallo $[-1,1]$ e moltiplicarli per $\frac{b-a}{2}$.

In particolare, per $d=2$ si hanno i pesi
\[
w_0 = \frac16(b-a), \quad w_1 = \frac46 (b-a), \quad w_2 = \frac16 (b-a).
\]
e quindi la formula di Newton--Cotes di grado $d=2$ su un generico intervallo $[a,b]$ è
\[
I \approx \tilde{I}_{CS} = \frac{b-a}{6}\left(f(a) + 4f(c) + f(b)\right).
\]
Questa formula è nota anche come \emph{formula di Cavalieri--Simpson}. Nello stesso modo è possibile calcolare i pesi delle formule di Newton--Cotes di grado più alto.



\paragraph{Ordine delle formule di Newton--Cotes}

La formula di Cavalieri--Simpson che abbiamo costruito ha grado di esattezza almeno 2: difatti, corrisponde a prendere il polinomio di interpolazione $p(x)$ a $f(x)$ di grado al più 2, e calcolarne l'integrale; quindi se $f(x)$ è già di partenza un polinomio di grado al più $2$ riotteniamo l'integrale di partenza. La cosa sorprendente è che questa formula in realtà ha grado di esattezza 3, cioè restituisce il risultato esatto anche per polinomi di grado $3$. Possiamo verificare facilmente che per $[a,b]=[-1,1]$ e $f(x)=x^3$, per simmetria $I = \int_{a}^b f(x) dx = 0$, e la  formula di Cavalieri--Simpson fornisce $\tilde{I}_2=0$. Non vediamo i dettagli, ma poiché sia gli integrali che le nostre formule di integrazione sono lineari nella $f$, questo è sufficiente per concludere che la formula è esatta per \emph{ogni} polinomio di grado 3.

Più in generale, per le formule di Newton--Cotes vale questo risultato.
\begin{theorem}
La formula di Newton--Cotes di grado $d$ (con $d+1$ punti equispaziati) ha come ordine il più piccolo numero pari maggiore di $d$:
\[
p = \begin{cases}
    d+1 & \text{$d$ dispari},\\
    d+2 & \text{$d$ pari}.
\end{cases}
\]
\end{theorem}
Quindi abbiamo per ogni $d$ la stima per l'errore
\[
\abs{\tilde{I}_d - I} \leq K_d C_{p} (b-a)^{p+1},
\]
dove $K_d$ è un'opportuna costante che dipende dal grado. Per il metodo dei trapezi ($d=1$), già sappiamo che $K_1 = \frac{1}{12}$. Per il metodo di Cavalieri--Simpson ($d=2$), vale $K_2 = \frac{1}{90}$. Non dimostriamo questi risultati.

\paragraph{Formule di Newton--Cotes composite}
In realtà, utilizzare formule di Newton--Cotes con valori molto grandi di $d$ non è una buona idea: si incorre negli stessi problemi di cattivo condizionamento che abbiamo visto con l'interpolazione polinomiale. Tipicamente, si scelgono formule di grado al massimo 4, e se si vuole ridurre ancora l'errore si usano queste formule come versione semplice di una formula composita.

Per esempio, per applicare il metodo di Cavalieri--Simpson composito, dividiamo l'intervallo $[a,b]$ in $n$ sottointervalli uguali, e su ognuno di essi applichiamo la formula di Cavalieri--Simpson:
\[
\int_{x_k}^{x_{k+1}} f(x) \, dx \approx \frac{x_{k+1}-x_k}{6}\left(f(x_k)+4f\left(\frac{x_k+x_{k+1}}{2}\right) + f(x_{k+1})\right).
\]
Come nel caso della formula dei trapezi, possiamo scrivere la formula risultante in modo più semplice usando il fatto che ogni termine della forma $f(x_i)$ compare due volte (tranne il primo e l'ultimo):
\begin{align*}
    \tilde{I}_{CS,n} &= \sum_{k=0}^{n-1} \frac{x_{k+1}-x_k}{6}\left(f(x_k)+4f\left(\frac{x_k+x_{k+1}}{2}\right) + f(x_{k+1})\right)\\
    &= \frac{h}{6} \left( f(x_0) + 4f\left(\frac{x_0+x_1}{2}\right) + f(x_1) + f(x_1) + \dots + 4f\left(\frac{x_{n-1}+x_n}{2}\right) +  f(x_n)   \right)\\
    &= \frac{h}{6} \left(f(x_0) + 2\sum_{k=1}^{n-1}f(x_k) + f(x_n) \right) \frac{4h}{6} \sum_{k=0}^{n-1} f\left(\frac{x_{k}+x_{k+1}}{2}\right) \\
    &= \frac13 \tilde{I}_{T,n} +\frac{2}{3}\tilde{I}_{M,n}.
\end{align*}
Nell'ultima riga di questa catena di uguaglianze compare il fatto interessante che il metodo di Cavalieri--Simpson si può scrivere come una media pesata del metodo del punto medio e di quello dei trapezi.

Il metodo di Cavalieri--Simpson richiede di valutare la funzione $f$ in $2n+1$ punti diversi, e quindi ha un costo computazionale pari a circa il doppio di quello degli altri metodi che abbiamo visto. In cambio, però, ha ordine $4$, e quindi l'errore converge a zero molto più velocemente al crescere di $n$.

Questo trucco per ridurre il numero di valutazioni si può applicare non solo per la formula dei trapezi e di Cavalieri--Simpson, ma tutte le volte che una formula di integrazione semplice include come nodi i due estremi dell'intervallo di valutazione $x_k$ e $x_{k+1}$. Le formule che soddisfano questa proprietà sono dette \emph{chiuse} (per analogia con gli intervalli chiusi, che includono gli estremi).

\paragraph{Stima dell'errore per le formule composite} Sia $n$ un intero pari. Applicando una formula di integrazione composita con ordine di convergenza $p$ prima con $n$ intervalli e poi con $n/2$ sottointervalli, ci aspettiamo quindi che
\[
    \tilde{I}_n = I + e_n, \quad \tilde{I}_{n/2} = I + e_{n/2} \approx I + 2^{p}e_n.
\]
(Questa relazione è solo approssimata, perché la riduzione dell'errore non è esattamente di un fattore $2^p$.)

Da queste due relazioni possiamo eliminare $I$ e ricavare approssimativamente il valore dell'errore $e_n$ come
\[
\frac{\tilde{I}_{n/2} - \tilde{I}_{n}}{2^p -1} \approx \frac{I + 2^p e_n -(I+e_n)}{2^p-1} = e_n.
\]
Questo ci permette di ottenere una stima dell'errore del metodo.

Notiamo che per la formula dei trapezi il calcolo di $\tilde{I}_{n/2}$ non richiede ulteriori valutazioni rispetto a quelle già utilizzate per il calcolo di $\tilde{I}_n$. Per esempio, se vogliamo calcolare un integrale su $[a,b]=[0,1]$ con la formula dei trapezi composita $\tilde{I}_{T,10}$, ci serve calcolare $f(0),f(0.1),f(0.2),\dots,f(0.9),f(1)$. Se vogliamo in aggiunta anche calcolare $\tilde{I}_{T,5}$, per farlo ci servono i valori $f(0),f(0.2),f(0.4),f(0.6),f(0.8),f(1)$, ma questi sono tutti punti su cui abbiamo già calcolato la funzione.

Quindi calcolare questa stima dell'errore ha un costo aggiuntivo trascurabile. Questa osservazione si applica anche ad altri metodi (ad esempio Cavalieri--Simpson), ma non a tutti i metodi: ad esempio, nel metodo del punto medio non possiamo riutilizzare gli stessi punti per calcolare $\tilde{I}_{M,10}$ e $\tilde{I}_{M,5}$; i punti in cui ci occorre calcolare la $f$ sono tutti diversi.

\section{Quadratura Gaussiana}
Ci poniamo ora (insieme a Gauss) il problema di quanto alto può essere l'ordine di una formula di quadratura, se scegliamo bene pesi e nodi. Perché una formula $\tilde{I}$ con $n$ nodi sia esatta su tutti i polinomi di grado $ < p$, è necessario e sufficiente che sia esatta su $1, x, x^2, \dots, x^{p-1}$, visto che i polinomi di grado $< p$ sono combinazioni lineari di queste funzioni. Questo porta a $p$ equazioni (non lineari!) nelle $2n$ incognite $w_1,x_1,\dots, w_n,x_n$: per esempio, con $[a,b]=[-1,1]$ abbiamo
\begin{equation} \label{eqquadgaussiana}
    \sum_{k=1}^n w_k 1 = 2, \quad \sum_{k=1}^n w_k x_k = 0, \quad \sum_{k=1}^n w_k x_k^2 = \frac23, \quad \sum_{k=1}^n w_k x_k^3 = 0, \quad \dots    
\end{equation}
Visto che abbiamo $p$ equazioni in $2n$ incognite, possiamo aspettarci che il sistema abbia delle soluzioni quando $p=2n$.  Questo è vero: esiste una (e una sola) scelta di $x_1,\dots,x_n,w_1,\dots,w_n$ che risolve le prime $2n$ equazioni della forma~\eqref{eqquadgaussiana}, e fornisce una formula con ordine $p=2n$. Non vediamo la dimostrazione qui; non è semplice, perché queste equazioni non sono lineari!

Per ogni scelta di $n$ quindi possiamo quindi trovare nodi e pesi $x_1,\dots,x_n,w_1,\dots,w_n$ che forniscono l'ordine massimo possibile $p=2n$. Nodi e pesi di queste formule, dette di \emph{quadratura Gaussiana}, si possono trovare su diverse fonti online, per esempio \url{https://en.wikipedia.org/wiki/Gaussian_quadrature}. Per esempio con $n=2$ abbiamo
\[
x_1 = \frac{1}{\sqrt{3}} = 0.57735\dots, \quad x_2 = -\frac{1}{\sqrt{3}} = -0.57735\dots, w_1=w_2=1
\]
che sono i nodi e i pesi dell'unica formula di quadratura su $[-1,1]$ con due punti di ordine $4$, che fornisce il valore esatto dell'integrale su tutti i polinomi di grado minore o uguale a $3$. Con un cambio di variabile simile a quello visto sopra è possibile adattarle ad altri intervalli. Non essendo formule chiuse, tipicamente non vengono usate nella versione composita, ma sono particolarmente utili nella loro versione semplice (non composita), quando basta un'approssimazione dell'integrale con bassa precisione ma calcolabile con poche valutazioni di funzione.

\end{conditional}


\begin{conditional}[ich]

\chapter{Equazioni differenziali ordinarie}

\paragraph{Il problema} In questo capitolo, ci poniamo il problema di risolvere numericamente un'equazione differenziale, o più precisamente un \emph{problema ai valori iniziali} (o \emph{problema di Cauchy})
\begin{equation} \label{cauchy}
    \begin{cases}
    \y'(t) = \f(t, \y(t)), \quad t \in [a,b],\\
    \y(a) = \y_0.
    \end{cases}
\end{equation}
Qui $\y: [a,b]\to \mathbb{R}^m$ è una funzione a valori vettori (anche se nella maggior parte degli esempi che vedremo $m=1$), e $\f(t,\y(t))$ è una funzione $f:[a,b] \times \mathbb{R}^m \to \mathbb{R}^m$ che specifica il problema. Il simbolo $\y'$ indica la derivata di $\y$ rispetto alla variabile $t$ (che possiamo pensare come `tempo'), e $\y_0\in \mathbb{R}^m$ è un valore iniziale dato.

Questa è la formulazione più generale, ma in molti esempi $m=1$ e quindi il problema riguarda una funzione reale di variabile reale. Per esempio, uno degli esempi che vedremo molto spesso è il seguente (detto \emph{problema test})
\begin{equation} \label{testproblem}
    \begin{cases}
    y'(t) = \lambda y(t), \quad y: [0,1] \to \mathbb{R}\\  
    y(0) = y_0,
    \end{cases}
\end{equation}
in cui quindi abbiamo $f(t, y) = \lambda y$. La soluzione di questo problema è $y(t) = \exp( \lambda t)$.

\paragraph{Altri esempi}
Un esempio famoso di un'equazione differenziale con più variabili è l'\emph{equazione di Lotka--Volterra}, o \emph{modello preda--predatore}. Fu studiata proprio qui a Pisa dal matematico Vito Volterra. L'equazione simula (approssimandoli con variabili continue) la quantità $u$ di prede e $v$ di predatori in un certo ambiente, e dice che
\[
    \begin{cases}
        u' = (A-Bv)u,\\
        v' = (Cu-D)v,
    \end{cases}
\]
per certe costanti $A,B,C,D>0$. Notiamo che qui non abbiamo scritto esplicitamente $u(t)$ ma solo $u$, anche se $u$ è una funzione del tempo (e lo stesso per $v(t)$); questo è abbastanza comune quando si parla di equazioni differenziali.

Questo sistema di due equazioni mostra come variano le derivate del numero di predatori $v(t)$ e del numero di prede $u(t)$: più grande è il numero di predatori $v$, e più lentamente cresce il numero di prede $u$. Più grande è il numero di prede $u$, e più velocemente cresce la popolazione dei predatori. Le due funzioni quindi sono collegate e variano l'una in funzione dell'altra. Possiamo riscrivere questa relazione in termine di una sola funzione incognita che è un vettore con due elementi: ponendo
\[
    \y(t) = 
    \begin{bmatrix}
        y_1(t) \\ 
        y_2(t)
    \end{bmatrix} = 
    \begin{bmatrix}
        u(t)\\
        v(t)
    \end{bmatrix},
\]
abbiamo
\[
    \frac{d}{dt} \y(t) = \f(t,\y) = \begin{bmatrix}
        (A-By_2)y_1,\\
        (Cy_1-D)y_2,
    \end{bmatrix}.
\]
Notiamo che negli esempi che abbiamo visto finora la funzione $\f(t,\y)$ dipende solo dalla $\y$ e non dal tempo $t$; questo è abbastanza comune nelle equazioni differenziali. Esistono però anche problemi in cui c'è dipendenza dal tempo, per esempio
\[
y'(t) = 2 t y(t),
\]
che ha soluzione $y(t) = e^{t^2}$, è nella forma $y'(t) = f(t,y)$, con la funzione $f: (t,y) \mapsto 2ty$.

Equazioni che contengono derivate di ordine superiore si possono sempre riscrivere nella forma~\eqref{cauchy} introducendo variabili ausiliarie: per esempio, l'equazione scalare di ordine 2
\[
\begin{cases}
x'' = 3t^2 x' + 5(t+1)x - t, \quad x:[a,b]\to\mathbb{R}, \\
x(a) = 1, \, x'(a) = 0
\end{cases}
\]
diventa, ponendo $\mathbf{y}(t) = \begin{bmatrix}
    y_1(t)\\
    y_2(t)
\end{bmatrix} = \begin{bmatrix}
    x(t)\\
    x'(t)
\end{bmatrix}$,
\[
\frac{d}{dt} \mathbf{y} = 
\frac{d}{dt}
\begin{bmatrix}
    y_1\\ y_2
\end{bmatrix} = \begin{bmatrix}
    y_2\\
    3t^2y_2 + 5(t+1)y_1 - t
\end{bmatrix}.
\]
Questa volta la funzione $\f(t,\y)$ al membro di destra dipende sia dalla $t$ che dagli elementi del vettore $\y$.

La maggior parte degli algoritmi che vedremo calcolano un'approssimazione dei valori assunti dalla soluzione $\y(t)$ su una griglia di punti equispaziati in $[a,b]$: useremo la notazione già vista nel capitolo scorso
\[
h = \frac{b-a}{n}, \quad t_k = a + kh, \quad n = 0,1,2,\dots,n.
\]
Chiameremo queste approssimazioni $\y_k \approx \y(t_k)$, per $k = 1,2,\dots, n$. Vediamo un esempio qui sotto. Notare che i punti neri \emph{non} stanno esattamente sul grafico della funzione.

\begin{tikzpicture}
  % Plot the smooth function
  \begin{axis}[
      domain=0:6.28,
      samples=100,
      width=10cm,
      height=6cm,
      axis lines=left,
      ymin=0, ymax=1,
      xmin=0, xmax=1,
      ytick={-1,0,1},
      xtick={0,0.2,0.4,0.6,0.8,1},
      xticklabels={$a=t_0$,$t_1$,$t_2$,$t_3$,$t_4$,$t_5=b$},
      legend style={at={(0.97,0.97)},anchor=north east}
    ]
    % Smooth function
    \addplot [blue, thick, domain=0:1, samples=200] {exp(-x)};
    \addlegendentry{soluzione $y(t)$}
    
    % Zigzag approximation points
    \addplot [
      mark=*,
      only marks,
      black,
    ]  coordinates {
      (0,1) (0.2,0.8) (0.4, 0.7) (0.6, 0.6) (0.8, 0.4) (1, 0.3)
    };
    \addlegendentry{approssimazioni $y_k$}

    \node[pin=below:{$y_4$}] at (axis cs:0.8,0.4) {};
    \node[pin=above:{$y(t_4)$}] at (axis cs:0.8,0.4493) {};
    \addplot[only marks, blue, mark=*] coordinates {(0.8,0.4493)};

  \end{axis}
\end{tikzpicture}

Vediamo subito alcuni algoritmi particolarmente semplici.

\section{Metodi a un passo}

\paragraph{Metodo di Eulero esplicito}

Facendo uno sviluppo di Taylor in $t_k$, abbiamo
\begin{equation} \label{euleroesp_taylor}
    \y(t_{k+1}) = \y(t_k) + \y'(t_k)h + \mathcal{O}(h^2) = \y(t_k) + \f(t_k, \y_k)h + \mathcal{O}(h^2)
\end{equation}
Se ignoriamo il resto $\mathcal{O}(h^2)$ e rimpiazziamo $\y(t_k), \y(t_{k+1})$ con le loro approssimazioni sui punti della griglia, otteniamo
\[
\y_{k+1} = \y_k + h \f(t_k, \y_k).
\]
Questa formula definisce una sequenza di valori approssimati $y_k$: ci permette di calcolare $\y_{k+1}$ a partire da $\y_k$. Otteniamo quindi il \emph{metodo di Eulero esplicito}
\begin{equation} \label{euleroesplicito}
    \y_{k+1} = \y_k + h \f_k, \quad k = 0,1,2,\dots,n-1,
\end{equation}
dove abbiamo posto $\f_k = \f(t_k, \y_k)$ per brevità.

Il metodo di Eulero esplicito, quindi, consiste nel calcolare una dopo l'altra le seguenti quantità:
\begin{align*}
    \y_0 &\phantom{{}={}} \text{dato},\\
    \y_1 &= \y_0 + h \f(t_0,\y_0),\\
    \y_2 &= \y_1 + h \f(t_1,\y_1),\\
    \vdots& \quad \vdots\\
    \y_n &= \y_{n-1} + h \f(t_{n-1},\y_{n-1}).
\end{align*}
Il costo computazionale è di $n$ valutazioni di $\f$, più $\mathcal{O}(mn)$ operazioni aritmetiche. Come per altri metodi, l'operazione più costosa qui è la valutazione della funzione, quindi sostanzialmente il costo è di $n$ valutazioni della funzione, una per passo.

Calcoliamo esplicitamente la successione generata dal metodo in un caso semplice, il problema test~\eqref{testproblem}. Si ha
\[
    y_{k+1} = y_k + hf(t_k,y_k) = y_k + h\lambda y_k = (1+h\lambda)y_k,
\]
quindi ad ogni passo il valore precedente viene moltiplicato per $(1+h\lambda)$. Otteniamo
\[
y_0 = 1, \quad y_1 = (1+h\lambda), \quad y_2 = (1+h\lambda)^2, \quad \dots \quad y_n = (1+h\lambda)^n.
\]
Abbiamo quindi, ricordando che $h = \frac{b-a}{n} = 1/n$,
\[
    y_n = \left(1+\frac{\lambda}{n}\right)^n.
\]
Questa quantità è l'approssimazione prodotta dal metodo per $y(t_n) = y(1) = e^{\lambda}$. Per un limite notevole che avete visto nel corso di analisi,
\[
    \lim_{n\to \infty} y_n = \lim_{n\to \infty} \left(1+\frac{\lambda}{n}\right)^n = e^{\lambda}.
\]
Questo limite ci dice che, almeno per questo problema semplice, il valore di $y_n$ converge al valore esatto di $y(t_n)$, quando il numero di sottointervalli $n$ tende a infinito. Vedremo più avanti che il metodo converge anche per molti altri problemi.

\paragraph{Metodo di Eulero implicito}

Facendo invece uno sviluppo di Taylor con centro in $t_{k+1}$, abbiamo
\begin{equation} \label{euleroimp_taylor}
    \y(t_k) = \y(t_{k+1}) - \y'(t_{k+1})h + \mathcal{O}(h^2),    
\end{equation}
che operando nello stesso modo conduce alla relazione
\begin{equation} \label{euleroimplicito}
    \y_{k+1} = \y_k + h \underbrace{\f(t_{k+1}, \y_{k+1})}_{\f_{k+1}}.    
\end{equation}
La differenza importante è che questa volta la $\y_{k+1}$ compare anche al secondo termine, nascosta dentro il termine $\f_{k+1}$. Quindi non possiamo calcolare direttamente $\y_{k+1}$ a partire da $\y_k$: ci servirebbe conoscere $\y_{k+1}$ per calcolare $\f_{k+1}$. L'equazione \eqref{euleroimplicito} è un'equazione che definisce implicitamente $\y_{k+1}$. È necessario risolverla per calcolare $\y_{k+1}$. 

Per alcune equazioni differenziali, questa equazione è semplice da risolvere. Per esempio, consideriamo il problema test~\eqref{testproblem}: si ha
\[
    y_{k+1} = y_k + h\lambda y_{k+1};
\]
questa è un'equazione di grado 1 nella $y_{k+1}$; risolvendola otteniamo
\[
y_{k+1} = \frac{1}{1-h\lambda} y_k.
\]

Per equazioni differenziali più complicate, possiamo per esempio vedere la~\eqref{euleroimplicito} come un'equazione di punto fisso: per ogni $k$ fissato generiamo una successione
\[
\z_0 = \y_k, \quad \z_{j+1} = \y_k + h \f(t_{k+1}, \z_j), \quad j=0,1,2,\dots
\]
che (sperabilmente) converge a una soluzione $\lim_{j\to\infty} \z_j = \y_{k+1}$. Oppure possiamo utilizzare il metodo di Newton. 

In ogni caso, si chiama \emph{metodo di Eulero implicito} il metodo in cui si calcola $\y_{k+1}$ a partire da $\y_k$ risolvendo la~\eqref{euleroimplicito} (in qualche modo) ad ogni passo per $k=0,1,2,\dots,n-1$. Il costo computazionale dipende dal modo in cui risolviamo la~\eqref{euleroimplicito}.

%%
% Spostare più avanti, e usare come esempio introduttivo per parlare di ordine di consistenza / convergenza?
%%

\paragraph{Metodo dei trapezi}
È il metodo
\begin{equation} \label{mettrapezi}
    \y_{k+1} = \y_k + h\left(\frac12 \f_k + \frac12 \f_{k+1}\right).    
\end{equation}
Al membro di destra abbiamo una sorta di ``media'' tra il metodo di Eulero esplicito e di quello implicito. Il metodo ha questo nome perché si può ottenere scrivendo
\[
\y(t_{k+1}) = \y(t_k) + \int_{t_k}^{t_{k+1}} \y'(t) dt = \y(t_k) + \int_{t_k}^{t_{k+1}} \f(t,\y(t)) dt
\]
e approssimando l'integrale con la formula dei trapezi otteniamo la~\eqref{mettrapezi}. Il vantaggio di questo metodo rispetto ai due metodi di Eulero è che l'errore che commettiamo è minore: difatti, applicando il metodo dei trapezi per integrare una funzione su un intervallo di lunghezza $h$, commettiamo un errore dell'ordine di $\mathcal{O}(h^3)$:
\begin{equation} \label{trapezi_taylor}
    \y(t_{k+1}) = \y(t_k) + \int_{t_k}^{t_{k+1}} \f(t,\y(t)) dt = \y(t_k) + \frac{h}{2}(\f_k + \f_{k+1}) + \mathcal{O}(h^3).
\end{equation}
% TODO: cambia f_k vs. f(t_k,y_k)
\paragraph{Convergenza del metodo di Eulero esplicito (*)}
Vedremo tra poco l'enunciato di un risultato generale che dice che le sequenze di approssimazioni prodotte da questi metodi convergono alla soluzione esatta dell'equazione~\eqref{cauchy}. Vogliamo però dare una dimostrazione esplicita della convergenza almeno per il caso più semplice, quello del metodo di Eulero esplicito per un problema scalare con $m=1$.

Prima di tutto, definiamo cosa intendiamo per ``convergenza''. Data un'equazione differenziale~\eqref{cauchy} con soluzione $\y(t)$, e una sequenza di approssimazioni $\y_k \approx \y(t_k)$ su una griglia $(t_0,t_1,\dots,t_n)$, chiamiamo \emph{errore globale} la quantità
\begin{equation} \label{globalerror}
    E_n = \max_{k=1,2,\dots,n} e_k, \quad e_k = \norm{\y_k - \y(t_k)},
\end{equation}
cioè il massimo tra gli errori $e_k$ calcolati su tutti punti della griglia; ognuno di questi errori è la differenza (in norma, o in valore assoluto se $m=1$) tra la sequenza e la funzione che essa vuole approssimare. Al crescere del numero di punti $n$, ci aspettiamo che l'errore globale $E_n$ ottenuto con il metodo di Eulero diminuisca.

Intuitivamente, l'errore $e_{k+1}$ al passo $k+1$ viene da due fonti: la prima è che abbiamo un errore $e_k$ ``ereditato'' dai passi precedenti, per cui non applichiamo la nostra formula a partire dal valore esatto $\y(t_k)$, ma dalla sua approssimazione $\y_k$. La seconda è che, anche se partissimo dal valore esatto, la formula che usiamo per calcolare il passo successivo è approssimata: difatti l'abbiamo ottenuta trascurando il resto $\mathcal{O}(h^2)$ dallo sviluppo di Taylor~\eqref{euleroesp_taylor}.

Per dimostrare il nostro teorema, chiediamo un'ipotesi sulla funzione $\f(t,\y)$ che compare nella~\ref{cauchy}. Diciamo che $\f$ è \emph{Lipschitziana} nella variabile $\y$ (con costante $L$) se esiste un numero reale $L \geq 0$ tale che per ogni $t\in [a,b]$ e $\y_1,\y_2\in\mathbb{R}^m$ vale
\[
\norm{f(t, \y_1) - f(t, \y_2)} \leq L\norm{\y_1 - \y_2}.
\]
Questa proprietà ricorda un po' le proprietà di buon condizionamento: facendo una piccola perturbazione (assoluta, questa volta) dell'input $\y$, l'output $\f(t,\y)$ varia di al più questa perturbazione moltiplicata per un fattore $L$. Forse avete già visto questa proprietà ad analisi, perché è la stessa che serve per dimostrare l'esistenza di soluzioni di un problema ai valori iniziali~\eqref{cauchy}.

Quando $m=1$ (e quindi al posto delle norme abbiamo dei valori assoluti), un modo di assicurare questa proprietà, per esempio, è provare che la $f$ ha derivata parziale limitata $\abs*{\frac{\partial f}{\partial y}(t,y)} \leq L$ per ogni valore di $t,y$: difatti, il teorema di Lagrange ci assicura che per un certo $\xi$ compreso tra $y_1$ e $y_2$ vale
\[
f(t, y_1) - f(t, y_2) = \frac{\partial f}{\partial y}(t,\xi) (y_1 - y_2).
\]

\begin{theorem}
Sia dato un problema ai valori iniziali~\eqref{cauchy} con $m=1$. Supponiamo che la funzione $f$ sia Lipschitziana nella $y$ con costante $L$, e che la soluzione $y(t)$ sia di classe $\mathcal{C}^2$ su $[a,b]$. Allora, $\lim_{n\to \infty} E_n = 0$, e più precisamente $E_n = \mathcal{O}(h)$ (cioè, esiste una costante $C>0$ tale che $E_n \leq Ch$).
\end{theorem}
Solitamente gli errori si scrivono come ordini rispetto a $h = \frac{b-a}{n}$, come qui sopra, ma visto che $b-a$ è costante questo vuol dire che al crescere del numero di punti $n$ la soluzione tende a zero come $1/n$.
\begin{proof}
Innanzitutto, poiché la soluzione $y(t)$ è una funzione di classe $\mathcal{C}^2$, per il teorema di Weierstrass esiste
\[
C_2 = \max_{t\in [a,b]} \abs{y''(t)}.
\]
Andiamo quindi a enunciare il nostro risultato di convergenza.
    
Siamo interessati a stimare la quantità $e_k = \abs{y_k - y(t_k)}$ per ogni passo $k=0,1,\dots,n$. Per fare questo, utilizziamo una strategia che abbiamo già visto in altre dimostrazioni del corso: cerchiamo di scrivere $e_{k+1}$ in funzione di $e_k$. Per farlo, scriviamo
\begin{align*}
y_{k+1} &= y_k + h f(t_k, y_k),\\
y(t_{k+1}) &= y(t_k) + h \underbrace{y'(t_k)}_{=f(t_k,y(t_k))} + \frac{h^2}{2} y''(\xi),
\end{align*}
dove la seconda equazione è uno sviluppo di Taylor. Sottraendo membro a membro e prendendo valori assoluti abbiamo
\begin{align*}
    e_{k+1} &= \abs*{y_{k+1} - y(t_{k+1})} = \abs*{y_k - y(t_k) + h(f(t_k,y_k) - f(t_k,y(t_k))) - \frac{h^2}{2} y''(\xi)}\\
            & \leq \abs*{y_k - y(t_k)} + h \abs*{f(t_k,y_k) - f(t_k,y(t_k))} + \frac{h^2}{2} \abs*{y''(\xi)}\\
            & \leq e_k + hL e_k + \frac{h^2}{2}C_2 = (1+hL) e_k + \frac{h^2}{2}C_2.
\end{align*}
Per semplificare la notazione nei passaggi successivi, poniamo $A = 1+hL$ e $B = \frac{h^2}{2}C_2$; in questo modo la relazione che abbiamo trovato diventa $e_{k+1} \leq A e_k + B$. Possiamo dare una limitazione dell'errore non ricorsiva ragionando per passi successivi: partendo da $e_0 = y_0 - y(0) = 0$, abbiamo
\begin{align*}
    e_1 &\leq B,\\
    e_2 &\leq Ae_1 + B = (A + 1)B,\\    
    e_3 &\leq Ae_2 + B = (A^2 + A +1)B,\\
    \vdots & \quad\quad\vdots\\
    e_n &\leq (A^{n-1}+ \dots + A^2 + A + 1)B.
\end{align*}
Chiaramente tra tutti questi termini il più grande è l'ultimo; quindi vale la disuguaglianza
\[
E_n = \max(e_1,e_2,\dots,e_n) \leq (A^{n-1}+ \dots + A^2 + A + 1)B.
\]
Vogliamo ora determinare qual è il limite di $(A^{n-1}+ \dots + A^2 + A + 1)B$ quando $n\to\infty$; questo non è immediato, visto che non solo $A$ e $B$ sono funzioni di $h = \frac{b-a}{n}$, ma anche il numero di termini nella somma dipende da $n$. Cominciamo col semplificare la quantità
\[
    (A^{n-1}+ \dots + A^2 + A + 1) = \frac{A^n-1}{A-1} = \frac{(1+hL)^n-1}{1+hL-1} = \frac{\left(1+\frac{(b-a)L}{n}\right)^n-1}{hL}.
\]
Riconosciamo di nuovo la possibilità di applicare il limite notevole
\[
    \lim_{n\to \infty} \left(1+\frac{x}{N}\right)^n = e^{x}.
\]
Nei corsi di analisi probabilmente avete anche dimostrato che questo limite tende a $e^{x}$ \emph{dal basso}, quindi si ha per ogni $n$
\[
    \left(1+\frac{(b-a)L}{n}\right)^N \leq e^{(b-a)L}.
\]
Pertanto rimettendo insieme tutti i pezzi abbiamo per ogni $k=1,2,\dots,n$
\[
E_n \leq (A^{n-1}+ \dots + A^2 + A + 1)B \leq \frac{e^{(b-a)L}-1}{hL} \frac{h^2}{2}C_2 = \frac{(e^{(b-a)L}-1) C_2}{2L} h.
\]
Le quantità $C_2, L, b-a$ sono costanti che non dipendono da $N$, quindi possiamo affermare che $E_n = \mathcal{O}(h)$.
\end{proof}

\paragraph{Metodi generali a un passo}

In generale possiamo scrivere un metodo a un passo come
\begin{equation} \label{metodoaunpasso}
    \y_{k+1} = \y_k + h\Phi(t_k,\y_k)    
\end{equation}
per un'opportuna funzione $\Phi$: anche se nella sua espressione compaiono $t_{k+1},\y_{k+1}$, ecc., possiamo comunque considerarla come una funzione di quei soli due argomenti, perché il valore $\y_{k+1}$ si può calcolare a partire dai soli $t_k$ e $\y_k$ (conoscendo il valore di $h$ e l'espressione per $\f$); non serve conoscere altre quantità come per esempio il valore di $\y_{k-1}$.

Vogliamo dare un risultato generale di convergenza per questi metodi. Per questo ci serve introdurre alcune definizioni. Innanzitutto, diciamo che un metodo è \emph{convergente di ordine $p$} (per un qualche $p>0$) se $E_n = \mathcal{O}(h^p)$; quindi per esempio più sopra abbiamo dimostrato che il metodo di Eulero esplicito è convergente di ordine $1$.

Oltre all'errore globale $E_n$ definito più sopra, definiamo anche l'\emph{errore locale di troncamento} come
\[
T_n = \max_{k=0,1,\dots,n-1} \norm{\boldsymbol{\tau}_k}, \quad \boldsymbol{\tau}_k = \y(t_{k+1}) - \y(t_k) - h\Phi(t_k, \y(t_k)) ,
\]
cioè la differenza tra il valore esatto della soluzione $\y(t_{k+1})$ e il valore $\y(t_k) + h\Phi(t_k, \y(t_k))$ calcolato tramite un passo dell'algoritmo a partire dal valore esatto $\y(t_k)$. Abbiamo già incontrato questa quantità nella derivazione dei tre metodi che abbiamo visto: è il termine $\mathcal{O}(h^2)$ che compare nelle equazioni~\eqref{euleroesp_taylor} e~\eqref{euleroimp_taylor}, e il termine $\mathcal{O}(h^3)$ che compare nella~\eqref{trapezi_taylor}.

Un metodo si dice \emph{consistente di ordine $p$} se $T_n = \mathcal{O}(h^{p+1})$ nel limite quando il numero di passi tende a $n\to \infty$ (e quindi $h \to 0$). La logica dietro a questa definizione è la stessa dietro a quella delle formule per l'errore nelle formule di integrazione: visto che stiamo considerando un intervallo di lunghezza $h$, ci aspettiamo di avere un fattore pari alla lunghezza $h$ dell'intervallo nella formula dell'errore, e quindi per definire l'ordine consideriamo solo l'altro fattore: diciamo che l'ordine di un metodo è $p$ se la distanza tra $\y(t_{k+1})$ e $\y(t_k) - h\Phi(t_k, \y(t_k))$ si scrive nella forma $h \cdot \mathcal{O}(h^p)$.

Queste definizioni si applicano quando abbiamo un'equazione differenziale con soluzione $\y(t)$ sufficientemente regolare; per esempio, ci serve avere una funzione di classe almeno $\mathcal{C}^2$ per scrivere la~\eqref{euleroesp_taylor}.

Il metodo di Eulero esplicito è consistente di ordine $1$; difatti abbiamo ottenuto
\[
\y(t_{k+1}) = \y(t_k) + \y'(t_k)h + \mathcal{O}(h^2),
\]
quindi
\[
\norm*{\y(t_{k+1}) - \y(t_k) - h \f(t_k, \y(t_k))} = \mathcal{O}(h^2) = h \cdot \mathcal{O}(h^1).
\]
Stessa cosa per il metodo di Eulero implicito. Invece il metodo dei trapezi è consistente di ordine $2$.

\paragraph{Convergenza dei metodi a un passo}
Vale il seguente risultato. Non lo dimostriamo, ma la dimostrazione è simile a quella che abbiamo visto sopra per il metodo di Eulero esplicito.
\begin{theorem}
Supponiamo di avere un metodo a un passo in cui la funzione $\Phi(t,\y)$ sia continua in $[a,b] \times \mathbb{R}^m$ e Lipschitziana nella $\y$, con una costante $L$ che non dipende da $h$.
Allora, un metodo è convergente di ordine~$p$ se e solo se è consistente di ordine~$p$.
\end{theorem}


\paragraph{Metodi di Runge--Kutta} I metodi di Runge--Kutta sono una classe più generale di metodi a un passo (quindi definiti da una $\Phi(t_k,\y_k)$ come nella~\eqref{metodoaunpasso}). Avendo una maggiore quantità di parametri, essi possono raggiungere ordini di consistenza e convergenza maggiori. Un metodo di Runge--Kutta si definisce tramite parametri che vengono convenzionalmente raccolti in una tabella, detta \emph{tavola} (o \emph{tableau}) \emph{di Butcher}:
\[
\begin{array}{c|cccc}
c_1 & a_{11} & a_{12} & \dots & a_{1s}\\
c_2 & a_{21} & a_{22} & \dots & a_{2s}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
c_s & a_{s1} & a_{s2} & \dots & a_{ss}\\
\hline
& b_1 & b_2 & \dots & b_s
\end{array}.
\]
L'intero $s$ è detto \emph{numero di stadi} del metodo. A partire dai coefficienti in questa tabella possiamo definire la funzione $\Phi(t_k,y_k)$ in questo modo: definiamo
\begin{align*}
    \mathbf{k}_i &= \mathbf{f}\left(t_k + c_i h, \y_k + h\left(\sum_{j=1}^s a_{ij}\mathbf{k}_j\right)\right), & i&=1,2,\dots,s,\\
    \Phi(t_k, \mathbf{y}_k) &= \sum_{j=1}^s b_j \mathbf{k}_j.
\end{align*}
La funzione $\Phi(t_k, \mathbf{y}_k)$ definita in questo modo è quella che compare nella definizione di metodo a un passo~\eqref{metodoaunpasso}.

Un metodo di Runge--Kutta è \emph{esplicito} se nella tavola di Butcher la matrice
\[
    A = \begin{bmatrix}
        a_{11} & \dots & a_{1s}\\
        \vdots & \ddots & \ddots\\
        a_{s1} & \dots & a_{ss}
    \end{bmatrix}
\]
è strettamente triangolare superiore, cioè $a_{ij}=0$ se $i \leq j$ (inclusi gli elementi sulla diagonale). In questo caso è possibile calcolare esplicitamente i valori di $\mathbf{k}_i$ uno per volta a partire dal primo. Altrimenti abbiamo un metodo \emph{implicito}: è necessario risolvere un sistema di equazioni non-lineari per calcolare i $\mathbf{k}_i$, analogamente a quello che succede nel metodo di Eulero implicito.

\paragraph{Esempio: un metodo esplicito}
Consideriamo il metodo con tavola di Butcher
\[
\begin{array}{c|cc}
0 & 0 & 0\\
1 & 1 & 0\\
\hline
& \frac12 & \frac12
\end{array}.
\]
Scrivendo esplicitamente le relazioni otteniamo
\begin{align*}
\mathbf{k}_1 &= \mathbf{f}(t_k + 0 \cdot h, \mathbf{y}_k + h(0\cdot \mathbf{k}_1 + 0\cdot \mathbf{k}_2)) = \mathbf{f}(t_k,\mathbf{y}_k),\\
\mathbf{k}_2 &= \mathbf{f}(t_k + 1 \cdot h, \mathbf{y}_k + h(1\cdot \mathbf{k}_1 + 0\cdot \mathbf{k}_2)) = \mathbf{f}(t_{k+1},\mathbf{y}_k+\mathbf{k}_1),\\
\mathbf{y}_{k+1} &= \mathbf{y}_k + \frac12 \mathbf{k}_1 + \frac12 \mathbf{k}_2 = \mathbf{y}_k + \frac12 \left(\mathbf{f}(t_k,\mathbf{y}_k) + \mathbf{f}(t_{k+1},\mathbf{y}_k+ \mathbf{f}(t_k,\mathbf{y}_k))\right).
\end{align*}
Questo metodo è noto come \emph{metodo di Heun}; si può mostrare che ha ordine $p=2$. È interessante notare che è una sorta di ``variante esplicita'' del metodo dei trapezi: al posto di $\mathbf{y}_{k+1}$ nel membro di destra usiamo la sua approssimazione $\mathbf{y}_k+ \mathbf{f}(t_k,\mathbf{y}_k)$ ottenuta con il metodo di Eulero esplicito.

\paragraph{Esempio: un metodo implicito}
Consideriamo il metodo con tavola di Butcher
\[
\begin{array}{c|cc}
\frac14 & \frac14 & 0\\
\frac34 & \frac12 & \frac14\\
\hline
& \frac12 & \frac12
\end{array}.
\]
Scritte per esteso, questo metodo diventa
\begin{align*}
    \mathbf{k}_1 &= \mathbf{f}(t_k + \frac14 h, \mathbf{y}_k +  \frac14 h \mathbf{k}_1),\\
    \mathbf{k}_2 &= \mathbf{f}(t_k + \frac34 h, \mathbf{y}_k + h(\frac12 \mathbf{k}_1 + \frac14 \mathbf{k}_2)),\\
    \mathbf{y}_{k+1} &= \mathbf{y}_k + \frac12 \mathbf{k}_1 + \frac12 \mathbf{k}_2.
\end{align*}
Questa volta il metodo è implicito: l'equazione per $\mathbf{k}_1$ contiene $\mathbf{k}_1$ stesso al membro di destra, quindi possiamo risolverla solo implicitamente; analogamente per l'equazione per $\mathbf{k}_2$. Notiamo che questo caso è un caso un po' più semplice di quello generale: visto che la prima equazione dipende solo da $\mathbf{k}_1$, possiamo risolvere un'equazione per volta, anziché considerarlo come un sistema di due equazioni nelle due incognite $\mathbf{k}_1$ e $\mathbf{k}_2$, come succederebbe nel caso più generale in cui $a_{12}\neq 0$.

Esercizio: che formula esplicita si ottiene applicando questo metodo al problema test $y' = \lambda y$?

\paragraph{Altri metodi visti come metodi di Runge--Kutta}
I metodi che abbiamo visto in precedenza sono tutti casi particolari dei metodi di Runge--Kutta. Per il metodo di Eulero esplicito abbiamo $s=1$ e tavola di Butcher
\[
\begin{array}{c|c}
0 & 0\\
\hline
 & 1
\end{array},
\]
per il metodo di Eulero implicito
\[
\begin{array}{c|c}
1 & 1\\
\hline
 & 1
\end{array},
\]
e per il metodo dei trapezi $s=2$ (difatti ci sono due diverse valutazioni di funzione) e 
\[
\begin{array}{c|cc}
0 & 0 & 0\\
1 & \frac12 & \frac12\\
\hline
& \frac12 & \frac12
\end{array}.
\]
Per derivare le tavole degli ultimi due metodi abbiamo dovuto risostituire la relazione finale per scrivere il termine $\y_{k+1}$ che compare dentro $\mathbf{f}_{k+1}$ nella forma $\y_k + h(\dots)$.

Nella pratica, i metodi di Runge--Kutta sono usati con scelte particolari dei coefficienti fatte in modo da ottenere un alto ordine di consistenza (e quindi di convergenza). Per esempio Matlab utilizza in una delle sue funzioni per risolvere equazioni differenziali (\lstinline{ode45}) un metodo con tavola di Butcher
\[
\begin{array}{c|ccccccc}
    0\\
    1/5 &    1/5\\
    3/10 &   3/40 &   9/40\\
    4/5 &    44/45 &  -56/15 &  32/9\\
    8/9   &  19372/6561 & -25360/2187  &   64448/6561 & -212/729\\
    1 &  9017/3168  & -355/33   &  46732/5247 & 49/176 & -5103/18656\\
    1 &  35/384 & 0 &  500/1113  &  125/192   &  -2187/6784 & 11/84   \\
    \hline
    &  35/384 & 0 &  500/1113  &  125/192   &  -2187/6784 & 11/84 & 0  \\
%    & \frac{5179}{57600} & 0 & \frac{7571}{16695} & \frac{393}{640} & -\frac{92097}{339200} & \frac{187}{2100} & \frac{1}{40}
\end{array},
\]
che ha $s=7$ stadi e ordine di convergenza $p=5$ (\emph{metodo di Dormand--Prince}).

Esistono molte altre possibili scelte dei coefficienti; si veda per esempio \href{https://en.wikipedia.org/wiki/List_of_Runge%E2%80%93Kutta_methods}{questa lista} su Wikipedia.

\paragraph{Problemi stiff}

Il risultato di convergenza che abbiamo visto ci dice cosa succede al limite $h \to 0$; però ci sono differenze importanti tra un metodo e l'altro che riguardano quello che succede con un valore \emph{finito} di $h$. In particolare, in diversi esperimenti numerici, riducendo il numero di passi $n$ il metodo di Eulero esplicito produce sequenze $\y_k$ che cominciano a oscillare, e poi riducendo ancora $n$ assumono valori molto grandi, anche quando la soluzione vera dell'equazione differenziale è una funzione monotona. Vediamo un esempio in Figura~\ref{fig: esempio Eulero esplicito problema stiff}.

\begin{figure}
\begin{center}
    \begin{tikzpicture}
        \begin{axis}[title={$n=1000$}, width=\textwidth, height=0.25\textheight, ylabel={$y$}]
            \addplot+[mark=none, thick] table{
         x    y
         0    0.5000
    0.0100    0.4520
    0.0200    0.4449
    0.0300    0.4421
    0.0400    0.4399
    0.0500    0.4377
    0.0600    0.4355
    0.0700    0.4333
    0.0800    0.4312
    0.0900    0.4290
    0.1000    0.4269
    0.1100    0.4248
    0.1200    0.4227
    0.1300    0.4206
    0.1400    0.4185
    0.1500    0.4164
    0.1600    0.4143
    0.1700    0.4123
    0.1800    0.4102
    0.1900    0.4082
    0.2000    0.4061
    0.2100    0.4041
    0.2200    0.4021
    0.2300    0.4001
    0.2400    0.3981
    0.2500    0.3961
    0.2600    0.3942
    0.2700    0.3922
    0.2800    0.3902
    0.2900    0.3883
    0.3000    0.3864
    0.3100    0.3844
    0.3200    0.3825
    0.3300    0.3806
    0.3400    0.3787
    0.3500    0.3769
    0.3600    0.3750
    0.3700    0.3731
    0.3800    0.3713
    0.3900    0.3694
    0.4000    0.3676
    0.4100    0.3657
    0.4200    0.3639
    0.4300    0.3621
    0.4400    0.3603
    0.4500    0.3585
    0.4600    0.3567
    0.4700    0.3550
    0.4800    0.3532
    0.4900    0.3514
    0.5000    0.3497
    0.5100    0.3479
    0.5200    0.3462
    0.5300    0.3445
    0.5400    0.3428
    0.5500    0.3411
    0.5600    0.3394
    0.5700    0.3377
    0.5800    0.3360
    0.5900    0.3343
    0.6000    0.3327
    0.6100    0.3310
    0.6200    0.3294
    0.6300    0.3277
    0.6400    0.3261
    0.6500    0.3245
    0.6600    0.3229
    0.6700    0.3212
    0.6800    0.3196
    0.6900    0.3181
    0.7000    0.3165
    0.7100    0.3149
    0.7200    0.3133
    0.7300    0.3118
    0.7400    0.3102
    0.7500    0.3087
    0.7600    0.3071
    0.7700    0.3056
    0.7800    0.3041
    0.7900    0.3026
    0.8000    0.3011
    0.8100    0.2996
    0.8200    0.2981
    0.8300    0.2966
    0.8400    0.2951
    0.8500    0.2937
    0.8600    0.2922
    0.8700    0.2907
    0.8800    0.2893
    0.8900    0.2879
    0.9000    0.2864
    0.9100    0.2850
    0.9200    0.2836
    0.9300    0.2822
    0.9400    0.2808
    0.9500    0.2794
    0.9600    0.2780
    0.9700    0.2766
    0.9800    0.2752
    0.9900    0.2738
    1.0000    0.2725
            };
    
    \end{axis}
    \end{tikzpicture}
    
    \begin{tikzpicture}
        \begin{axis}[title={$n=130$}, width=\textwidth, height=0.25\textheight, ylabel={$y$}]
            \addplot+[mark=none, thick] table{
         x    y
         0    0.5000
    0.0077    0.4192
    0.0154    0.4604
    0.0231    0.4354
    0.0308    0.4463
    0.0385    0.4378
    0.0462    0.4398
    0.0538    0.4361
    0.0615    0.4355
    0.0692    0.4333
    0.0769    0.4319
    0.0846    0.4301
    0.0923    0.4286
    0.1000    0.4269
    0.1077    0.4252
    0.1154    0.4236
    0.1231    0.4220
    0.1308    0.4204
    0.1385    0.4187
    0.1462    0.4171
    0.1538    0.4155
    0.1615    0.4139
    0.1692    0.4124
    0.1769    0.4108
    0.1846    0.4092
    0.1923    0.4076
    0.2000    0.4061
    0.2077    0.4045
    0.2154    0.4030
    0.2231    0.4014
    0.2308    0.3999
    0.2385    0.3983
    0.2462    0.3968
    0.2538    0.3953
    0.2615    0.3938
    0.2692    0.3923
    0.2769    0.3908
    0.2846    0.3893
    0.2923    0.3878
    0.3000    0.3863
    0.3077    0.3848
    0.3154    0.3833
    0.3231    0.3818
    0.3308    0.3804
    0.3385    0.3789
    0.3462    0.3775
    0.3538    0.3760
    0.3615    0.3746
    0.3692    0.3731
    0.3769    0.3717
    0.3846    0.3703
    0.3923    0.3689
    0.4000    0.3674
    0.4077    0.3660
    0.4154    0.3646
    0.4231    0.3632
    0.4308    0.3618
    0.4385    0.3605
    0.4462    0.3591
    0.4538    0.3577
    0.4615    0.3563
    0.4692    0.3550
    0.4769    0.3536
    0.4846    0.3522
    0.4923    0.3509
    0.5000    0.3495
    0.5077    0.3482
    0.5154    0.3469
    0.5231    0.3455
    0.5308    0.3442
    0.5385    0.3429
    0.5462    0.3416
    0.5538    0.3403
    0.5615    0.3390
    0.5692    0.3377
    0.5769    0.3364
    0.5846    0.3351
    0.5923    0.3338
    0.6000    0.3325
    0.6077    0.3312
    0.6154    0.3300
    0.6231    0.3287
    0.6308    0.3274
    0.6385    0.3262
    0.6462    0.3249
    0.6538    0.3237
    0.6615    0.3224
    0.6692    0.3212
    0.6769    0.3200
    0.6846    0.3187
    0.6923    0.3175
    0.7000    0.3163
    0.7077    0.3151
    0.7154    0.3139
    0.7231    0.3127
    0.7308    0.3115
    0.7385    0.3103
    0.7462    0.3091
    0.7538    0.3079
    0.7615    0.3067
    0.7692    0.3055
    0.7769    0.3044
    0.7846    0.3032
    0.7923    0.3020
    0.8000    0.3009
    0.8077    0.2997
    0.8154    0.2986
    0.8231    0.2974
    0.8308    0.2963
    0.8385    0.2951
    0.8462    0.2940
    0.8538    0.2929
    0.8615    0.2918
    0.8692    0.2906
    0.8769    0.2895
    0.8846    0.2884
    0.8923    0.2873
    0.9000    0.2862
    0.9077    0.2851
    0.9154    0.2840
    0.9231    0.2829
    0.9308    0.2818
    0.9385    0.2808
    0.9462    0.2797
    0.9538    0.2786
    0.9615    0.2775
    0.9692    0.2765
    0.9769    0.2754
    0.9846    0.2744
    0.9923    0.2733
    1.0000    0.2723
            };
    \end{axis}
    \end{tikzpicture}

\begin{tikzpicture}
        \begin{axis}[title={$n=101$}, width=\textwidth, height=0.25\textheight, ylabel={$y$}]
            \addplot+[mark=none, thick] table{
         x    y
         0    0.5000
    0.0099    0.3960
    0.0198    0.4941
    0.0297    0.3931
    0.0396    0.4882
    0.0495    0.3902
    0.0594    0.4825
    0.0693    0.3873
    0.0792    0.4768
    0.0891    0.3844
    0.0990    0.4712
    0.1089    0.3815
    0.1188    0.4657
    0.1287    0.3786
    0.1386    0.4603
    0.1485    0.3757
    0.1584    0.4549
    0.1683    0.3728
    0.1782    0.4497
    0.1881    0.3699
    0.1980    0.4445
    0.2079    0.3670
    0.2178    0.4393
    0.2277    0.3641
    0.2376    0.4343
    0.2475    0.3612
    0.2574    0.4293
    0.2673    0.3584
    0.2772    0.4244
    0.2871    0.3555
    0.2970    0.4195
    0.3069    0.3527
    0.3168    0.4148
    0.3267    0.3498
    0.3366    0.4101
    0.3465    0.3470
    0.3564    0.4054
    0.3663    0.3442
    0.3762    0.4008
    0.3861    0.3414
    0.3960    0.3963
    0.4059    0.3386
    0.4158    0.3919
    0.4257    0.3358
    0.4356    0.3875
    0.4455    0.3330
    0.4554    0.3831
    0.4653    0.3302
    0.4752    0.3788
    0.4851    0.3275
    0.4950    0.3746
    0.5050    0.3247
    0.5149    0.3705
    0.5248    0.3220
    0.5347    0.3663
    0.5446    0.3193
    0.5545    0.3623
    0.5644    0.3166
    0.5743    0.3583
    0.5842    0.3139
    0.5941    0.3543
    0.6040    0.3112
    0.6139    0.3504
    0.6238    0.3085
    0.6337    0.3466
    0.6436    0.3059
    0.6535    0.3428
    0.6634    0.3033
    0.6733    0.3390
    0.6832    0.3006
    0.6931    0.3353
    0.7030    0.2980
    0.7129    0.3317
    0.7228    0.2954
    0.7327    0.3281
    0.7426    0.2929
    0.7525    0.3245
    0.7624    0.2903
    0.7723    0.3210
    0.7822    0.2878
    0.7921    0.3175
    0.8020    0.2852
    0.8119    0.3141
    0.8218    0.2827
    0.8317    0.3107
    0.8416    0.2802
    0.8515    0.3073
    0.8614    0.2778
    0.8713    0.3040
    0.8812    0.2753
    0.8911    0.3008
    0.9010    0.2728
    0.9109    0.2975
    0.9208    0.2704
    0.9307    0.2944
    0.9406    0.2680
    0.9505    0.2912
    0.9604    0.2656
    0.9703    0.2881
    0.9802    0.2632
    0.9901    0.2850
    1.0000    0.2609
            };
    \end{axis}
    \end{tikzpicture}

\begin{tikzpicture}
        \begin{axis}[title={$n=80$}, width=\textwidth, height=0.25\textheight, ylabel={$y$}]
            \addplot+[mark=none, thick] table{
         x    y

            0   5.0000e-01
   1.2500e-02   3.6875e-01
   2.5000e-02   5.5945e-01
   3.7500e-02   2.6525e-01
   5.0000e-02   7.0149e-01
   6.2500e-02   3.7537e-02
   7.5000e-02   1.0308e+00
   8.7500e-02  -4.7210e-01
   1.0000e-01   1.7849e+00
   1.1250e-01  -1.6215e+00
   1.2500e-01   3.5028e+00
   1.3750e-01  -4.2223e+00
   1.5000e-01   7.4072e+00
   1.6250e-01  -1.0116e+01
   1.7500e-01   1.6272e+01
   1.8750e-01  -2.3483e+01
   2.0000e-01   3.6393e+01
   2.1250e-01  -5.3802e+01
   2.2500e-01   8.2049e+01
   2.3750e-01  -1.2258e+02
   2.5000e-01   1.8564e+02
   2.6250e-01  -2.7863e+02
   2.7500e-01   4.2068e+02
   2.8750e-01  -6.3268e+02
   3.0000e-01   9.5396e+02
   3.1250e-01  -1.4359e+03
   3.2500e-01   2.1639e+03
   3.3750e-01  -3.2584e+03
   3.5000e-01   4.9090e+03
   3.6250e-01  -7.3933e+03
   3.7500e-01   1.1137e+04
   3.8750e-01  -1.6775e+04
   4.0000e-01   2.5268e+04
   4.1250e-01  -3.8059e+04
   4.2500e-01   5.7329e+04
   4.3750e-01  -8.6351e+04
   4.5000e-01   1.3007e+05
   4.6250e-01  -1.9592e+05
   4.7500e-01   2.9510e+05
   4.8750e-01  -4.4450e+05
   5.0000e-01   6.6954e+05
   5.1250e-01  -1.0085e+06
   5.2500e-01   1.5191e+06
   5.3750e-01  -2.2881e+06
   5.5000e-01   3.4465e+06
   5.6250e-01  -5.1914e+06
   5.7500e-01   7.8196e+06
   5.8750e-01  -1.1778e+07
   6.0000e-01   1.7741e+07
   6.1250e-01  -2.6723e+07
   6.2500e-01   4.0253e+07
   6.3750e-01  -6.0631e+07
   6.5000e-01   9.1326e+07
   6.6250e-01  -1.3756e+08
   6.7500e-01   2.0720e+08
   6.8750e-01  -3.1211e+08
   7.0000e-01   4.7011e+08
   7.1250e-01  -7.0812e+08
   7.2500e-01   1.0666e+09
   7.3750e-01  -1.6066e+09
   7.5000e-01   2.4200e+09
   7.6250e-01  -3.6451e+09
   7.7500e-01   5.4905e+09
   7.8750e-01  -8.2702e+09
   8.0000e-01   1.2457e+10
   8.1250e-01  -1.8764e+10
   8.2500e-01   2.8263e+10
   8.3750e-01  -4.2572e+10
   8.5000e-01   6.4124e+10
   8.6250e-01  -9.6588e+10
   8.7500e-01   1.4549e+11
   8.8750e-01  -2.1914e+11
   9.0000e-01   3.3009e+11
   9.1250e-01  -4.9720e+11
   9.2500e-01   7.4891e+11
   9.3750e-01  -1.1281e+12
   9.5000e-01   1.6992e+12
   9.6250e-01  -2.5594e+12
   9.7500e-01   3.8551e+12
   9.8750e-01  -5.8068e+12
   1.0000e+00   8.7466e+12
    };
    \end{axis}
    \end{tikzpicture}
\end{center}
\caption{Metodo di Eulero esplicito su $\mathbf{y}' = -\begin{bsmallmatrix}101 & 100\\ 100 & 100\end{bsmallmatrix}\mathbf{y}$, prima componente, con diversi valori di $n$.} \label{fig: esempio Eulero esplicito problema stiff}
\end{figure}

Un modo per investigare cosa succede è attraverso il ``problema test'', \eqref{testproblem}. Prendiamo un problema test con $\lambda < 0$; la sua soluzione esatta $y(t) = e^{\lambda t}$ è decrescente e ha $\lim_{t\to+\infty} y(t) = 0$. Applicando il metodo di Eulero esplicito a questo problema, come abbiamo già visto, otteniamo $y_k = (1+h\lambda)^k$. Se $\lambda < -\frac{2}{h}$, abbiamo $1+h\lambda < -1$, quindi il metodo produce iterate $y_k$ che diventano sempre più grandi in valore assoluto, e magari oscillano con segni alterni. Il loro comportamento quindi è completamente diverso da quello della soluzione esatta, che converge a $0$ quando $t\to\infty$. Questo succede quando scegliamo un passo $h$ troppo grande, e la limitazione esatta dipende dal valore di $\lambda$: più grande è $\lambda$, più piccolo dev'essere $h$. 

% Notiamo però anche che se $\lambda$ è negativo e molto grande la funzione $y(t) = e^{\lambda t}$ tende a zero molto rapidamente. Potremmo quindi pensare che la ``scala'' di $h$ sia dettata dal grafico della funzione, in un qualche senso.

% Le cose però si complicano per problemi in più variabili, in cui possono comparire contemporaneamente valori diversi di $\lambda$; per esempio pensiamo al problema
% \[
% \underbrace{
% \begin{bmatrix}
%     u'(t)\\
%     v'(t)\\
%     w'(t)
% \end{bmatrix}}_{\y'(t)} = \begin{bmatrix}
%     \lambda_1 u(t)\\
%     \lambda_2 v(t)\\
%     \lambda_3 w(t)
% \end{bmatrix} = \begin{bmatrix}
%     \lambda_1 \\ 
%     & \lambda_2\\
%     && \lambda_3
% \end{bmatrix} \underbrace{\begin{bmatrix}
%     u(t)\\ v(t)\\ w(t)
% \end{bmatrix}}_{\y(t)},
% \]
% con $\lambda_1 < \lambda_2 < \lambda_3 < 0$: la norma $\norm{\y(t)}$ tende a zero come l'esponente più vicino a zero $e^{\lambda_3 t}$, ma il passo massimo che possiamo scegliere dipende dall'esponente più lontano da zero $\lambda_1$. Quindi per approssimare la soluzione senza oscillazioni catastrofiche siamo costretti a scegliere per un passo molto piccolo rispetto alla scala del problema.

Per problemi più complessi del problema test, diventa complicato fare un'analisi esatta come questa, ma possiamo comunque affermare qualcosa sul loro comportamento. Esistono problemi per cui il metodo di Eulero esplicito (e con lui molti altri metodi) produce successioni che hanno oscillazioni spurie e divergono, a meno che la scelta del passo sia molto piccola; questi si chiamano \emph{problemi stiff}, o in italiano \emph{rigidi}. Una definizione precisa è complicata; in generale questo fenomeno è associato a:
\begin{itemize}
    \item componenti della soluzione $\y$ che hanno improvvisi cambiamenti (come la funzione del nostro esempio in Figura~\ref{fig: esempio Eulero esplicito problema stiff}, che ha una prima parte con una discesa molto ripida e poi una con pendenza minore);
    \item fenomeni fisici che avvengono a diverse scale di tempi;
    \item funzioni del tipo $\mathbf{f}(t,\y)=A\y$ (lineari nella $\y$) con una matrice $A$ mal condizionata, 
    \item funzioni $\mathbf{f}(t,\y)$ che non sono lineari nella $\y$, ma la loro matrice Jacobiana $\frac{\partial \mathbf{f}}{\partial \mathbf{y}}$ (che ne dà un'approssimazione con una funzione lineare) è mal condizionata.
\end{itemize}
A differenza del mal condizionamento di sistemi lineari, la ``stiffness'' di un problema non è un fenomeno che riusciamo a quantificare esattamente e misurare con un numero.

La presenza di questi fenomeni dipende dal metodo scelto; in particolare i metodi impliciti sembrano esenti dal problema; possiamo vedere per esempio il metodo di Eulero implicito in Figura~\ref{fig: esempio Eulero implicito problema stiff}. Anche se l'approssimazione della soluzione non è perfetta, comunque non ci sono oscillazioni e divergenze che rendono completamente inaccurato il risultato ottenuto con $n$ piccolo.

\begin{figure}
\begin{center}
\begin{tikzpicture}
        \begin{axis}[title={$n=80$}, width=\textwidth, height=0.25\textheight, ylabel={$y$}]
            \addplot+[mark=none, thick] table{
         x    y

            0   5.0000e-01
   1.2500e-02   4.6058e-01
   2.5000e-02   4.4737e-01
   3.7500e-02   4.4165e-01
   5.0000e-02   4.3807e-01
   6.2500e-02   4.3511e-01
   7.5000e-02   4.3235e-01
   8.7500e-02   4.2965e-01
   1.0000e-01   4.2698e-01
   1.1250e-01   4.2434e-01
   1.2500e-01   4.2171e-01
   1.3750e-01   4.1909e-01
   1.5000e-01   4.1650e-01
   1.6250e-01   4.1392e-01
   1.7500e-01   4.1135e-01
   1.8750e-01   4.0880e-01
   2.0000e-01   4.0627e-01
   2.1250e-01   4.0375e-01
   2.2500e-01   4.0125e-01
   2.3750e-01   3.9877e-01
   2.5000e-01   3.9630e-01
   2.6250e-01   3.9384e-01
   2.7500e-01   3.9140e-01
   2.8750e-01   3.8897e-01
   3.0000e-01   3.8656e-01
   3.1250e-01   3.8417e-01
   3.2500e-01   3.8179e-01
   3.3750e-01   3.7942e-01
   3.5000e-01   3.7707e-01
   3.6250e-01   3.7474e-01
   3.7500e-01   3.7242e-01
   3.8750e-01   3.7011e-01
   4.0000e-01   3.6781e-01
   4.1250e-01   3.6554e-01
   4.2500e-01   3.6327e-01
   4.3750e-01   3.6102e-01
   4.5000e-01   3.5878e-01
   4.6250e-01   3.5656e-01
   4.7500e-01   3.5435e-01
   4.8750e-01   3.5216e-01
   5.0000e-01   3.4997e-01
   5.1250e-01   3.4781e-01
   5.2500e-01   3.4565e-01
   5.3750e-01   3.4351e-01
   5.5000e-01   3.4138e-01
   5.6250e-01   3.3927e-01
   5.7500e-01   3.3716e-01
   5.8750e-01   3.3507e-01
   6.0000e-01   3.3300e-01
   6.1250e-01   3.3094e-01
   6.2500e-01   3.2889e-01
   6.3750e-01   3.2685e-01
   6.5000e-01   3.2482e-01
   6.6250e-01   3.2281e-01
   6.7500e-01   3.2081e-01
   6.8750e-01   3.1882e-01
   7.0000e-01   3.1685e-01
   7.1250e-01   3.1488e-01
   7.2500e-01   3.1293e-01
   7.3750e-01   3.1099e-01
   7.5000e-01   3.0907e-01
   7.6250e-01   3.0715e-01
   7.7500e-01   3.0525e-01
   7.8750e-01   3.0336e-01
   8.0000e-01   3.0148e-01
   8.1250e-01   2.9961e-01
   8.2500e-01   2.9775e-01
   8.3750e-01   2.9591e-01
   8.5000e-01   2.9408e-01
   8.6250e-01   2.9225e-01
   8.7500e-01   2.9044e-01
   8.8750e-01   2.8864e-01
   9.0000e-01   2.8686e-01
   9.1250e-01   2.8508e-01
   9.2500e-01   2.8331e-01
   9.3750e-01   2.8156e-01
   9.5000e-01   2.7981e-01
   9.6250e-01   2.7808e-01
   9.7500e-01   2.7636e-01
   9.8750e-01   2.7464e-01
   1.0000e+00   2.7294e-01
    };
    \end{axis}
    \end{tikzpicture}
\begin{tikzpicture}
        \begin{axis}[title={$n=20$}, width=\textwidth, height=0.25\textheight, ylabel={$y$}]
            \addplot+[mark=none, thick] table{
         x    y
            0   5.0000e-01
   5.0000e-02   4.4248e-01
   1.0000e-01   4.2760e-01
   1.5000e-01   4.1682e-01
   2.0000e-01   4.0665e-01
   2.5000e-01   3.9675e-01
   3.0000e-01   3.8710e-01
   3.5000e-01   3.7768e-01
   4.0000e-01   3.6849e-01
   4.5000e-01   3.5952e-01
   5.0000e-01   3.5077e-01
   5.5000e-01   3.4224e-01
   6.0000e-01   3.3391e-01
   6.5000e-01   3.2579e-01
   7.0000e-01   3.1786e-01
   7.5000e-01   3.1013e-01
   8.0000e-01   3.0258e-01
   8.5000e-01   2.9522e-01
   9.0000e-01   2.8804e-01
   9.5000e-01   2.8103e-01
   1.0000e+00   2.7419e-01
    };
    \end{axis}
    \end{tikzpicture}



\end{center}
\caption{Metodo di Eulero \emph{implicito} su $\mathbf{y}' = -\begin{bsmallmatrix}101 & 100\\ 100 & 100\end{bsmallmatrix}\mathbf{y}$, prima componente, con diversi valori di $n$.} \label{fig: esempio Eulero implicito problema stiff}
\end{figure}

Questo esperimento suggerisce che alcuni metodi sono più adatti ai problemi \emph{stiff} di altri; e tipicamente si tratta di metodi impliciti. Facciamo un'analisi più generale per studiare questo fenomeno.

\paragraph{Funzione di stabilità e A-stabilità} Possiamo replicare l'analisi fatta per il metodo di Eulero e applicarla a un metodo di Runge--Kutta generico. Scrivendo esplicitamente un qualunque metodo di Runge--Kutta per il problema test~\eqref{testproblem}, si può vedere che questo assume sempre la forma
\[
y_{k+1} = R(q)y_k, \quad q = h\lambda,
\]
per una certa funzione razionale $R(q)$. Per esempio, per il metodo dei trapezi abbiamo
\[
y_{k+1} = y_k + h \frac12(\lambda y_k + \lambda y_{k+1}) \iff y_{k+1} = \underbrace{\frac{1+\frac12 q}{1-\frac12q}}_{=:R(q)}y_k
\]

Ogni volta che $\lambda$ è un numero complesso con parte reale $\operatorname{Re}(\lambda) < 0$, abbiamo $\lim_{t\to\infty} y(t) = 0$. Ci chiediamo quindi quando la successione generata $y_k$ ha lo stesso comportamento al limite, $\lim_{k\to\infty} y_k = 0$. Sembra infatti ragionevole chiederci da un metodo numerico che esso rispetti il comportamento generale della funzione: quando $y(t)$ tende a zero, vogliamo che anche la successione delle approssimazioni $y_k$ lo faccia.

La successione $y_k = R(q)^k y_0$ converge a zero per $k\to\infty$ se e solo se $\abs{R(q)} < 1$. Si definisce quindi \emph{regione di (assoluta) stabilità} del metodo l'insieme $S_A = \{z \in \mathbb{C} : \abs{R(z)}<1\}$. Quindi la soluzione numerica del problema test (con un certo valore di $\lambda\in\mathbb{C}$) produce una successione $y_k$ che converge a zero se e solo se $h$ è scelto in modo che $h\lambda \in S_A$.

La soluzione esatta del problema test $y(t) = e^{\lambda t}$ invece converge a zero se (e solo se) $\lambda$ sta nel semipiano sinistro $\{z\in \mathbb{C} : \operatorname{Re}(z) < 0\}$. Questo motiva una definizione: un metodo di Runge--Kutta si dice \emph{A-stabile} se la sua regione di stabilità contiene tutto il semipiano sinistro. Esistono diverse varianti di questa definizione: per esempio un metodo si dice \emph{$A_0$-stabile} se la regione di stabilità contiene la semiretta reale negativa $\{z\in\mathbb{R}: z<0\}$; imparare tutti i loro nomi non è importante.

Per il metodo di Eulero esplicito, $R(q)= 1+q$; quindi per determinare la regione di stabilità bisogna trovare le soluzioni della disequazione $\abs{1+q}<1$. Attenzione: stiamo cercando le soluzioni \emph{complesse} qui: non possiamo risolvere il problema distinguendo due casi $1+q \leq 0$ e $1+q<0$ come siamo abituati a fare nel caso reale. Ci può aiutare un'interpretazione geometrica: dati due numeri complessi $z_1,z_2$, la quantità $\abs{z_1-z_2}$ è la loro distanza nel piano complesso. Quindi, in particolare, $\abs{1+q}$ è la distanza tra $q\in\mathbb{C}$ e il punto $-1$. Questo ragionamento mostra che la regione di stabilità del metodo di Eulero esplicito $\{q\in\mathbb{C} \colon \abs{1+q}<1\}$ è un cerchio di centro $-1$ e raggio $1$.

Essa \emph{non} contiene tutto il semipiano sinistro, e difatti già abbiamo visto che questo metodo non è $A$-stabile.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.3\textwidth}
        \centering
        \begin{tikzpicture}
            \draw[thick,->] (-2,0) -- (2,0);
            \draw[thick,->] (0,-2) -- (0,2);
            \draw[red, fill=red, opacity=0.5] (-0.5,0) circle (0.5);
        \end{tikzpicture}
        \caption{Eulero esplicito}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.3\textwidth}
        \centering
        \begin{tikzpicture}[even odd rule]
            \draw[thick,->] (-2,0) -- (2,0);
            \draw[thick,->] (0,-2) -- (0,2);
            \draw[red, fill=red, opacity=0.5] (-2,-2) rectangle (2,2) (0.5,0) circle (0.5);
        \end{tikzpicture}
        \caption{Eulero implicito}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.3\textwidth}
        \centering
        \begin{tikzpicture}
            \draw[thick,->] (-2,0) -- (2,0);
            \draw[thick,->] (0,-2) -- (0,2);
            \draw[red, fill=red, opacity=0.5] (-2,-2) rectangle (0,2);
        \end{tikzpicture}
        \caption{trapezi}
    \end{subfigure}
    \caption{Regioni di stabilità (in rosa) di tre metodi a un passo.}
\end{figure}

La regione di stabilità del metodo dei trapezi è esattamente il semipiano sinistro; possiamo dimostrarlo con un ragionamento geometrico. Si ha
\[
\abs{R(q)} = \frac{\abs{1+\frac12q}}{\abs{1-\frac12q}} = \frac{d(-1,\frac12q)}{d(1,\frac12q)},
\]
e questo è il rapporto tra le distanze del punto $\frac12q$ da $1$ e da $-1$. Se $q$ sta nel semipiano sinistro, allora è più vicino a $-1$ che a $1$, e quindi il rapporto è minore di $1$.

Potete calcolare come esercizio la regione di stabilità del metodo di Eulero implicito, e verificare che essa è l'\emph{esterno} di un cerchio di centro $1$ e raggio $1$; in particolare anche questo metodo è A-stabile. Anzi, è anche ``troppo stabile'', visto che la sequenza $y_k$ converge a zero anche in casi in cui $\lambda$ sta nel semipiano destro e quindi $y(t) = e^
{\lambda t}$ dovrebbe tendere a infinito per $t\to+\infty$. La definizione che abbiamo dato non cattura questo problema però.

\paragraph{A-Stabilità e metodi impliciti} Vale questo risultato (che non dimostriamo).
\begin{theorem}
Nessun metodo di Runge--Kutta esplicito è $A$-stabile.
\end{theorem}
Quindi in presenza di un problema stiff è solitamente meglio usare un metodo implicito; altrimenti il metodo potrebbe richiedere un passo $h$ molto piccolo per fornire risultati non oscillanti. Questo giustifica l'utilità dei metodi impliciti, che utilizzano un metodo più complicato per calcolare $\y_{k+1}$ ad ogni passo rispetto a quelli espliciti: sono gli unici che possono fornire garanzie di A-stabilità, quindi assenza di oscillazioni catastrofiche indipententemente dal problema.

\section{Metodi a più passi}

Vediamo ora un'altra famiglia di metodi, i \emph{metodi a più passi} (o \emph{multistep} in inglese). In particolare ci concentriamo sui \emph{metodi lineari a più passi}.

L'idea è la seguente: i metodi di Runge--Kutta ci consentono di ottenere metodi con alto ordine di convergenza, ma al costo di avere $s>1$ valutazioni della $\mathbf{f}$ all'interno di ogni passo $k$. Possiamo però ottenere ordini più alti a costo computazionale minore con un'altra strategia: quella di riutilizzare anche i valori precedenti già calcolati di $\y_{k-1}, \y_{k-2}, \dots$ e $\f_{k-1},\f_{k-2},\dots$ per ottenere una migliore approssimazione. Per esempio, vedremo che il metodo
\begin{equation} \label{ab2}
    \y_{k+2} = \y_{k+1} + h\left(\frac32 \f_{k+1} - \frac12 \f_k\right)    
\end{equation}
ha ordine $p=2$. Se supponiamo di avere a disposizione \emph{due} valori iniziali $\y_0, \y_1$, anziché uno solo, possiamo usare la~\eqref{ab2} per $k=0,1,2,\dots$ per calcolare tutti i valori successivi con un errore locale di troncamento migliore del metodo di Eulero (ordine 2 anziché 1), mantenendone comunque il costo di una sola nuova valutazione della $\f$ per passo.

In generale, definiamo un \emph{metodo lineare a $s$ passi} con una formula del tipo
\begin{equation} \label{linearmultistep}
    \sum_{j=0}^s \alpha_j \y_{k+j} = h\sum_{j=0}^s \beta_j \f_{k+j}, \quad k=0,1,2,\dots,    
\end{equation}
dove abbiamo posto $\f_i := \f(t_i, \y_i)$ come già fatto in passato, per un'opportuna scelta delle costanti reali $\alpha_i, \beta_i$. Per evitare casi degeneri, supponiamo che $\alpha_0,\beta_0$ non siano entrambi nulli, così come $\alpha_s$ e $\beta_s$. Se $\beta_s=0$, allora possiamo calcolare esplicitamente $\y_{k+s}$, e il metodo si dice \emph{esplicito}; altrimenti il metodo si dice \emph{implicito} e abbiamo bisogno di un algoritmo per risolvere l'equazione~\eqref{linearmultistep} ad ogni passo $k$.

\paragraph{Scelta dei valori iniziali} Per poter applicare il metodo~\eqref{linearmultistep}, abbiamo bisogno di opportuni valori iniziali $\y_1,\y_2,\dots, \y_{s-1}$, in aggiunta a $\y_0$. Questi non sono tra i dati iniziali del problema, quindi vanno calcolati in qualche modo. Solitamente si utilizza un metodo a un passo per calcolarli; quindi ogni metodo a più passi ha bisogno di essere ``inizializzato'' calcolando questi primi valori tramite un opportuno metodo a un passo.

Diciamo che un modo di scegliere questi valori iniziali è un'inizializzazione consistente di ordine $p$ se
\[
\y_k = \y(t_k) + \mathcal{O}(h^p), \quad k=1,2,\dots,s-1.
\]
Il modo più facile di inizializzare un metodo a più passi è di usare $s-1$ iterazioni di un metodo a un passo. Ma attenzione: questo metodo dev'essere di ordine $p$.

Quindi la struttura generale di un metodo a più passi è la seguente:
\begin{center}
\begin{tabular}{rl}
    $\begin{array}{r}\y_0\end{array}$ & dato\\
    \hline
    $
    \begin{array}{r}
        \y_1\\
        \y_2\\
        \vdots\\
        \y_{s-1}
    \end{array}
    $ & calcolati con un altro metodo di \emph{inizializzazione}\\
    \hline
    $
    \begin{array}{r}
        \y_{s+1}\\
        \y_{s+2}\\
        \vdots\\
        \y_{n}
    \end{array}
    $ & calcolati risolvendo $\sum_{j=0}^s \alpha_j \y_{k+j} = h\sum_{j=0}^s \beta_j \f_{k+j}$ \\
\end{tabular}
\end{center}
Il costo computazionale per ogni passo (a parte i pochi passi iniziali) è quello di risolvere $\sum_{j=0}^s \alpha_j \y_{k+j} = h\sum_{j=0}^s \beta_j \f_{k+j}$: quindi per un metodo esplicito dobbiamo valutare la funzione $\f$ una volta in un punto nuovo $\f_{k+s}$(tutti gli altri valori $\f_{k},\dots,\f_{k+s-1}$ sono già stati calcolati nei passi precedenti!); invece per un metodo implicito dobbiamo risolvere un'equazione che coinvolge il valore della $\f$ in un punto nuovo.

\paragraph{Famiglie di metodi} Ci sono diverse famiglie di metodi lineari a più passi: tra queste i \emph{metodi di Adams--Bashforth} (tra cui ricade anche il nostro primo esempio~\eqref{ab2}), espliciti, e i \emph{metodi di Adams--Moulton} e le \emph{Backward differentiation formulas (BDF)}, entrambi impliciti. Per esempio, i primi metodi della famiglia BDF sono
\begin{align*}
\y_{k+1} - \y_k &= h\f_{k+1}, & \text{(Eulero implicito)}\\
\y_{k+2} - \frac43 \y_{k+1} + \frac13 \y_k &= \frac23 h\f_{k+2},\\
\y_{k+3} - \frac{18}{11}\y_{k+2} + \frac{9}{11}\y_{k+1} - \frac{2}{11}\y_k &= \frac{6}{11}h \f_{k+3},
\end{align*}
e i successivi sono fatti in modo simile, con un solo valore $\beta_s\neq 0$ a destra dell'uguale e opportune combinazioni lineari delle $\y_{k+j}$ a sinistra.

In tutti questi metodi, i valori numerici dei coefficienti sono stati scelti in modo da assicurare l'ordine di convergenza $p$ il più alto possibile.

Per altri metodi, potete vedere per esempio \url{https://en.wikipedia.org/wiki/Linear_multistep_method} e \url{https://en.wikipedia.org/wiki/Backward_differentiation_formula}.

\paragraph{Consistenza e convergenza}

Come nei metodi a un passo, definiamo l'\emph{errore locale di troncamento}
\[
\boldsymbol{\tau}_k = \sum_{j=0}^s \alpha_j \y(t_{k+j}) - h\sum_{j=0}^s \beta_j \f(t_{k+j}, \y(t_{k+j})),
\]
cioè, la quantità che otteniamo come ``resto'' se al posto di $\y_k,\dots,\y_{k+s}$ sostituiamo i valori esatti della funzione soluzione $\y(t_k), \dots, \y(t_{k+s})$.

Questa quantità a volte viene normalizzata diversamente dividendola per $\alpha_s$, o per la somma dei $\beta_j$. in ogni caso, $\boldsymbol{\tau}_k$ misura di quanto $\y(t_{k+s})$ differisce dalla quantità $\y_{k+s}$ calcolata dal metodo assumendo che tutti i passi precedenti siano esatti. Come nel caso dei metodi a un passo, un metodo si dice \emph{consistente di ordine $p$} se $T = \max_{k} \norm{\boldsymbol{\tau}_k}$ è $\mathcal{O}(h^{p+1})$.

Analogamente, un metodo si dice \emph{convergente di ordine $p$} se l'errore globale~\eqref{globalerror} (definito esattamente come nei metodi a un passo) è $\mathcal{O}(h^p)$.

Possiamo dimostrare che (sotto opportune ipotesi) questi due concetti sono equivalenti, proprio come nei metodi a un passo.

\paragraph{Teorema di equivalenza di Dahlquist} Vale il seguente risultato, nella cui formulazione compare una condizione che non abbiamo ancora enunciato, quella di \emph{zero-stabilità}; vedremo più avanti cosa vuol dire. Per ora, ci accontentiamo di dire che i metodi a più passi che abbiamo visto finora, così come tutti quelli che vengono usati in pratica, sono zero-stabili.
\begin{theorem}
Consideriamo un metodo lineare a più passi~\eqref{linearmultistep}. Supponiamo che il metodo sia zero-stabile, e che la soluzione $\y(t)$ sia una funzione di classe $\mathcal{C}^{p+1}$. Allora, un metodo consistente di ordine $p$, con inizializzazione anch'essa consistente di ordine $p$, è convergente di ordine $p$.
\end{theorem}
La dimostrazione di questo risultato è complicata, quindi ci accontentiamo dell'enunciato. 

\paragraph{A-stabilità}

Come nel caso dei metodi a un passo, la sola convergenza non esclude che per valori piccoli e finiti di $h$ ci possa essere una divergenza catastrofica. Possiamo studiare la A-stabilità dei metodi a più passi, esattamente nello stesso modo in cui abbiamo affrontato quelli a un passo; questo ci darà informazioni su quali metodi sono adatti per problemi stiff.

Applicando il metodo~\eqref{linearmultistep} al problema test~\eqref{testproblem}, otteniamo
\begin{equation} \label{multistep-test}
    \sum_{j=0}^s (\alpha_j - \underbrace{\lambda h}_{:=q} \beta_j) \y_{k+j} = 0.    
\end{equation}
Analogamente a quanto richiesto per i metodi a un passo, $\lambda$ e $h$ compaiono in questa formula solo tramite il loro prodotto $q=h\lambda$. Una volta fissato un valore di $q$, la~\eqref{multistep-test} ci dà una relazione tra i valori di $\y_k, \y_{k+1},\dots,\y_{k+s}$, da cui possiamo ricavare $\y_{k+s}$ noti tutti i valori precedenti. I valori generati dal metodo quindi sono determinati univocamente a patto di conoscere $\y_0,\y_1,\dots,\y_{s-1}$.

La \emph{regione di stabilità} di un metodo lineare a più passi è definita come l'insieme dei valori $q\in\mathbb{C}$ per cui tutte le successioni generate dalla~\eqref{multistep-test} convergono a zero, \emph{per ogni scelta} dei valori iniziali $\y_0,\y_1,\dots,\y_{s-1}$. Questa volta è più complicato ricavare dalla~\eqref{multistep-test} una formula esplicita per gli $\y_k$; non si tratta semplicemente delle potenze di una funzione $R(q)$. Vedremo nella prossima sezione come farlo.

Analogamente al caso dei metodi a un passo, un metodo si dice \emph{A-stabile} se la sua regione di stabilità contiene tutto il semipiano sinistro, in modo che le approssimazioni generate dal metodo abbiano lo stesso comportamento qualitativo della soluzione esatta del problema test $y(t) = e^{\lambda t}$, che converge a zero quando $\operatorname{Re}(\lambda) < 0$. Vedremo più avanti un modo più esplicito di determinare queste regioni di stabilità.

\paragraph{Barriere di Dahlquist} Anche in questo caso la A-stabilità è una condizione molto stringente, che in particolare esclude tutti i metodi espliciti. Questo è dimostrato in un teorema che contiene una serie di risultati noti come ``barriere di Dahlquist''.
\begin{theorem} Valgono i seguenti risultati.
\begin{itemize}
    \item Non esistono metodi lineari a più passi \emph{espliciti} A-stabili.
    \item I metodi lineari a più passi \emph{impliciti} A-stabili hanno ordine $p \leq 2$.
    \item Tra i metodi lineari a più passi A-stabili impliciti di ordine $p=2$, quello per cui l'errore converge a zero più velocemente è il metodo dei trapezi.
\end{itemize}
\end{theorem}
Quindi nessun metodo lineare a più passi A-stabile migliora in termini di accuratezza il metodo dei trapezi (che in realtà è a un passo, $s=1$). Una famiglia di metodi (quelli BDF) in realtà si avvicina molto ad essere A-stabile, visto che le loro regioni di stabilità includono tutto il semipiano negativo tranne una regione molto piccola\footnote{Queste regioni di stabilità sono raffigurate per esempio su~\url{https://en.wikipedia.org/wiki/Backward_differentiation_formula}}. Questi metodi sono tra quelli più usati per problemi stiff.

\section{Equazioni alle differenze e applicazioni ai metodi a più passi (*)}

In questa sezione, vogliamo studiare la teoria delle \emph{equazioni alle differenze}, un analogo di quella delle equazioni differenziali lineari che avete già visto nei corsi di analisi. Questa teoria ci permetterà di essere più precisi sulle condizioni di stabilità dei metodi lineari a più passi.

Consideriamo innanzitutto cosa succede applicando un metodo a più passi al problema (scalare, $m=1$) $y'=0$, con condizioni iniziali $y_0,y_1,\dots,y_{s-1}$ qualunque. La successione delle $y_i$ allora soddisfa la relazione
\begin{equation} \label{ricorrenza}
    \alpha_0 y_k + \alpha_1 y_{k+1} + \dots + \alpha_s y_{k+s} = 0, \quad k = 0,1,2,\dots.
\end{equation}
Relazioni della forma~\eqref{ricorrenza} si chiamano \emph{equazioni alle differenze (lineari a coefficienti costanti)}; sono una sorta di analogo discreto delle equazioni differenziali lineari a coefficienti costanti. Forse l'esempio più celebre di una successione di questo tipo è quello dei numeri di Fibonacci, che soddisfano la relazione
\[
y_k + y_{k+1} - y_{k+2} = 0.
\]
Esiste una teoria per calcolare le soluzioni delle~\eqref{ricorrenza} che è molto simile a quella per calcolare le soluzioni delle equazioni differenziali lineari a coefficienti costanti. Enunciamo cosa succede, per semplicità limitandoci al caso scalare $(m=1)$.

\begin{theorem}
Data l'equazione alle differenze~\eqref{ricorrenza}, definiamo
\[
p_1(z) = \alpha_0 + \alpha_1 z + \dots + \alpha_s z^s
\]
il suo polinomio associato (di grado $s$). 
\begin{itemize}
    \item Se $p_1(z)$ ha $s$ zeri distinti nel piano complesso $\lambda_1, \lambda_2,\dots, \lambda_s$, allora ogni soluzione della~\eqref{ricorrenza} si scrive come combinazione lineare delle soluzioni di base $\lambda_1^k, \lambda_2^k, \dots, \lambda_s^k$.
    \item Per ogni zero $\lambda$ di $p_1(z)$ ripetuto con molteplicità $m>1$, come soluzioni di base invece di prendere $m$ copie di $\lambda$ dobbiamo prendere $\lambda^n, n\lambda^n, n^2\lambda^n,\dots, n^{m-1}\lambda^n$.
\end{itemize}
\end{theorem}

\paragraph{Esempi}
\begin{itemize}
    \item Quali sono le successioni tali che $y_{k+1} = \frac{1}{2}y_k$? Questa formula si può riscrivere come $y_{k+1}-\frac{1}{2}y_k=0$, e ha polinomio caratteristico $z-\frac{1}{2}$, con un solo zero $\lambda=\frac{1}{2}$. le sue soluzioni sono del tipo $y_k = C \frac{1}{2}^k$. Se ci viene dato un valore iniziale, per esempio $y_0=1$, possiamo determinare il valore corrispondente di $C$ (in questo caso $C=1$), esattamente come avete visto nel corso di analisi per le equazioni differenziali lineari a coefficienti costanti.
    \item Quali sono le successioni tali che $y_{k+2} - y_{k+1} = y_{k+1}-y_k$ per ogni $k$? La successione ha come polinomio caratteristico $z^2-2z+1$, che ha uno zero doppio $\lambda=1$. Le soluzioni sono le successioni del tipo $y_k = C_1 1^k + C_2 k 1^k = C_1 + C_2 k$, cioè tutte le funzioni lineari affini.
    \item Quali sono le successioni tali che $y_{k+2} = y_k + y_{k+1}$? Sono tutte le successioni del tipo
    \[
        y_k = C_1 \left(\frac{1+\sqrt{5}}{2}\right)^k + C_2 \left(\frac{1-\sqrt{5}}{2}\right)^k.
    \]
    Una di esse è la famosa \emph{sequenza di Fibonacci}, che è ottenuta prendendo come valori iniziali $y_0 = 0$, $y_1=1$.
\end{itemize}
In particolare, vale il seguente risultato.
\begin{theorem} \label{thm:eq-differenze} Per un'equazione alle differenze~\eqref{ricorrenza}:
\begin{itemize}
    \item Se (e solo se) tutti gli zeri del polinomio $p_1(z)$ hanno valore assoluto strettamente minore di $1$, allora per ogni scelta dei valori iniziali $y_0, y_1,\dots, y_{s-1}$ la soluzione della~\eqref{ricorrenza} tende a zero quando $k\to\infty$.
    \item Se (e solo se) tutti gli zeri del polinomio $p_1(z)$ hanno valore assoluto minore o uguale a $1$, e in più tutte le radici di modulo $1$ sono semplici (molteplicità $=1$), allora per ogni scelta dei valori iniziali $y_0, y_1,\dots, y_{s-1}$ la soluzione della~\eqref{ricorrenza} è limitata, cioè $\sup_{k\in\mathbb{N}} \abs{y_k}$ è finito.
\end{itemize}
\end{theorem}
La seconda di queste condizioni si chiama \emph{condizione delle radici} (in inglese \emph{root condition}).

\paragraph{Zero-stabilità}
Quando gli $\alpha_i$ sono i coefficienti di un metodo a più passi~\eqref{linearmultistep}, il polinomio caratteristico $p_1(z)$ definito sopra si chiama \emph{primo polinomio caratteristico} del metodo.

Un metodo lineare a più passi si dice \emph{zero-stabile} se il suo primo polinomio caratteristico $p_1(z)$ soddisfa la condizione delle radici; questo in particolare implica che le successioni che genera per la soluzione del problema $y'=0$ sono sempre limitate (uniformemente in $k$), indipendentemente dalla scelta dei valori iniziali. Questo è quello che ci aspettiamo se il metodo deve ``funzionare bene'' su questa equazione, visto che tutte le soluzioni di $y'=0$ sono costanti (e quindi limitate).

\paragraph{Esempio} Consideriamo il metodo~\eqref{ab2}. Il primo polinomio caratteristico è $z^2-z$; difatti, $\alpha_2=1, \alpha_1=-1, \alpha_0 = 0$. Questo polinomio ha zeri $\lambda=1$ e $\lambda=0$. In particolare, esso soddisfa la condizione delle radici, quindi il metodo è zero-stabile.

Notiamo che $\alpha = 1$ è sempre una radice del primo polinomio caratteristico, per ogni metodo consistente: altrimenti è impossibile che si abbia $\boldsymbol{\tau}_k \to \mathbf{0}$, già solo considerando il problema $y'=0$.

La zero-stabilità sembra un concetto di poco rilievo, visto che ci concentriamo su un problema molto facile e di poco interesse; in realtà ha una conseguenza importante, perché ci assicura che piccole perturbazioni nei dati iniziali $\y_1,\dots,\y_{s-1}$ non causano errori molto più grandi sugli elementi successivi della successione. Questo è il motivo per cui compare tra le ipotesi del teorema di equivalenza di Dahlquist enunciato sopra.

\paragraph{Condizioni di A-stabilità}
Fissato il valore di $q$, la~\eqref{multistep-test} è un'equazione alle differenze. Quindi, per il Teorema~\ref{thm:eq-differenze}, la successione generata converge a zero (per ogni scelta dei valori iniziali) quando tutte le radici del polinomio associato
\[
\pi_q(z) = \sum_{j=0}^s (\alpha_j - q\beta_j) z^j
\]
hanno modulo \emph{strettamente} minore di $1$. Il polinomio $\pi_q(z)$ dipende dal valore di $q$, che supponiamo fissato; esso si chiama \emph{polinomio di stabilità}; possiamo scriverlo come
\[
\pi_q(z) = p_1(z) - q p_2(z)
\]
in termini del primo polinomio caratteristico (che già abbiamo incontrato) e del \emph{secondo polinomio caratteristico}
\[
p_2(z) = \beta_0 + \beta_1 z + \dots + \beta_s z^s.
\]
Come conseguenza del Teorema~\ref{thm:eq-differenze}, possiamo quindi scrivere in una forma più esplicita la regione di assoluta stabilità di un metodo a più passi:
\[
  S_A = \{q \in \mathbb{C} \colon \text{tutte le radici del polinomio $\pi_q(z)$ hanno modulo minore di $1$}\}.
\]

\paragraph{Esempio} Consideriamo di nuovo il problema~\eqref{ab2}. Il suo polinomio di stabilità è 
\[
    \pi_q(z) = (z^2 -z) - q\left(\frac{3}{2}z - \frac{1}{2}\right) = z^2 - \left(1+\frac32 q\right) z + \frac12 q.
\]
Possiamo calcolare le sue soluzioni (in funzione di $q$), ma la formula ottenuta non è particolarmente illuminante. È più interessante vedere cosa succede per qualche valore di $q$ fissato. Per $q=-1$, il polinomio diventa $\pi_{-1}(z) = z^2 - \frac12 q - \frac12$, che ha zeri $\lambda=-1$ e $\lambda=1/2$. Queste soluzioni \emph{non} sono entrambe minori di $1$, quindi $q=-1$ non appartiene alla regione di stabilità del metodo. (In particolare, questo ci dice anche che il metodo \emph{non} è A-stabile).



\section{Solutori di equazioni differenziali in Matlab}

Nel laboratorio abbiamo implementato noi da soli alcuni metodi numerici, ma Matlab contiene già al suo interno diverse funzioni che possono essere usate per risolvere numericamente problemi ai valori iniziali~\eqref{cauchy}. La più usata è \lstinline{function [T, Y] = } \lstinline{ode45(f, [a,b], y0)}. Essa prende in input una \emph{function handle} alla funzione $\f(t,\y)$ (che dev'essere \emph{sempre} una funzione di due variabili), un vettore di due elementi \lstinline{[a,b]} (attenzione: qui la sintassi è diversa rispetto alle funzioni che abbiamo scritto in laboratorio), e un valore iniziale \lstinline{y0} (scalare o vettore). Essa restituisce un vettore colonna $T$ e una matrice $Y$ che contiene le iterate $\y_k$ prodotte dal metodo come \emph{righe}; quindi essi sono i trasposti dei valori di output prodotti dalle funzioni che abbiamo scritto noi nel laboratorio.

La funzione \lstinline{ode45} utilizza un metodo di Runge--Kutta esplicito di ordine $p=5$, ma contiene uno stimatore dell'errore e lo usa per modificare la lunghezza del passo $h$, adattandola in modo da non fare mai passi più corti o più lunghi del necessario per ottenere una soluzione accurata (metodo di Dormand--Prince o RK45). Pertanto il vettore \lstinline{T} restituito non contiene una sequenza di punti equispaziati, ma una sequenza di punti opportunamente scelti. Tipicamente sono necessari più punti negli intervalli in cui la $\y(t)$ varia più velocemente. Le $\y_k$ restituite corrispondono alla funzione valutata su questa sequenza di punti, cioè $\y_k \approx \y(t_k)$.

È possibile usare il comando \lstinline{odeset} per specificare alcune opzioni, per esempio la tolleranza richiesta sulla soluzione. Si usa in questo modo:
\begin{lstlisting}
>> opzioni = odeset('AbsTol', 1e-6, 'RelTol', 1e-3);
\end{lstlisting}
specifica una tolleranza assoluta sulla soluzione calcolata di $10^{-6}$ (cioè, vogliamo che $\norm{\y_k - \y(t_k)}_\infty \leq 10^{-6}$) e una relativa di $10^{-3}$ (cioè, $\frac{\norm{\y_k - \y(t_k)}}{\norm{\y(t_k)}} \leq 10^{-3}$).

Le opzioni impostate vengono salvate in una variabile \lstinline{opzioni} che possiamo poi passare al solutore come ultimo argomento:
\begin{lstlisting}
>> ode45(f, [a,b], y0, opzioni);
\end{lstlisting}
Guardando la documentazione di \lstinline{odeset} (con il comando \lstinline{>> doc odeset} da dentro Matlab) trovate altre opzioni.

Indipendentemente da questi miglioramenti, \lstinline{ode45} usa un metodo esplicito, quindi ha sempre il problema di richiedere passi $h$ molto corti (e quindi un alto numero di iterazioni e costo computazionale) per risolvere adeguatamente problemi stiff.

Matlab contiene anche funzioni per risolvere equazioni differenziali che utilizzano metodi impliciti; la più comune è la funzione \lstinline{ode15s}. Essa accetta e ritorna gli stessi argomenti di \lstinline{ode45}, ma utilizza un metodo implicito e quindi è adatta anche a problemi stiff (come indica la \lstinline{s} nel nome della funzione). Utilizza diversi metodi impliciti a più passi, di ordine variabile da 1 a 5, cambiando il metodo e la lunghezza del passo a seconda dell'accuratezza richiesta. I metodi usati sono una variante dei metodi BDF che già abbiamo citato. Notare che cambiare la lunghezza del passo è più complicato per metodi a più passi, visto che non è più possibile riutilizzare direttamente i valori di $\f(t_{k+j},\y_{k+j})$ calcolati nei passi precedenti.

\begin{lstlisting}
>> A = [-10 -10; -10 -11];
>> f = @(t, y) A*y;
>> ode15s(f, [0,1], [1,0])
\end{lstlisting}

Nel caso dei metodi impliciti, un'opzione aggiuntiva particolarmente utile per migliorare le performance dei metodi è fornire a Matlab la matrice Jacobiana $\frac{\partial \f}{\partial \y}$. Difatti \lstinline{ode15s} (e varianti) utilizzano un metodo tipo-Newton per calcolare $\y_{k+s}$ dall'equazione implicita che lo definisce; e se lo ricordate questi metodi necessitano al loro interno della derivata della funzione che definisce l'equazione da risolvere. Lo Jacobiano può essere inserito tramite un'altra coppia di parametri \lstinline{'Jacobian', J} passati ad \lstinline{odeset}; qui \lstinline{J} può essere una matrice costante oppure una function handle \lstinline{J(t, y)}.

\begin{lstlisting}
>> ode15s(f, [0,1], [1,0], odeset('Jacobian', A));
\end{lstlisting}

In questo caso il problema è comunque semplice, quindi le performance dei due metodi non cambiano di molto.

Esistono anche altre funzioni, per esempio \lstinline{ode23} che utilizza un metodo di Runge--Kutta di ordine inferiore, o \lstinline{ode23s} che (come indica la \lstinline{s}) è un altro metodo adatto per problemi stiff.

\section{Esempio: problema di Robertson}

Un esempio classico di problema stiff deriva dalla modellizzazione del sistema di reazioni chimiche
\[
\begin{cases}
    A \stackrel{k_1}{\to} B\\
    B + B \stackrel{k_2}{\to} B+C\\
    B + C \stackrel{k_3}{\to} A + C.
\end{cases}
\]
Qualitativamente, la prima e la terza reazione convertono la specie $A$ nella specie $B$ e viceversa, mentre la seconda reazione ``rimuove'' la specie $B$ dal sistema trasformandola irreversibilmente nella specie $C$. Quindi sul lungo periodo ci aspettiamo che le specie $A$ e $B$ vengano convertite interamente in $C$. Inoltre, la quantità totale $[A] + [B] + [C]$ (massa) è conservata.

Il sistema di equazioni differenziali che fornisce la quantità delle tre specie presente rispetto al tempo è
\[
\frac{d}{dt}
\begin{bmatrix}
    y^{(1)}\\
    y^{(2)}\\
    y^{(3)}
\end{bmatrix}
=
\begin{bmatrix}
    -k_1y^{(1)} + k_3 y^{(2)} y^{(3)}\\
    k_1 y^{(1)} - k_2 (y^{(2)})^2 - k_3 y^{(2)} y^{(3)}\\
    k_2 (y^{(2)})^2
\end{bmatrix}.
\]
Solitamente, si sceglie il valore iniziale $\y_0 = [1,0,0]^T$ e tre valori su scale molto diverse per le tre costanti cinetiche, $k_1=0.04, k_2=3\cdot 10^7, k_3 = 10^4$. Questa differenza di scale rende il problema fortemente stiff.

Osservazioni numeriche:

\begin{itemize}
    \item \lstinline{ode45} richiede un numero estremamente alto di passi intermedi: anche su $[a,b]=[0,100]$ sono necessari più di 400.000 punti intermedi. Tentare periodi più lunghi è senza speranza.
    \item \lstinline{ode15s} risolve il problema con molti meno passi.
    \item È necessaria una simulazione su un intervallo di tempo molto lungo prima di confermare le proprietà viste teoricamente che tutta la massa viene convertita da $A$ a $C$; si ha $\y(10^6) \approx [0.002, 0, 0.998]$.
    \item Si apprezza molto meglio il comportamento disegnando il grafico in scala semilogaritmica (\lstinline{semilogx(t, y, '-x')}).
    \item La seconda componente (quantità di $B$) resta sempre molto bassa e va plottata a parte perché si veda qualcosa (\lstinline{semilogx(t,y(:,2), '-x')}).
    \item Ci sono poche speranze con metodi ``semplici'' come Eulero esplicito o implicito.
    \item Possiamo anche calcolare lo Jacobiano del sistema e fornirlo come argomento a \lstinline{ode15s}.
\end{itemize}

\end{conditional}

\end{document}